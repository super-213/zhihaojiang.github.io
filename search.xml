<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>广州旅游</title>
    <url>/zhihaojiang.github.io/2024/07/31/20240731%E5%B9%BF%E5%B7%9E%E6%97%85%E6%B8%B8/</url>
    <content><![CDATA[<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/super-213/hexo-images/blob/main/articles/2024/07/31/2024-05811.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/07/31/2024-05829.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/07/31/2024-05837.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/07/31/2024-05840.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/07/31/2024-05883.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/07/31/2024-05884.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/07/31/2024-05904.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/07/31/001.jpg"
                      alt="photo"
                ></p>
]]></content>
      <categories>
        <category>旅游</category>
      </categories>
      <tags>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title>嘉兴大学演出</title>
    <url>/zhihaojiang.github.io/2024/10/17/20241017%E5%98%89%E5%85%B4%E5%A4%A7%E5%AD%A6%E6%BC%94%E5%87%BA/</url>
    <content><![CDATA[<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07355.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07363.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07436.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07465.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07470.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07494.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07495.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2024/10/17/2024-07496.jpg"
                      alt="photo"
                ></p>
]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL语句</title>
    <url>/zhihaojiang.github.io/2025/01/06/20250106MySQL%E8%AF%AD%E5%8F%A5/</url>
    <content><![CDATA[<p>本位与2025-01-06在CSDN上发布 现将其转移至自己的博客</p>
<h2 id="引擎相关"><a href="#引擎相关" class="headerlink" title="引擎相关"></a>引擎相关</h2><h3 id="查看存储引擎："><a href="#查看存储引擎：" class="headerlink" title="查看存储引擎："></a>查看存储引擎：</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">show engines;</span><br></pre></td></tr></table></figure></div>
<h3 id="查看显示支持的存储引擎信息："><a href="#查看显示支持的存储引擎信息：" class="headerlink" title="查看显示支持的存储引擎信息："></a>查看显示支持的存储引擎信息：</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">show variables like <span class="string">&#x27;have%&#x27;</span></span><br></pre></td></tr></table></figure></div>

<h3 id="查看默认的存储引擎："><a href="#查看默认的存储引擎：" class="headerlink" title="查看默认的存储引擎："></a>查看默认的存储引擎：</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">show variables like <span class="string">&#x27;storage_engine&#x27;</span></span><br></pre></td></tr></table></figure></div>

<h2 id="数据库相关操作-增-删-改"><a href="#数据库相关操作-增-删-改" class="headerlink" title="数据库相关操作(增 删 改)"></a>数据库相关操作(增 删 改)</h2><h3 id="创建数据库："><a href="#创建数据库：" class="headerlink" title="创建数据库："></a>创建数据库：</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">create datbase [<span class="keyword">if</span> not exists] db_name</span><br><span class="line">[[DEFAULT] CHARACTER SET charset_name]</span><br><span class="line">[[DEFALUT] COLLATE collation_name]</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>PS</p>

    </div>
    <div class="notel-content">
      <p>“[ ]”中的是可选项 可写可不写<br>将db_name替换成你想给数据库取的名字</p>

    </div>
  </div>

<h3 id="查看所有数据库"><a href="#查看所有数据库" class="headerlink" title="查看所有数据库"></a>查看所有数据库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">show databases;</span><br></pre></td></tr></table></figure></div>

<h3 id="查看数据库的详细信息"><a href="#查看数据库的详细信息" class="headerlink" title="查看数据库的详细信息"></a>查看数据库的详细信息</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">show create database db_name;</span><br></pre></td></tr></table></figure></div>

<h3 id="使用某个数据库"><a href="#使用某个数据库" class="headerlink" title="使用某个数据库"></a>使用某个数据库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">use db_name;</span><br></pre></td></tr></table></figure></div>

<h3 id="修改数据库编码"><a href="#修改数据库编码" class="headerlink" title="修改数据库编码"></a>修改数据库编码</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alter database [db_name]</span><br><span class="line">[DEFAULT CHARACTER SET charset_name]| [[DEFAULT]COLLATE collation_name]</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>PS</p>

    </div>
    <div class="notel-content">
      <p>例1：将schoolDB的编码方式有GBK修改为UTF8。</p>
<p>法1:ALTER DATABASE schoolDB CHARACTER SET UTF8;</p>
<p>法2:ALTER DATABASE schoolDB collate utf8_general_ci;</p>

    </div>
  </div>

<h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">drop database [<span class="keyword">if</span> exists] db_name;</span><br></pre></td></tr></table></figure></div>
<h2 id="表的相关操作（增删改查）"><a href="#表的相关操作（增删改查）" class="headerlink" title="表的相关操作（增删改查）"></a>表的相关操作（增删改查）</h2><h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">create table [<span class="keyword">if</span> exists] t_name(</span><br><span class="line">    name_1 int [primary key],</span><br><span class="line">    name_2 varchar(10)[...],</span><br><span class="line">    name_3 <span class="built_in">float</span>(5, 3)[...]</span><br><span class="line">)[engine = INNODB charset = UTF-8];</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>PS</p>

    </div>
    <div class="notel-content">
      <p>这里t_name是表名</p>
<p>name_1 name_2 name_3 是字段名</p>
<p>字段名后面[ ]中的是完整性约束(可选填)</p>
<p> 完整性约束条件：<br> PRIMARY KEY主键（唯一来标识的，每一个表都一个，自动非空）<br> AUTO_INCREMENT自增长<br> FOREIGN KEY外键<br> NOT NULL非空<br> UNIQUE KEY唯一<br> DEFAULT默认值<br>最下面的[ ] 中的是引擎和编码方式的选择</p>

    </div>
  </div>

<h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><h4 id="在name-3的（前面-后面）-增加新列name-4"><a href="#在name-3的（前面-后面）-增加新列name-4" class="headerlink" title="[在name_3的（前面|后面）] 增加新列name_4"></a>[在name_3的（前面|后面）] 增加新列name_4</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alter table t_name</span><br><span class="line">    add name_4 [first|after name_3];</span><br></pre></td></tr></table></figure></div>

<h4 id="修改列的数据类型"><a href="#修改列的数据类型" class="headerlink" title="修改列的数据类型"></a>修改列的数据类型</h4><p>将name_2的数据类型修改成float(4,3)</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alter table t_name</span><br><span class="line">    modify name_2 <span class="built_in">float</span>(4,3)</span><br></pre></td></tr></table></figure></div>

<h4 id="修改列名"><a href="#修改列名" class="headerlink" title="修改列名"></a>修改列名</h4><p>将表t_name中的name_1列的名字修改成new_name_1</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alter table t_name</span><br><span class="line">    change name_1 new_name_1;</span><br></pre></td></tr></table></figure></div>

<h4 id="修改表名"><a href="#修改表名" class="headerlink" title="修改表名"></a>修改表名</h4><p>将表t_name的名字修改成new_t_name</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alter table t_name</span><br><span class="line">    rename [to] new_t_name;</span><br></pre></td></tr></table></figure></div>

<h4 id="删除列"><a href="#删除列" class="headerlink" title="删除列"></a>删除列</h4><p>将表t_name中的name_1列删除</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alter table t_name</span><br><span class="line">drop column name_1；</span><br></pre></td></tr></table></figure></div>

<h4 id="删除行"><a href="#删除行" class="headerlink" title="删除行"></a>删除行</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">delete from t_name</span><br><span class="line"><span class="built_in">where</span> 条件表达式；</span><br></pre></td></tr></table></figure></div>

<h4 id="修改存储引擎"><a href="#修改存储引擎" class="headerlink" title="修改存储引擎"></a>修改存储引擎</h4><p>将表t_name的存储引擎修改成INNODB</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alter table t_name</span><br><span class="line">    engine = INNODB;</span><br></pre></td></tr></table></figure></div>

<h3 id="查看表"><a href="#查看表" class="headerlink" title="查看表"></a>查看表</h3><p>查看表名</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">show tables;</span><br></pre></td></tr></table></figure></div>

<p>查看表的结构</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#法1</span></span><br><span class="line">show create table t_name；</span><br><span class="line"> </span><br><span class="line"><span class="comment">#法2</span></span><br><span class="line">describe t_name;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#法3</span></span><br><span class="line">desc t_name;</span><br></pre></td></tr></table></figure></div>

<h3 id="复制表"><a href="#复制表" class="headerlink" title="复制表"></a>复制表</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">create table [<span class="keyword">if</span> not existe] t_name</span><br><span class="line">[like t_name_2]</span><br><span class="line">[as 表信息]</span><br><span class="line"> </span><br><span class="line"><span class="comment">#like可以复制表的结构 表中的信息不会被复制 复制出来的是个空表</span></span><br><span class="line"><span class="comment">#as 可以复制表中的信息 相当于CV大法</span></span><br></pre></td></tr></table></figure></div>

<h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><p>将表t_name删除</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">drop table t_name；</span><br></pre></td></tr></table></figure></div>

<h2 id="数据相关操作"><a href="#数据相关操作" class="headerlink" title="数据相关操作"></a>数据相关操作</h2><h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">insert [into]</span><br><span class="line">    t_name(name_1, name_2, name_3)</span><br><span class="line">    values(12,<span class="string">&#x27;hello&#x27;</span>, <span class="string">&#x27;2025-01-04&#x27;</span>);</span><br></pre></td></tr></table></figure></div>

<h3 id="查看插入信息"><a href="#查看插入信息" class="headerlink" title="查看插入信息"></a>查看插入信息</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * from t_name;</span><br></pre></td></tr></table></figure></div>

<h3 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">update t_name</span><br><span class="line"><span class="built_in">set</span> name_1 = x,</span><br><span class="line">    name_2 = y,</span><br><span class="line">    name_3 = z</span><br><span class="line">[<span class="built_in">where</span> 条件表达式];</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>PS</p>

    </div>
    <div class="notel-content">
      <p>若where不写<br>则更新全部记录</p>

    </div>
  </div>

<h3 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">delate from t_name</span><br><span class="line">[<span class="built_in">where</span> 条件表达式];</span><br></pre></td></tr></table></figure></div>

<p>完全清除某个表<br>完全清除表t_name：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">truncate</span> [table] t_name;</span><br></pre></td></tr></table></figure></div>

<h2 id="单表查询（重点）"><a href="#单表查询（重点）" class="headerlink" title="单表查询（重点）"></a>单表查询（重点）</h2><p>先给出语法：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> [distinct] name_1 [as new_name],</span><br><span class="line">       [distinct] name_2 [as new_name],</span><br><span class="line">from t_name</span><br><span class="line">[<span class="built_in">where</span> 条件表达式,]</span><br><span class="line">[group by name [ASC|DESC],]</span><br><span class="line">[order by name [ASC|DESC],]</span><br><span class="line">[<span class="built_in">limit</span> 条数]；</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>PS</p>

    </div>
    <div class="notel-content">
      <p>SELECT子句：<br>指定要查询的列名称，列与列之间用逗号隔开。<br>还可以为列指定新的别名，显示在输出的结果中。<br>ALL关键字表示显示所有的行，包括重复行，是系统默认的<br>DISTINCT表示显示的结果要消除重复的行。<br>FROM子句：指定要查询的表，可以指定两个以上的表，表与表之间用逗号隔开。<br>WHERE子句：指定要查询的条件。<br>如果有WHERE子句，就按照“条件表达式”指定的条件进行查询；<br>如果没有WHERE子句，就查询所有记录。</p>
<p>GROUP BY ：<br>子句用于对查询结构进行分组。<br>按照“列名1”指定的字段进行分组；<br>如果GROUP BY子句后带着HAVING关键字，那么只有满足“条件表达式2”中指定的条件的才能够输出。<br>GROUP BY子句通常和COUNT()、SUM()等聚合函数一起使用。</p>
<p>HAVING子句：<br>指定分组的条件，通常放Group by字句之后</p>
<p>ORDER BY子句：用于对查询结果的进行排序。<br>排序方式由ASC和DESC两个参数指出；<br>ASC参数表示按升序进行排序。默认情况下是ASC。<br>DESC参数表示按降序的顺序进行排序。升序表示值按从小到大的顺序排列。</p>
<p>LIMIT 子句：限制查询的输出结果的行数。</p>

    </div>
  </div>

<h2 id="多表查询"><a href="#多表查询" class="headerlink" title="多表查询"></a>多表查询</h2><h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><p>等值连接</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> x_name_1,</span><br><span class="line">       y_name_2</span><br><span class="line">from t_x </span><br><span class="line">inner <span class="built_in">join</span> t_y on t_x.id = t_y.id</span><br><span class="line"><span class="built_in">where</span>...;</span><br></pre></td></tr></table></figure></div>
<p>左连接、右连接和联合查询不过多赘述</p>
<h3 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h3><p>带in关键词的子查询</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> *</span><br><span class="line">from t_name_1</span><br><span class="line"><span class="built_in">where</span> name_1 <span class="keyword">in</span>(</span><br><span class="line">    <span class="keyword">select</span> name_2 from t_name_2</span><br><span class="line">);</span><br></pre></td></tr></table></figure></div>

<p>带比较运算符的子查询</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> *</span><br><span class="line">from t_name_1</span><br><span class="line"><span class="built_in">where</span> name = (</span><br><span class="line">    <span class="keyword">select</span> <span class="built_in">id</span></span><br><span class="line">    from t_name_2</span><br><span class="line">    <span class="built_in">where</span> <span class="built_in">id</span> = 2</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>引:<br>    面试题：select id,name,age from sd where name&#x3D;’张飞’<br>    怎么优化？最佳方案是什么？<br>    答：在name上创建索引：<br>    create index in name on sd(name);</p>
<h3 id="语法（已存在的表）："><a href="#语法（已存在的表）：" class="headerlink" title="语法（已存在的表）："></a>语法（已存在的表）：</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">create index in_id</span><br><span class="line">on t_name(<span class="built_in">id</span>);</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>PS</p>

    </div>
    <div class="notel-content">
      <p>in_id:索引名 （自己取）<br>t_name:表名<br>id:列名</p>

    </div>
  </div>

<h3 id="在创建表的时候创建索引"><a href="#在创建表的时候创建索引" class="headerlink" title="在创建表的时候创建索引"></a>在创建表的时候创建索引</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">create table t_name(</span><br><span class="line">...</span><br><span class="line">[unique|fulltext|spatial] index|key [in_id](name[长度])[ASC|DESC]</span><br><span class="line">);</span><br></pre></td></tr></table></figure></div>
<h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><h3 id="创建视图"><a href="#创建视图" class="headerlink" title="创建视图"></a>创建视图</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">create view view_name as</span><br><span class="line"><span class="comment">#查询语句:</span></span><br><span class="line"><span class="keyword">select</span>...</span><br><span class="line">[with [cascaded|<span class="built_in">local</span>] check option];</span><br></pre></td></tr></table></figure></div>

<h3 id="删除视图"><a href="#删除视图" class="headerlink" title="删除视图"></a>删除视图</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">drop view view_name;</span><br></pre></td></tr></table></figure></div>
<h2 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h2><h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">create user <span class="string">&#x27;用户名&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> identifiednby <span class="string">&#x27;密码&#x27;</span>;</span><br></pre></td></tr></table></figure></div>

<h3 id="查询用户"><a href="#查询用户" class="headerlink" title="查询用户"></a>查询用户</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * from mysql.user;</span><br></pre></td></tr></table></figure></div>

<h3 id="分配权限"><a href="#分配权限" class="headerlink" title="分配权限"></a>分配权限</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">grant 权限 on 库.表 to <span class="string">&#x27;用户名&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span>;</span><br></pre></td></tr></table></figure></div>
<h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><h3 id="触发器设置"><a href="#触发器设置" class="headerlink" title="触发器设置"></a>触发器设置</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#触发器设置</span></span><br><span class="line">CREATE TRIGGER before_position_update</span><br><span class="line">BEFORE UPDATE ON staff</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    IF OLD.position != NEW.position THEN</span><br><span class="line">        CASE NEW.position</span><br><span class="line">            WHEN <span class="string">&#x27;董事长&#x27;</span> THEN</span><br><span class="line">                SET NEW.role = 9;</span><br><span class="line">            WHEN <span class="string">&#x27;经理&#x27;</span> THEN</span><br><span class="line">                SET NEW.role = 6;</span><br><span class="line">            ELSE</span><br><span class="line">                SET NEW.role = 2;</span><br><span class="line">        END CASE;</span><br><span class="line">    END IF;</span><br><span class="line">END;</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>PS</p>

    </div>
    <div class="notel-content">
      <p>这里是当position设置为经理或董事长时 自动更改权限等级</p>

    </div>
  </div>

<h3 id="显示设置的触发器"><a href="#显示设置的触发器" class="headerlink" title="显示设置的触发器"></a>显示设置的触发器</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#显示设置的触发器</span></span><br><span class="line">SHOW TRIGGERS;</span><br></pre></td></tr></table></figure></div>

<h2 id="备份与恢复"><a href="#备份与恢复" class="headerlink" title="备份与恢复"></a>备份与恢复</h2><h3 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h3><p>备份数据库到文件。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">mysqldump -u username -p db_name &gt; backup.sql</span><br></pre></td></tr></table></figure></div>

<h3 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h3><p>从文件恢复数据库。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -u username -p db_name &lt; backup.sql</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>澳洲旅游</title>
    <url>/zhihaojiang.github.io/2025/01/25/20250125%E6%BE%B3%E6%B4%B2%E6%97%85%E6%B8%B8/</url>
    <content><![CDATA[<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09682.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09718.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09763.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09941.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09945.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09946.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09958.jpg"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/01/25/2025-09967.jpg"
                      alt="photo"
                ></p>
]]></content>
      <categories>
        <category>旅游</category>
      </categories>
      <tags>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习作业笔记</title>
    <url>/zhihaojiang.github.io/2025/03/28/20250328%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>我们需要利用回归分析预测世界大学综合得分</p>
<p>#Jupyter notebook代码<br>基本库导入</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line">from sklearn.metrics import mean_squared_error,r2_score</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.metrics import root_mean_squared_error</span><br><span class="line">from sklearn import linear_model</span><br><span class="line">from sklearn import metrics</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">university = pd.read_csv(<span class="string">&#x27;cwurData.csv&#x27;</span>)</span><br><span class="line">university.head()</span><br></pre></td></tr></table></figure></div>
<p>此时可能会出现报错</p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>报错信息</p>

    </div>
    <div class="notel-content">
      <p>File parsers.pyx:574, in pandas._libs.parsers.TextReader.<strong>cinit</strong>()</p>
<p>File parsers.pyx:663, in pandas._libs.parsers.TextReader._get_header()</p>
<p>File parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()</p>
<p>File parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()</p>
<p>File parsers.pyx:2053, in pandas._libs.parsers.raise_parser_error()</p>
<p>File <frozen codecs>:322, in decode(self, input, final)</p>
<p>UnicodeDecodeError: ‘utf-8’ codec can’t decode bytes in position 3864-3865: invalid continuation byte</p>

    </div>
  </div>
<p>不用担心，这是因为pd.read_csv()在不指明encoding时默认使用utf-8编码<br>这段报错是因为该文件不是使用utf-8进行编码。<br>我们可以写一段代码判断文件的编码格式</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import chardet</span><br><span class="line"></span><br><span class="line">with open(<span class="string">&#x27;cwurData.csv&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) as f:</span><br><span class="line">    university = f.read()</span><br><span class="line">    encoding = chardet.detect(university)</span><br><span class="line">    <span class="built_in">print</span>(encoding)</span><br></pre></td></tr></table></figure></div>
<p>之后将其输出的encoding写入pd.read_csv()即可</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">university = pd.read_csv(<span class="string">&#x27;cwurData.csv&#x27;</span>, encoding=<span class="string">&#x27;GBK&#x27;</span>)</span><br><span class="line">university.head()</span><br></pre></td></tr></table></figure></div>
<p>输出结果为<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/001.png"
                      alt="photo"
                ><br>通过该数据可知其数字应该是越小越好<br>因此相关性应该是负数 且越小越好</p>
<p>之后我们查看文件的维度</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">university.shape</span><br></pre></td></tr></table></figure></div>
<p>输出结果为:(2200, 14)<br>说明该文件总共有2200行数据，14个特征</p>
<p>接下来我们分析下文件是否有异常</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">university.describe()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/002.png"
                      alt="photo"
                ><br>从第一行(count)看到 broad_impact数据与其他数据不同<br>上述从head()函数我猜测broad_impact列全是NA<br>仔细查看文件后可知:2012年和2013年的broad_impact存在缺失<br>其他数据看起来没什么问题 数据质量基本完整</p>
<p>先用相关性矩阵看看各个数据之间的关系</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = university[<span class="string">&#x27;score&#x27;</span>]</span><br><span class="line">X = university.drop([<span class="string">&quot;score&quot;</span>,<span class="string">&quot;institution&quot;</span>,<span class="string">&quot;country&quot;</span>, <span class="string">&quot;year&quot;</span>,<span class="string">&quot;broad_impact&quot;</span>],axis=1)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">correlation_matrix = pd.concat([X_train, y_train], axis=1).corr()</span><br><span class="line"></span><br><span class="line">sns.heatmap(correlation_matrix, annot=True, cmap=<span class="string">&#x27;coolwarm&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/003.png"
                      alt="photo"
                ><br>通过上图可以看到world_rank与publications、influence、citations有强相关性<br>我们用matplotlib.pyplot库做出这些图</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = university[<span class="string">&quot;publications&quot;</span>]</span><br><span class="line">y = university[<span class="string">&quot;world_rank&quot;</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;world_rank&amp;publications&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/004.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = university[<span class="string">&quot;influence&quot;</span>]</span><br><span class="line">y = university[<span class="string">&quot;world_rank&quot;</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;world_rank&amp;influence&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/005.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = university[<span class="string">&quot;citations&quot;</span>]</span><br><span class="line">y = university[<span class="string">&quot;world_rank&quot;</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;world_rank&amp;citations&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/006.png"
                      alt="photo"
                ></p>
<p>从上述三幅图可以看到world_rank与publications、influence有强相关性<br>world_rank与citations也有一定的相关性 但不是很明显<br>再继续做几张图看看其他数据之间的关系怎么样</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = university[<span class="string">&quot;publications&quot;</span>]</span><br><span class="line">y = university[<span class="string">&quot;influence&quot;</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;influence&amp;publications&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/007.png"
                      alt="photo"
                ><br>从图中可以看出点近似集中在一条直线上<br>说明出版物与影响力成正比</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = university[<span class="string">&quot;broad_impact&quot;</span>]</span><br><span class="line">y = university[<span class="string">&quot;score&quot;</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;score&amp;broad_impact&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/03/28/008.png"
                      alt="photo"
                ><br>从图中可以看出broad_impact与score成非线性关系 broad_impact的大小与score无关<br><br>用相关性进行检测</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = university[<span class="string">&quot;broad_impact&quot;</span>]</span><br><span class="line">y = university[<span class="string">&quot;score&quot;</span>]</span><br><span class="line">correlation = x.corr(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;r:&quot;</span>, correlation)</span><br></pre></td></tr></table></figure></div>
<p>输出结果为:r: -0.5315904271503679</p>
<p>呈现负相关 因此确定 broad_impact的大小与score无关<br>并且broad_impact中存在缺失值<br>缺失值的处理一般会使用用众数填充、前或后一个数填充、删除缺失列来处理<br>这里broad_impact的大小与score无关<br>因此可以将此列删去<br>同时也可以降低维度</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = university[<span class="string">&#x27;score&#x27;</span>]</span><br><span class="line">X = university.drop([<span class="string">&quot;score&quot;</span>,<span class="string">&quot;institution&quot;</span>,<span class="string">&quot;country&quot;</span>, <span class="string">&quot;year&quot;</span>,<span class="string">&quot;broad_impact&quot;</span>],axis=1)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">lr.intercept_</span><br><span class="line"></span><br><span class="line">coefs_lr = pd.Series(lr.coef_).round()</span><br><span class="line">coefs_lr.index = X_train.columns</span><br><span class="line">coefs_lr</span><br></pre></td></tr></table></figure></div>

<p>其结果为:<br>63.60601390140695</p>
<p>world_rank              0.0<br>national_rank          -0.0<br>quality_of_education   -0.0<br>alumni_employment      -0.0<br>quality_of_faculty     -0.0<br>publications           -0.0<br>influence              -0.0<br>citations              -0.0<br>patents                -0.0<br>dtype: float64</p>
<p>说明模型拟合得不好<br>查看其均方根误差和决定系数</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">lr_train_pred = lr.predict(X_train)</span><br><span class="line">lr_test_pred = lr.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;训练集上的均方根误差和决定系数分别为:&quot;</span>, root_mean_squared_error(lr_train_pred,y_train), r2_score(lr_train_pred,y_train))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;测试集上的均方根误差和决定系数分别为:&quot;</span>, root_mean_squared_error(lr_test_pred,y_test), r2_score(lr_test_pred,y_test))</span><br></pre></td></tr></table></figure></div>
<p>输出结果为:<br>训练集上的均方根误差和决定系数分别为: 5.441831802594455 0.079429595738992<br>测试集上的均方根误差和决定系数分别为: 5.369301125131177 0.06344204755145388</p>
<p>上述系数过小可能是数值之间差别过大导致拟合得不好<br>将其进行标准化</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(X_train_scaled, y_train)</span><br><span class="line">coefs_lr = pd.Series(lr.coef_).round()</span><br><span class="line">coefs_lr.index = X_train.columns</span><br><span class="line">coefs_lr</span><br><span class="line"></span><br><span class="line">lr.intercept_</span><br></pre></td></tr></table></figure></div>
<p>输出结果为:<br>world_rank              0.0<br>national_rank          -0.0<br>quality_of_education   -0.0<br>alumni_employment      -1.0<br>quality_of_faculty     -4.0<br>publications           -0.0<br>influence              -0.0<br>citations              -0.0<br>patents                -0.0<br>dtype: float64</p>
<p>47.83457386363636</p>
<p>模型得到的结果很低 说明拟合得不好<br>更换其他线性回归模型试试</p>
<div class="tabs" id="tab-线性回归模型"><ul class="nav-tabs"><li class="tab active"><a class="#线性回归模型-1">岭回归</a></li><li class="tab"><a class="#线性回归模型-2">lasso回归</a></li><li class="tab"><a class="#线性回归模型-3">弹性网回归</a></li></ul><div class="tab-content"><div class="tab-pane active" id="线性回归模型-1"><p><strong>岭回归</strong></p>
 <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ridge= linear_model.Ridge(alpha=0.05)</span><br><span class="line">ridge.fit(X_train,y_train)</span><br><span class="line">Y_hat = ridge.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距为：&quot;</span>, ridge.intercept_)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;回归系数为：&quot;</span>, ridge.coef_)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;RMSE:&quot;</span>, np.sqrt(metrics.mean_squared_error(y_test, Y_hat)))</span><br></pre></td></tr></table></figure></div>
<p> 输出结果为:<br> 截距为： 63.60601382257282<br>回归系数为： [ 0.00116895 -0.00608447 -0.00380894 -0.00592045 -0.06344228 -0.00045937<br> -0.0009899  -0.00046924 -0.00164281]<br> RMSE: 5.369301120766853</p></div><div class="tab-pane" id="线性回归模型-2"><p><strong>lasso回归</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">lasso= linear_model.Lasso(alpha=0.05)</span><br><span class="line">lasso.fit(X_train,y_train)</span><br><span class="line">Y_hat=lasso.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距为：&quot;</span>,lasso.intercept_)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;回归系数为：&quot;</span>, lasso.coef_)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;RMSE:&quot;</span>, np.sqrt(metrics.mean_squared_error(y_test, Y_hat)))</span><br></pre></td></tr></table></figure></div>
<p>输出结果为:<br>截距为： 63.602800047243974<br>回归系数为： [ 0.00115484 -0.00606551 -0.00381082 -0.00591616 -0.06342471 -0.00045677<br> -0.00098495 -0.00046729 -0.00164163]<br> RMSE: 5.369181579518303</p></div><div class="tab-pane" id="线性回归模型-3"><p><strong>弹性网回归</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">elastic= linear_model.ElasticNet(alpha=0.1,l1_ratio=0.4)</span><br><span class="line">elastic.fit(X_train,y_train)</span><br><span class="line">y_hat = elastic.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距为：&quot;</span>,elastic.intercept_)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;回归系数为：&quot;</span>, elastic.coef_)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;RMSE:&quot;</span>, np.sqrt(metrics.mean_squared_error(y_test, Y_hat)))</span><br></pre></td></tr></table></figure></div>
<p>输出结果为:<br>截距为： 63.60327653271375<br>回归系数为： [ 0.00115777 -0.0060693  -0.00381124 -0.00591707 -0.06342543 -0.00045734<br> -0.00098603 -0.00046779 -0.00164194]<br> RMSE: 5.369181579518303</p></div></div></div>

<p>可以看到这些回归得到的结果都不好<br>说明这个不是呈线性关系</p>
<p>我们使用随机森林进行尝试</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">rf = RandomForestRegressor()</span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">rf_train_pred = rf.predict(X_train)</span><br><span class="line">rf_test_pred = rf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;训练集上的均方根误差和决定系数分别为:&quot;</span>, root_mean_squared_error(rf_train_pred,y_train), r2_score(rf_train_pred,y_train))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;测试集上的均方根误差和决定系数分别为:&quot;</span>, root_mean_squared_error(rf_test_pred,y_test), r2_score(rf_test_pred,y_test))</span><br></pre></td></tr></table></figure></div>
<p>输出结果为:<br>训练集上的均方根误差和决定系数分别为: 0.396126717281446 0.9974538720434839<br>测试集上的均方根误差和决定系数分别为: 1.0185613846393418 0.9808937922886296</p>
<p>可以看到 决定系数为0.99 0.98以上 说明模型拟合得很好</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>连续特征离散化的处理方法及其python实现</title>
    <url>/zhihaojiang.github.io/2025/03/29/20250329%E8%BF%9E%E7%BB%AD%E7%89%B9%E5%BE%81%E7%A6%BB%E6%95%A3%E5%8C%96%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E5%8F%8A%E5%85%B6python%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="等距离散法"><a href="#等距离散法" class="headerlink" title="等距离散法"></a>等距离散法</h2><p>将连续数据的范围划分为几个宽度相等的区间。每个区间内的数值都有相同的范围。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成连续数据</span></span><br><span class="line">data = np.random.randn(1000)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据分为 5 个等宽区间</span></span><br><span class="line">bins = pd.cut(data, bins=5)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看分箱结果</span></span><br><span class="line"><span class="built_in">print</span>(bins.value_counts())</span><br></pre></td></tr></table></figure></div>

<h2 id="等频离散法"><a href="#等频离散法" class="headerlink" title="等频离散法"></a>等频离散法</h2><p>将数据分成几个区间，使得每个区间内的数据量相同。这样可以避免某些区间的数据过于集中。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成连续数据</span></span><br><span class="line">data = np.random.randn(1000)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据分为 5 个等频区间</span></span><br><span class="line">bins = pd.qcut(data, q=5)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看分箱结果</span></span><br><span class="line"><span class="built_in">print</span>(bins.value_counts())</span><br></pre></td></tr></table></figure></div>

<h2 id="K-means-模型离散法"><a href="#K-means-模型离散法" class="headerlink" title="K-means 模型离散法"></a>K-means 模型离散法</h2><p>先从样本集中随机选取 k个样本作为簇中心，并计算所有样本与这 k个“簇中心”的距离，对于每一个样本，将其划分到与其距离最近的“簇中心”所在的簇中。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成连续数据</span></span><br><span class="line">data = np.random.randn(1000).reshape(-1, 1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 K-means 聚类</span></span><br><span class="line">kmeans = KMeans(n_clusters=5)</span><br><span class="line">labels = kmeans.fit_predict(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看聚类标签</span></span><br><span class="line"><span class="built_in">print</span>(pd.Series(labels).value_counts())</span><br></pre></td></tr></table></figure></div>

<h2 id="基于决策树的离散化"><a href="#基于决策树的离散化" class="headerlink" title="基于决策树的离散化"></a>基于决策树的离散化</h2><p>基于决策树的方法利用决策树的分割规则进行离散化，将连续特征分割成多个区间，通常用于有监督学习中的离散化。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成连续数据</span></span><br><span class="line">data = np.random.randn(1000)</span><br><span class="line">target = np.random.randint(0, 2, size=1000)  <span class="comment"># 假设目标变量是二分类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将连续数据转化为二维数组</span></span><br><span class="line">X = data.reshape(-1, 1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用决策树进行离散化</span></span><br><span class="line">clf = DecisionTreeClassifier(max_leaf_nodes=5)</span><br><span class="line">clf.fit(X, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取每个样本所属的区间</span></span><br><span class="line">labels = clf.apply(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看离散化结果</span></span><br><span class="line"><span class="built_in">print</span>(pd.Series(labels).value_counts())</span><br></pre></td></tr></table></figure></div>

<h2 id="分位数离散法"><a href="#分位数离散法" class="headerlink" title="分位数离散法"></a>分位数离散法</h2><p>分位数离散化的核心思想是：<br>按照数据的累积分布函数 (CDF) 计算分位点。<br>根据分位数（如四分位数 (quartiles)、十分位数 (deciles)）划分数据，使得每个区间的样本数接近相等。<br>由于基于数据的分布进行划分，适用于非均匀分布的数据。</p>
<p>以下是不同的方法进行实现</p>
<div class="tabs" id="tab-分位数离散法实现方法"><ul class="nav-tabs"><li class="tab active"><a class="#分位数离散法实现方法-1">方法一</a></li><li class="tab"><a class="#分位数离散法实现方法-2">方法二</a></li></ul><div class="tab-content"><div class="tab-pane active" id="分位数离散法实现方法-1"><p><strong>使用pandas.qcut()</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成 1000 个随机数据</span></span><br><span class="line">data = np.random.randn(1000)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 qcut 进行分位数离散化（四分位）</span></span><br><span class="line">bins = pd.qcut(data, q=4, labels=[<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>, <span class="string">&#x27;Q3&#x27;</span>, <span class="string">&#x27;Q4&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计每个分箱的数据量</span></span><br><span class="line"><span class="built_in">print</span>(bins.value_counts())</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="分位数离散法实现方法-2"><p><strong>使用numpy.percentile()</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成 1000 个随机数据</span></span><br><span class="line">data = np.random.randn(1000)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 10 分位数（十分位数）</span></span><br><span class="line">percentiles = np.percentile(data, q=[10, 20, 30, 40, 50, 60, 70, 80, 90])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 np.digitize 进行分箱</span></span><br><span class="line">bins = np.digitize(data, percentiles)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计每个分箱的数据量</span></span><br><span class="line"><span class="built_in">print</span>(np.bincount(bins))</span><br></pre></td></tr></table></figure></div></div></div></div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>分位数离散化的优缺点</p>

    </div>
    <div class="notel-content">
      <p>✅ 优点<br>适用于非均匀分布数据，相比于等宽离散化更合理。<br>避免某些区间数据过多或过少，能够更好地均衡数据。<br>能够减少异常值的影响，因为分箱是基于数据分布，而不是固定范围。</p>
<p>❌ 缺点<br>对极端值敏感，如果数据中有极端值，可能会影响分位数计算结果。<br>区间边界难以解释，不像等宽分箱那样有固定的区间宽度。<br>对新数据可能需要重新计算分位点，导致难以适用于流式数据。</p>

    </div>
  </div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>何时使用分位数离散化？</p>

    </div>
    <div class="notel-content">
      <p>数据分布不均匀（例如数据集中在某些范围）。<br>避免某些区间样本过多或过少，如在决策树、统计建模等场景中使用。<br>希望减少异常值的影响，避免极端值导致不均匀的划分。</p>

    </div>
  </div>

<h2 id="基于卡方分裂的离散法"><a href="#基于卡方分裂的离散法" class="headerlink" title="基于卡方分裂的离散法"></a>基于卡方分裂的离散法</h2><p>该分裂算法是把整个属性的取值区间当做一个离散的属性值，然后对该区间进行划分，一般是一分为二，即把一个区间分为两个相邻的区间，每个区间对应一个离散的属性值，该划分可以一直进行下去，直到满足某种停止条件，其关键是划分点的选取。</p>
<p><strong>方法一</strong><br><strong>手动实现</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from scipy.stats import chi2_contingency</span><br><span class="line"></span><br><span class="line">def chi2_value(freq_table):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;计算卡方值&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    chi2, p, _, _ = chi2_contingency(freq_table)</span><br><span class="line">    <span class="built_in">return</span> chi2</span><br><span class="line"></span><br><span class="line">def chimerge(data, target, max_bins=5):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    基于卡方分裂的离散化方法（ChiMerge）</span></span><br><span class="line"><span class="string">    :param data: 连续特征（NumPy 数组或 Pandas Series）</span></span><br><span class="line"><span class="string">    :param target: 目标变量（分类变量）</span></span><br><span class="line"><span class="string">    :param max_bins: 期望的最大分箱数</span></span><br><span class="line"><span class="string">    :return: 分箱边界</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="built_in">df</span> = pd.DataFrame(&#123;<span class="string">&#x27;feature&#x27;</span>: data, <span class="string">&#x27;target&#x27;</span>: target&#125;)</span><br><span class="line">    <span class="built_in">df</span> = df.sort_values(by=<span class="string">&#x27;feature&#x27;</span>).reset_index(drop=True)  <span class="comment"># 按特征值排序</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计每个特征值下的类别频次</span></span><br><span class="line">    freq_table = df.groupby(<span class="string">&#x27;feature&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].value_counts().unstack().fillna(0)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始边界（每个值单独作为一个区间）</span></span><br><span class="line">    bins = list(freq_table.index)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> len(bins) &gt; max_bins:  <span class="comment"># 直到达到最大分箱数</span></span><br><span class="line">        min_chi2 = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">        min_index = -1</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历所有相邻区间，找到卡方值最小的区间</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(bins) - 1):</span><br><span class="line">            merged_table = freq_table.loc[[bins[i], bins[i + 1]]].<span class="built_in">sum</span>(axis=0).values.reshape(2, -1)</span><br><span class="line">            chi2 = chi2_value(merged_table)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> chi2 &lt; min_chi2:  <span class="comment"># 找到最小的卡方值</span></span><br><span class="line">                min_chi2 = chi2</span><br><span class="line">                min_index = i</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 合并卡方值最小的区间</span></span><br><span class="line">        bins[min_index] = (bins[min_index] + bins[min_index + 1]) / 2</span><br><span class="line">        bins.pop(min_index + 1)  <span class="comment"># 删除合并的区间</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> bins</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">np.random.seed(42)</span><br><span class="line">data = np.random.randn(100) * 10 + 50  <span class="comment"># 生成随机数</span></span><br><span class="line">target = np.random.choice([0, 1], size=100)  <span class="comment"># 二分类目标变量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算分箱边界</span></span><br><span class="line">bin_edges = chimerge(data, target, max_bins=4)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卡方分裂后的分箱边界:&quot;</span>, bin_edges)</span><br></pre></td></tr></table></figure></div>

<p><strong>方法二</strong><br><strong>使用optbinning库</strong></p>
<p>如果不想手动实现，可以使用 optbinning 库，它可以进行最优分箱（Optimal Binning），内部使用 ChiMerge 或者 Decision Tree 进行离散化。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from optbinning import OptimalBinning</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(42)</span><br><span class="line">data = np.random.randn(100) * 10 + 50</span><br><span class="line">target = np.random.choice([0, 1], size=100)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 OptimalBinning 进行卡方离散化</span></span><br><span class="line">optb = OptimalBinning(name=<span class="string">&quot;feature&quot;</span>, dtype=<span class="string">&quot;numerical&quot;</span>, solver=<span class="string">&quot;cp&quot;</span>)</span><br><span class="line">optb.fit(data, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取分箱边界</span></span><br><span class="line">bin_edges = optb.splits</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自动计算的分箱边界:&quot;</span>, bin_edges)</span><br></pre></td></tr></table></figure></div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>ChiMerge的优缺点</p>

    </div>
    <div class="notel-content">
      <p>✅ 优点<br>保持类别信息：确保离散化后不同类别仍然可以区分，提高模型效果。<br>自动确定最优分箱：基于卡方值合并区间，减少信息损失。<br>避免过度离散化：不像等宽分箱或等频分箱可能导致信息丢失。</p>
<p>❌ 缺点<br>计算量较大：随着样本数增加，计算卡方统计量的复杂度会增加。<br>依赖类别变量：只能用于分类任务，如果目标变量是连续值，需要先离散化。<br>需要调整超参数：最大分箱数 max_bins 需要根据数据调优。</p>

    </div>
  </div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>何时使用ChiMerge</p>

    </div>
    <div class="notel-content">
      <p>分类任务：目标变量是离散类别（如二分类、多分类）。<br>决策树模型：离散化后可以提升决策树模型的可解释性。<br>数据量较大：对于大规模数据，可通过 optbinning 等库加速处理。</p>

    </div>
  </div>

<p>ChiMerge 离散化适用于分类任务，可以在决策树、朴素贝叶斯等模型中提升效果。对于回归任务，可以考虑 KMeans 或 等宽&#x2F;等频分箱。</p>
<h2 id="1R离散法"><a href="#1R离散法" class="headerlink" title="1R离散法"></a>1R离散法</h2><p>1R 就是 1-rule，称为1 规则，也就是产生一层的决策树，用一个规则集的形式，只在某个特定的属性上进行测试。1R是一个简单廉价的方法，但却常常能得到令人吃惊的准确率。<br>它的核心思想是：<br>将连续特征划分为多个区间，然后<br>寻找能够最好地预测目标变量（类别）的区间划分。</p>
<p>1R 方法的基本步骤如下：<br>对特征值排序。<br>尝试不同的分箱方法（等宽、等频、信息增益等），并计算分类错误率。<br>选择错误率最低的分箱方式作为最终的离散化方式。</p>
<p><strong>方法一</strong><br><strong>手动实现</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">def one_r_discretization(data, target, max_bins=5):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    基于 1R 规则的离散化方法</span></span><br><span class="line"><span class="string">    :param data: 连续特征 (NumPy 数组或 Pandas Series)</span></span><br><span class="line"><span class="string">    :param target: 目标变量 (分类变量)</span></span><br><span class="line"><span class="string">    :param max_bins: 期望的最大分箱数</span></span><br><span class="line"><span class="string">    :return: 最优分箱边界</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="built_in">df</span> = pd.DataFrame(&#123;<span class="string">&#x27;feature&#x27;</span>: data, <span class="string">&#x27;target&#x27;</span>: target&#125;)</span><br><span class="line">    <span class="built_in">df</span> = df.sort_values(by=<span class="string">&#x27;feature&#x27;</span>).reset_index(drop=True)  <span class="comment"># 按特征值排序</span></span><br><span class="line"></span><br><span class="line">    best_bins = None</span><br><span class="line">    best_error = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 尝试不同分箱方式</span></span><br><span class="line">    <span class="keyword">for</span> bins <span class="keyword">in</span> range(2, max_bins + 1):</span><br><span class="line">        <span class="built_in">df</span>[<span class="string">&#x27;bin&#x27;</span>] = pd.cut(<span class="built_in">df</span>[<span class="string">&#x27;feature&#x27;</span>], bins=bins, labels=False)  <span class="comment"># 进行分箱</span></span><br><span class="line">        bin_stats = df.groupby(<span class="string">&#x27;bin&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].agg(lambda x: x.value_counts().index[0])  <span class="comment"># 每个分箱内占比最高的类别</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算错误率</span></span><br><span class="line">        <span class="built_in">df</span>[<span class="string">&#x27;pred&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;bin&#x27;</span>].map(bin_stats)</span><br><span class="line">        error_rate = (<span class="built_in">df</span>[<span class="string">&#x27;pred&#x27;</span>] != <span class="built_in">df</span>[<span class="string">&#x27;target&#x27;</span>]).mean()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 选择错误率最低的分箱方案</span></span><br><span class="line">        <span class="keyword">if</span> error_rate &lt; best_error:</span><br><span class="line">            best_error = error_rate</span><br><span class="line">            best_bins = <span class="built_in">df</span>[<span class="string">&#x27;bin&#x27;</span>].unique()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> best_bins</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">np.random.seed(42)</span><br><span class="line">data = np.random.randn(100) * 10 + 50  <span class="comment"># 生成随机数</span></span><br><span class="line">target = np.random.choice([0, 1], size=100)  <span class="comment"># 目标变量（0 或 1）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算分箱边界</span></span><br><span class="line">bin_edges = one_r_discretization(data, target, max_bins=4)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;1R 规则下的最佳分箱边界:&quot;</span>, bin_edges)</span><br></pre></td></tr></table></figure></div>

<p><strong>方法二</strong><br><strong>使用KBinsDiscretizer</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import KBinsDiscretizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">data = data.reshape(-1, 1)  <span class="comment"># 需要转换为 2D 数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用监督式分箱</span></span><br><span class="line">discretizer = KBinsDiscretizer(n_bins=4, encode=<span class="string">&#x27;ordinal&#x27;</span>, strategy=<span class="string">&#x27;uniform&#x27;</span>)</span><br><span class="line">binned_data = discretizer.fit_transform(data)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;1R 近似分箱结果:&quot;</span>, np.unique(binned_data))</span><br></pre></td></tr></table></figure></div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>1R方法的优缺点</p>

    </div>
    <div class="notel-content">
      <p>✅ 优点<br>监督式分箱：保留目标变量信息，减少信息损失。<br>简单易懂：规则明确，适合初步数据探索。<br>适用于分类任务：尤其适用于决策树、朴素贝叶斯等分类模型。</p>
<p>❌ 缺点<br>计算复杂度较高：需要尝试多个分箱方案，计算错误率。<br>可能过拟合：如果 max_bins 过大，可能导致分箱过多，导致模型过拟合。<br>仅适用于分类任务：如果目标变量是连续值，需要先进行离散化。</p>

    </div>
  </div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>何时使用1R离散化？</p>

    </div>
    <div class="notel-content">
      <p>分类任务（目标变量是离散类别，如 0&#x2F;1 或 A&#x2F;B&#x2F;C）。<br>数据探索：快速找到能够划分类别的最优分箱方式。<br>决策树建模：如 CART、ID3、C4.5 等模型。</p>

    </div>
  </div>

<h2 id="二值化离散法"><a href="#二值化离散法" class="headerlink" title="二值化离散法"></a>二值化离散法</h2><p>二值化离散法是一种简单且常用的离散化方法，它的基本思想是 将连续变量转换为两个类别（0 和 1），即：<br>小于某个阈值的设为 0<br>大于等于某个阈值的设为 1</p>
<p>这种方法特别适用于需要转换成 布尔值（Boolean） 的场景，如 信用评分、风险预测 或 神经网络中的二元特征输入。</p>
<p><strong>方法一</strong><br><strong>手动二值化</strong></p>
 <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"> import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(42)</span><br><span class="line">data = np.random.randn(10) * 10 + 50  <span class="comment"># 生成 10 个均值为 50 的随机数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定阈值（如50）</span></span><br><span class="line">threshold = 50</span><br><span class="line">binarized_data_fixed = (data &gt;= threshold).astype(int)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 均值二值化</span></span><br><span class="line">threshold_mean = np.mean(data)</span><br><span class="line">binarized_data_mean = (data &gt;= threshold_mean).astype(int)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中位数二值化</span></span><br><span class="line">threshold_median = np.median(data)</span><br><span class="line">binarized_data_median = (data &gt;= threshold_median).astype(int)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 75% 分位数二值化</span></span><br><span class="line">threshold_percentile = np.percentile(data, 75)</span><br><span class="line">binarized_data_percentile = (data &gt;= threshold_percentile).astype(int)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Original Data&#x27;</span>: data,</span><br><span class="line">    <span class="string">&#x27;Fixed Threshold&#x27;</span>: binarized_data_fixed,</span><br><span class="line">    <span class="string">&#x27;Mean Threshold&#x27;</span>: binarized_data_mean,</span><br><span class="line">    <span class="string">&#x27;Median Threshold&#x27;</span>: binarized_data_median,</span><br><span class="line">    <span class="string">&#x27;Percentile Threshold&#x27;</span>: binarized_data_percentile</span><br><span class="line">&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">df</span>)</span><br></pre></td></tr></table></figure></div>
<p><strong>方法二</strong><br><strong>使用 sklearn 进行二值化</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import Binarizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定固定阈值</span></span><br><span class="line">binarizer = Binarizer(threshold=50)  <span class="comment"># 以50为阈值</span></span><br><span class="line">binarized_data = binarizer.fit_transform(data.reshape(-1, 1))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;二值化后的数据:\n&quot;</span>, binarized_data.flatten())</span><br></pre></td></tr></table></figure></div>

<p><strong>方法三</strong><br><strong>监督式二值化（基于决策树）</strong></p>
<p>如果有分类标签 Y，可以使用决策树来学习最佳的二值化阈值：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设目标变量 Y</span></span><br><span class="line">target = np.random.choice([0, 1], size=len(data))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练决策树</span></span><br><span class="line">tree = DecisionTreeClassifier(max_depth=1)  <span class="comment"># 只允许一层分裂</span></span><br><span class="line">tree.fit(data.reshape(-1, 1), target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取最优的分裂阈值</span></span><br><span class="line">optimal_threshold = tree.tree_.threshold[0]</span><br><span class="line">binarized_data_tree = (data &gt;= optimal_threshold).astype(int)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;决策树选择的最优二值化阈值: &#123;optimal_threshold&#125;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;基于决策树的二值化结果:&quot;</span>, binarized_data_tree)</span><br></pre></td></tr></table></figure></div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>何时使用二值化？</p>

    </div>
    <div class="notel-content">
      <p>✅ 适用场景<br>逻辑回归或朴素贝叶斯模型（需要布尔特征）。<br>信用评分、欺诈检测（例如：收入是否高于某个值？）。<br>生物信息学（例如：基因表达水平是否超过某个阈值？）。<br>特征筛选（减少噪声，提高模型可解释性）。<br>规则挖掘（如 Apriori 算法）（将数据转换为 0&#x2F;1 格式）。</p>
<p>❌ 不适用场景<br>信息损失严重：如果数据本身具有重要的连续性信息（如温度、房价），二值化可能会损失过多信息。<br>非布尔场景：如果数据有多个类别，建议使用多级离散化（如分箱）。</p>

    </div>
  </div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP介绍及其创建使用</title>
    <url>/zhihaojiang.github.io/2025/03/30/20250330MCP%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%88%9B%E5%BB%BA%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="MCP是什么"><a href="#MCP是什么" class="headerlink" title="MCP是什么"></a>MCP是什么</h2><p>MCP（Model Context Protocol，模型上下文协议）是由 Anthropic 于 2024 年 11 月推出的一种开放标准协议，旨在统一大型语言模型（LLM）与外部数据源和工具之间的通信方式。​<br><strong>Model Context Protocol (MCP)</strong><br>MCP 是一个标准协议，就像给 AI 大模型装了一个 “万能接口”，让 AI 模型能够与不同的数据源和工具进行无缝交互。它就像 USB-C 接口一样，提供了一种标准化的方法，将 AI 模型连接到各种数据源和工具。<br>MCP 旨在替换碎片化的 Agent 代码集成，从而使 AI 系统更可靠，更有效。通过建立通用标准，服务商可以基于协议来推出它们自己服务的 AI 能力，从而支持开发者更快的构建更强大的 AI 应用。开发者也不需要重复造轮子，通过开源项目可以建立强大的 AI Agent 生态。<br>MCP 的核心概念包括：</p>
<ol>
<li>上下文共享：​应用程序可以通过 MCP 向模型提供所需的上下文信息，如文件内容、数据库记录等，增强模型的理解和生成能力。</li>
<li>工具暴露：​MCP 允许应用程序将功能（如文件读写、API 调用）暴露给模型，模型可以调用这些工具完成复杂任务。​</li>
<li>可组合的工作流：​开发者可以利用 MCP 集成多个服务和组件，构建灵活、可扩展的 AI 工作流。​</li>
<li>安全性：​通过本地服务器运行，MCP 避免将敏感数据上传至第三方平台，确保数据隐私。 ​</li>
</ol>
<p>MCP 的架构主要由以下组件组成：</p>
<ol>
<li>MCP 主机（Host）：​如 Claude Desktop、IDE 或其他 AI 工具，即大模型的应用。​</li>
<li>MCP 客户端（Client）：​在主机应用内的连接器，负责与 MCP 服务器建立连接。​</li>
<li>MCP 服务器（Server）：​实现 MCP 协议的程序，提供特定功能或数据资源，供客户端访问。​</li>
<li>远程服务：​如 Slack、GitHub API 等，MCP 服务器可以连接的外部服务。 ​</li>
</ol>
<p>通过 MCP，AI 模型可以直接与数据源建立标准化的连接，避免了为每个新数据源定制对接方案的繁琐过程，从而实现真正的互联互通。</p>
<p>MCP（Model Context Protocol）允许你定义和暴露自定义的函数（工具），让大模型调用这些工具来完成特定任务。例如，你可以构建一个函数，让模型查询数据库、读取文件、调用 API，甚至执行本地计算。</p>
<h2 id="MCP-让模型调用工具的方式"><a href="#MCP-让模型调用工具的方式" class="headerlink" title="MCP 让模型调用工具的方式"></a>MCP 让模型调用工具的方式</h2><p><strong>定义一个工具（函数）</strong><br>在本地或远程服务器上编写一个 API 或函数，例如：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def get_weather(city):</span><br><span class="line">    <span class="comment"># 这里可以调用真实的天气 API</span></span><br><span class="line">    <span class="built_in">return</span> f<span class="string">&quot;&#123;city&#125; 当前气温 25°C，晴天&quot;</span></span><br></pre></td></tr></table></figure></div>

<p><strong>通过 MCP 暴露该工具</strong><br>通过 MCP 让大模型知道这个工具的存在，并允许它调用。例如，在 Claude 或其他支持 MCP 的环境中，模型可以动态调用你的 get_weather(city) 函数。<br><strong>模型调用工具</strong><br>当用户询问「北京的天气如何？」时，模型可以自动调用 get_weather(“北京”)，并将结果返回给用户，而不是依赖自身训练的数据。</p>
<h2 id="创建并使用的流程"><a href="#创建并使用的流程" class="headerlink" title="创建并使用的流程"></a>创建并使用的流程</h2><p>以get_weather为例<br>我们首先创建一个.py文件叫weather<br>在文件中输入下述代码</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">from mcp import MCPServer, tool</span><br><span class="line"></span><br><span class="line">class WeatherServer(MCPServer):</span><br><span class="line">    @tool</span><br><span class="line">    def get_weather(self, city: str) -&gt; str:</span><br><span class="line">        <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">        获取指定城市的天气信息。</span></span><br><span class="line"><span class="string">        &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 调用天气 API 获取数据</span></span><br><span class="line">        api_key = <span class="string">&#x27;您的API密钥&#x27;</span></span><br><span class="line">        response = requests.get(f<span class="string">&#x27;http://api.weatherapi.com/v1/current.json?key=&#123;api_key&#125;&amp;q=&#123;city&#125;&amp;lang=zh&#x27;</span>)</span><br><span class="line">        data = response.json()</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;error&#x27;</span> <span class="keyword">in</span> data:</span><br><span class="line">            <span class="built_in">return</span> f<span class="string">&quot;无法获取&#123;city&#125;的天气信息。&quot;</span></span><br><span class="line">        weather = data[<span class="string">&#x27;current&#x27;</span>][<span class="string">&#x27;condition&#x27;</span>][<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">        temp_c = data[<span class="string">&#x27;current&#x27;</span>][<span class="string">&#x27;temp_c&#x27;</span>]</span><br><span class="line">        <span class="built_in">return</span> f<span class="string">&quot;&#123;city&#125;当前天气：&#123;weather&#125;，气温：&#123;temp_c&#125;°C。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    server = WeatherServer()</span><br><span class="line">    server.run()</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>记得安装必要的库</p>

    </div>
    <div class="notel-content">
      <p>pip install mcp-server</p>

    </div>
  </div>
<p>这样，MCP工具就做好了</p>
<p>之后，我们要将这个工具告诉AI<br>打开一个支持MCP的AI软件或网站 这里我使用vs code中的cline插件<br>在插件设置中找到MCP Servers -&gt; installed -&gt; Configure MCP Server 点击<br>会进入到一个叫cline_mcp_settings.json的文档<br>里面应该是这样的</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;mcpServers&quot;</span>: &#123;</span><br><span class="line">  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>在mcpServers中插入你写的工具</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;mcpServers&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;weather&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;command&quot;</span>: <span class="string">&quot;python&quot;</span>,</span><br><span class="line">      <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;--directory&quot;</span>,</span><br><span class="line">        <span class="string">&quot;/Volumes/HIKSEMI/mcp_server&quot;</span>,</span><br><span class="line">        <span class="string">&quot;run&quot;</span>,</span><br><span class="line">        <span class="string">&quot;weather.py&quot;</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>记得安装必要的库</p>

    </div>
    <div class="notel-content">
      <p>“weather”: { -&gt; 这个是你的MCP工具的名字 可以自己随便取</p>
<p>“command”: “python” -&gt;这个是告诉他使用 python 命令来运行 Python 解释器 启动服务器</p>
<p>“args”: [<br>        “–directory”, -&gt;这个选项通常用来告诉服务器在哪个路径下查找需要的资源 或者在该目录下运行服务器<br>        “&#x2F;Volumes&#x2F;HIKSEMI&#x2F;mcp_server”, -&gt;这是指定你weather.py的路径<br>        “run”, -&gt; 这个是告诉程序去执行接下来的操作 即运行指定的Python脚本<br>        “weather.py” -&gt; 这是要执行的 Python 脚本的名称</p>

    </div>
  </div>

<p>保存好后会在下面看见你的MCP工具已经启用了 在向大模型询问天气时 他会优先查询是否有可用的MCP工具 并按照对应的格式给出答复</p>
]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MCP</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>字母在字符串中的百分比</title>
    <url>/zhihaojiang.github.io/2025/03/31/20250331%E5%AD%97%E6%AF%8D%E5%9C%A8%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E7%99%BE%E5%88%86%E6%AF%94/</url>
    <content><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给你一个字符串 s 和一个字符 letter ，返回在 s 中等于 letter 字符所占的 百分比 ，向下取整到最接近的百分比。</p>
<p>示例 1：</p>
<p>输入：s &#x3D; “foobar”, letter &#x3D; “o”<br>输出：33<br>解释：<br>等于字母 ‘o’ 的字符在 s 中占到的百分比是 2 &#x2F; 6 * 100% &#x3D; 33% ，向下取整，所以返回 33 。<br>示例 2：</p>
<p>输入：s &#x3D; “jjjj”, letter &#x3D; “k”<br>输出：0<br>解释：<br>等于字母 ‘k’ 的字符在 s 中占到的百分比是 0% ，所以返回 0 。</p>
<p>提示：</p>
<p>1 &lt;&#x3D; s.length &lt;&#x3D; 100<br>s 由小写英文字母组成<br>letter 是一个小写英文字母</p>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><div class="tabs" id="tab-first-unique-name"><ul class="nav-tabs"><li class="tab active"><a class="#first-unique-name-1">方法一</a></li><li class="tab"><a class="#first-unique-name-2">方法二</a></li></ul><div class="tab-content"><div class="tab-pane active" id="first-unique-name-1"><p><strong>正常思路</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def percentageLetter(self, s, letter):</span><br><span class="line">        n = len(s)  <span class="comment">#把长度赋值给n</span></span><br><span class="line">        count = 0   <span class="comment">#初始化统计个数变量</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> s: <span class="comment">#从字符串第一个字符开始循环</span></span><br><span class="line">            <span class="keyword">if</span> index == letter: <span class="comment">#如果s的下标index和我们要找的字符letter相同</span></span><br><span class="line">                count += 1  <span class="comment">#+1</span></span><br><span class="line">        <span class="built_in">return</span> 100 * count // n <span class="comment">#个数比总数在乘以100%就得到了其百分比</span></span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="first-unique-name-2"><p><strong>python库实现</strong></p>
 <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"> class Solution:</span><br><span class="line">    def percentageLetter(self, s: str, letter: str) -&gt; int:</span><br><span class="line">        <span class="built_in">return</span> s.count(letter) * 100 // len(s)  <span class="comment">#主要用到了count()函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#作者：灵茶山艾府</span></span><br><span class="line"><span class="comment">#链接：https://leetcode.cn/problems/percentage-of-letter-in-string/solutions/#1510439/ku-han-shu-mo-ni-by-endlesscheng-fqad/</span></span><br><span class="line"><span class="comment">#来源：力扣（LeetCode）</span></span><br><span class="line"><span class="comment">#著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span></span><br></pre></td></tr></table></figure></div></div></div></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>力扣</tag>
      </tags>
  </entry>
  <entry>
    <title>λ演算</title>
    <url>/zhihaojiang.github.io/2025/04/01/20250401%CE%BB%E6%BC%94%E7%AE%97/</url>
    <content><![CDATA[<p>在B站看到了有人讲解λ演算 很感兴趣 于是去了解了一下<br>原视频：<a class="link"   href="https://www.youtube.com/watch?v=RcVA8Nj6HEo&t=44s" >https://www.youtube.com/watch?v=RcVA8Nj6HEo&amp;t=44s<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>原视频很精彩 图文描述 我也是看了这个视频写的 推荐观看</p>
<h2 id="什么是λ演算"><a href="#什么是λ演算" class="headerlink" title="什么是λ演算"></a>什么是λ演算</h2><p>λ演算（Lambda Calculus）是一种用于研究函数定义、函数应用和递归的数学逻辑系统 由阿隆佐·丘奇（Alonzo Church）在 1930 年代提出。它是计算理论的基础之一 并在编程语言的设计中发挥了重要作用 特别是对函数式编程语言（如 Haskell、Lisp 和 ML）有深远的影响 </p>
<p>诶 这里学过python的人肯定想到了 python中有个lambda表达式 是不是和这个λ演算相关呢<br>没错 Python 中的 lambda 表达式确实与 λ（Lambda）演算有关系 但它只是 λ演算的一个简单应用 并没有完全实现 λ演算的全部概念 这里不过多叙述 只是告诉大家他们之间确实有关系</p>
<h2 id="λ演算的基本概念"><a href="#λ演算的基本概念" class="headerlink" title="λ演算的基本概念"></a>λ演算的基本概念</h2><p>λ演算由三种基本表达式组成：</p>
<ul>
<li>变量：例如 x、y，代表某个值。</li>
<li>λ抽象（Lambda Abstraction）：用于定义匿名函数，例如 λx.x+1 表示“输入 x，返回 x+1”</li>
<li>函数应用（Function Application）：用于调用函数，例如 (λx.x+1) 2，表示将 2 代入 λx.x+1，结果为 3</li>
</ul>
<h3 id="λ表达式"><a href="#λ表达式" class="headerlink" title="λ表达式"></a>λ表达式</h3><p>在λ演算中 主要有三类样式：</p>
<ul>
<li>括号：()</li>
<li>变量：x, y, z…</li>
<li>“λ”和”.”:λ和.总是成对出现</li>
</ul>
<p>这样 我们就有了三个模版：</p>
<ul>
<li>(_ _)</li>
<li>a</li>
<li>(λa._)</li>
</ul>
<p>这里的下划线可以填入上述任意模块 a是一个变量 我们可以像搭积木一样进行构造<br>例如：<br>((λa.y)(λx.(λc.e)))<br>并且 这些变量也可以是一个函数</p>
<h3 id="结合代码理解"><a href="#结合代码理解" class="headerlink" title="结合代码理解"></a>结合代码理解</h3><p>上述的a其实就是一个变量 并且他也可以看成一个函数<br>现在我们重点看看( _ _ ) 和 ( λa._ )</p>
<p>(_ _)可以理解为</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#以(ab)为例</span></span><br><span class="line"><span class="comment">#将左边的a看成一个函数</span></span><br><span class="line"><span class="comment">#右边的b就是这个函数a的输入</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#为了方便理解 我们定义一个函数 叫a</span></span><br><span class="line">def a(x):</span><br><span class="line">    <span class="built_in">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="comment">#先别管变量output 右边的a(b)等价于λ演算中的(ab)</span></span><br><span class="line">output = a(b)</span><br></pre></td></tr></table></figure></div>

<p>(λa._)可以理解为</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#以(λx.y)为例</span></span><br><span class="line">def fun(x):</span><br><span class="line">    <span class="built_in">return</span> y</span><br></pre></td></tr></table></figure></div>

<p>这些就是λ表达式的内容</p>
<h2 id="λ图"><a href="#λ图" class="headerlink" title="λ图"></a>λ图</h2><p>有很多种可视化λ图</p>
<ol>
<li>Tromp图表：<a class="link"   href="https://tromp.github.io/cl/diagrams.html" >https://tromp.github.io/cl/diagrams.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>David C Keenan的λ演算图形符号：<a class="link"   href="https://dkeenan.com/Lambda/" >https://dkeenan.com/Lambda/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>de Bruijn索引：<a class="link"   href="https://en.wikipedia.org/wiki/De_Bruijn_index" >https://en.wikipedia.org/wiki/De_Bruijn_index<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> </li>
<li>Vex（Wayne Citrin，Richard Hall，Benjamin Zorn）：<a class="link"   href="https://www.researchgate.net/publication/2726047_Programming_with_Visual_Expressions" >https://www.researchgate.net/publication/2726047_Programming_with_Visual_Expressions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> </li>
<li>视觉λ演算（Viktor Massalõgin）：<a class="link"   href="https://github.com/bntre/visual-lambda" >https://github.com/bntre/visual-lambda<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ol>
<h2 id="λ演算的计算规则"><a href="#λ演算的计算规则" class="headerlink" title="λ演算的计算规则"></a>λ演算的计算规则</h2><p>λ演算主要有三个计算规则：</p>
<ol>
<li>α-变换（Alpha Conversion）</li>
<li>β-规约（Beta Reduction）</li>
<li>η-变换（Eta Conversion）</li>
</ol>
<h3 id="α-变换（Alpha-Conversion）"><a href="#α-变换（Alpha-Conversion）" class="headerlink" title="α-变换（Alpha Conversion）"></a>α-变换（Alpha Conversion）</h3><p>简单来说就是变量重命名</p>
<blockquote>
<p>λx.x &#x3D; λy.y</p>
</blockquote>
<p>只要不影响表达式的意义 就可以更改变量名称 就像你可以随意地取变量名</p>
<h3 id="β-规约"><a href="#β-规约" class="headerlink" title="β-规约"></a>β-规约</h3><p>函数应用的计算<br>我们来看这样的一个式子：</p>
<blockquote>
<p>((λx.x+2)3)</p>
</blockquote>
<p>根据前文的理解<br>我们逐步进行分析<br>首先来看内层的(λx.x+2)<br>这个意思相当于是 我们定义个一个函数叫x 函数的返回值是x + 2</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#(λx.x+2)</span></span><br><span class="line">def x(x):</span><br><span class="line">    <span class="built_in">return</span> x + 2</span><br></pre></td></tr></table></figure></div>

<p>接下来我们看外层 还记得前面说的</p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>引用</p>

    </div>
    <div class="notel-content">
      <p>以(ab)为例<br>将左边的a看成一个函数<br>右边的b就是这个函数a的输入</p>

    </div>
  </div>
<p>现在把刚才的(λx.x+2)看成a 把3看成b</p>
<p>于是 ((λx.x+2)3)就可以用python写成</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def x(x):</span><br><span class="line">    <span class="built_in">return</span> x + 2</span><br><span class="line">    </span><br><span class="line">output = x(3)</span><br></pre></td></tr></table></figure></div>
<p>其用数学符号就是</p>
<blockquote>
<p>3 + 2</p>
</blockquote>
<p>综上 ((λx.x+2)3)等价于 3 + 2</p>
<h3 id="η-变换"><a href="#η-变换" class="headerlink" title="η-变换"></a>η-变换</h3><p>函数等价转换<br>先给出定义</p>
<blockquote>
<p>λx.fx 等价于 f</p>
</blockquote>
<p>只要 f 在所有输入 x 上都保持不变 那么 λx. f x 和 f 是等价的<br>什么意思呢<br>以f(x) &#x3D; x + 3为例</p>
<p>假设有f(x) &#x3D; x + 3<br>在 λ 形式下 他可以表示为</p>
<blockquote>
<p>f &#x3D; λx. x + 1</p>
</blockquote>
<p>那么 λx.fx 等价于 f 即</p>
<blockquote>
<p>λx. (λx. x + 1) x  ≡  λx. x + 1</p>
</blockquote>
<h2 id="自由变量与束缚变量"><a href="#自由变量与束缚变量" class="headerlink" title="自由变量与束缚变量"></a>自由变量与束缚变量</h2><p>定义</p>
<ul>
<li><p>束缚变量（Bound Variable）<br>如果一个变量 x 出现在 λx.M 这样的函数定义中 并且 x 是由 λx 绑定的 则 x 是束缚变量<br>简单理解：变量被 λ 绑定 就称为束缚变量 </p>
</li>
<li><p>自由变量（Free Variable）<br>如果一个变量 x 在 λ 表达式中出现 但没有被任何 λ 绑定 则 x 是自由变量<br>简单理解：变量没有被 λ 绑定 它就是自由变量</p>
</li>
</ul>
<h3 id="自由变量"><a href="#自由变量" class="headerlink" title="自由变量"></a>自由变量</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">λx. y  // 变量 y 是自由变量</span><br></pre></td></tr></table></figure></div>

<h3 id="束缚变量"><a href="#束缚变量" class="headerlink" title="束缚变量"></a>束缚变量</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">λx. x  // 变量 x 是束缚变量</span><br></pre></td></tr></table></figure></div>

<h2 id="组合子"><a href="#组合子" class="headerlink" title="组合子"></a>组合子</h2><p>在λ演算中，组合子（Combinator） 是指 没有自由变量 的 λ 表达式 也就是说 组合子是 只包含束缚变量 的 λ 表达式 它们是纯粹的函数抽象 不依赖于外部环境 因此它们可以被认为是“自给自足”的函数 </p>
<p>组合子 之所以叫这个名字 是因为它们不依赖外部的变量或环境 只能依赖自己定义的参数 并且可以通过组合多个组合子来构建复杂的计算 组合子本质上是 λ 演算中的基础构建模块 类似于函数式编程中的高阶函数</p>
<h3 id="恒等组合子"><a href="#恒等组合子" class="headerlink" title="恒等组合子"></a>恒等组合子</h3><p>恒等组合子就是一个接受一个参数并返回这个参数的组合子 它的定义非常简单：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">I = λx. x</span><br></pre></td></tr></table></figure></div>
<p>作用：恒等组合子返回输入参数本身 不做任何改变</p>
<blockquote>
<p>I 5 → 5</p>
</blockquote>
<h3 id="K-组合子"><a href="#K-组合子" class="headerlink" title="K 组合子"></a>K 组合子</h3><p>K 组合子（又叫 K 函数或常量函数）接受两个参数 但只返回第一个参数 它的定义是：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">K = λx. λy. x</span><br></pre></td></tr></table></figure></div>
<p>作用：返回第一个参数 忽略第二个参数</p>
<blockquote>
<p>K 5 10 → 5</p>
</blockquote>
<p>在这个例子中 K 5 返回的是一个函数 λy. 5 再与任何第二个参数（比如 10）结合时 结果依然是 5</p>
<h3 id="S-组合子"><a href="#S-组合子" class="headerlink" title="S 组合子"></a>S 组合子</h3><p>S 组合子（又叫 S 函数）比较复杂 接受三个参数 并执行一些组合操作 它的定义如下：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">S = λx. λy. λz. (x z) (y z)</span><br></pre></td></tr></table></figure></div>
<p>作用：S 组合子将输入的两个函数 x 和 y 应用于相同的参数 z 并将结果作为两个函数的输出</p>
<blockquote>
<p>S (λx. x + 1) (λx. x * 2) 3 → (λx. x + 1) 3  (λx. x * 2) 3<br>                              → 3 + 1    3 * 2<br>                              → 4        6</p>
</blockquote>
<p>S 组合子可以用于组合多个函数，使得它们的输入可以共享。</p>
<h3 id="组合子的性质"><a href="#组合子的性质" class="headerlink" title="组合子的性质"></a>组合子的性质</h3><p>组合子通常具有一些有用的性质 它们可以与其他组合子进行组合 以实现更加复杂的计算 几个重要的性质包括：</p>
<ol>
<li><p>函数应用<br>组合子是纯粹的 λ 演算表达式 它们的行为仅依赖于传入的参数 可以通过函数应用来将它们的计算结果传递给其他组合子 进一步构建复杂的计算</p>
</li>
<li><p>无外部依赖<br>组合子是完全自足的 它们的定义仅依赖于它们自己内部的参数 不需要从外部环境引入其他变量 这使得它们在编程语言和计算机科学中非常重要 尤其是在函数式编程中</p>
</li>
<li><p>高阶函数<br>组合子本质上是高阶函数（Higher-Order Function）它们可以作为输入传递给其他函数 或者返回作为结果 例如，S 组合子通过两个输入函数生成新的函数 具有高度的抽象能力</p>
</li>
</ol>
<h2 id="λ演算的作用"><a href="#λ演算的作用" class="headerlink" title="λ演算的作用"></a>λ演算的作用</h2><p>说了这么多 大家应该会进行一些关于λ演算的计算了 可λ演算有什么用呢 感觉就是换个抽象的形式进行计算<br>其实λ演算本质上是换了一种抽象的方式来进行计算 但它的意义远不止于此</p>
<h3 id="计算理论的基础"><a href="#计算理论的基础" class="headerlink" title="计算理论的基础"></a>计算理论的基础</h3><p>λ演算与图灵机（Turing Machine）一样 是计算理论的两大核心模型之一 它们都能表达可计算函数 但λ演算采用的是纯粹的函数变换 而图灵机基于状态和存储</p>
<ul>
<li>通过 λ演算 可以定义所有可计算的函数 因此它是图灵完备的</li>
<li>计算机科学家用它来研究可计算性、算法复杂度等问题</li>
</ul>
<h3 id="影响现代编程语言"><a href="#影响现代编程语言" class="headerlink" title="影响现代编程语言"></a>影响现代编程语言</h3><p>λ演算是函数式编程的理论基础 影响了 Haskell、Lisp、ML、Scala、JavaScript（匿名函数、箭头函数）、Python（Lambda 表达式）等编程语言 例如</p>
<ul>
<li>匿名函数（Lambda 表达式）</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">add = lambda x, y: x + y</span><br><span class="line"><span class="built_in">print</span>(add(2, 3))  <span class="comment"># 输出 5</span></span><br></pre></td></tr></table></figure></div>
<ul>
<li>高阶函数（函数可以作为参数传递）</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def apply_func(f, x):</span><br><span class="line">    <span class="built_in">return</span> f(x)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(apply_func(lambda x: x * 2, 10))  <span class="comment"># 输出 20</span></span><br></pre></td></tr></table></figure></div>

<p>现代语言的 闭包（Closure）、惰性求值、纯函数 等概念都源于 λ演算</p>
<h3 id="形式化数学-逻辑推理"><a href="#形式化数学-逻辑推理" class="headerlink" title="形式化数学 &amp; 逻辑推理"></a>形式化数学 &amp; 逻辑推理</h3><p>λ演算被用作数学逻辑的基础，特别是在构造主义数学和类型理论中。例如：</p>
<ul>
<li>Curry-Howard 对应：λ演算中的函数和逻辑推理中的证明之间存在对应关系 程序可以被视为数学证明</li>
<li>依赖类型（Dependent Types）：Coq、Agda 这些数学证明工具都基于λ演算的扩展形式</li>
</ul>
<h3 id="递归与无变量编程"><a href="#递归与无变量编程" class="headerlink" title="递归与无变量编程"></a>递归与无变量编程</h3><p>λ演算能够表示 递归，即使它本身没有显式的循环结构。例如，阶乘可以用 Y 组合子（Y Combinator）来实现：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">factorial = \f. \n. <span class="keyword">if</span> n == 0 <span class="keyword">then</span> 1 <span class="keyword">else</span> n * (f (n - 1))</span><br><span class="line">Y factorial 5   -- 计算 5!</span><br></pre></td></tr></table></figure></div>

<h3 id="编译器优化"><a href="#编译器优化" class="headerlink" title="编译器优化"></a>编译器优化</h3><p>λ演算提供了转换和简化代码的规则 例如：</p>
<ul>
<li>β-规约（函数应用） 可以减少计算步骤 优化执行效率</li>
<li>α-变换（变量重命名） 可避免变量名冲突</li>
<li>η-变换（函数简化） 可以减少不必要的函数包装 提高性能</li>
</ul>
<p>许多编译器（如 GHC Haskell、Scala、Lisp 解释器）都会用 λ演算作为中间表示（IR）帮助优化代码</p>
<h3 id="并发-分布式计算"><a href="#并发-分布式计算" class="headerlink" title="并发 &amp; 分布式计算"></a>并发 &amp; 分布式计算</h3><p>λ演算的无状态特性使其非常适用于并发计算和分布式系统 例如：</p>
<ul>
<li>MapReduce（Google 的大规模数据处理模型）依赖于 λ演算的映射与归约思想</li>
<li>Actor Model（Erlang、Akka）与函数式编程紧密相关 受λ演算启发</li>
</ul>
]]></content>
      <categories>
        <category>分享</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>解决智力问题</title>
    <url>/zhihaojiang.github.io/2025/04/01/20250401%E8%A7%A3%E5%86%B3%E6%99%BA%E5%8A%9B%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给你一个下标从 0 开始的二维整数数组 questions ，其中 questions[i] &#x3D; [pointsi, brainpoweri] 。</p>
<p>这个数组表示一场考试里的一系列题目，你需要 按顺序 （也就是从问题 0 开始依次解决），针对每个问题选择 解决 或者 跳过 操作。解决问题 i 将让你 获得  pointsi 的分数，但是你将 无法 解决接下来的 brainpoweri 个问题（即只能跳过接下来的 brainpoweri 个问题）。如果你跳过问题 i ，你可以对下一个问题决定使用哪种操作。</p>
<p>比方说，给你 questions &#x3D; [[3, 2], [4, 3], [4, 4], [2, 5]] ：</p>
<ul>
<li>如果问题 0 被解决了， 那么你可以获得 3 分，但你不能解决问题 1 和 2 。</li>
<li>如果你跳过问题 0 ，且解决问题 1 ，你将获得 4 分但是不能解决问题 2 和 3 。</li>
<li>请你返回这场考试里你能获得的 最高 分数。</li>
</ul>
<p>示例 1：</p>
<p>输入：questions &#x3D; [[3,2],[4,3],[4,4],[2,5]]<br>输出：5<br>解释：解决问题 0 和 3 得到最高分。</p>
<ul>
<li>解决问题 0 ：获得 3 分，但接下来 2 个问题都不能解决。</li>
<li>不能解决问题 1 和 2</li>
<li>解决问题 3 ：获得 2 分<br>总得分为：3 + 2 &#x3D; 5 。没有别的办法获得 5 分或者多于 5 分。<br>示例 2：</li>
</ul>
<p>输入：questions &#x3D; [[1,1],[2,2],[3,3],[4,4],[5,5]]<br>输出：7<br>解释：解决问题 1 和 4 得到最高分。</p>
<ul>
<li>跳过问题 0</li>
<li>解决问题 1 ：获得 2 分，但接下来 2 个问题都不能解决。</li>
<li>不能解决问题 2 和 3</li>
<li>解决问题 4 ：获得 5 分<br>总得分为：2 + 5 &#x3D; 7 。没有别的办法获得 7 分或者多于 7 分。</li>
</ul>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>这题需要决定在每个问题上是“解决”还是“跳过” 如果选择解决问题 i 我们将会获得 pointsi 的分数 但接下来的 brainpoweri 个问题会被跳过 如果我们选择跳过问题 i 则直接考虑下一个问题<br>目标是找到能获得的最高分数</p>
<p>使用动态规划<br>设dp[i]是从第i个问题开始 能获得最高分<br>对于每个问题 i 有两种选择</p>
<div class="tabs" id="tab-choice"><ul class="nav-tabs"><li class="tab active"><a class="#choice-1">选择一</a></li><li class="tab"><a class="#choice-2">选择二</a></li></ul><div class="tab-content"><div class="tab-pane active" id="choice-1"><p><strong>解决问题i</strong></p>
<p>可以获得 pointsi 的分数 但需要跳过接下来的 brainpoweri 个问题 因此，总分数为：</p>
<blockquote>
<p>pointsi + dp[i + brainpoweri + 1]</p>
</blockquote>
<p>其中  i + brainpoweri + 1 是下一个可以解决的问题索引 如果其超出了数组范围 则 dp[i + brainpoweri + 1] &#x3D; 0</p></div><div class="tab-pane" id="choice-2"><p><strong>跳过问题i</strong></p>
<p> 不解决问题 i 直接考虑下一个问题 i+1 总分数为：<br> dp[i + 1]</p></div></div></div>

<p>因此 我们要选择两者的最大值</p>
<blockquote>
<p>dp[i] &#x3D; max(pointsi + dp[i + brainpoweri + 1],  dp[i + 1])</p>
</blockquote>
<p>当 i &gt;&#x3D; n（超出数组范围时）dp[i] &#x3D; 0<br>当 i + brainpoweri + 1 &gt;&#x3D; n dp[i + brainpoweri + 1] &#x3D; 0<br>因此最终结果为dp[0] 我们永远要从第一个问题开始才能能获得最高分</p>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def mostPoints(questions):</span><br><span class="line">    n = len(questions)</span><br><span class="line">    dp = [0] * (n + 1)  <span class="comment"># 初始化 dp 数组，长度为 n+1，dp[n] = 0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 从后往前填充 dp 数组</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n - 1, -1, -1):</span><br><span class="line">        points, brainpower = questions[i]</span><br><span class="line">        j = i + brainpower + 1  <span class="comment"># 下一个可以解决的问题索引</span></span><br><span class="line">        <span class="keyword">if</span> j &lt; n:</span><br><span class="line">            solved = points + dp[j]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            solved = points  <span class="comment"># 如果 j 超出范围，则没有后续问题</span></span><br><span class="line">        </span><br><span class="line">        skipped = dp[i + 1]  <span class="comment"># 跳过当前问题的分数</span></span><br><span class="line">        </span><br><span class="line">        dp[i] = max(solved, skipped)  <span class="comment"># 取最大值</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">return</span> dp[0]  <span class="comment"># 返回从第一个问题开始的最大分数</span></span><br></pre></td></tr></table></figure></div>

<p>怎么样 解决了你的智力问题吗^_^</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>力扣</tag>
      </tags>
  </entry>
  <entry>
    <title>有序三元组中的最大值 I</title>
    <url>/zhihaojiang.github.io/2025/04/02/20250402%E6%9C%89%E5%BA%8F%E4%B8%89%E5%85%83%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC%20I/</url>
    <content><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给你一个下标从 0 开始的整数数组 nums 。</p>
<p>请你从所有满足 i &lt; j &lt; k 的下标三元组 (i, j, k) 中，找出并返回下标三元组的最大值。如果所有满足条件的三元组的值都是负数，则返回 0 。</p>
<p>下标三元组 (i, j, k) 的值等于 (nums[i] - nums[j]) * nums[k] 。</p>
<p>示例 1：</p>
<blockquote>
<p>输入：nums &#x3D; [12,6,1,2,7]<br>输出：77<br>解释：下标三元组 (0, 2, 4) 的值是 (nums[0] - nums[2]) * nums[4] &#x3D; 77 。<br>可以证明不存在值大于 77 的有序下标三元组。</p>
</blockquote>
<p>示例 2：</p>
<blockquote>
<p>输入：nums &#x3D; [1,10,3,4,19]<br>输出：133<br>解释：下标三元组 (1, 2, 4) 的值是 (nums[1] - nums[2]) * nums[4] &#x3D; 133 。<br>可以证明不存在值大于 133 的有序下标三元组。 </p>
</blockquote>
<p>示例 3：</p>
<blockquote>
<p>输入：nums &#x3D; [1,2,3]<br>输出：0<br>解释：唯一的下标三元组 (0, 1, 2) 的值是一个负数，(nums[0] - nums[1]) * nums[2] &#x3D; -3 。因此，答案是 0 。</p>
</blockquote>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><div class="tabs" id="tab-first-unique-name"><ul class="nav-tabs"><li class="tab active"><a class="#first-unique-name-1">方法一</a></li><li class="tab"><a class="#first-unique-name-2">方法二</a></li></ul><div class="tab-content"><div class="tab-pane active" id="first-unique-name-1"><p><strong>暴力枚举</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maximumTripletValue(self, nums):</span><br><span class="line">        n = len(nums)   <span class="comment">#把数组长度赋值给n</span></span><br><span class="line">        result = 0  <span class="comment">#初始化result</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):  <span class="comment">#暴力枚举 3层for循环</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i + 1,n):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> range(j + 1,n):</span><br><span class="line">                    <span class="keyword">if</span> (nums[i] - nums[j]) * nums[k] &gt; result:</span><br><span class="line">                        result = (nums[i] - nums[j]) * nums[k]  <span class="comment">#找出最大值</span></span><br><span class="line">        <span class="keyword">if</span> result &lt; 0:  <span class="comment">#判断结果是否都为负数</span></span><br><span class="line">            <span class="built_in">return</span> 0</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">return</span> result</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="first-unique-name-2"><p><strong>贪心</strong></p>
 <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maximumTripletValue(self, nums: List[int]) -&gt; int:</span><br><span class="line">        n = len(nums)</span><br><span class="line">        res, imax, dmax = 0, 0, 0</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(n):</span><br><span class="line">            res = max(res, dmax * nums[k])</span><br><span class="line">            dmax = max(dmax, imax - nums[k])</span><br><span class="line">            imax = max(imax, nums[k])</span><br><span class="line">        <span class="built_in">return</span> res</span><br><span class="line"></span><br><span class="line">作者：力扣官方题解</span><br><span class="line">链接：https://leetcode.cn/problems/maximum-value-of-an-ordered-triplet-i/solutions/3610891/you-xu-san-yuan-zu-zhong-de-zui-da-zhi-i-y6zb/</span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure></div></div></div></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>力扣</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习数据分析helper</title>
    <url>/zhihaojiang.github.io/2025/04/07/20250407%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90helper/</url>
    <content><![CDATA[<p>数据分析是一个循环迭代的过程，主要步骤如下：</p>
<ol>
<li>明确问题 ：定义目标和需求。</li>
<li>数据收集 ：获取相关数据。</li>
<li>数据清洗 ：处理缺失值、异常值等问题。</li>
<li>数据探索 ：理解数据特性。</li>
<li>特征工程 ：提取和优化特征。</li>
<li>模型选择与训练 ：构建和训练模型。</li>
<li>模型评估 ：验证模型性能。</li>
<li>结果解释与可视化 ：呈现分析结果。</li>
<li>部署与监控 ：应用到实际场景。</li>
<li>反馈与迭代 ：持续改进。</li>
</ol>
<h2 id="基本库"><a href="#基本库" class="headerlink" title="基本库"></a>基本库</h2><h3 id="最基础的库"><a href="#最基础的库" class="headerlink" title="最基础的库"></a>最基础的库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure></div>

<h3 id="MacOS中文显示库"><a href="#MacOS中文显示库" class="headerlink" title="MacOS中文显示库"></a>MacOS中文显示库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">MacOS专用字体设置</span></span><br><span class="line"><span class="string">MacOS 系统中使用的中文字体路径</span></span><br><span class="line"><span class="string">适用于MacOS15版本</span></span><br><span class="line"><span class="string">可直接复制到代码中使用</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib import font_manager</span><br><span class="line"><span class="comment"># 设置字体路径</span></span><br><span class="line">font_path = <span class="string">&#x27;/System/Library/Fonts/STHeiti Medium.ttc&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载字体</span></span><br><span class="line">my_font = font_manager.FontProperties(fname=font_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = my_font.get_name()</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = False  <span class="comment"># 正确显示负号</span></span><br></pre></td></tr></table></figure></div>
<h3 id="画图库"><a href="#画图库" class="headerlink" title="画图库"></a>画图库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure></div>

<h3 id="机器学习库"><a href="#机器学习库" class="headerlink" title="机器学习库"></a>机器学习库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line">from sklearn.metrics import mean_squared_error,r2_score</span><br></pre></td></tr></table></figure></div>
<p>sklearn库有很多 需要什么就import什么<br>不要直接import整个库</p>
<h2 id="浏览数据"><a href="#浏览数据" class="headerlink" title="浏览数据"></a>浏览数据</h2><h3 id="阅读数据"><a href="#阅读数据" class="headerlink" title="阅读数据"></a>阅读数据</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;data.csv&#x27;</span>)  <span class="comment">#打开data.csv文件</span></span><br><span class="line">data.head   <span class="comment">#浏览前5行</span></span><br></pre></td></tr></table></figure></div>

<h3 id="查看数据信息"><a href="#查看数据信息" class="headerlink" title="查看数据信息"></a>查看数据信息</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">diabetes.describe() <span class="comment">#查看数据的统计信息 如最大值 最小值 均值等</span></span><br><span class="line">diabetes.info() <span class="comment">#查看数据信息 如字段名 字段类型</span></span><br></pre></td></tr></table></figure></div>

<h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><h3 id="通用-subplot-模板（可自定义图表类型）："><a href="#通用-subplot-模板（可自定义图表类型）：" class="headerlink" title="通用 subplot 模板（可自定义图表类型）："></a>通用 subplot 模板（可自定义图表类型）：</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选出要绘图的列（比如数值型列，或你指定的一组列）</span></span><br><span class="line">plot_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> <span class="built_in">df</span>[col].dtype <span class="keyword">in</span> [<span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>]]</span><br><span class="line"><span class="comment"># plot_cols = [&#x27;col1&#x27;, &#x27;col2&#x27;, &#x27;col3&#x27;]  # 或者你手动指定</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 subplot 的行列数（每行几个图）</span></span><br><span class="line">n_cols = 2</span><br><span class="line">n_rows = math.ceil(len(plot_cols) / n_cols)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建子图网格</span></span><br><span class="line">fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows))</span><br><span class="line">axes = axes.flatten()  <span class="comment"># 保证是 1D，方便遍历</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历每个列，绘制你想要的图</span></span><br><span class="line"><span class="keyword">for</span> i, col <span class="keyword">in</span> enumerate(plot_cols):</span><br><span class="line">    ax = axes[i]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可以自定义图表类型的部分（替换这里）</span></span><br><span class="line">    <span class="comment"># 示例：绘制箱线图</span></span><br><span class="line">    sns.boxplot(data=<span class="built_in">df</span>, x=<span class="string">&#x27;Country&#x27;</span>, y=col, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 示例：绘制散点图（替换上面一行即可）</span></span><br><span class="line">    <span class="comment"># sns.scatterplot(data=df, x=&#x27;Country&#x27;, y=col, ax=ax)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 示例：绘制折线图（如果是时间序列）</span></span><br><span class="line">    <span class="comment"># sns.lineplot(data=df, x=&#x27;Date&#x27;, y=col, ax=ax)</span></span><br><span class="line"></span><br><span class="line">    ax.set_title(col)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, rotation=45)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除多余的子图</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(i+1, len(axes)):</span><br><span class="line">    fig.delaxes(axes[j])</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<h3 id="subplot-模板"><a href="#subplot-模板" class="headerlink" title="subplot 模板"></a>subplot 模板</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 2x2 的画布，共4个子图</span></span><br><span class="line">fig, axes = plt.subplots(2, 2, figsize=(12, 8))  <span class="comment"># 2行2列，画布大小可调</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第1个子图（左上）</span></span><br><span class="line">ax1 = axes[0, 0]</span><br><span class="line"><span class="comment"># TODO: 在这里画图，例如：ax1.plot(...) / sns.violinplot(ax=ax1, ...)</span></span><br><span class="line">ax1.set_title(<span class="string">&quot;子图 1：图的说明&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第2个子图（右上）</span></span><br><span class="line">ax2 = axes[0, 1]</span><br><span class="line"><span class="comment"># TODO: 在这里画图</span></span><br><span class="line">ax2.set_title(<span class="string">&quot;子图 2：图的说明&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第3个子图（左下）</span></span><br><span class="line">ax3 = axes[1, 0]</span><br><span class="line"><span class="comment"># TODO: 在这里画图</span></span><br><span class="line">ax3.set_title(<span class="string">&quot;子图 3：图的说明&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第4个子图（右下）</span></span><br><span class="line">ax4 = axes[1, 1]</span><br><span class="line"><span class="comment"># TODO: 在这里画图</span></span><br><span class="line">ax4.set_title(<span class="string">&quot;子图 4：图的说明&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动调整子图间距，防止标题/坐标轴重叠</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<h3 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h3><p>matlab库</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = data[<span class="string">&quot;x&quot;</span>]</span><br><span class="line">y = data[<span class="string">&quot;y&quot;</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;title&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<h3 id="相关性分析"><a href="#相关性分析" class="headerlink" title="相关性分析"></a>相关性分析</h3><p>相关性矩阵</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = data[<span class="string">&#x27;target&#x27;</span>]  <span class="comment">#填入要进行分析的结果列 通常为最后一列</span></span><br><span class="line">X = diabetes.drop([<span class="string">&#x27;target&#x27;</span>, <span class="string">&#x27;others&#x27;</span>], axis=1) <span class="comment">#去除结果列和字符列（如果有）</span></span><br><span class="line"><span class="comment">#通常string类型的列（离散的特性）进行调整成int类型（连续化）即离散特征连续化</span></span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">correlation_matrix = pd.concat([X_train, y_train], axis=1).corr()</span><br><span class="line"></span><br><span class="line">sns.heatmap(correlation_matrix, annot=True, cmap=<span class="string">&#x27;coolwarm&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h3><div class="tabs" id="tab-001"><ul class="nav-tabs"><li class="tab active"><a class="#001-1">删除含有缺失值的行</a></li><li class="tab"><a class="#001-2">使用均值填充缺失值</a></li><li class="tab"><a class="#001-3">使用众数填充缺失值</a></li><li class="tab"><a class="#001-4">使用分位数填充缺失值</a></li></ul><div class="tab-content"><div class="tab-pane active" id="001-1"><p><strong>删除含有缺失值的行</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">data_cleaned = df.dropna()</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="001-2"><p><strong>使用均值填充缺失值</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_filled = df.fillna(df.mean())</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="001-3"><p><strong>使用众数填充缺失值</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [1, 2, 2, None, 4, 2], <span class="string">&#x27;B&#x27;</span>: [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, None, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>]&#125;</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到每列的众数</span></span><br><span class="line">mode_A = <span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>].mode()[0]  <span class="comment"># 数值型列</span></span><br><span class="line">mode_B = <span class="built_in">df</span>[<span class="string">&#x27;B&#x27;</span>].mode()[0]  <span class="comment"># 类别型列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用众数填充缺失值</span></span><br><span class="line">df_filled_mode = df.fillna(&#123;<span class="string">&#x27;A&#x27;</span>: mode_A, <span class="string">&#x27;B&#x27;</span>: mode_B&#125;)</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="001-4"><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = &#123;<span class="string">&#x27;C&#x27;</span>: [1, 2, 3, None, 5, 6, None]&#125;</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算指定分位数</span></span><br><span class="line">quantile_25 = <span class="built_in">df</span>[<span class="string">&#x27;C&#x27;</span>].quantile(0.25)  <span class="comment"># 第一四分位数 (25%)</span></span><br><span class="line">quantile_50 = <span class="built_in">df</span>[<span class="string">&#x27;C&#x27;</span>].quantile(0.50)  <span class="comment"># 中位数 (50%)</span></span><br><span class="line">quantile_75 = <span class="built_in">df</span>[<span class="string">&#x27;C&#x27;</span>].quantile(0.75)  <span class="comment"># 第三四分位数 (75%)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用分位数填充缺失值</span></span><br><span class="line">df_filled_quantile_25 = df.fillna(&#123;<span class="string">&#x27;C&#x27;</span>: quantile_25&#125;)</span><br><span class="line">df_filled_quantile_50 = df.fillna(&#123;<span class="string">&#x27;C&#x27;</span>: quantile_50&#125;)</span><br><span class="line">df_filled_quantile_75 = df.fillna(&#123;<span class="string">&#x27;C&#x27;</span>: quantile_75&#125;)</span><br></pre></td></tr></table></figure></div></div></div></div>


<h3 id="处理异常值"><a href="#处理异常值" class="headerlink" title="处理异常值"></a>处理异常值</h3><h4 id="异常值检测"><a href="#异常值检测" class="headerlink" title="异常值检测"></a>异常值检测</h4><div class="tabs" id="tab-异常值检测"><ul class="nav-tabs"><li class="tab active"><a class="#异常值检测-1">使用 Z-Score 检测</a></li><li class="tab"><a class="#异常值检测-2">使用 IQR 方法检测</a></li><li class="tab"><a class="#异常值检测-3">使用可视化方法检测</a></li></ul><div class="tab-content"><div class="tab-pane active" id="异常值检测-1"><p><strong>使用 Z-Score 检测</strong></p>
<p> Z-Score 衡量某个值距离均值的标准差数量。通常，绝对 Z-Score 大于 3 的值被认为是异常值。<br> <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [1, 2, 3, 4, 5, 100]&#125;</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 Z-Score</span></span><br><span class="line">mean = <span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>].mean()</span><br><span class="line">std = <span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>].std()</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Z-Score&#x27;</span>] = (<span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>] - mean) / std</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测异常值（Z-Score &gt; 3 或 &lt; -3）</span></span><br><span class="line">outliers = <span class="built_in">df</span>[abs(<span class="built_in">df</span>[<span class="string">&#x27;Z-Score&#x27;</span>]) &gt; 3]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;异常值：\n&quot;</span>, outliers)</span><br></pre></td></tr></table></figure></div></p></div><div class="tab-pane" id="异常值检测-2"><p><strong>使用 IQR 方法检测</strong></p>
<p>IQR（四分位距）是第三四分位数（Q3）与第一四分位数（Q1）的差值。通常，低于 Q1−1.5×IQR 或高于 Q3+1.5×IQR 的值被认为是异常值。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [1, 2, 3, 4, 5, 100]&#125;</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 IQR</span></span><br><span class="line">Q1 = <span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>].quantile(0.25)</span><br><span class="line">Q3 = <span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>].quantile(0.75)</span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义上下界</span></span><br><span class="line">lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测异常值</span></span><br><span class="line">outliers = <span class="built_in">df</span>[(<span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>] &lt; lower_bound) | (<span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>] &gt; upper_bound)]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;异常值：\n&quot;</span>, outliers)</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="异常值检测-3"><p><strong>This is Tab 3.</strong></p>
<p>箱线图（Box Plot）是一种直观的异常值检测工具。<br>箱线图中的点位于箱子外部的上界或下界之外，这些点即为异常值。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制箱线图</span></span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Box Plot of Data&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div></div></div></div>

<h4 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h4><div class="tabs" id="tab-异常值处理方法"><ul class="nav-tabs"><li class="tab active"><a class="#异常值处理方法-1">删除异常值</a></li><li class="tab"><a class="#异常值处理方法-2">替换异常值</a></li><li class="tab"><a class="#异常值处理方法-3">胜率变换</a></li></ul><div class="tab-content"><div class="tab-pane active" id="异常值处理方法-1"><p><strong>删除异常值</strong><br>直接从数据集中移除异常值。<br> <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"> <span class="comment"># 删除基于 IQR 方法检测到的异常值</span></span><br><span class="line">filtered_df = <span class="built_in">df</span>[(<span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>] &gt;= lower_bound) &amp; (<span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>] &lt;= upper_bound)]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;删除异常值后的数据：\n&quot;</span>, filtered_df)</span><br></pre></td></tr></table></figure></div></p></div><div class="tab-pane" id="异常值处理方法-2"><p><strong>替换异常值</strong></p>
<p>将异常值替换为合理的值，例如均值、中位数或边界值。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将异常值替换为中位数</span></span><br><span class="line">median = <span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>].median()</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>] = np.where((df[&#x27;A&#x27;] &lt; lower_bound) | (df[&#x27;A&#x27;] &gt; upper_bound), median, df[&#x27;A&#x27;])</span><br><span class="line"></span><br><span class="line">print(&quot;替换异常值后的数据：\n&quot;, df)</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="异常值处理方法-3"><p><strong>胜率变换</strong></p>
<p>将异常值限制在一定范围内，而不是完全删除或替换。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy.stats import mstats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 胜率变换：将异常值限制在 5% 和 95% 分位数之间</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;A_winsorized&#x27;</span>] = mstats.winsorize(<span class="built_in">df</span>[<span class="string">&#x27;A&#x27;</span>], limits=[0.05, 0.05])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;胜率变换后的数据：\n&quot;</span>, <span class="built_in">df</span>)</span><br></pre></td></tr></table></figure></div></div></div></div>

<h3 id="数据标准化与归一化"><a href="#数据标准化与归一化" class="headerlink" title="数据标准化与归一化"></a>数据标准化与归一化</h3><h4 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h4><p>将数据转换为零均值（Mean &#x3D; 0）和单位方差（Variance &#x3D; 1）</p>
<ul>
<li>适用于数据分布接近正态分布的情况 ：标准化假设数据服从正态分布，因此在数据分布大致对称时效果更好。</li>
<li>适用于对距离敏感的算法 ：例如 K-Means、KNN、SVM 和神经网络等。这些算法对特征的尺度非常敏感，标准化可以确保每个特征对结果的贡献是均衡的。</li>
<li>适用于梯度下降优化的模型 ：如线性回归、逻辑回归等。标准化可以使梯度下降更快收敛。</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler, MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = [[1, 2], [3, 4], [5, 6]]</span><br><span class="line">X = pd.DataFrame(data, columns=[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_standardized = scaler.fit_transform(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;标准化后的数据：\n&quot;</span>, X_standardized)</span><br></pre></td></tr></table></figure></div>

<h4 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h4><p>将数据缩放到指定范围（通常是 [0, 1] 或 [-1, 1]）</p>
<ul>
<li>适用于数据分布未知或非正态分布的情况 ：归一化不要求数据服从正态分布，因此适用于分布不规则的数据。</li>
<li>适用于最大值和最小值明确的场景 ：例如图像像素值通常在 [0, 255] 范围内，归一化可以将其缩放到 [0, 1]。</li>
<li>适用于距离计算或相似性度量的算法 ：例如余弦相似度、基于距离的聚类算法等。归一化可以避免大值特征主导结果。</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler, MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = [[1, 2], [3, 4], [5, 6]]</span><br><span class="line">X = pd.DataFrame(data, columns=[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化</span></span><br><span class="line">minmax_scaler = MinMaxScaler()</span><br><span class="line">X_normalized = minmax_scaler.fit_transform(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;归一化后的数据：\n&quot;</span>, X_normalized)</span><br></pre></td></tr></table></figure></div>

<h3 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h3><p>特征编码（Feature Encoding）是将非数值型特征（如类别型、文本型数据）转换为数值型表示的过程。它是机器学习中数据预处理的重要步骤，因为大多数机器学习算法只能处理数值型数据。</p>
<div class="tabs" id="tab-常见的特征编码方法"><ul class="nav-tabs"><li class="tab active"><a class="#常见的特征编码方法-1">标签编码</a></li><li class="tab"><a class="#常见的特征编码方法-2">独热编码</a></li><li class="tab"><a class="#常见的特征编码方法-3">目标编码</a></li></ul><div class="tab-content"><div class="tab-pane active" id="常见的特征编码方法-1"><p>将类别型变量映射为整数（如 “red” → 0, “blue” → 1, “green” → 2）。<br>适用场景 ：类别之间具有顺序关系（如 “low”, “medium”, “high”）。<br>优点 ：简单高效，适用于少量类别的情况。<br>缺点 ：可能导致模型误以为类别之间有数值上的大小关系。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>]</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">encoded_data = le.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;标签编码结果：&quot;</span>, encoded_data)</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="常见的特征编码方法-2"><p>将每个类别值转换为一个二进制向量。<br>适用场景 ：类别之间没有顺序关系（如 “red”, “blue”, “green”）。<br>优点 ：消除了类别间的数值关系，适合无序类别。<br>缺点 ：可能会导致维度爆炸（类别数量过多时生成的特征维度过大）。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>]</span><br><span class="line">ohe = OneHotEncoder(sparse=False)</span><br><span class="line">encoded_data = ohe.fit_transform(pd.DataFrame(data))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;独热编码结果：\n&quot;</span>, encoded_data)</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="常见的特征编码方法-3"><p>使用目标变量的统计信息（如均值）对类别变量进行编码。<br>适用场景 ：类别数量较多且数据量较大时，避免维度爆炸问题。<br>优点 ：保留了类别与目标变量的关系。<br>缺点 ：可能导致过拟合，需注意平滑处理。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = &#123;<span class="string">&#x27;category&#x27;</span>: [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>], <span class="string">&#x27;target&#x27;</span>: [1, 0, 1, 1, 0]&#125;</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个类别的目标均值</span></span><br><span class="line">target_mean = df.groupby(<span class="string">&#x27;category&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean()</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;target_encoded&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;category&#x27;</span>].map(target_mean)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;目标编码结果：\n&quot;</span>, <span class="built_in">df</span>)</span><br></pre></td></tr></table></figure></div></div></div></div>

<h3 id="特征选择与降维"><a href="#特征选择与降维" class="headerlink" title="特征选择与降维"></a>特征选择与降维</h3><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><p>特征选择是从原始特征集中选择最重要的子集，从而减少无关或冗余特征对模型的影响。</p>
<p>减少过拟合 ：通过去除无关特征，降低模型复杂度。<br>提高训练效率 ：减少特征数量可以加速模型训练。<br>增强可解释性 ：保留关键特征有助于理解模型的工作机制。</p>
<p>根据特征选择的方式，可分为以下三类：</p>
<div class="tabs" id="tab-特征选择"><ul class="nav-tabs"><li class="tab active"><a class="#特征选择-1">过滤法</a></li><li class="tab"><a class="#特征选择-2">包装法</a></li><li class="tab"><a class="#特征选择-3">嵌入法</a></li></ul><div class="tab-content"><div class="tab-pane active" id="特征选择-1"><p>根据统计指标（如相关性、互信息等）独立评估每个特征的重要性。<br>不依赖于具体模型。<br>优点 ：计算简单，速度快。<br>缺点 ：可能忽略特征之间的交互关系。</p>
<blockquote>
<p>示例 ：<br>相关系数（Pearson、Spearman）<br>卡方检验<br>互信息</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectKBest, chi2</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">X, y = load_iris(return_X_y=True)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用卡方检验选择前 2 个最佳特征</span></span><br><span class="line">selector = SelectKBest(chi2, k=2)</span><br><span class="line">X_new = selector.fit_transform(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择后的特征形状：&quot;</span>, X_new.shape)</span><br></pre></td></tr></table></figure></div></div><div class="tab-pane" id="特征选择-2"><p>通过反复训练模型来评估特征子集的表现。<br>常用算法：递归特征消除（RFE）。<br>优点 ：考虑特征之间的交互关系。<br>缺点 ：计算成本高。</p>
<blockquote>
<p>示例 ：<br>RFE（Recursive Feature Elimination）</p>
 <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"> from sklearn.feature_selection import RFE</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line">rfe = RFE(model, n_features_to_select=2)</span><br><span class="line">X_new = rfe.fit_transform(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择后的特征形状：&quot;</span>, X_new.shape)</span><br></pre></td></tr></table></figure></div></blockquote></div><div class="tab-pane" id="特征选择-3"><p>在模型训练过程中自动选择重要特征。<br>常用算法：Lasso 回归、树模型（如随机森林、XGBoost）。<br>优点 ：结合了模型训练和特征选择。<br>缺点 ：依赖于具体模型。</p>
<blockquote>
<p>示例 ：<br>Lasso 回归（基于 L1 正则化） </p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import Lasso</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 Lasso 回归进行特征选择</span></span><br><span class="line">lasso = Lasso(alpha=0.1)</span><br><span class="line">lasso.fit(X, y)</span><br><span class="line">selected_features = [i <span class="keyword">for</span> i, coef <span class="keyword">in</span> enumerate(lasso.coef_) <span class="keyword">if</span> coef != 0]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征索引：&quot;</span>, selected_features)</span><br></pre></td></tr></table></figure></div></div></div></div>
<h4 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h4><p>将数据投影到方差最大的方向上。<br>优点 ：线性变换，计算高效。<br>缺点 ：仅适用于线性可分的数据。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.decomposition import PCA</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 PCA 降维到 2 维</span></span><br><span class="line">pca = PCA(n_components=2)</span><br><span class="line">X_pca = pca.fit_transform(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;降维后的数据形状：&quot;</span>, X_pca.shape)</span><br></pre></td></tr></table></figure></div>


<h2 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h2><h3 id="分离特征和目标变量"><a href="#分离特征和目标变量" class="headerlink" title="分离特征和目标变量"></a>分离特征和目标变量</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 假设 &#x27;target&#x27; 是目标变量列名</span></span><br><span class="line">X = data.drop(columns=[<span class="string">&#x27;target&#x27;</span>])  <span class="comment"># 特征</span></span><br><span class="line">y = data[<span class="string">&#x27;target&#x27;</span>]  <span class="comment"># 目标变量</span></span><br></pre></td></tr></table></figure></div>
<h3 id="数据划分-1"><a href="#数据划分-1" class="headerlink" title="数据划分"></a>数据划分</h3><p>将数据划分为训练集和测试集</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集大小：&quot;</span>, X_train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集大小：&quot;</span>, X_test.shape)</span><br></pre></td></tr></table></figure></div>

<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="sklearn-中的常用二分类模型代码示例"><a href="#sklearn-中的常用二分类模型代码示例" class="headerlink" title="sklearn 中的常用二分类模型代码示例"></a>sklearn 中的常用二分类模型代码示例</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line">from sklearn.neural_network import MLPClassifier</span><br><span class="line"></span><br><span class="line">models = &#123;</span><br><span class="line">    <span class="string">&quot;Logistic Regression&quot;</span>: LogisticRegression(),</span><br><span class="line">    <span class="string">&quot;SVM&quot;</span>: SVC(),</span><br><span class="line">    <span class="string">&quot;Random Forest&quot;</span>: RandomForestClassifier(),</span><br><span class="line">    <span class="string">&quot;KNN&quot;</span>: KNeighborsClassifier(),</span><br><span class="line">    <span class="string">&quot;Naive Bayes&quot;</span>: GaussianNB(),</span><br><span class="line">    <span class="string">&quot;MLP Neural Net&quot;</span>: MLPClassifier()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="模型标准化-训练-优化模版"><a href="#模型标准化-训练-优化模版" class="headerlink" title="模型标准化+训练+优化模版"></a>模型标准化+训练+优化模版</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import StandardScaler            <span class="comment"># ✅ 可换成 MinMaxScaler、RobustScaler 等</span></span><br><span class="line">from sklearn.svm import SVC                                  <span class="comment"># ✅ 可换成 LogisticRegression, RandomForestClassifier, etc.</span></span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 第1处：构建Pipeline步骤</span></span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler()),                           <span class="comment"># 标准化步骤（可删、可换）</span></span><br><span class="line">    (<span class="string">&#x27;svm&#x27;</span>, SVC())                                           <span class="comment"># 模型步骤（可换）</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 第2处：定义参数网格</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;svm__C&#x27;</span>: [0.1, 1, 10],                                  <span class="comment"># 可调SVM的 C 值范围</span></span><br><span class="line">    <span class="string">&#x27;svm__kernel&#x27;</span>: [<span class="string">&#x27;linear&#x27;</span>, <span class="string">&#x27;rbf&#x27;</span>],                        <span class="comment"># 可选 kernel 类型</span></span><br><span class="line">    <span class="string">&#x27;svm__gamma&#x27;</span>: [<span class="string">&#x27;scale&#x27;</span>, <span class="string">&#x27;auto&#x27;</span>]                          <span class="comment"># 适用于 rbf kernel</span></span><br><span class="line">    <span class="comment"># 替换模型时需要换成对应模型参数名，例如：</span></span><br><span class="line">    <span class="comment"># &#x27;logreg__penalty&#x27;: [&#x27;l2&#x27;], </span></span><br><span class="line">    <span class="comment"># &#x27;logreg__C&#x27;: [0.01, 0.1, 1, 10]</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 第3处：GridSearchCV 封装 Pipeline</span></span><br><span class="line">grid_search = GridSearchCV(pipeline, param_grid, cv=5)       <span class="comment"># cv 可改为 3/10 或 StratifiedKFold 等</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 第4处：训练</span></span><br><span class="line">grid_search.fit(X_train, y_train)                            <span class="comment"># 训练数据输入（确保已经分好训练集）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 第5处：结果查看</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最优参数:&quot;</span>, grid_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最优交叉验证得分:&quot;</span>, grid_search.best_score_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 第6处：在测试集上做预测</span></span><br><span class="line">y_pred = grid_search.predict(X_test)</span><br></pre></td></tr></table></figure></div>
<h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="准确率"><a href="#准确率" class="headerlink" title="准确率"></a>准确率</h3><p>准确率是指模型预测正确的样本占总样本的比例。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = [0, 1, 1, 0, 1]</span><br><span class="line">y_pred = [0, 1, 0, 0, 1]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率：&quot;</span>, accuracy)</span><br></pre></td></tr></table></figure></div>
<h3 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h3><p>混淆矩阵是一个表格，用于总结分类模型的预测结果。</p>
<blockquote>
<p>常见术语：<br>TP（True Positive）：正类正确预测为正类。<br>TN（True Negative）：负类正确预测为负类。<br>FP（False Positive）：负类错误预测为正类。<br>FN（False Negative）：正类错误预测为负类。</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = [0, 1, 1, 0, 1]</span><br><span class="line">y_pred = [0, 1, 0, 0, 1]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算混淆矩阵</span></span><br><span class="line">cm = confusion_matrix(y_true, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化混淆矩阵</span></span><br><span class="line">sns.heatmap(cm, annot=True, <span class="built_in">fmt</span>=<span class="string">&#x27;d&#x27;</span>, cmap=<span class="string">&#x27;Blues&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted Labels&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Labels&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<h3 id="召回率"><a href="#召回率" class="headerlink" title="召回率"></a>召回率</h3><p>召回率（也称灵敏度或 True Positive Rate）是指模型正确预测为正类的样本占实际正类的比例。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import recall_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = [0, 1, 1, 0, 1]</span><br><span class="line">y_pred = [0, 1, 0, 0, 1]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算召回率</span></span><br><span class="line">recall = recall_score(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;召回率：&quot;</span>, recall)</span><br></pre></td></tr></table></figure></div>

<h3 id="精确率"><a href="#精确率" class="headerlink" title="精确率"></a>精确率</h3><p>精确率是指模型预测为正类的样本中实际为正类的比例。</p>
<blockquote>
<p>适用场景<br>关注减少误报时使用（如推荐系统）。</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import precision_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = [0, 1, 1, 0, 1]</span><br><span class="line">y_pred = [0, 1, 0, 0, 1]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算精确率</span></span><br><span class="line">precision = precision_score(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;精确率：&quot;</span>, precision)</span><br></pre></td></tr></table></figure></div>

<h3 id="F1-分数"><a href="#F1-分数" class="headerlink" title="F1 分数"></a>F1 分数</h3><p>F1 分数是精确率和召回率的调和平均值，用于综合衡量模型性能。</p>
<blockquote>
<p>适用场景<br>类别不平衡时使用。</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = [0, 1, 1, 0, 1]</span><br><span class="line">y_pred = [0, 1, 0, 0, 1]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 F1 分数</span></span><br><span class="line">f1 = f1_score(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;F1 分数：&quot;</span>, f1)</span><br></pre></td></tr></table></figure></div>

<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>AUC 是 ROC 曲线下的面积，用于衡量模型区分正负类的能力。<br>范围：[0, 1]，值越大表示模型性能越好。</p>
<blockquote>
<p>适用场景<br>需要评估模型整体性能时使用。</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = [0, 1, 1, 0, 1]</span><br><span class="line">y_scores = [0.1, 0.9, 0.8, 0.2, 0.7]  <span class="comment"># 模型预测的概率值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 AUC</span></span><br><span class="line">auc = roc_auc_score(y_true, y_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;AUC：&quot;</span>, auc)</span><br></pre></td></tr></table></figure></div>

<h3 id="均方误差-均方根误差-R²-决定系数"><a href="#均方误差-均方根误差-R²-决定系数" class="headerlink" title="均方误差 均方根误差 R² 决定系数"></a>均方误差 均方根误差 R² 决定系数</h3><p>均方误差是预测值与真实值之间差值平方的平均值。</p>
<p>均方根误差是均方误差的平方根，用于将误差恢复到原始单位。</p>
<p>R² 决定系数衡量模型对数据的拟合程度，取值范围为 (−∞,1]。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = [3.0, -0.5, 2.0, 7.0]  <span class="comment"># 真实值</span></span><br><span class="line">y_pred = [2.5, 0.0, 2.0, 8.0]  <span class="comment"># 预测值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 MSE</span></span><br><span class="line">mse = mean_squared_error(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;均方误差（MSE）：&quot;</span>, mse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 RMSE</span></span><br><span class="line">rmse = np.sqrt(mse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;均方根误差（RMSE）：&quot;</span>, rmse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 MAE</span></span><br><span class="line">mae = mean_absolute_error(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;平均绝对误差（MAE）：&quot;</span>, mae)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 R²</span></span><br><span class="line">r2 = r2_score(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;R² 决定系数：&quot;</span>, r2)</span><br></pre></td></tr></table></figure></div>

<h2 id="综合案例"><a href="#综合案例" class="headerlink" title="综合案例"></a>综合案例</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV</span><br><span class="line">from sklearn.linear_model import LinearRegression, Ridge, Lasso</span><br><span class="line">from sklearn.preprocessing import StandardScaler, OneHotEncoder</span><br><span class="line">from sklearn.compose import ColumnTransformer</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设 data 是一个 Pandas DataFrame</span></span><br><span class="line"><span class="comment"># data = pd.read_csv(&#x27;data.csv&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">X = data.drop(columns=[<span class="string">&#x27;target&#x27;</span>])</span><br><span class="line">y = data[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line">numeric_features = X.select_dtypes(include=[<span class="string">&#x27;int64&#x27;</span>, <span class="string">&#x27;float64&#x27;</span>]).columns</span><br><span class="line">categorical_features = X.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>, <span class="string">&#x27;category&#x27;</span>]).columns</span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">    transformers=[</span><br><span class="line">        (<span class="string">&#x27;num&#x27;</span>, StandardScaler(), numeric_features),</span><br><span class="line">        (<span class="string">&#x27;cat&#x27;</span>, OneHotEncoder(), categorical_features)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">plt.figure(figsize=(8, 5))</span><br><span class="line">sns.histplot(y, kde=True, bins=30, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Target Variable Distribution&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型选择</span></span><br><span class="line">models = &#123;</span><br><span class="line">    <span class="string">&quot;Linear Regression&quot;</span>: Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor), (<span class="string">&#x27;regressor&#x27;</span>, LinearRegression())]),</span><br><span class="line">    <span class="string">&quot;Ridge Regression&quot;</span>: Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor), (<span class="string">&#x27;regressor&#x27;</span>, Ridge())]),</span><br><span class="line">    <span class="string">&quot;Lasso Regression&quot;</span>: Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor), (<span class="string">&#x27;regressor&#x27;</span>, Lasso())])</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">param_grid = &#123;<span class="string">&#x27;regressor__alpha&#x27;</span>: [0.01, 0.1, 1, 10, 100]&#125;</span><br><span class="line"><span class="keyword">for</span> model_name, model <span class="keyword">in</span> list(models.items())[1:]:</span><br><span class="line">    grid_search = GridSearchCV(model, param_grid, cv=5, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">    grid_search.fit(X_train, y_train)</span><br><span class="line">    models[model_name] = grid_search.best_estimator_</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;&#123;model_name&#125; 最佳参数：&quot;</span>, grid_search.best_params_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型验证</span></span><br><span class="line">results = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> model_name, model <span class="keyword">in</span> models.items():</span><br><span class="line">    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">    results[model_name] = -scores.mean()</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;&#123;model_name&#125; 的平均 MSE：&quot;</span>, results[model_name])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集评估</span></span><br><span class="line">best_model_name = min(results, key=results.get)</span><br><span class="line">best_model = models[best_model_name]</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;最佳模型：&#123;best_model_name&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">best_model.fit(X_train, y_train)</span><br><span class="line">y_pred = best_model.predict(X_test)</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;测试集 MSE：&#123;mse&#125;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;测试集 R²：&#123;r2&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line">plt.figure(figsize=(8, 6))</span><br><span class="line">plt.scatter(y_test, y_pred, alpha=0.7, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot([y.min(), y.max()], [y.min(), y.max()], <span class="string">&#x27;r--&#x27;</span>, lw=2)</span><br><span class="line">plt.title(<span class="string">&#x27;True vs Predicted Values&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">residuals = y_test - y_pred</span><br><span class="line">plt.figure(figsize=(8, 6))</span><br><span class="line">sns.histplot(residuals, kde=True, bins=30, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Residuals Distribution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>使数组元素互不相同所需的最少操作次数</title>
    <url>/zhihaojiang.github.io/2025/04/08/20250408%E4%BD%BF%E6%95%B0%E7%BB%84%E5%85%83%E7%B4%A0%E4%BA%92%E4%B8%8D%E7%9B%B8%E5%90%8C%E6%89%80%E9%9C%80%E7%9A%84%E6%9C%80%E5%B0%91%E6%93%8D%E4%BD%9C%E6%AC%A1%E6%95%B0/</url>
    <content><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给你一个整数数组 nums，你需要确保数组中的元素 互不相同 。为此，你可以执行以下操作任意次：</p>
<p>从数组的开头移除 3 个元素。如果数组中元素少于 3 个，则移除所有剩余元素。<br>注意：空数组也视作为数组元素互不相同。返回使数组元素互不相同所需的 最少操作次数 。</p>
<blockquote>
<p>示例 1：</p>
<p>输入： nums &#x3D; [1,2,3,4,2,3,3,5,7]</p>
<p>输出： 2</p>
<p>解释：</p>
<p>第一次操作：移除前 3 个元素，数组变为 [4, 2, 3, 3, 5, 7]。<br>第二次操作：再次移除前 3 个元素，数组变为 [3, 5, 7]，此时数组中的元素互不相同。<br>因此，答案是 2。</p>
<p>示例 2：</p>
<p>输入： nums &#x3D; [4,5,6,4,4]</p>
<p>输出： 2</p>
<p>解释：</p>
<p>第一次操作：移除前 3 个元素，数组变为 [4, 4]。<br>第二次操作：移除所有剩余元素，数组变为空。<br>因此，答案是 2。</p>
<p>示例 3：</p>
<p>输入： nums &#x3D; [6,7,8,9]</p>
<p>输出： 0</p>
<p>解释：</p>
<p>数组中的元素已经互不相同，因此不需要进行任何操作，答案是 0。</p>
</blockquote>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><p>采用倒序判断 arr为一个布尔数组 用于判断数字是否重复出现 是O(n)的时间复杂度</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def minimumOperations(self, nums):</span><br><span class="line">        n = len(nums)</span><br><span class="line">        arr = [False] * 128</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n - 1,-1 , -1):</span><br><span class="line">            <span class="keyword">if</span> arr[nums[i]]:</span><br><span class="line">                <span class="built_in">return</span> i // 3 + 1</span><br><span class="line">            arr[nums[i]] = True</span><br><span class="line">        <span class="built_in">return</span> 0</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>力扣</tag>
      </tags>
  </entry>
  <entry>
    <title>使数组的值全部为 K 的最少操作次数</title>
    <url>/zhihaojiang.github.io/2025/04/09/20250409%E4%BD%BF%E6%95%B0%E7%BB%84%E7%9A%84%E5%80%BC%E5%85%A8%E9%83%A8%E4%B8%BA%20K%20%E7%9A%84%E6%9C%80%E5%B0%91%E6%93%8D%E4%BD%9C%E6%AC%A1%E6%95%B0/</url>
    <content><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给你一个整数数组 nums 和一个整数 k 。</p>
<p>如果一个数组中所有 严格大于 h 的整数值都 相等 ，那么我们称整数 h 是 合法的 。</p>
<p>比方说，如果 nums &#x3D; [10, 8, 10, 8] ，那么 h &#x3D; 9 是一个 合法 整数，因为所有满足 nums[i] &gt; 9 的数都等于 10 ，但是 5 不是 合法 整数。</p>
<p>你可以对 nums 执行以下操作：</p>
<p>选择一个整数 h ，它对于 当前 nums 中的值是合法的。<br>对于每个下标 i ，如果它满足 nums[i] &gt; h ，那么将 nums[i] 变为 h 。<br>你的目标是将 nums 中的所有元素都变为 k ，请你返回 最少 操作次数。如果无法将所有元素都变 k ，那么返回 -1 。</p>
<blockquote>
<p>示例 1：</p>
<p>输入：nums &#x3D; [5,2,5,4,5], k &#x3D; 2</p>
<p>输出：2</p>
<p>解释：</p>
<p>依次选择合法整数 4 和 2 ，将数组全部变为 2 。</p>
<p>示例 2：</p>
<p>输入：nums &#x3D; [2,1,2], k &#x3D; 2</p>
<p>输出：-1</p>
<p>解释：</p>
<p>没法将所有值变为 2 。</p>
<p>示例 3：</p>
<p>输入：nums &#x3D; [9,7,5,3], k &#x3D; 1</p>
<p>输出：4</p>
<p>解释：</p>
<p>依次选择合法整数 7 ，5 ，3 和 1 ，将数组全部变为 1 。</p>
</blockquote>
<h2 id="解释题目"><a href="#解释题目" class="headerlink" title="解释题目"></a>解释题目</h2><p>异常情况: nums[i]&lt;k, 直接返回 −1<br>需要进行转换的元素: nums[i]&gt;k<br>无需转换的元素: nums[i]&#x3D;&#x3D;k</p>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def minOperations(self, nums, k):</span><br><span class="line">        n = len(nums)</span><br><span class="line">        s = <span class="built_in">set</span>([])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="keyword">if</span> nums[i] &lt; k:</span><br><span class="line">                <span class="built_in">return</span> -1</span><br><span class="line">            <span class="keyword">if</span> nums[i] != k:</span><br><span class="line">                s.add(nums[i])</span><br><span class="line">        <span class="built_in">return</span> len(s)</span><br></pre></td></tr></table></figure></div>

<h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><p><strong>set()</strong><br>set顾名思义是集合 里面不能包含重复的元素 接收一个list作为参数<br>set() 函数创建一个无序不重复元素集 可进行关系测试 删除重复数据 还可以计算交集、差集、并集等</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">list = [2,3,5,7]</span><br><span class="line">s = <span class="built_in">set</span>(list)</span><br><span class="line"><span class="built_in">print</span>(s) <span class="comment">#输出set([2,3,5,7])</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加</span></span><br><span class="line">s.add(9)</span><br><span class="line">s.add(7)</span><br><span class="line"><span class="built_in">print</span>(s) <span class="comment">#输出set([2,3,5,7,9])</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#删除</span></span><br><span class="line">s.remove(9)</span><br><span class="line"><span class="built_in">print</span>(s) <span class="comment">#输出set([2,3,5,7])</span></span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>力扣</tag>
      </tags>
  </entry>
  <entry>
    <title>向字符串添加空格</title>
    <url>/zhihaojiang.github.io/2025/04/10/20250410%E5%90%91%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%B7%BB%E5%8A%A0%E7%A9%BA%E6%A0%BC/</url>
    <content><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给你一个下标从 0 开始的字符串 s ，以及一个下标从 0 开始的整数数组 spaces 。</p>
<p>数组 spaces 描述原字符串中需要添加空格的下标。每个空格都应该插入到给定索引处的字符值 之前 。</p>
<p>例如，s &#x3D; “EnjoyYourCoffee” 且 spaces &#x3D; [5, 9] ，那么我们需要在 ‘Y’ 和 ‘C’ 之前添加空格，这两个字符分别位于下标 5 和下标 9 。因此，最终得到 “Enjoy Your Coffee” 。<br>请你添加空格，并返回修改后的字符串。</p>
<blockquote>
<p>示例 1：</p>
<p>输入：s &#x3D; “LeetcodeHelpsMeLearn”, spaces &#x3D; [8,13,15]<br>输出：”Leetcode Helps Me Learn”<br>解释：<br>下标 8、13 和 15 对应 “LeetcodeHelpsMeLearn” 中加粗斜体字符。<br>接着在这些字符前添加空格。<br>示例 2：</p>
<p>输入：s &#x3D; “icodeinpython”, spaces &#x3D; [1,5,7,9]<br>输出：”i code in py thon”<br>解释：<br>下标 1、5、7 和 9 对应 “icodeinpython” 中加粗斜体字符。<br>接着在这些字符前添加空格。<br>示例 3：</p>
<p>输入：s &#x3D; “spacing”, spaces &#x3D; [0,1,2,3,4,5,6]<br>输出：” s p a c i n g”<br>解释：<br>字符串的第一个字符前可以添加空格。</p>
</blockquote>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def addSpaces(self, s, spaces):</span><br><span class="line">        s = list(s) <span class="comment">#字符串字符串在 Python 中是不可变的 而列表是可变的</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> spaces:    <span class="comment">#遍历 spaces 中的每个元素 即i = spaces[i]</span></span><br><span class="line">            s[i] = <span class="string">&#x27; &#x27;</span> + s[i]</span><br><span class="line">        <span class="built_in">return</span> <span class="string">&#x27;&#x27;</span>.<span class="built_in">join</span>(s)   <span class="comment">#将修改后的字符列表重新组合成一个字符串。</span></span><br></pre></td></tr></table></figure></div>

<h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><p><strong>‘’.join(s)</strong><br>join函数是一个字符串操作函数 这个函数展开来写应该是str.join(item) str表示字符串（字符），item表示一个成员</p>
<blockquote>
<p>例子：<br>‘,’.join(‘abc’)<br>输出：<br>‘a,b,c’</p>
</blockquote>
<p>join里也可以放列表、元组、字典</p>
<blockquote>
<p>例子：<br>‘ ‘.join([a,b,c])<br>输出：<br>a b c</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>力扣</tag>
      </tags>
  </entry>
  <entry>
    <title>统计对称整数的数目</title>
    <url>/zhihaojiang.github.io/2025/04/11/20250411%E7%BB%9F%E8%AE%A1%E5%AF%B9%E7%A7%B0%E6%95%B4%E6%95%B0%E7%9A%84%E6%95%B0%E7%9B%AE/</url>
    <content><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给你两个正整数 low 和 high 。</p>
<p>对于一个由 2 * n 位数字组成的整数 x ，如果其前 n 位数字之和与后 n 位数字之和相等，则认为这个数字是一个对称整数。</p>
<p>返回在 [low, high] 范围内的 对称整数的数目 。</p>
<blockquote>
<p>示例 1：</p>
<p>输入：low &#x3D; 1, high &#x3D; 100<br>输出：9<br>解释：在 1 到 100 范围内共有 9 个对称整数：11、22、33、44、55、66、77、88 和 99 。<br>示例 2：</p>
<p>输入：low &#x3D; 1200, high &#x3D; 1230<br>输出：4<br>解释：在 1200 到 1230 范围内共有 4 个对称整数：1203、1212、1221 和 1230 。</p>
<p>提示：<br>1 &lt;&#x3D; low &lt;&#x3D; high &lt;&#x3D; 104</p>
</blockquote>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def countSymmetricIntegers(self, low, high):</span><br><span class="line">        count = 0</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(low, high + 1):</span><br><span class="line">            <span class="keyword">if</span> i &gt; 0 and i &lt; 100:</span><br><span class="line">                <span class="keyword">if</span> i % 11 == 0:</span><br><span class="line">                    count += 1</span><br><span class="line">            <span class="keyword">if</span> i &gt; 1000 and i &lt; 10000:</span><br><span class="line">                left = i // 1000 + i // 100 % 10</span><br><span class="line">                right = i // 10 % 10 + i % 10</span><br><span class="line">                <span class="keyword">if</span> left == right:</span><br><span class="line">                    count += 1</span><br><span class="line">        <span class="built_in">return</span> count</span><br></pre></td></tr></table></figure></div>

<h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><p><strong>如何取出4位数中的各个位数</strong><br>以2357为例<br>2 &#x3D; 2357 &#x2F;&#x2F; 1000<br>3 &#x3D; 2357 &#x2F;&#x2F; 100 % 10<br>5 &#x3D; 2357 &#x2F;&#x2F; 10 % 10<br>7 &#x3D; 2357 % 10</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>力扣</tag>
      </tags>
  </entry>
  <entry>
    <title>成人抑郁症数据分析</title>
    <url>/zhihaojiang.github.io/2025/04/14/20250414%E6%88%90%E4%BA%BA%E6%8A%91%E9%83%81%E7%97%87%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><p><a class="link"   href="https://www.kaggle.com/datasets/sonawanelalitsunil/adult-depression-lghc-indicator/data" >https://www.kaggle.com/datasets/sonawanelalitsunil/adult-depression-lghc-indicator/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="成人抑郁症"><a href="#成人抑郁症" class="headerlink" title="成人抑郁症"></a>成人抑郁症</h2><p>成人抑郁症（LGHC 指标）数据集提供了由地方健康地理比较 (LGHC) 计划跟踪的成人抑郁症患病率的见解。它可作为了解不同人群和地区心理健康趋势的公共卫生资源。</p>
<p>主要特点：<br>健康指标：根据健康调查的自我报告数据，关注被诊断患有抑郁症的成年人的百分比。<br>人口统计和地理：按年龄、性别、种族&#x2F;民族、收入水平和地理位置（州、县或地方区域）细分数据。</p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul>
<li>对数据集进行探索性分析，找出数据集中的问题。</li>
<li>对数据进行预处理，包括缺失值处理、异常值处理、数据类型转换等。</li>
<li>对数据进行可视化分析，找出数据中的规律。</li>
<li>对数据进行分析，找出数据中的规律并预测抑郁症的概率。</li>
</ul>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>导入库</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.metrics import mean_squared_error,r2_score</span><br></pre></td></tr></table></figure></div>

<p>读取文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;adult-depression-lghc-indicator-24.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<p>查看文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/001.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/002.png"
                      alt="photo"
                ></p>
<h3 id="分析每个字段的含义"><a href="#分析每个字段的含义" class="headerlink" title="分析每个字段的含义"></a>分析每个字段的含义</h3><ul>
<li><code>Year</code>：数据收集年份</li>
<li><code>Strata</code>：包含了各种类别</li>
<li><code>Strata Name</code>：不同类别的详细名称</li>
<li><code>Frequency</code>：频率</li>
<li><code>Weighted Frequency</code>：权重频率</li>
<li><code>Percent</code>：患病百分比 – target</li>
<li><code>Lower 95% CL</code>：较低的 95% CL</li>
<li><code>Upper 95% CL</code>：较高的 95% CL</li>
</ul>
<p>针对Strata</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Strata&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/003.png"
                      alt="photo"
                ></p>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">x = <span class="built_in">df</span>[<span class="string">&#x27;Year&#x27;</span>]</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;Percent&#x27;</span>]</span><br><span class="line"></span><br><span class="line">sns.lineplot(x=x, y=y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Year&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Percent&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Percent of Adults Depressed Over Time&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/004.png"
                      alt="photo"
                ></p>
<p>可以看到 抑郁症发病率在逐年上升 在2017年达到了最高值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">Strata_features = [<span class="string">&#x27;Income&#x27;</span>, <span class="string">&#x27;Race-Ethnicity&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Education&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> Strata_features:</span><br><span class="line">    sns.barplot(x=<span class="string">&#x27;Strata Name&#x27;</span>, y=<span class="string">&#x27;Percent&#x27;</span>, data=<span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">&#x27;Strata&#x27;</span>]== feature], hue=<span class="string">&#x27;Year&#x27;</span>)</span><br><span class="line">    plt.title(f<span class="string">&#x27;Percent of Adults Depressed by &#123;feature&#125;&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/005.png"
                      alt="photo"
                ></p>
<p>可以看到 收入小于$20，000的人得抑郁症的概率高于其他收入水平</p>
<p>可能的原因：低收入水平的人可能面临经济困难和压力，从而增加了他们对抑郁的感知和应对的难度。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/006.png"
                      alt="photo"
                ></p>
<p>可以看到 亚非裔的人得抑郁症的概率低于其他种族和民族</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/007.png"
                      alt="photo"
                ></p>
<p>可以看到 随着年龄的增长 得抑郁症的概率也在增长 在65岁以上时又减小</p>
<p>可能的原因：随着年龄的增长 人们的生活和工作环境也在不断变化 压力也越来越大 因此也会增加得抑郁症的概率 在65岁以上时 人们已经退休了 没有了生活和工作的压力 因此也会减少得抑郁症的概率<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/008.png"
                      alt="photo"
                ></p>
<p>可以看到 学历对得抑郁症的概率没有明显影响</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/009.png"
                      alt="photo"
                ></p>
<p>可以看到 女性得抑郁症的概率高于男性</p>
<p>男女性得抑郁症的概率都逐年上升 在2017年达到最高</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter(<span class="built_in">df</span>[<span class="string">&#x27;Lower 95% CL&#x27;</span>], <span class="built_in">df</span>[<span class="string">&#x27;Percent&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter(<span class="built_in">df</span>[<span class="string">&#x27;Upper 95% CL&#x27;</span>], <span class="built_in">df</span>[<span class="string">&#x27;Percent&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/010.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/011.png"
                      alt="photo"
                ></p>
<p>上述两张散点图可以看到 Upper 95% CL和 Lower 95% CL 对得抑郁症的影响很大</p>
<p>用相关性矩阵查看特征之间的关系</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">num_df = df.select_dtypes(include=[np.number])</span><br><span class="line">sns.heatmap(num_df.corr(), annot=True, cmap=<span class="string">&#x27;coolwarm&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Correlation Heatmap&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/14/012.png"
                      alt="photo"
                ></p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.drop(columns=[<span class="string">&#x27;Strata Name&#x27;</span>, <span class="string">&#x27;Strata&#x27;</span>], inplace=True)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>Year                  0<br>Frequency             0<br>Weighted Frequency    7<br>Percent               0<br>Lower 95% CL          0<br>Upper 95% CL          0<br>dtype: int64</p>
</blockquote>
<p>由于只有7个缺失值 所以直接删除</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.dropna(inplace=True)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算 Z-Score</span></span><br><span class="line">mean = <span class="built_in">df</span>[<span class="string">&#x27;Frequency&#x27;</span>].mean()</span><br><span class="line">std = <span class="built_in">df</span>[<span class="string">&#x27;Frequency&#x27;</span>].std()</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Z-Score&#x27;</span>] = (<span class="built_in">df</span>[<span class="string">&#x27;Frequency&#x27;</span>] - mean) / std</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测异常值（Z-Score &gt; 3 或 &lt; -3）</span></span><br><span class="line">outliers = <span class="built_in">df</span>[abs(<span class="built_in">df</span>[<span class="string">&#x27;Z-Score&#x27;</span>]) &gt; 3]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;异常值：\n&quot;</span>, outliers)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>异常值：<br>    Year  Frequency  Weighted Frequency  Percent  Lower 95% CL  Upper 95% CL  <br>2  2012       1359           2163108.0    15.25         14.30         16.20<br>3  2012       1314           1806371.0    14.57         13.67         15.46   </p>
<pre><code>Z-Score  
</code></pre>
<p>2  3.498507<br>3  3.339020</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy.stats import mstats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 胜率变换：将异常值限制在 5% 和 95% 分位数之间</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Frequency_winsorized&#x27;</span>] = mstats.winsorize(<span class="built_in">df</span>[<span class="string">&#x27;Frequency&#x27;</span>], limits=[0.05, 0.05])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;胜率变换后的数据：\n&quot;</span>, <span class="built_in">df</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>胜率变换后的数据：<br>      Year  Frequency  Weighted Frequency  Percent  Lower 95% CL  Upper 95% CL  <br>1    2012        561           1116664.0     8.12          7.32          8.92<br>2    2012       1359           2163108.0    15.25         14.30         16.20<br>3    2012       1314           1806371.0    14.57         13.67         15.46<br>4    2012         97            222022.0    13.54         10.44         16.65<br>5    2012        412            923174.0     9.98          8.91         11.05<br>..    …        …                 …      …           …           …<br>156  2018        496           1623933.0    17.69         13.72         21.66<br>157  2018        285            749615.0    14.56         10.91         18.21<br>158  2018        301           1052945.0    20.06         15.60         24.52<br>159  2018        432            854201.0    21.44         17.65         25.23<br>160  2018        450            661974.0    15.60         13.42         17.78   </p>
<pre><code>  Z-Score  Frequency_winsorized  
</code></pre>
<p>1    0.670280                   561<br>2    3.498507                  1055<br>3    3.339020                  1055<br>4   -0.974202                    97<br>5    0.142203                   412<br>..        …                   …<br>156  0.439911                   496<br>157 -0.307903                   285<br>158 -0.251197                   301<br>159  0.213086                   432<br>160  0.276880                   450  </p>
<p>[154 rows x 8 columns]</p>
</blockquote>
<p>就是将第2，3行的一场数据进行了胜率变换 其他行数据没有变化</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop(columns=[<span class="string">&#x27;Percent&#x27;</span>, <span class="string">&#x27;Z-Score&#x27;</span>, <span class="string">&#x27;Frequency&#x27;</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;Percent&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line"><span class="comment">#进行标准化</span></span><br><span class="line">scaler =  StandardScaler()</span><br><span class="line">scaler.fit(X_train, X_test)</span><br><span class="line">X_train_scaled = scaler.transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br></pre></td></tr></table></figure></div>
<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(X_train_scaled, y_train)</span><br><span class="line">y_pred = lr.predict(X_test_scaled)</span><br></pre></td></tr></table></figure></div>

<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression MSE:&quot;</span>, mse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression R^2:&quot;</span>, r2)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>Linear Regression MSE: 1.439819098234569e-05<br>Linear Regression R^2: 0.999999015347916</p>
</blockquote>
<p>决定系数为0.99以上 说明模型拟合得很好</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Predict Podcast Listening Time</title>
    <url>/zhihaojiang.github.io/2025/04/16/20250416Predict%20Podcast%20Listening%20Time/</url>
    <content><![CDATA[<h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><p><a class="link"   href="https://www.kaggle.com/competitions/playground-series-s5e4/data" >https://www.kaggle.com/competitions/playground-series-s5e4/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h2><p>Dataset Description<br>The dataset for this competition (both train and test) was generated from a deep learning model trained on the Podcast Listening Time Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.</p>
<p>Files<br>train.csv - the training dataset; Listening_Time_minutes is the target<br>test.csv - the test dataset; your objective is to predict the Listening_Time_minutes for each row<br>sample_submission.csv - a sample submission file in the correct format.</p>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>导入库</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.metrics import mean_squared_error,r2_score</span><br></pre></td></tr></table></figure></div>

<h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;/kaggle/input/playground-series-s5e4/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/001.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.describe()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/002.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/003.png"
                      alt="photo"
                ></p>
<p>现在分析一下这些字段是什么意思：</p>
<ul>
<li><code>id</code>：播客名称</li>
<li><code>podcast_Name</code>：播客名称</li>
<li><code>Episode_Title</code>：章节标题</li>
<li><code>Episode_Length_minutes</code>：章节时长</li>
<li><code>Genre</code>：播客类别</li>
<li><code>Host_Popularity_percentage</code>：主持人人气百分比</li>
<li><code>Publication_Day</code>：播放日期</li>
<li><code>Publication_Time</code>：播放时间</li>
<li><code>Guest_Popularity_percentage</code>：嘉宾人人气百分比</li>
<li><code>Number_of_Ads</code>：广告数量</li>
<li><code>Episode_Sentiment</code>：剧集氛围</li>
<li><code>Listening_Time_minutes</code>：收听时长 – target</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/004.png"
                      alt="photo"
                ></p>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.histplot(<span class="built_in">df</span>[<span class="string">&#x27;Episode_Length_minutes&#x27;</span>], kde=True, bins=30)</span><br><span class="line">plt.title(<span class="string">&#x27;Episode_Length_minutes&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/005.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.histplot(<span class="built_in">df</span>[<span class="string">&#x27;Guest_Popularity_percentage&#x27;</span>], kde=True, bins=30)</span><br><span class="line">plt.title(<span class="string">&#x27;Guest_Popularity_percentage&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/006.png"
                      alt="photo"
                ></p>
<p>可以看到 这两个字段的分布情况比较均匀 并且他们都是连续数值型数据 利用均值填充</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">missing_features = [<span class="string">&#x27;Episode_Length_minutes&#x27;</span>, <span class="string">&#x27;Guest_Popularity_percentage&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> missing_features:</span><br><span class="line">    <span class="built_in">df</span>[feature].fillna(<span class="built_in">df</span>[feature].mean(), inplace=True)</span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/007.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.dropna(inplace=True)</span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/008.png"
                      alt="photo"
                ><br>接下来我们查看是否存在异常值<br>利用箱线图来查看是否存在异常值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">features = [<span class="string">&#x27;Episode_Length_minutes&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;Host_Popularity_percentage&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Guest_Popularity_percentage&#x27;</span>, <span class="string">&#x27;Number_of_Ads&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Listening_Time_minutes&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    sns.boxplot(x=<span class="built_in">df</span>[col])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/009.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/010.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/011.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/012.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/013.png"
                      alt="photo"
                ></p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>从上述图中可以看到 Episode_Length_minutes和Number_of_Ads存在异常值</p>
<p>Host_Popularity_percentage和Guest_Popularity_percentage存在超过100的值</p>
<p>从常理来看 百分比不可能大于100</p>
<p>因此 将Episode_Length_minutes和Number_of_Ads的异常值删除</p>
<p>将Host_Popularity_percentage和Guest_Popularity_percentage的异常值进行胜率变换</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">deleted_features = [<span class="string">&#x27;Episode_Length_minutes&#x27;</span>, <span class="string">&#x27;Number_of_Ads&#x27;</span>]</span><br><span class="line">df_cleaned = df.copy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> deleted_features:</span><br><span class="line">    Q1 = df_cleaned[col].quantile(0.25)</span><br><span class="line">    Q3 = df_cleaned[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">    lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">    upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 只保留当前列在正常范围内的数据（逐步过滤）</span></span><br><span class="line">    df_cleaned = df_cleaned[(df_cleaned[col] &gt;= lower_bound) &amp; (df_cleaned[col] &lt;= upper_bound)]</span><br></pre></td></tr></table></figure></div>

<p>检查一遍</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">features = [<span class="string">&#x27;Episode_Length_minutes&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;Host_Popularity_percentage&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Guest_Popularity_percentage&#x27;</span>, <span class="string">&#x27;Number_of_Ads&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Listening_Time_minutes&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    sns.boxplot(x=df_cleaned[col])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/014.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/015.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/016.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/017.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/018.png"
                      alt="photo"
                ></p>
<p>接下来 我们对字符数据进行处理</p>
<p>值得被编码的特征有：</p>
<ul>
<li>Genre</li>
<li>Publication_Day</li>
<li>Publication_Time</li>
<li>Episode_Sentiment</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_cleaned[<span class="string">&#x27;Genre&#x27;</span>].describe()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/16/019.png"
                      alt="photo"
                ></p>
<p>发现他们的类别都较少 使用独热编码</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line"></span><br><span class="line">one_hot_features = [<span class="string">&#x27;Genre&#x27;</span>, <span class="string">&#x27;Publication_Day&#x27;</span>, <span class="string">&#x27;Publication_Time&#x27;</span>, <span class="string">&#x27;Episode_Sentiment&#x27;</span>]</span><br><span class="line"></span><br><span class="line">ohe = OneHotEncoder(sparse_output=False, handle_unknown=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">encoded_array = ohe.fit_transform(df_cleaned[one_hot_features])</span><br><span class="line">encoded_cols = ohe.get_feature_names_out(one_hot_features)</span><br><span class="line"></span><br><span class="line">encoded_df = pd.DataFrame(encoded_array, columns=encoded_cols, index=df_cleaned.index)</span><br><span class="line"></span><br><span class="line">df_cleaned_encoded = pd.concat([df_cleaned.drop(columns=one_hot_features), encoded_df], axis=1)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_cleaned_encoded.drop(columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;Podcast_Name&#x27;</span>, <span class="string">&#x27;Episode_Title&#x27;</span>], inplace=True)</span><br></pre></td></tr></table></figure></div>

<h3 id="模型选择-模型评估"><a href="#模型选择-模型评估" class="headerlink" title="模型选择&amp;模型评估"></a>模型选择&amp;模型评估</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line">X = df_cleaned_encoded.drop(columns=[<span class="string">&#x27;Listening_Time_minutes&#x27;</span>])</span><br><span class="line">y = df_cleaned_encoded[<span class="string">&#x27;Listening_Time_minutes&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line">rf = RandomForestRegressor(n_estimators=100, random_state=42)</span><br><span class="line">rf.fit(X_train_scaled, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = rf.predict(X_test_scaled)</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Squared Error:&quot;</span>, mse)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;R^2 Score:&quot;</span>, r2)</span><br></pre></td></tr></table></figure></div>

<p>在我的MacBook AirM2上 该模型用时约4‘47秒</p>
<p>Mean Squared Error: 161.35316711251312</p>
<p>R^2 Score: 0.7801317443922687</p>
<p>未进行特征工程</p>
<h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><p>chatGPT 4o<br>提问的问题：</p>
<ol>
<li>在数据分析中 如何查看是否存在缺失值</li>
<li>针对缺失值 在什么情况下用均值填充 在什么情况下用众数填充 在什么情况下用中位数填充</li>
<li>如何对缺失值做可视化图表 查看缺失值的分布情况</li>
<li>数据分布比较均匀的 其缺失值如何填充</li>
<li>Mean Squared Error: 161.35316711251312 R^2 Score: 0.7801317443922687 这个分数对于一个有29个维度 使用随机森林训练的数据来说怎么样</li>
<li>做相关性矩阵就是做个sns.heatmap吗</li>
<li>我对object进行独热编码后对相关性矩阵<br>这个图看起来很吃力 我该怎么做</li>
<li>代码优化：</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line"></span><br><span class="line">one_hot_features = [<span class="string">&#x27;Genre&#x27;</span>, <span class="string">&#x27;Publication_Day&#x27;</span>, <span class="string">&#x27;Publication_Time&#x27;</span>, <span class="string">&#x27;Episode_Sentiment&#x27;</span>]</span><br><span class="line">ohe = OneHotEncoder(sparse=False)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> one_hot_features:</span><br><span class="line">    df_cleaned_encoded = ohe.fit_transform(pd.DataFrame(col))</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">Cell In[18], line 4</span><br><span class="line">      1 from sklearn.preprocessing import OneHotEncoder</span><br><span class="line">      3 one_hot_features = [<span class="string">&#x27;Genre&#x27;</span>, <span class="string">&#x27;Publication_Day&#x27;</span>, <span class="string">&#x27;Publication_Time&#x27;</span>, <span class="string">&#x27;Episode_Sentiment&#x27;</span>]</span><br><span class="line">----&gt; 4 ohe = OneHotEncoder(sparse=False)</span><br><span class="line">      5 encoded_parts = []</span><br><span class="line">      6 <span class="keyword">for</span> col <span class="keyword">in</span> one_hot_features:</span><br><span class="line"></span><br><span class="line">TypeError: OneHotEncoder.__init__() got an unexpected keyword argument <span class="string">&#x27;sparse&#x27;</span></span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectKBest, chi2</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用卡方检验选择前 2 个最佳特征</span></span><br><span class="line">selector = SelectKBest(chi2, k=2)</span><br><span class="line">X_new = selector.fit_transform(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择后的特征形状：&quot;</span>, X_new.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每个特征的得分：&quot;</span>, selector.scores_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;是否被选择：&quot;</span>, selector.get_support())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出每个特征的得分</span></span><br><span class="line">scores = pd.Series(selector.scores_, index=X.columns)</span><br><span class="line">scores = scores.sort_values(ascending=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卡方检验得分最高的特征：\n&quot;</span>, scores.head(20))</span><br><span class="line"></span><br><span class="line">显示报错</span><br><span class="line"></span><br><span class="line">ValueError: Unknown label <span class="built_in">type</span>: (array([48.82398, 72.06621,  0.     , ..., 13.09288, 30.92493, 29.3002 ]),)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.decomposition import PCA</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 PCA 降维到 2 维</span></span><br><span class="line">pca = PCA(n_components=9)</span><br><span class="line">X_pca = pca.fit_transform(X_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;降维后的数据形状：&quot;</span>, X_pca.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看每个主成分的贡献率</span></span><br><span class="line">explained_variance = pd.Series(pca.explained_variance_ratio_, index=[f<span class="string">&#x27;PC&#123;i+1&#125;&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(9)])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;主成分贡献率：\n&quot;</span>, explained_variance)</span><br><span class="line"></span><br><span class="line">降维后的数据形状： (599991, 9)</span><br><span class="line">主成分贡献率：</span><br><span class="line"> PC1    0.458917</span><br><span class="line">PC2    0.297558</span><br><span class="line">PC3    0.241425</span><br><span class="line">PC4    0.000588</span><br><span class="line">PC5    0.000160</span><br><span class="line">PC6    0.000159</span><br><span class="line">PC7    0.000125</span><br><span class="line">PC8    0.000119</span><br><span class="line">PC9    0.000114</span><br><span class="line"></span><br><span class="line">我想查看到底是哪9个特征</span><br></pre></td></tr></table></figure></div>
<p>我的此项目的kaggle网址：<br><a class="link"   href="https://www.kaggle.com/code/super213/randomforest-r-2-0-78" >https://www.kaggle.com/code/super213/randomforest-r-2-0-78<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Spaceship Titanic</title>
    <url>/zhihaojiang.github.io/2025/04/18/20250418Spaceship%20Titanic/</url>
    <content><![CDATA[<h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><p><a class="link"   href="https://www.kaggle.com/competitions/spaceship-titanic/data" >https://www.kaggle.com/competitions/spaceship-titanic/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h2><p>欢迎来到2912年，你需要运用数据科学技能来解开一个宇宙之谜。我们收到了来自四光年外的传输信息，情况看起来不太妙。</p>
<p>泰坦尼克号宇宙飞船是一艘星际客轮，于一个月前发射升空。这艘载有近1.3万名乘客的飞船开始了它的首航，将来自我们太阳系的移民运送到三颗围绕邻近恒星运行的、新发现的宜居系外行星。</p>
<p>在绕过半人马座阿尔法星，前往其首个目的地——炙热的巨蟹座E星——的途中，粗心大意的泰坦尼克号宇宙飞船与隐藏在尘埃云中的时空异常相撞。不幸的是，它遭遇了与一千年前同名飞船相似的命运。虽然飞船完好无损，但几乎一半的乘客被传送到了另一个维度！</p>
<p>为了帮助救援队找回失踪的乘客，您需要使用从宇宙飞船受损的计算机系统中恢复的记录来预测哪些乘客是被异常现象运送的。</p>
<p>帮助拯救他们并改变历史！</p>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>导入库</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/001.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/002.png"
                      alt="photo"
                ></p>
<p>现在我们分析一下各个字段的含义：</p>
<ul>
<li>PassengerId：乘客的ID</li>
<li>HomePlanet：乘客出发的星球 通常是他们永久居住的星球</li>
<li>CryoSleep：指示乘客是否选择在航行期间处于休眠状态 处于休眠状态的乘客将被限制在自己的船舱内</li>
<li>Cabin：乘客所住舱位号。格式为deck&#x2F;num&#x2F;side 其中side可以是P左舷 也可以是S右舷 </li>
<li>Destination：乘客即将登陆的星球</li>
<li>Age：乘客的年龄</li>
<li>VIP：乘客是否已支付航行期间的特殊VIP服务费用</li>
<li>RoomService： 乘客在泰坦尼克号宇宙飞船的众多豪华设施中支付的金额</li>
<li>FoodCourt： 乘客在泰坦尼克号宇宙飞船的众多豪华设施中支付的金额</li>
<li>ShoppingMall： 乘客在泰坦尼克号宇宙飞船的众多豪华设施中支付的金额</li>
<li>Spa： 乘客在泰坦尼克号宇宙飞船的众多豪华设施中支付的金额</li>
<li>VRDeck： 乘客在泰坦尼克号宇宙飞船的众多豪华设施中支付的金额</li>
<li>Name：乘客的名字和姓氏</li>
<li>Transported：乘客是否被传送到了另一个维度。这是目标，也就是你要预测的列</li>
</ul>
<h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><p>我们首先处理缺失值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/003.png"
                      alt="photo"
                ></p>
<p>针对数值型特征 使用均值填充</p>
<p>针对类别型特征 使用众数填充</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">missing_features = [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;RoomService&#x27;</span>, <span class="string">&#x27;FoodCourt&#x27;</span>, <span class="string">&#x27;ShoppingMall&#x27;</span>, <span class="string">&#x27;Spa&#x27;</span>, <span class="string">&#x27;VRDeck&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> missing_features:</span><br><span class="line">    <span class="built_in">df</span>[feature].fillna(<span class="built_in">df</span>[feature].mean(), inplace=True)</span><br><span class="line"></span><br><span class="line">categorical_features = [<span class="string">&#x27;HomePlanet&#x27;</span>, <span class="string">&#x27;CryoSleep&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>,<span class="string">&#x27;Destination&#x27;</span>, <span class="string">&#x27;VIP&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> categorical_features:</span><br><span class="line">    <span class="built_in">df</span>[feature].fillna(<span class="built_in">df</span>[feature].mode()[0], inplace=True)</span><br></pre></td></tr></table></figure></div>

<p>我们删除一些不必要的列 例如id和名称</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.drop(columns=[<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>], inplace=True)</span><br><span class="line"></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/004.png"
                      alt="photo"
                ></p>
<p>其中 我发现Cabin这个特征包含了许多信息 将其分为三列</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[[<span class="string">&#x27;Cabin_deck&#x27;</span>, <span class="string">&#x27;Cabin_num&#x27;</span>, <span class="string">&#x27;Cabin_side&#x27;</span>]] = <span class="built_in">df</span>[<span class="string">&#x27;Cabin&#x27;</span>].str.split(<span class="string">&#x27;/&#x27;</span>, <span class="built_in">expand</span>=True)</span><br><span class="line"></span><br><span class="line">df.drop(columns=[<span class="string">&#x27;Cabin&#x27;</span>], inplace=True)</span><br><span class="line"></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/005.png"
                      alt="photo"
                ></p>
<h3 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h3><p>用箱线图可视化查看异常值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">features = [<span class="string">&#x27;Age&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;RoomService&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;FoodCourt&#x27;</span>, <span class="string">&#x27;ShoppingMall&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Spa&#x27;</span>, <span class="string">&#x27;VRDeck&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    sns.boxplot(x=<span class="built_in">df</span>[col])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/006.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/007.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/008.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/009.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/010.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/011.png"
                      alt="photo"
                ><br>对异常值进行处理</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">features = [ <span class="string">&#x27;RoomService&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;FoodCourt&#x27;</span>, <span class="string">&#x27;ShoppingMall&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Spa&#x27;</span>, <span class="string">&#x27;VRDeck&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    <span class="built_in">df</span>[col] = np.log1p(<span class="built_in">df</span>[col])</span><br><span class="line"></span><br><span class="line">    Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">    Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">    lower = Q1 - 1.5 * IQR</span><br><span class="line">    upper = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line">    <span class="built_in">df</span>[col] = <span class="built_in">df</span>[col].clip(lower=lower, upper=upper)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">Q1 = <span class="built_in">df</span>[<span class="string">&#x27;Age&#x27;</span>].quantile(0.25)</span><br><span class="line">Q3 = <span class="built_in">df</span>[<span class="string">&#x27;Age&#x27;</span>].quantile(0.75)</span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">lower = Q1 - 1.5 * IQR</span><br><span class="line">upper = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Age&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;Age&#x27;</span>].clip(lower=lower, upper=upper)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">features = [<span class="string">&#x27;Age&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;RoomService&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;FoodCourt&#x27;</span>, <span class="string">&#x27;ShoppingMall&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Spa&#x27;</span>, <span class="string">&#x27;VRDeck&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    sns.boxplot(x=<span class="built_in">df</span>[col])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/012.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/013.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/014.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/015.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/016.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/017.png"
                      alt="photo"
                ></p>
<h3 id="可视化分析"><a href="#可视化分析" class="headerlink" title="可视化分析"></a>可视化分析</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">features = [<span class="string">&#x27;HomePlanet&#x27;</span>, <span class="string">&#x27;CryoSleep&#x27;</span>, <span class="string">&#x27;Destination&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Cabin_deck&#x27;</span>, <span class="string">&#x27;Cabin_side&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">    sns.countplot(x=feature, hue=<span class="string">&#x27;Transported&#x27;</span>, data=<span class="built_in">df</span>)</span><br><span class="line">    plt.title(feature)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/018.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/019.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/020.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/021.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/022.png"
                      alt="photo"
                ></p>
<h3 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line"></span><br><span class="line">one_hot_features = [<span class="string">&#x27;HomePlanet&#x27;</span>, <span class="string">&#x27;Destination&#x27;</span>, <span class="string">&#x27;CryoSleep&#x27;</span>, <span class="string">&#x27;VIP&#x27;</span>, <span class="string">&#x27;Cabin_deck&#x27;</span>, <span class="string">&#x27;Cabin_side&#x27;</span>]</span><br><span class="line"></span><br><span class="line">ohe = OneHotEncoder(sparse_output=False, handle_unknown=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">encoded_array = ohe.fit_transform(<span class="built_in">df</span>[one_hot_features])</span><br><span class="line">encoded_cols = ohe.get_feature_names_out(one_hot_features)</span><br><span class="line"></span><br><span class="line">encoded_df = pd.DataFrame(encoded_array, columns=encoded_cols, index=df.index)</span><br><span class="line"></span><br><span class="line">df_cleaned_encoded = pd.concat([df.drop(columns=one_hot_features), encoded_df], axis=1)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_cleaned_encoded.drop(columns=[<span class="string">&#x27;Cabin_num&#x27;</span>], inplace=True)</span><br></pre></td></tr></table></figure></div>

<h3 id="相关性矩阵"><a href="#相关性矩阵" class="headerlink" title="相关性矩阵"></a>相关性矩阵</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = df_cleaned_encoded[<span class="string">&#x27;Transported&#x27;</span>]</span><br><span class="line">X = df_cleaned_encoded.drop([<span class="string">&#x27;Transported&#x27;</span>], axis=1)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">correlation_matrix = pd.concat([X_train, y_train], axis=1).corr()</span><br><span class="line"><span class="comment"># 设置相关性的阈值</span></span><br><span class="line">threshold = 0.2</span><br><span class="line">mask = np.abs(correlation_matrix) &gt; threshold</span><br><span class="line"></span><br><span class="line">sns.heatmap(correlation_matrix, annot=True, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, mask=~mask, center=0)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/024.png"
                      alt="photo"
                ></p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectKBest, chi2</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用卡方检验选择前 2 个最佳特征</span></span><br><span class="line">selector = SelectKBest(chi2, k=9)</span><br><span class="line">X_new = selector.fit_transform(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择后的特征形状：&quot;</span>, X_new.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每个特征的得分：&quot;</span>, selector.scores_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;是否被选择：&quot;</span>, selector.get_support())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出每个特征的得分</span></span><br><span class="line">scores = pd.Series(selector.scores_, index=X.columns)</span><br><span class="line">scores = scores.sort_values(ascending=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卡方检验得分最高的特征：\n&quot;</span>, scores.head(29))</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/025.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卡方检验得分最低的特征：\n&quot;</span>, scores.tail(15))</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/026.png"
                      alt="photo"
                ></p>
<p>我们将特征分数较低的删除</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_cleaned_encoded.drop(columns=[</span><br><span class="line">    <span class="string">&#x27;Cabin_deck_A&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Destination_PSO J318.5-22&#x27;</span></span><br><span class="line">, <span class="string">&#x27;VIP_False&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_T&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_G&#x27;</span></span><br><span class="line">, <span class="string">&#x27;HomePlanet_Mars&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_D&#x27;</span></span><br><span class="line">, <span class="string">&#x27;VIP_True&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Destination_TRAPPIST-1e&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_side_S&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_side_P&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_F&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_E&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Destination_55 Cancri e&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_C&#x27;</span>], inplace=True)</span><br></pre></td></tr></table></figure></div>

<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = df_cleaned_encoded[<span class="string">&#x27;Transported&#x27;</span>]</span><br><span class="line">X = df_cleaned_encoded.drop([<span class="string">&#x27;Transported&#x27;</span>], axis=1)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line">rf = RandomForestClassifier(n_estimators=100, random_state=42)</span><br><span class="line">rf.fit(X_train_scaled, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = rf.predict(X_test_scaled)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/027.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import lightgbm as lgb</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line">model = lgb.LGBMClassifier()</span><br><span class="line">model.fit(X_train_scaled, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = model.predict(X_test_scaled)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征重要性</span></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">lgb.plot_importance(model, max_num_features=20)</span><br><span class="line">plt.title(<span class="string">&quot;Feature Importance&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/028.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/029.png"
                      alt="photo"
                ></p>
<h3 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay</span><br><span class="line"></span><br><span class="line">cm = confusion_matrix(y_test, y_pred)</span><br><span class="line">disp = ConfusionMatrixDisplay(confusion_matrix=cm)</span><br><span class="line">disp.plot(cmap=<span class="string">&#x27;Blues&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/18/030.png"
                      alt="photo"
                ></p>
<h2 id="测试集预测"><a href="#测试集预测" class="headerlink" title="测试集预测"></a>测试集预测</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#整理测试集</span></span><br><span class="line">tdf = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">missing_features = [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;RoomService&#x27;</span>, <span class="string">&#x27;FoodCourt&#x27;</span>, <span class="string">&#x27;ShoppingMall&#x27;</span>, <span class="string">&#x27;Spa&#x27;</span>, <span class="string">&#x27;VRDeck&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> missing_features:</span><br><span class="line">    tdf[feature].fillna(tdf[feature].mean(), inplace=True)</span><br><span class="line"></span><br><span class="line">categorical_features = [<span class="string">&#x27;HomePlanet&#x27;</span>, <span class="string">&#x27;CryoSleep&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>,<span class="string">&#x27;Destination&#x27;</span>, <span class="string">&#x27;VIP&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用众数填充缺失值</span></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> categorical_features:</span><br><span class="line">    tdf[feature].fillna(tdf[feature].mode()[0], inplace=True)</span><br><span class="line"></span><br><span class="line">tdf.drop(columns=[<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>], inplace=True)</span><br><span class="line"></span><br><span class="line">tdf[[<span class="string">&#x27;Cabin_deck&#x27;</span>, <span class="string">&#x27;Cabin_num&#x27;</span>, <span class="string">&#x27;Cabin_side&#x27;</span>]] = tdf[<span class="string">&#x27;Cabin&#x27;</span>].str.split(<span class="string">&#x27;/&#x27;</span>, <span class="built_in">expand</span>=True)</span><br><span class="line"></span><br><span class="line">tdf.drop(columns=[<span class="string">&#x27;Cabin&#x27;</span>], inplace=True)</span><br><span class="line"></span><br><span class="line">features = [ <span class="string">&#x27;RoomService&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;FoodCourt&#x27;</span>, <span class="string">&#x27;ShoppingMall&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Spa&#x27;</span>, <span class="string">&#x27;VRDeck&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    tdf[col] = np.log1p(tdf[col])</span><br><span class="line"></span><br><span class="line">    Q1 = tdf[col].quantile(0.25)</span><br><span class="line">    Q3 = tdf[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">    lower = Q1 - 1.5 * IQR</span><br><span class="line">    upper = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line">    tdf[col] = tdf[col].clip(lower=lower, upper=upper)</span><br><span class="line"></span><br><span class="line">Q1 = <span class="built_in">df</span>[<span class="string">&#x27;Age&#x27;</span>].quantile(0.25)</span><br><span class="line">Q3 = <span class="built_in">df</span>[<span class="string">&#x27;Age&#x27;</span>].quantile(0.75)</span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">lower = Q1 - 1.5 * IQR</span><br><span class="line">upper = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line">tdf[<span class="string">&#x27;Age&#x27;</span>] = tdf[<span class="string">&#x27;Age&#x27;</span>].clip(lower=lower, upper=upper)</span><br><span class="line"></span><br><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line"></span><br><span class="line">one_hot_features = [<span class="string">&#x27;HomePlanet&#x27;</span>, <span class="string">&#x27;Destination&#x27;</span>, <span class="string">&#x27;CryoSleep&#x27;</span>, <span class="string">&#x27;VIP&#x27;</span>, <span class="string">&#x27;Cabin_deck&#x27;</span>, <span class="string">&#x27;Cabin_side&#x27;</span>]</span><br><span class="line"></span><br><span class="line">ohe = OneHotEncoder(sparse_output=False, handle_unknown=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">encoded_array = ohe.fit_transform(tdf[one_hot_features])</span><br><span class="line">encoded_cols = ohe.get_feature_names_out(one_hot_features)</span><br><span class="line"></span><br><span class="line">encoded_df = pd.DataFrame(encoded_array, columns=encoded_cols, index=tdf.index)</span><br><span class="line"></span><br><span class="line">tdf_cleaned_encoded = pd.concat([tdf.drop(columns=one_hot_features), encoded_df], axis=1)</span><br><span class="line"></span><br><span class="line">tdf_cleaned_encoded.drop(columns=[<span class="string">&#x27;Cabin_num&#x27;</span>], inplace=True)</span><br><span class="line"></span><br><span class="line">tdf_cleaned_encoded.drop(columns=[</span><br><span class="line">    <span class="string">&#x27;Cabin_deck_A&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Destination_PSO J318.5-22&#x27;</span></span><br><span class="line">, <span class="string">&#x27;VIP_False&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_T&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_G&#x27;</span></span><br><span class="line">, <span class="string">&#x27;HomePlanet_Mars&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_D&#x27;</span></span><br><span class="line">, <span class="string">&#x27;VIP_True&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Destination_TRAPPIST-1e&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_side_S&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_side_P&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_F&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_E&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Destination_55 Cancri e&#x27;</span></span><br><span class="line">, <span class="string">&#x27;Cabin_deck_C&#x27;</span>], inplace=True)</span><br><span class="line"></span><br><span class="line">X_test_scaled = scaler.transform(tdf_cleaned_encoded)</span><br><span class="line"></span><br><span class="line">model = lgb.LGBMClassifier()</span><br><span class="line">model.fit(X_train_scaled, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_pred = model.predict(tdf_cleaned_encoded)</span><br><span class="line"></span><br><span class="line">tdf = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line">tdf[<span class="string">&#x27;pred&#x27;</span>] = y_pred</span><br><span class="line"></span><br><span class="line">result = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;iPassengerId&#x27;</span>: tdf[<span class="string">&#x27;PassengerId&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;Transported&#x27;</span>: tdf[<span class="string">&#x27;pred&#x27;</span>]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">result.to_csv(<span class="string">&quot;submission.csv&quot;</span>, index=False)</span><br></pre></td></tr></table></figure></div>

<h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><p>chatGPT 4o<br>提问的问题：</p>
<ol>
<li>我有一份数据 其中的一个特征内容为：B&#x2F;0&#x2F;P 这种形式 如何将这一组数据以“&#x2F;”拆分成三列特征</li>
<li>bool类型的数据怎么处理</li>
<li>bool类型要转换为数值型吗</li>
<li>我想查看类别型与target之间的关系</li>
<li>在数据分析时 我有一列是类别型 但是这一列的内容是数字 如何将其转换为数值型</li>
<li>如何将object类型添加到相关性矩阵查看其相关性</li>
<li>分类问题选择哪个模型好 GBDT怎么样</li>
<li>如何用这个模型来预测测试集</li>
<li>就是说我要重新把测试集也像训练集一样进行处理吗</li>
<li>假设我有两列叫id和pred 我如何将其保存到一个新的csv文件中</li>
<li>代码问题：</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ValueError: Classification metrics can<span class="string">&#x27;t handle a mix of continuous-multioutput and binary targets</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import lightgbm as lgb</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line">model = lgb.LGBMClassifier()</span><br><span class="line">model.fit(X_train_scaled, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = model.predict(X_test_scaled)</span><br><span class="line"><span class="built_in">print</span>(classification_report(X_test_scaled, y_pred))</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Squared Error:&quot;</span>, mse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;R^2 Score:&quot;</span>, r2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征重要性</span></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">lgb.plot_importance(model, max_num_features=20)</span><br><span class="line">plt.title(<span class="string">&quot;Feature Importance&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ValueError                                Traceback (most recent call last)</span><br><span class="line">Cell In[67], line 9</span><br><span class="line">      6 model.fit(X_train_scaled, y_train)</span><br><span class="line">      8 y_pred = model.predict(X_test_scaled)</span><br><span class="line">----&gt; 9 <span class="built_in">print</span>(classification_report(X_test, y_pred))</span><br><span class="line">     11 mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">     12 r2 = r2_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line">File /opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213, <span class="keyword">in</span> validate_params.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)</span><br><span class="line">    207 try:</span><br><span class="line">    208     with config_context(</span><br><span class="line">    209         skip_parameter_validation=(</span><br><span class="line">    210             prefer_skip_nested_validation or global_skip_validation</span><br><span class="line">    211         )</span><br><span class="line">    212     ):</span><br><span class="line">--&gt; 213         <span class="built_in">return</span> func(*args, **kwargs)</span><br><span class="line">    214 except InvalidParameterError as e:</span><br><span class="line">    215     <span class="comment"># When the function is just a wrapper around an estimator, we allow</span></span><br><span class="line">    216     <span class="comment"># the function to delegate validation to the estimator, but we replace</span></span><br><span class="line">    217     <span class="comment"># the name of the estimator by the name of the function in the error</span></span><br><span class="line">    218     <span class="comment"># message to avoid confusion.</span></span><br><span class="line">    219     msg = re.sub(</span><br><span class="line">    220         r<span class="string">&quot;parameter of \w+ must be&quot;</span>,</span><br><span class="line">    221         f<span class="string">&quot;parameter of &#123;func.__qualname__&#125; must be&quot;</span>,</span><br><span class="line">...</span><br><span class="line">    116     )</span><br><span class="line">    118 <span class="comment"># We can&#x27;t have more than one value on y_type =&gt; The set is no more needed</span></span><br><span class="line">    119 y_type = y_type.pop()</span><br><span class="line"></span><br><span class="line">ValueError: Classification metrics can<span class="string">&#x27;t handle a mix of continuous-multioutput and binary t</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">Cell In[68], line 11</span><br><span class="line">      8 y_pred = model.predict(X_test_scaled)</span><br><span class="line">      9 <span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line">---&gt; 11 mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">     12 r2 = r2_score(y_test, y_pred)</span><br><span class="line">     14 <span class="built_in">print</span>(<span class="string">&quot;Mean Squared Error:&quot;</span>, mse)</span><br><span class="line"></span><br><span class="line">File /opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213, <span class="keyword">in</span> validate_params.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)</span><br><span class="line">    207 try:</span><br><span class="line">    208     with config_context(</span><br><span class="line">    209         skip_parameter_validation=(</span><br><span class="line">    210             prefer_skip_nested_validation or global_skip_validation</span><br><span class="line">    211         )</span><br><span class="line">    212     ):</span><br><span class="line">--&gt; 213         <span class="built_in">return</span> func(*args, **kwargs)</span><br><span class="line">    214 except InvalidParameterError as e:</span><br><span class="line">    215     <span class="comment"># When the function is just a wrapper around an estimator, we allow</span></span><br><span class="line">    216     <span class="comment"># the function to delegate validation to the estimator, but we replace</span></span><br><span class="line">    217     <span class="comment"># the name of the estimator by the name of the function in the error</span></span><br><span class="line">    218     <span class="comment"># message to avoid confusion.</span></span><br><span class="line">    219     msg = re.sub(</span><br><span class="line">    220         r<span class="string">&quot;parameter of \w+ must be&quot;</span>,</span><br><span class="line">    221         f<span class="string">&quot;parameter of &#123;func.__qualname__&#125; must be&quot;</span>,</span><br><span class="line">...</span><br><span class="line">--&gt; 510 output_errors = np.average((y_true - y_pred) ** <span class="number">2</span>, axis=<span class="number">0</span>, weights=sample_weight)</span><br><span class="line">    <span class="number">512</span> if isinstance(multioutput, str):</span><br><span class="line">    <span class="number">513</span>     if multioutput == &quot;raw_values&quot;:</span><br><span class="line"></span><br><span class="line">TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">这个是用RandomForestClassifier</span><br><span class="line">precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">       False       0.78      0.75      0.76       861</span><br><span class="line">        True       0.76      0.79      0.77       878</span><br><span class="line"></span><br><span class="line">    accuracy                           0.77      1739</span><br><span class="line">   macro avg       0.77      0.77      0.77      1739</span><br><span class="line">weighted avg       0.77      0.77      0.77      1739</span><br><span class="line"></span><br><span class="line">这个是用GBDT</span><br><span class="line">[LightGBM] [Info] Number of positive: 3500, number of negative: 3454</span><br><span class="line">[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.</span><br><span class="line">You can <span class="built_in">set</span> `force_row_wise=<span class="literal">true</span>` to remove the overhead.</span><br><span class="line">And <span class="keyword">if</span> memory is not enough, you can <span class="built_in">set</span> `force_col_wise=<span class="literal">true</span>`.</span><br><span class="line">[LightGBM] [Info] Total Bins 1356</span><br><span class="line">[LightGBM] [Info] Number of data points <span class="keyword">in</span> the train <span class="built_in">set</span>: 6954, number of used features: 11</span><br><span class="line">[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -&gt; initscore=0.013230</span><br><span class="line">[LightGBM] [Info] Start training from score 0.013230</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">       False       0.80      0.75      0.77       861</span><br><span class="line">        True       0.77      0.82      0.79       878</span><br><span class="line"></span><br><span class="line">    accuracy                           0.78      1739</span><br><span class="line">   macro avg       0.78      0.78      0.78      1739</span><br><span class="line">weighted avg       0.78      0.78      0.78      1739</span><br><span class="line"></span><br><span class="line">他们的结果还可以吗 哪个好</span><br></pre></td></tr></table></figure></div>

<h2 id="kaggle地址"><a href="#kaggle地址" class="headerlink" title="kaggle地址"></a>kaggle地址</h2><p>我的此项目的kaggle网址：<br><a class="link"   href="https://www.kaggle.com/code/super213/randomforest-gbdt-f1-0-77" >https://www.kaggle.com/code/super213/randomforest-gbdt-f1-0-77<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>环境检测</title>
    <url>/zhihaojiang.github.io/2025/04/21/20250421%E7%8E%AF%E5%A2%83%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<h2 id="开发板"><a href="#开发板" class="headerlink" title="开发板"></a>开发板</h2><p>Arduino UNO R3</p>
<h2 id="接线"><a href="#接线" class="headerlink" title="接线"></a>接线</h2><p><strong>BMP180</strong></p>
<blockquote>
<p>VCC → 3.3V 或 5V<br>GND → GND<br>SCL → A5<br>SDA → A4</p>
</blockquote>
<p><strong>OLED (SSD1306 I2C)</strong></p>
<blockquote>
<p>VCC → 3.3V 或 5V<br>GND → GND<br>SCL → A5<br>SDA → A4</p>
</blockquote>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>报错信息</p>

    </div>
    <div class="notel-content">
      <p>这两个的SDA和SCL都接A4和A5 可以共用的</p>

    </div>
  </div>

<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#include &lt;Wire.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;Adafruit_Sensor.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;Adafruit_BMP085_U.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;Adafruit_GFX.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;Adafruit_SSD1306.h&gt;</span></span><br><span class="line"></span><br><span class="line">// OLED 设置</span><br><span class="line"><span class="comment">#define SCREEN_WIDTH 128</span></span><br><span class="line"><span class="comment">#define SCREEN_HEIGHT 64</span></span><br><span class="line"><span class="comment">#define OLED_RESET    -1</span></span><br><span class="line">Adafruit_SSD1306 display(SCREEN_WIDTH, SCREEN_HEIGHT, &amp;Wire, OLED_RESET);</span><br><span class="line"></span><br><span class="line">// BMP180 传感器对象</span><br><span class="line">Adafruit_BMP085_Unified bmp = Adafruit_BMP085_Unified(10085);</span><br><span class="line"></span><br><span class="line">void <span class="function"><span class="title">setup</span></span>() &#123;</span><br><span class="line">  Serial.begin(9600);</span><br><span class="line"></span><br><span class="line">  // 初始化 OLED</span><br><span class="line">  <span class="keyword">if</span> (!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;OLED ERROR&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span> (1);</span><br><span class="line">  &#125;</span><br><span class="line">  display.clearDisplay();</span><br><span class="line">  display.setTextSize(1);</span><br><span class="line">  display.setTextColor(WHITE);</span><br><span class="line"></span><br><span class="line">  // 初始化 BMP180</span><br><span class="line">  <span class="keyword">if</span> (!bmp.begin()) &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;can&#x27;t find BMP180&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span> (1);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void <span class="function"><span class="title">loop</span></span>() &#123;</span><br><span class="line">  sensors_event_t event;</span><br><span class="line">  bmp.getEvent(&amp;event);</span><br><span class="line"></span><br><span class="line">  display.clearDisplay();</span><br><span class="line">  display.setCursor(0, 0);</span><br><span class="line">  display.println(<span class="string">&quot;Environment&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (event.pressure) &#123;</span><br><span class="line">    display.setCursor(0, 20);</span><br><span class="line">    display.print(<span class="string">&quot;ATM: &quot;</span>);</span><br><span class="line">    display.print(event.pressure);</span><br><span class="line">    display.println(<span class="string">&quot; hPa&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">float</span> temperature;</span><br><span class="line">    bmp.getTemperature(&amp;temperature);</span><br><span class="line"></span><br><span class="line">    display.setCursor(0, 40);</span><br><span class="line">    display.print(<span class="string">&quot;temperature: &quot;</span>);</span><br><span class="line">    display.print(temperature);</span><br><span class="line">    display.println(<span class="string">&quot; C&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    display.setCursor(0, 20);</span><br><span class="line">    display.println(<span class="string">&quot;ERROR&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  display.display();</span><br><span class="line">  delay(1000);  // 每秒刷新一次</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>超声波雷达测距</title>
    <url>/zhihaojiang.github.io/2025/04/21/20250421%E8%B6%85%E5%A3%B0%E6%B3%A2%E9%9B%B7%E8%BE%BE%E6%B5%8B%E8%B7%9D/</url>
    <content><![CDATA[<h2 id="开发板"><a href="#开发板" class="headerlink" title="开发板"></a>开发板</h2><p>Arduino UNO R3</p>
<h2 id="接线"><a href="#接线" class="headerlink" title="接线"></a>接线</h2><p><strong>HC-SR04</strong></p>
<blockquote>
<p>VCC → 3.3V 或 5V<br>GND → GND<br>Trig → Arduino D9<br>Echo → Arduino D10</p>
</blockquote>
<p><strong>OLED (SSD1306 I2C)</strong></p>
<blockquote>
<p>VCC → 3.3V 或 5V<br>GND → GND<br>SCL → A5<br>SDA → A4</p>
</blockquote>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#include &lt;Adafruit_GFX.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;Adafruit_SSD1306.h&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#define TRIG_PIN 9</span></span><br><span class="line"><span class="comment">#define ECHO_PIN 10</span></span><br><span class="line"><span class="comment">#define SCREEN_WIDTH 128</span></span><br><span class="line"><span class="comment">#define SCREEN_HEIGHT 64</span></span><br><span class="line"><span class="comment">#define OLED_RESET     -1</span></span><br><span class="line">Adafruit_SSD1306 display(SCREEN_WIDTH, SCREEN_HEIGHT, &amp;Wire, OLED_RESET);</span><br><span class="line"></span><br><span class="line">void <span class="function"><span class="title">setup</span></span>() &#123;</span><br><span class="line">  pinMode(TRIG_PIN, OUTPUT);</span><br><span class="line">  pinMode(ECHO_PIN, INPUT);</span><br><span class="line"></span><br><span class="line">  Serial.begin(9600);</span><br><span class="line">  <span class="keyword">if</span>(!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) &#123;</span><br><span class="line">    Serial.println(F(<span class="string">&quot;OLED init failed&quot;</span>));</span><br><span class="line">    <span class="keyword">for</span>(;;);</span><br><span class="line">  &#125;</span><br><span class="line">  display.clearDisplay();</span><br><span class="line">  display.display();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">float</span> <span class="function"><span class="title">getDistance</span></span>() &#123;</span><br><span class="line">  digitalWrite(TRIG_PIN, LOW);</span><br><span class="line">  delayMicroseconds(2);</span><br><span class="line">  digitalWrite(TRIG_PIN, HIGH);</span><br><span class="line">  delayMicroseconds(10);</span><br><span class="line">  digitalWrite(TRIG_PIN, LOW);</span><br><span class="line">  long duration = pulseIn(ECHO_PIN, HIGH);</span><br><span class="line">  <span class="built_in">return</span> duration * 0.034 / 2;  // 距离（厘米）</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int posX = 0; // 用来在横向慢慢移动</span><br><span class="line"></span><br><span class="line">void <span class="function"><span class="title">loop</span></span>() &#123;</span><br><span class="line"></span><br><span class="line">      // 绘制两边的参考线</span><br><span class="line">  display.drawLine(0, 0, 0, SCREEN_HEIGHT, WHITE);  // 左边的距离线</span><br><span class="line">  display.drawLine(SCREEN_WIDTH - 1, 0, SCREEN_WIDTH - 1, SCREEN_HEIGHT, WHITE);  // 右边的距离线</span><br><span class="line">  display.display();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">float</span> distance = getDistance();  // 单位 cm</span><br><span class="line">  Serial.<span class="built_in">print</span>(<span class="string">&quot;Distance: &quot;</span>);</span><br><span class="line">  Serial.println(distance);</span><br><span class="line"></span><br><span class="line">  // 归一化距离（最多显示到60cm）</span><br><span class="line">  int r = map(min(distance, 60.0), 0, 60, SCREEN_HEIGHT - 1, 0); // 越远越上</span><br><span class="line"></span><br><span class="line">  display.drawPixel(posX, r, WHITE);</span><br><span class="line">  posX++;</span><br><span class="line">  <span class="keyword">if</span> (posX &gt;= SCREEN_WIDTH) &#123;</span><br><span class="line">    posX = 0;</span><br><span class="line">    display.clearDisplay(); // 清除屏幕从头来</span><br><span class="line">  &#125;</span><br><span class="line">  display.display();</span><br><span class="line">  delay(100); // 每秒10个点</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Predict Calorie Expenditure</title>
    <url>/zhihaojiang.github.io/2025/05/09/20250509Predict%20Calorie%20Expenditure/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/competitions/playground-series-s5e5/data" >https://www.kaggle.com/competitions/playground-series-s5e5/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h1><p>The dataset for this competition (both train and test) was generated from a deep learning model trained on the Calories Burnt Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.</p>
<p>Files<br>train.csv - the training dataset; Calories is the continuous target<br>test.csv - the test dataset; your objective is to predict the Calories for each row<br>sample_submission.csv - a sample submission file in the correct format.</p>
<h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><p>导入库</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/001.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/002.png"
                      alt="photo"
                ></p>
<p>通过翻译得到每个特征的意思：</p>
<ul>
<li>Sex: 性别，1表示男性，0表示女性</li>
<li>Age: 年龄</li>
<li>Height: 身高，单位为厘米</li>
<li>Weight: 体重，单位为千克</li>
<li>Duration: 活动持续时间，单位为分钟</li>
<li>Heart_Rate: 心率，每分钟的心跳次数</li>
<li>Body_Temp: 体温，单位为摄氏度</li>
<li>Calories: 卡路里，这是我们要预测的目标变量</li>
</ul>
<p>我们首先检查数据集中是否存在缺失值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.drop(columns=[<span class="string">&#x27;id&#x27;</span>], inplace=True)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/003.png"
                      alt="photo"
                ></p>
<p>可以看到 没有缺失值</p>
<p>由于我们要预测卡路里的消耗量 因此我们自然想到BMI这个指标与人体有关 因此添加BMI这个特征</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;BMI&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;Weight&#x27;</span>] / (<span class="built_in">df</span>[<span class="string">&#x27;Height&#x27;</span>] / 100) ** 2</span><br></pre></td></tr></table></figure></div>
<h2 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h2><p>将性别转换为数值型</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Sex&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;Sex&#x27;</span>].replace(&#123;<span class="string">&#x27;male&#x27;</span>: 1, <span class="string">&#x27;female&#x27;</span>: 0&#125;)</span><br></pre></td></tr></table></figure></div>

<h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.scatter(<span class="built_in">df</span>[col], <span class="built_in">df</span>[<span class="string">&#x27;Calories&#x27;</span>])</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Calories&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/004.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/005.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/006.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/007.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/008.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/009.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/010.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/011.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/012.png"
                      alt="photo"
                ></p>
<p>可以看到 duration、Heart_Rate、Body_Temp与Calories呈线性关系<br>接下来我们查看特征与特征之间的相关性。</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.countplot(x=pd.cut(<span class="built_in">df</span>[<span class="string">&#x27;Weight&#x27;</span>], bins=20, labels=False), data=<span class="built_in">df</span>,hue=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/013.png"
                      alt="photo"
                ></p>
<p>可以看到 男性的体重分布是偏右的，而女性的体重分布是偏左的</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.lineplot(x=<span class="string">&#x27;Height&#x27;</span>,y=<span class="string">&#x27;Weight&#x27;</span>,data=<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/014.png"
                      alt="photo"
                ></p>
<p>可以看到 Weight与Height存在正相关</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.lineplot(x=<span class="string">&#x27;Duration&#x27;</span>,y=<span class="string">&#x27;Heart_Rate&#x27;</span>,data=<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/015.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.lineplot(x=<span class="string">&#x27;Duration&#x27;</span>,y=<span class="string">&#x27;Body_Temp&#x27;</span>,data=<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/016.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.lineplot(x=<span class="string">&#x27;Heart_Rate&#x27;</span>,y=<span class="string">&#x27;Body_Temp&#x27;</span>,data=<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/017.png"
                      alt="photo"
                ></p>
<h2 id="异常值可视化检测"><a href="#异常值可视化检测" class="headerlink" title="异常值可视化检测"></a>异常值可视化检测</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    sns.boxplot(x=<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/018.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/019.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/020.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/021.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/022.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/023.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/024.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/025.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/026.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy.stats import mstats</span><br><span class="line"></span><br><span class="line">features = [<span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    <span class="built_in">df</span>[col] = mstats.winsorize(<span class="built_in">df</span>[col], limits=[0.05, 0.05])</span><br></pre></td></tr></table></figure></div>

<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.corr()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/09/027.png"
                      alt="photo"
                ></p>
<p>可以看到在相关性分析中</p>
<p><code>Calories</code>与<code>Duration</code>、<code>Heart_Rate</code>、<code>Body_Temp</code>的相关性最高<br>为0.959908、0.908748、0.828671，因此选择这三个特征作为模型的输入特征<br>接下来 我们通过卡方检验来选择特征</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;Calories&#x27;</span>]</span><br><span class="line">X = df.drop([<span class="string">&#x27;Calories&#x27;</span>], axis=1)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectKBest, chi2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用卡方检验选择前 2 个最佳特征</span></span><br><span class="line">selector = SelectKBest(chi2, k=3)</span><br><span class="line">X_new = selector.fit_transform(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择后的特征形状：&quot;</span>, X_new.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每个特征的得分：&quot;</span>, selector.scores_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;是否被选择：&quot;</span>, selector.get_support())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出每个特征的得分</span></span><br><span class="line">scores = pd.Series(selector.scores_, index=X.columns)</span><br><span class="line">scores = scores.sort_values(ascending=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卡方检验得分最高的特征：\n&quot;</span>, scores.head(10))</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>选择后的特征形状： (600000, 3)<br>每个特征的得分： [8.72102007e+03 2.13858892e+05 1.32375353e+04 4.71694088e+04<br> 2.61568982e+06 4.35154289e+05 6.94410801e+03 1.65968833e+03]<br>是否被选择： [False  True False False  True  True False False]<br>卡方检验得分最高的特征：<br> Duration      2.615690e+06<br>Heart_Rate    4.351543e+05<br>Age           2.138589e+05<br>Weight        4.716941e+04<br>Height        1.323754e+04<br>Sex           8.721020e+03<br>Body_Temp     6.944108e+03<br>BMI           1.659688e+03<br>dtype: float64</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.drop(columns=[<span class="string">&#x27;BMI&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>], inplace=True)</span><br></pre></td></tr></table></figure></div>

<h2 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;Calories&#x27;</span>]</span><br><span class="line">X = df.drop([<span class="string">&#x27;Calories&#x27;</span>], axis=1)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br></pre></td></tr></table></figure></div>

<h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line">import xgboost as xgb</span><br><span class="line">from sklearn.ensemble import GradientBoostingRegressor</span><br><span class="line">from sklearn.metrics import root_mean_squared_error, root_mean_squared_log_error, r2_score</span><br><span class="line"></span><br><span class="line">models = &#123;</span><br><span class="line">    <span class="string">&#x27;Linear Regression&#x27;</span>: LinearRegression(),</span><br><span class="line">    <span class="string">&#x27;Random Forest&#x27;</span>: RandomForestRegressor(),</span><br><span class="line">    <span class="string">&#x27;XGBoost&#x27;</span>: xgb.XGBRegressor(),</span><br><span class="line">    <span class="string">&#x27;Gradient Boosting&#x27;</span>: GradientBoostingRegressor()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">results = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():</span><br><span class="line">    y_train_log = np.log1p(y_train)</span><br><span class="line">    model.fit(X_train_scaled, y_train_log)</span><br><span class="line">    y_pred_log = model.predict(X_test_scaled)</span><br><span class="line">    y_pred = np.expm1(y_pred_log)</span><br><span class="line"></span><br><span class="line">    rmse = root_mean_squared_error(y_test, y_pred)</span><br><span class="line">    rmsle = root_mean_squared_log_error(y_test, y_pred)</span><br><span class="line">    r2 = r2_score(y_test, y_pred)</span><br><span class="line">    </span><br><span class="line">    results.append(&#123;</span><br><span class="line">        <span class="string">&#x27;Model&#x27;</span>: name,</span><br><span class="line">        <span class="string">&#x27;RMSE&#x27;</span>: rmse,</span><br><span class="line">        <span class="string">&#x27;RMSLE&#x27;</span>: rmsle,</span><br><span class="line">        <span class="string">&#x27;R²&#x27;</span>: r2</span><br><span class="line">    &#125;)</span><br><span class="line">results_df = pd.DataFrame(results)</span><br><span class="line"><span class="built_in">print</span>(results_df)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<pre><code>           Model       RMSE     RMSLE        R²
</code></pre>
<p>0  Linear Regression  16.044743  0.212877  0.933576<br>1      Random Forest   7.287551  0.102109  0.986297<br>2            XGBoost   6.839083  0.096267  0.987931<br>3  Gradient Boosting   7.001537  0.097709  0.987351</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习中的优化方法及其python实现</title>
    <url>/zhihaojiang.github.io/2025/04/26/20250426%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%8F%8A%E5%85%B6python%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><p><a class="link"   href="https://www.kaggle.com/datasets/mirichoi0218/insurance/data" >https://www.kaggle.com/datasets/mirichoi0218/insurance/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h2><p>About Dataset<br>Context<br>Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.</p>
<p>Content<br>Columns</p>
<p>age: age of primary beneficiary</p>
<p>sex: insurance contractor gender, female, male</p>
<p>bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,<br>objective index of body weight (kg &#x2F; m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9</p>
<p>children: Number of children covered by health insurance &#x2F; Number of dependents</p>
<p>smoker: Smoking</p>
<p>region: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.</p>
<p>charges: Individual medical costs billed by health insurance</p>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><h3 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler, OneHotEncoder</span><br><span class="line">from sklearn.compose import ColumnTransformer</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br></pre></td></tr></table></figure></div>

<h3 id="数据查看"><a href="#数据查看" class="headerlink" title="数据查看"></a>数据查看</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/001.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/002.png"
                      alt="photo"
                ></p>
<h3 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">num_cols = df.select_dtypes(include=[np.number]).columns.tolist()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> num_cols:</span><br><span class="line">    sns.boxplot(x=col, data=<span class="built_in">df</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/003.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/004.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/005.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/006.png"
                      alt="photo"
                ></p>
<p>可以看到 bmi有异常值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy.stats import mstats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 胜率变换：将异常值限制在 5% 和 95% 分位数之间</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;bmi&#x27;</span>] = mstats.winsorize(<span class="built_in">df</span>[<span class="string">&#x27;bmi&#x27;</span>], limits=[0.05, 0.05])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">object_cols = df.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>]).columns.tolist()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> object_cols:</span><br><span class="line">    sns.countplot(x=col, data=<span class="built_in">df</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/007.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/008.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/009.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#此图来源：https://www.kaggle.com/code/analyticaobscura/medical-cost-analysis</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(10, 6))</span><br><span class="line">sns.kdeplot(</span><br><span class="line">    data=<span class="built_in">df</span>, </span><br><span class="line">    x=<span class="string">&quot;age&quot;</span>, </span><br><span class="line">    y=<span class="string">&quot;charges&quot;</span>, </span><br><span class="line">    cmap=<span class="string">&quot;Purples&quot;</span>, </span><br><span class="line">    shade=True,     </span><br><span class="line">    cbar=True       </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Age vs Medical Charges KDE Plot&quot;</span>, fontsize=16, color=<span class="string">&#x27;indigo&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Age&quot;</span>, fontsize=12, color=<span class="string">&#x27;slateblue&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Medical Charges ($)&quot;</span>, fontsize=12, color=<span class="string">&#x27;slateblue&#x27;</span>)</span><br><span class="line">plt.grid(True, color=<span class="string">&#x27;lavender&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/015.png"
                      alt="photo"
                ></p>
<p>可以看到 费用与年龄的关系不大<br>大部份人的费用在 10000 左右 并且费用呈现3个档次：10000以下 20000左右 35000左右</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#此图来源：https://www.kaggle.com/code/analyticaobscura/medical-cost-analysis</span></span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(1, 2, figsize=(16, 6))</span><br><span class="line">colors = sns.color_palette(<span class="string">&quot;Purples&quot;</span>, 2)  </span><br><span class="line"></span><br><span class="line">sns.boxplot(</span><br><span class="line">    ax=axes[0], </span><br><span class="line">    data=<span class="built_in">df</span>, </span><br><span class="line">    x=<span class="string">&quot;smoker&quot;</span>, </span><br><span class="line">    y=<span class="string">&quot;charges&quot;</span>, </span><br><span class="line">    palette=<span class="string">&quot;Purples&quot;</span></span><br><span class="line">    )</span><br><span class="line">axes[0].set_title(<span class="string">&quot;Medical Charges by Smoking Status&quot;</span>, fontsize=16, color=<span class="string">&#x27;indigo&#x27;</span>)</span><br><span class="line">axes[0].set_xlabel(<span class="string">&quot;Smoker&quot;</span>, fontsize=12, color=<span class="string">&#x27;slateblue&#x27;</span>)</span><br><span class="line">axes[0].set_ylabel(<span class="string">&quot;Medical Charges ($)&quot;</span>, fontsize=12, color=<span class="string">&#x27;slateblue&#x27;</span>)</span><br><span class="line">axes[0].grid(True, linestyle=<span class="string">&#x27;--&#x27;</span>, color=<span class="string">&#x27;lavender&#x27;</span>)</span><br><span class="line"></span><br><span class="line">smoker_counts = <span class="built_in">df</span>[<span class="string">&#x27;smoker&#x27;</span>].value_counts()</span><br><span class="line">axes[1].pie(</span><br><span class="line">    smoker_counts, </span><br><span class="line">    labels=smoker_counts.index, </span><br><span class="line">    autopct=<span class="string">&#x27;%1.1f%%&#x27;</span>, </span><br><span class="line">    colors=colors, </span><br><span class="line">    startangle=140, </span><br><span class="line">    wedgeprops=&#123;<span class="string">&#x27;edgecolor&#x27;</span>: <span class="string">&#x27;white&#x27;</span>&#125;</span><br><span class="line">)</span><br><span class="line">axes[1].set_title(<span class="string">&quot;Proportion of Smokers vs Non-Smokers&quot;</span>, fontsize=16, color=<span class="string">&#x27;indigo&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/016.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.subplots(figsize=(10, 6))</span><br><span class="line">plt.subplot(1, 2, 1)</span><br><span class="line">sns.countplot(x=<span class="string">&#x27;smoker&#x27;</span>, data=<span class="built_in">df</span>,hue=<span class="string">&#x27;sex&#x27;</span>, palette=<span class="string">&#x27;Purples&#x27;</span>)</span><br><span class="line">plt.subplot(1, 2, 2)</span><br><span class="line">sns.barplot(x=<span class="string">&#x27;smoker&#x27;</span>,y = <span class="string">&#x27;charges&#x27;</span>, data=<span class="built_in">df</span>,hue=<span class="string">&#x27;sex&#x27;</span>, palette=<span class="string">&#x27;Purples&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/017.png"
                      alt="photo"
                ></p>
<p>可以看到 调查者中不吸烟的占大多数 吸烟者中 男性较多 并且 不吸烟的人医疗费用远小于吸烟者</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.barplot(x=<span class="string">&#x27;children&#x27;</span>,y = <span class="string">&#x27;charges&#x27;</span>, data=<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/018.png"
                      alt="photo"
                ></p>
<p>可以看到 有3个孩子的人医疗费用最高 不过我认为 孩子越多费用越高 不过那4和5比3要低 可能因为幸存者偏差：负担的费用过高而破产、自杀、没被记录所导致的</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.barplot(x=<span class="string">&#x27;region&#x27;</span>, y=<span class="string">&#x27;charges&#x27;</span>,data=<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/019.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.kdeplot(</span><br><span class="line">    x=<span class="string">&#x27;bmi&#x27;</span>, </span><br><span class="line">    y=<span class="string">&#x27;charges&#x27;</span>, </span><br><span class="line">    shade=True,</span><br><span class="line">    cmap=<span class="string">&#x27;Purples&#x27;</span>,</span><br><span class="line">    data=<span class="built_in">df</span></span><br><span class="line">    )</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/020.png"
                      alt="photo"
                ></p>
<p>可以看到 大部份人的bmi指数在20～40之间 且费用都在10000左右 通过查询得知 bmi指数在18.5～24.9之间为正常范围 由此得知 现在人们的bmi指数普遍偏高</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.barplot(x=<span class="string">&#x27;sex&#x27;</span>,y = <span class="string">&#x27;bmi&#x27;</span>,hue=<span class="string">&#x27;children&#x27;</span> ,data=<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/021.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">&#x27;age&#x27;</span>,y = <span class="string">&#x27;bmi&#x27;</span> ,data=<span class="built_in">df</span>, line_kws=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;orange&#x27;</span>&#125;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/022.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#此图来源：https://www.kaggle.com/code/analyticaobscura/medical-cost-analysis</span></span><br><span class="line"></span><br><span class="line">average_charges_by_region = df.groupby(<span class="string">&#x27;region&#x27;</span>)[<span class="string">&#x27;charges&#x27;</span>].mean().reset_index()</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(1, 2, figsize=(16, 6)) </span><br><span class="line">colors = sns.color_palette(<span class="string">&quot;Purples&quot;</span>, len(average_charges_by_region))  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.barplot(</span><br><span class="line">    ax=axes[0], </span><br><span class="line">    data=average_charges_by_region, </span><br><span class="line">    x=<span class="string">&quot;region&quot;</span>, </span><br><span class="line">    y=<span class="string">&quot;charges&quot;</span>, </span><br><span class="line">    palette=<span class="string">&quot;Purples&quot;</span></span><br><span class="line">    )</span><br><span class="line">axes[0].set_title(<span class="string">&quot;Average Medical Charges by Region&quot;</span>, fontsize=16, color=<span class="string">&#x27;indigo&#x27;</span>)</span><br><span class="line">axes[0].set_xlabel(<span class="string">&quot;Region&quot;</span>, fontsize=12, color=<span class="string">&#x27;slateblue&#x27;</span>)</span><br><span class="line">axes[0].set_ylabel(<span class="string">&quot;Average Medical Charges ($)&quot;</span>, fontsize=12, color=<span class="string">&#x27;slateblue&#x27;</span>)</span><br><span class="line">axes[0].grid(True, linestyle=<span class="string">&#x27;--&#x27;</span>, color=<span class="string">&#x27;lavender&#x27;</span>)</span><br><span class="line"></span><br><span class="line">charges = average_charges_by_region[<span class="string">&#x27;charges&#x27;</span>]</span><br><span class="line">regions = average_charges_by_region[<span class="string">&#x27;region&#x27;</span>]</span><br><span class="line">explode = [0.1 <span class="keyword">if</span> i == charges.idxmax() <span class="keyword">else</span> 0 <span class="keyword">for</span> i <span class="keyword">in</span> range(len(charges))] </span><br><span class="line">axes[1].pie(</span><br><span class="line">    charges, </span><br><span class="line">    labels=regions, </span><br><span class="line">    autopct=<span class="string">&#x27;%1.1f%%&#x27;</span>, </span><br><span class="line">    colors=colors, </span><br><span class="line">    explode=explode, </span><br><span class="line">    shadow=True, </span><br><span class="line">    startangle=140, </span><br><span class="line">    wedgeprops=&#123;<span class="string">&#x27;edgecolor&#x27;</span>: <span class="string">&#x27;white&#x27;</span>&#125;</span><br><span class="line">)</span><br><span class="line">axes[1].set_title(<span class="string">&quot;Proportion of Average Charges by Region&quot;</span>, fontsize=16, color=<span class="string">&#x27;indigo&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/023.png"
                      alt="photo"
                ></p>
<h3 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop(columns=[<span class="string">&#x27;charges&#x27;</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;charges&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><p>数值型 归一化<br>类别型 独热编码</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">num_cols = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;bmi&#x27;</span>, <span class="string">&#x27;children&#x27;</span>]</span><br><span class="line">obj_cols = [<span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;smoker&#x27;</span>, <span class="string">&#x27;region&#x27;</span>]</span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer([</span><br><span class="line">    (<span class="string">&#x27;scale_num&#x27;</span>, StandardScaler(), num_cols),</span><br><span class="line">    (<span class="string">&#x27;encode_obj&#x27;</span>, OneHotEncoder(), obj_cols)</span><br><span class="line">])</span><br></pre></td></tr></table></figure></div>

<h3 id="模型建立（线性回归）"><a href="#模型建立（线性回归）" class="headerlink" title="模型建立（线性回归）"></a>模型建立（线性回归）</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">preprocessor.fit(X_train)</span><br><span class="line"></span><br><span class="line">X_train_processed = preprocessor.transform(X_train)</span><br><span class="line">X_test_processed = preprocessor.transform(X_test)</span><br><span class="line"></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(X_train_processed, y_train)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y_pred = model.predict(X_test_processed)</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line">score = model.score(X_test_processed, y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mse =&quot;</span>, mse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;R2 =&quot;</span>, r2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;score =&quot;</span>, score)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/010.png"
                      alt="photo"
                ></p>
<h3 id="使用不同的优化算法进行优化"><a href="#使用不同的优化算法进行优化" class="headerlink" title="使用不同的优化算法进行优化"></a>使用不同的优化算法进行优化</h3><h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X_train_array = X_train_processed</span><br><span class="line">X_test_array = X_test_processed</span><br><span class="line"></span><br><span class="line">results = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降</span></span><br><span class="line">def gradient_descent(X, y, lr=0.01, n_epochs=1000):</span><br><span class="line">    m, n = X.shape</span><br><span class="line">    w = np.random.randn(n)</span><br><span class="line">    b = 0</span><br><span class="line">    losses = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        y_pred = X @ w + b</span><br><span class="line">        error = y_pred - y</span><br><span class="line">        grad_w = (1/m) * X.T @ error</span><br><span class="line">        grad_b = (1/m) * np.sum(error)</span><br><span class="line"></span><br><span class="line">        w -= lr * grad_w</span><br><span class="line">        b -= lr * grad_b</span><br><span class="line"></span><br><span class="line">        loss = (1/(2*m)) * np.sum(error**2)</span><br><span class="line">        losses.append(loss)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> w, b, losses</span><br><span class="line"></span><br><span class="line">w_gd, b_gd, losses_gd = gradient_descent(X_train_array, y_train.values, lr=0.002, n_epochs=20000)</span><br><span class="line">y_pred_gd = X_test_array @ w_gd + b_gd</span><br><span class="line">results[<span class="string">&#x27;Gradient Descent&#x27;</span>] = &#123;</span><br><span class="line">    <span class="string">&#x27;MSE&#x27;</span>: mean_squared_error(y_test, y_pred_gd),</span><br><span class="line">    <span class="string">&#x27;R2&#x27;</span>: r2_score(y_test, y_pred_gd)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">results_df = pd.DataFrame(results).T</span><br><span class="line"><span class="built_in">print</span>(results_df)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 5))</span><br><span class="line">plt.plot(range(1, len(losses_gd)+1), losses_gd, label=<span class="string">&#x27;Gradient Descent Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss (MSE)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Learning Curve - Gradient Descent&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/012.png"
                      alt="photo"
                ></p>
<h4 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 牛顿法（正规方程）</span></span><br><span class="line">X_train_bias = np.hstack([X_train_array, np.ones((X_train_array.shape[<span class="number">0</span>], <span class="number">1</span>))])</span><br><span class="line">X_test_bias = np.hstack([X_test_array, np.ones((X_test_array.shape[<span class="number">0</span>], <span class="number">1</span>))])</span><br><span class="line"></span><br><span class="line">XTX = X_train_bias.T @ X_train_bias</span><br><span class="line">XTy = X_train_bias.T @ y_train.values</span><br><span class="line">w_newton = np.linalg.pinv(XTX) @ XTy</span><br><span class="line">y_pred_newton = X_test_bias @ w_newton</span><br><span class="line"></span><br><span class="line">results[<span class="string">&quot;Newton&#x27;s Method&quot;</span>] = &#123;</span><br><span class="line">    <span class="string">&#x27;MSE&#x27;</span>: mean_squared_error(y_test, y_pred_newton),</span><br><span class="line">    <span class="string">&#x27;R2&#x27;</span>: r2_score(y_test, y_pred_newton)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">results_df = pd.DataFrame(results).T</span><br><span class="line"><span class="built_in">print</span>(results_df)</span><br></pre></td></tr></table></figure></div>

<h4 id="SGDRegressor"><a href="#SGDRegressor" class="headerlink" title="SGDRegressor"></a>SGDRegressor</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import SGDRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># sklearn SGDRegressor</span></span><br><span class="line">sgd_model = SGDRegressor(penalty=None,max_iter=10000, learning_rate=<span class="string">&#x27;adaptive&#x27;</span>, eta0=0.001, random_state=42)</span><br><span class="line">sgd_model.fit(X_train_array, y_train)</span><br><span class="line">y_pred_sgd = sgd_model.predict(X_test_array)</span><br><span class="line">results[<span class="string">&#x27;SGDRegressor (sklearn)&#x27;</span>] = &#123;</span><br><span class="line">    <span class="string">&#x27;MSE&#x27;</span>: mean_squared_error(y_test, y_pred_sgd),</span><br><span class="line">    <span class="string">&#x27;R2&#x27;</span>: r2_score(y_test, y_pred_sgd)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 动量法</span></span><br><span class="line">def momentum_optimizer(X, y, lr=0.01, n_epochs=1000, beta=0.9):</span><br><span class="line">    m, n = X.shape</span><br><span class="line">    w = np.random.randn(n)  <span class="comment"># 初始化权重</span></span><br><span class="line">    b = 0  <span class="comment"># 初始化偏置</span></span><br><span class="line"></span><br><span class="line">    v_w = np.zeros(n)  <span class="comment"># 初始化动量</span></span><br><span class="line">    v_b = 0  <span class="comment"># 初始化偏置动量</span></span><br><span class="line"></span><br><span class="line">    losses = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        y_pred = X @ w + b</span><br><span class="line">        error = y_pred - y</span><br><span class="line"></span><br><span class="line">        grad_w = (1/m) * (X.T @ error)</span><br><span class="line">        grad_b = (1/m) * np.sum(error)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新动量</span></span><br><span class="line">        v_w = beta * v_w + (1 - beta) * grad_w</span><br><span class="line">        v_b = beta * v_b + (1 - beta) * grad_b</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        w -= lr * v_w</span><br><span class="line">        b -= lr * v_b</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = (1/(2*m)) * np.sum(error**2)</span><br><span class="line">        losses.append(loss)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> w, b, losses</span><br><span class="line">    </span><br><span class="line">w_momentum, b_momentum, losses_momentum = momentum_optimizer(X_train_array, y_train.values, lr=0.001, n_epochs=10000, beta=0.9)</span><br><span class="line"></span><br><span class="line">y_pred_momentum = X_test_array @ w_momentum + b_momentum</span><br><span class="line"></span><br><span class="line">results[<span class="string">&#x27;momentum_optimizer&#x27;</span>] = &#123;</span><br><span class="line">    <span class="string">&#x27;MSE&#x27;</span>: mean_squared_error(y_test, y_pred_momentum),</span><br><span class="line">    <span class="string">&#x27;R2&#x27;</span>: r2_score(y_test, y_pred_momentum)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 5))</span><br><span class="line">plt.plot(range(1, len(losses_momentum)+1), losses_momentum, label=<span class="string">&#x27;momentum_optimizer Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss (MSE)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Learning Curve - momentum_optimizer&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/013.png"
                      alt="photo"
                ></p>
<h4 id="Adam优化器"><a href="#Adam优化器" class="headerlink" title="Adam优化器"></a>Adam优化器</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Adam优化器</span></span><br><span class="line">def adam_optimizer(X, y, lr=0.001, n_epochs=1000, beta1=0.9, beta2=0.999, epsilon=1e-8):</span><br><span class="line">    m, n = X.shape</span><br><span class="line">    w = np.random.randn(n)  <span class="comment"># 初始化权重</span></span><br><span class="line">    b = 0  <span class="comment"># 初始化偏置</span></span><br><span class="line"></span><br><span class="line">    m_w = np.zeros(n)  <span class="comment"># 初始化一阶矩</span></span><br><span class="line">    v_w = np.zeros(n)  <span class="comment"># 初始化二阶矩</span></span><br><span class="line">    m_b = 0  <span class="comment"># 初始化偏置的一阶矩</span></span><br><span class="line">    v_b = 0  <span class="comment"># 初始化偏置的二阶矩</span></span><br><span class="line"></span><br><span class="line">    losses = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        y_pred = X @ w + b</span><br><span class="line">        error = y_pred - y</span><br><span class="line"></span><br><span class="line">        grad_w = (1/m) * (X.T @ error)</span><br><span class="line">        grad_b = (1/m) * np.sum(error)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新一阶矩和二阶矩</span></span><br><span class="line">        m_w = beta1 * m_w + (1 - beta1) * grad_w</span><br><span class="line">        v_w = beta2 * v_w + (1 - beta2) * (grad_w ** 2)</span><br><span class="line">        m_b = beta1 * m_b + (1 - beta1) * grad_b</span><br><span class="line">        v_b = beta2 * v_b + (1 - beta2) * (grad_b ** 2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算偏差修正</span></span><br><span class="line">        m_w_hat = m_w / (1 - beta1 ** (epoch + 1))</span><br><span class="line">        v_w_hat = v_w / (1 - beta2 ** (epoch + 1))</span><br><span class="line">        m_b_hat = m_b / (1 - beta1 ** (epoch + 1))</span><br><span class="line">        v_b_hat = v_b / (1 - beta2 ** (epoch + 1))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新权重和偏置</span></span><br><span class="line">        w -= lr * m_w_hat / (np.sqrt(v_w_hat) + epsilon)</span><br><span class="line">        b -= lr * m_b_hat / (np.sqrt(v_b_hat) + epsilon)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = (1/(2*m)) * np.sum(error**2)</span><br><span class="line">        losses.append(loss)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> w, b, losses</span><br><span class="line">    </span><br><span class="line">w_adam, b_adam, losses_adam = adam_optimizer(X_train_array, y_train.values, lr=0.0001, n_epochs=50000,beta1=0.85)</span><br><span class="line"></span><br><span class="line">y_pred_adam = X_test_array @ w_adam + b_adam</span><br><span class="line"></span><br><span class="line">results[<span class="string">&#x27;adam_optimizer&#x27;</span>] = &#123;</span><br><span class="line">    <span class="string">&#x27;MSE&#x27;</span>: mean_squared_error(y_test, y_pred_adam),</span><br><span class="line">    <span class="string">&#x27;R2&#x27;</span>: r2_score(y_test, y_pred_adam)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 5))</span><br><span class="line">plt.plot(range(1, len(losses_adam)+1), losses_adam, label=<span class="string">&#x27;adam_optimizer Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss (MSE)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Learning Curve - adam_optimizer&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/014.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">results_df = pd.DataFrame(results).T</span><br><span class="line"><span class="built_in">print</span>(results_df)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/04/26/011.png"
                      alt="photo"
                ></p>
<h3 id="使用随机森林预测"><a href="#使用随机森林预测" class="headerlink" title="使用随机森林预测"></a>使用随机森林预测</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line">rf_model = RandomForestRegressor(n_estimators=100, random_state=42)</span><br><span class="line">rf_model.fit(X_train_processed, y_train)</span><br><span class="line"></span><br><span class="line">y_pred_rf = rf_model.predict(X_test_array)</span><br><span class="line"></span><br><span class="line">mse_rf = mean_squared_error(y_test, y_pred_rf)</span><br><span class="line">r2_rf = r2_score(y_test, y_pred_rf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Random Forest MSE: &#123;mse_rf:.4f&#125;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Random Forest R2: &#123;r2_rf:.4f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>Random Forest MSE: 21083936.2878<br>Random Forest R2: 0.8642</p>
</blockquote>
<h4 id="贝叶斯优化"><a href="#贝叶斯优化" class="headerlink" title="贝叶斯优化"></a>贝叶斯优化</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from hyperopt import fmin, tpe, hp, STATUS_OK, Trials</span><br><span class="line"></span><br><span class="line">def objective(params):</span><br><span class="line">    model = RandomForestRegressor(</span><br><span class="line">        n_estimators=int(params[<span class="string">&#x27;n_estimators&#x27;</span>]),</span><br><span class="line">        max_depth=int(params[<span class="string">&#x27;max_depth&#x27;</span>]),</span><br><span class="line">        min_samples_split=int(params[<span class="string">&#x27;min_samples_split&#x27;</span>]),</span><br><span class="line">        min_samples_leaf=int(params[<span class="string">&#x27;min_samples_leaf&#x27;</span>]),</span><br><span class="line">        random_state=42</span><br><span class="line">    )</span><br><span class="line">    model.fit(X_train_processed, y_train)</span><br><span class="line">    y_pred = model.predict(X_test_processed)</span><br><span class="line">    mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">    rmse = np.sqrt(mse)</span><br><span class="line">    <span class="built_in">return</span> &#123;<span class="string">&#x27;loss&#x27;</span>: rmse,<span class="string">&#x27;status&#x27;</span>: STATUS_OK&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数空间</span></span><br><span class="line">space = &#123;</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: hp.quniform(<span class="string">&#x27;n_estimators&#x27;</span>, 50, 200, 1),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: hp.quniform(<span class="string">&#x27;max_depth&#x27;</span>, 5, 20, 1),</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: hp.quniform(<span class="string">&#x27;min_samples_split&#x27;</span>, 2, 10, 1),</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: hp.quniform(<span class="string">&#x27;min_samples_leaf&#x27;</span>, 1, 4, 1)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 定义优化算法</span></span><br><span class="line">tpe_algorithm = tpe.suggest</span><br><span class="line"><span class="comment"># 定义优化过程</span></span><br><span class="line">trials = Trials()</span><br><span class="line">best = fmin(fn=objective,</span><br><span class="line">            space=space,</span><br><span class="line">            algo=tpe_algorithm,</span><br><span class="line">            max_evals=20,</span><br><span class="line">            trials=trials)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best parameters found: &quot;</span>, best)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>100%|██████████| 20&#x2F;20 [00:02&lt;00:00,  6.72trial&#x2F;s, best loss: 4357.951533549515]<br>Best parameters found:  {‘max_depth’: 7.0, ‘min_samples_leaf’: 3.0, ‘min_samples_split’: 7.0, ‘n_estimators’: 81.0}</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">best_model = RandomForestRegressor(</span><br><span class="line">    n_estimators=int(best[<span class="string">&#x27;n_estimators&#x27;</span>]),</span><br><span class="line">    max_depth=int(best[<span class="string">&#x27;max_depth&#x27;</span>]),</span><br><span class="line">    min_samples_split=int(best[<span class="string">&#x27;min_samples_split&#x27;</span>]),</span><br><span class="line">    min_samples_leaf=int(best[<span class="string">&#x27;min_samples_leaf&#x27;</span>]),</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line">best_model.fit(X_train_processed, y_train)</span><br><span class="line">y_pred = best_model.predict(X_test_processed)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">rmse = np.sqrt(mse)</span><br><span class="line">R2 = r2_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;RMSE: &#123;rmse&#125;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;R2: &#123;R2&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>RMSE: 4357.951533549515<br>R2: 0.8776689420501131</p>
</blockquote>
<h4 id="网格优化"><a href="#网格优化" class="headerlink" title="网格优化"></a>网格优化</h4><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: [100, 200, 300],</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [10, 20, None],</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: [2, 5, 10],</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: [1, 2, 4],</span><br><span class="line">    <span class="string">&#x27;max_features&#x27;</span>: [<span class="string">&#x27;sqrt&#x27;</span>, <span class="string">&#x27;log2&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># GridSearchCV</span></span><br><span class="line">grid_search = GridSearchCV(</span><br><span class="line">    estimator=rf_model,</span><br><span class="line">    param_grid=param_grid,</span><br><span class="line">    cv=5,             <span class="comment"># 5折交叉验证</span></span><br><span class="line">    n_jobs=-1,        <span class="comment"># 用所有CPU核加速</span></span><br><span class="line">    verbose=2         <span class="comment"># 输出搜索过程</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">grid_search.fit(X_train_processed, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最优参数：&quot;</span>, grid_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最优得分：&quot;</span>, grid_search.best_score_)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>最优参数： {‘max_depth’: 10, ‘max_features’: ‘sqrt’, ‘min_samples_leaf’: 2, ‘min_samples_split’: 2, ‘n_estimators’: 300}<br>最优得分： 0.8405858915839397</p>
</blockquote>
<p>综上 无论是线性回归还是随机森林 在进行优化后 他们的分数都至少上升了1% 说明使用优化器进行优化是有效果的</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>糖尿病预测分析</title>
    <url>/zhihaojiang.github.io/2025/05/18/20250518%E7%B3%96%E5%B0%BF%E7%97%85%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h1><p>心血管病、糖尿病等慢性疾病，每年导致的死亡人数占总死亡人数的80%，每年用于慢病医疗费用占中国公共医疗卫生支出的比例超过13%。作为一种常见慢性疾病，糖尿病目前无法根治，但通过科学有效的干预、预防和治疗，能降低发病率和提高患者的生活质量。本课题拟对UCI的糖尿病诊断数据集进行机器学习建模分析，在此基础上探讨诱发糖尿病的重要病因</p>
<h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><p>导入库</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from scipy.stats import mstats</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">from skopt import BayesSearchCV</span><br><span class="line">from skopt.space import Integer, Real</span><br><span class="line">from sklearn.model_selection import StratifiedKFold</span><br><span class="line">from sklearn.metrics import recall_score</span><br><span class="line">from skopt.space import Real, Categorical</span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix, accuracy_score</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import data_analysis_tools as dat <span class="comment">#我自己创建的库</span></span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>=pd.read_csv(<span class="string">&#x27;pima-indians-diabetes.data.csv&#x27;</span>)</span><br><span class="line">dat.summarize_df(<span class="built_in">df</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>{‘head’:      6    148    72    35      0  33.6  0.627    50    1  Unnamed: 9  <br> 0  1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  0.0         NaN<br> 1  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  1.0         NaN<br> 2  1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  0.0         NaN<br> 3  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  1.0         NaN<br> 4  5.0  116.0  74.0   0.0    0.0  25.6  0.201  30.0  0.0         NaN   </p>
<pre><code>Unnamed: 10  Unnamed: 11 Unnamed: 12  
</code></pre>
<p> 0          NaN          NaN         NaN<br> 1          NaN          NaN         NaN<br> 2          NaN          NaN         NaN<br> 3          NaN          NaN         NaN<br> 4          NaN          NaN         NaN  ,<br> ‘tail’:       6  148  72  35   0  33.6  0.627  50   1  Unnamed: 9  Unnamed: 10  <br> 772 NaN  NaN NaN NaN NaN   NaN    NaN NaN NaN         NaN          NaN<br> 773 NaN  NaN NaN NaN NaN   NaN    NaN NaN NaN         NaN          NaN<br> 774 NaN  NaN NaN NaN NaN   NaN    NaN NaN NaN         NaN          NaN<br> 775 NaN  NaN NaN NaN NaN   NaN    NaN NaN NaN         NaN          NaN<br> 776 NaN  NaN NaN NaN NaN   NaN    NaN NaN NaN         NaN          NaN   </p>
<pre><code>  Unnamed: 11                                        Unnamed: 12  
</code></pre>
<p> 772          NaN                # 5. 2-Hour serum insulin (mu U&#x2F;ml)<br> 773          NaN  # 6. Body mass index (weight in kg&#x2F;(height in …<br> 774          NaN                    # 7. Diabetes pedigree function<br> 775          NaN                                   # 8. Age (years)<br> 776          NaN                       # 9. Class variable (0 or 1)  ,<br> ‘describe’:                  6         148          72          35           0  <br> count   767.000000  767.000000  767.000000  767.000000  767.000000<br> unique         NaN         NaN         NaN         NaN         NaN<br> top            NaN         NaN         NaN         NaN         NaN<br> freq           NaN         NaN         NaN         NaN         NaN<br> mean      3.842243  120.859192   69.101695   20.517601   79.903520<br> std       3.370877   31.978468   19.368155   15.954059  115.283105<br> min       0.000000    0.000000    0.000000    0.000000    0.000000<br> 25%       1.000000   99.000000   62.000000    0.000000    0.000000<br> 50%       3.000000  117.000000   72.000000   23.000000   32.000000<br> 75%       6.000000  140.000000   80.000000   32.000000  127.500000<br> max      17.000000  199.000000  122.000000   99.000000  846.000000   </p>
<pre><code>           33.6       0.627          50           1  Unnamed: 9  \
</code></pre>
<p> count   767.000000  767.000000  767.000000  767.000000         0.0<br> unique         NaN         NaN         NaN         NaN         NaN<br> top            NaN         NaN         NaN         NaN         NaN<br> freq           NaN         NaN         NaN         NaN         NaN<br> mean     31.990482    0.471674   33.219035    0.348110         NaN<br> std       7.889091    0.331497   11.752296    0.476682         NaN<br> min       0.000000    0.078000   21.000000    0.000000         NaN<br> 25%      27.300000    0.243500   24.000000    0.000000         NaN<br> 50%      32.000000    0.371000   29.000000    0.000000         NaN<br> 75%      36.600000    0.625000   41.000000    1.000000         NaN<br> max      67.100000    2.420000   81.000000    1.000000         NaN   </p>
<pre><code>     Unnamed: 10  Unnamed: 11                    Unnamed: 12  
</code></pre>
<p> count           0.0          0.0                              9<br> unique          NaN          NaN                              9<br> top             NaN          NaN  # 1. Number of times pregnant<br> freq            NaN          NaN                              1<br> mean            NaN          NaN                            NaN<br> std             NaN          NaN                            NaN<br> min             NaN          NaN                            NaN<br> 25%             NaN          NaN                            NaN<br> 50%             NaN          NaN                            NaN<br> 75%             NaN          NaN                            NaN<br> max             NaN          NaN                            NaN  ,<br> ‘info’: “&lt;class ‘pandas.core.frame.DataFrame’&gt;\nRangeIndex: 777 entries, 0 to 776\nData columns (total 13 columns):\n #   Column       Non-Null Count  Dtype  \n—  ——       ————–  —–  \n 0   6            767 non-null    float64\n 1   148          767 non-null    float64\n 2   72           767 non-null    float64\n 3   35           767 non-null    float64\n 4   0            767 non-null    float64\n 5   33.6         767 non-null    float64\n 6   0.627        767 non-null    float64\n 7   50           767 non-null    float64\n 8   1            767 non-null    float64\n 9   Unnamed: 9   0 non-null      float64\n 10  Unnamed: 10  0 non-null      float64\n 11  Unnamed: 11  0 non-null      float64\n 12  Unnamed: 12  9 non-null      object \ndtypes: float64(12), object(1)\nmemory usage: 79.0+ KB\n”,<br> ‘dtypes’: 6              float64<br> 148            float64<br> 72             float64<br> 35             float64<br> 0              float64<br> 33.6           float64<br> 0.627          float64<br> 50             float64<br> 1              float64<br> Unnamed: 9     float64<br> Unnamed: 10    float64<br> Unnamed: 11    float64<br> Unnamed: 12     object<br> dtype: object,<br> ‘missing’: 6               10<br> 148             10<br> 72              10<br> 35              10<br> 0               10<br> 33.6            10<br> 0.627           10<br> 50              10<br> 1               10<br> Unnamed: 9     777<br> Unnamed: 10    777<br> Unnamed: 11    777<br> Unnamed: 12    768<br> dtype: int64}</p>
</blockquote>
<p>通过上述查看，我们得知此数据集的特征描述在文件的右下角，我们将字段名称补充进去</p>
<p>我们首先得到列名</p>
<p>df.columns.tolist()</p>
<blockquote>
<p>[‘6’,<br> ‘148’,<br> ‘72’,<br> ‘35’,<br> ‘0’,<br> ‘33.6’,<br> ‘0.627’,<br> ‘50’,<br> ‘1’,<br> ‘Unnamed: 9’,<br> ‘Unnamed: 10’,<br> ‘Unnamed: 11’,<br> ‘Unnamed: 12’]</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.drop([ <span class="string">&#x27;Unnamed: 9&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Unnamed: 10&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Unnamed: 11&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Unnamed: 12&#x27;</span>], axis=1, inplace=True)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/003.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/004.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">columns = [</span><br><span class="line">    <span class="string">&quot;Number of times pregnant&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Plasma glucose concentration&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Diastolic blood pressure (mm Hg)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Triceps skin fold thickness (mm)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2-Hour serum insulin (mu U/ml)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Body mass index (kg/m^2)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Diabetes pedigree function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Age (years)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Class variable&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加字段名称</span></span><br><span class="line">df.columns = columns</span><br><span class="line"></span><br><span class="line">new_row = pd.Series([6, 148, 72, 35, 0, 33.6, 0.627, 50, 1], index=df.columns)</span><br><span class="line"><span class="built_in">df</span> =pd.concat([<span class="built_in">df</span>, new_row.to_frame().T], ignore_index=True)</span><br><span class="line"></span><br><span class="line">df.tail()</span><br><span class="line"></span><br><span class="line">df.to_csv(<span class="string">&#x27;new_pima-indians-diabetes.data.csv&#x27;</span>, index=False)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>=pd.read_csv(<span class="string">&#x27;new_pima-indians-diabetes.data.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<p>从之前的输出中我们可以看到有空白行 将其删除</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = df.dropna(how=<span class="string">&#x27;all&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>Number of times pregnant            0<br>Plasma glucose concentration        0<br>Diastolic blood pressure (mm Hg)    0<br>Triceps skin fold thickness (mm)    0<br>2-Hour serum insulin (mu U&#x2F;ml)      0<br>Body mass index (kg&#x2F;m^2)            0<br>Diabetes pedigree function          0<br>Age (years)                         0<br>Class variable                      0<br>dtype: int64</p>
</blockquote>
<ul>
<li>Number of times pregnant</li>
<li>怀孕次数</li>
<li>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</li>
<li>口服葡萄糖耐量试验中 2 小时的血浆葡萄糖浓度</li>
<li>Diastolic blood pressure (mm Hg)</li>
<li>舒张压（毫米汞柱）</li>
<li>Triceps skin fold thickness (mm)</li>
<li>三头肌皮褶厚度（毫米）</li>
<li>2-Hour serum insulin (mu U&#x2F;ml)</li>
<li>2 小时血清胰岛素（微单位&#x2F;毫升）</li>
<li>Body mass index (weight in kg&#x2F;(height in m)^2)</li>
<li>体重指数（体重以千克除以身高以米的平方）</li>
<li>Diabetes pedigree function</li>
<li>糖尿病家族史功能</li>
<li>Age (years)</li>
<li>年龄（年）</li>
<li>Class variable (0 or 1)</li>
<li>类别变量（0 或 1）</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.describe()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/005.png"
                      alt="photo"
                ></p>
<p>从min中看到，有0元素，像是Diastolic blood pressure (mm Hg)之类的特征不应该存在0</p>
<p>说明这是缺失值，用均值填充</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">columns = [<span class="string">&#x27;Plasma glucose concentration&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Diastolic blood pressure (mm Hg)&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Triceps skin fold thickness (mm)&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;2-Hour serum insulin (mu U/ml)&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Body mass index (kg/m^2)&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Diabetes pedigree function&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Age (years)&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    mean_value = df.loc[<span class="built_in">df</span>[col] != 0, col].mean()</span><br><span class="line">    <span class="built_in">df</span>[col] = <span class="built_in">df</span>[col].replace(0, mean_value)</span><br></pre></td></tr></table></figure></div>

<p>接下来我们查看是否存在异常值 通过查询相关信息，得到了以下结果</p>
<ol>
<li>Number of times pregnant (怀孕次数)<br>正常范围 ：0 到任意正整数。<br>解释 ：这是一个计数字段，表示一个人怀孕的次数。通常没有上限，但常见的范围是 0 到 15 次（极少数情况下可能更高）。</li>
<li>Plasma glucose concentration a 2 hours in an oral glucose tolerance test (口服葡萄糖耐量试验中 2 小时的血浆葡萄糖浓度)<br>单位 ：mg&#x2F;dL 或 mmol&#x2F;L<br>正常范围 ：<br>正常：小于 140 mg&#x2F;dL（7.8 mmol&#x2F;L）<br>空腹血糖受损（IFG）或糖耐量受损（IGT）：140-199 mg&#x2F;dL（7.8-11.1 mmol&#x2F;L）<br>糖尿病：大于等于 200 mg&#x2F;dL（11.1 mmol&#x2F;L）<br>解释 ：这是诊断糖尿病的重要指标之一。通过口服葡萄糖耐量试验（OGTT），可以评估身体对葡萄糖的代谢能力。</li>
<li>Diastolic blood pressure (mm Hg) (舒张压，毫米汞柱)<br>正常范围 ：60-80 mm Hg<br>异常范围 ：<br>高血压前期：80-89 mm Hg<br>高血压：大于等于 90 mm Hg<br>低血压：小于 60 mm Hg<br>解释 ：舒张压是指心脏放松时血管内的压力。长期高血压可能导致心血管疾病。</li>
<li>Triceps skin fold thickness (mm) (三头肌皮褶厚度，毫米)<br>正常范围 （因性别和年龄而异）：<br>男性：约 10-15 mm<br>女性：约 15-25 mm<br>解释 ：三头肌皮褶厚度用于估算体脂百分比。较高的值可能表明较高的体脂水平。</li>
<li>2-Hour serum insulin (mu U&#x2F;ml) (2 小时血清胰岛素，微单位&#x2F;毫升)<br>正常范围 ：小于 30 mu U&#x2F;ml<br>解释 ：胰岛素是调节血糖的关键激素。高胰岛素水平可能表明胰岛素抵抗或糖尿病前期。</li>
<li>Body mass index (BMI) (体重指数，kg&#x2F;m²)<br>正常范围 ：18.5-24.9<br>分类 ：<br>低于 18.5：体重过轻<br>18.5-24.9：正常体重<br>25-29.9：超重<br>大于等于 30：肥胖<br>解释 ：BMI 是衡量体重是否健康的常用指标，但它不考虑肌肉质量等因素。</li>
<li>Diabetes pedigree function (糖尿病家族史功能)<br>单位 ：无单位（通常是概率值）<br>正常范围 ：0 到 1<br>解释 ：这是一个计算值，表示患糖尿病的概率。值越高，患糖尿病的风险越大。具体范围因模型而异，但通常在 0 到 1 之间。</li>
</ol>
<p>通过查看 没有存在那种明显超过人类水平的异常值</p>
<h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">dat.plot_all_barplots(<span class="built_in">df</span>, hue=<span class="string">&#x27;Class variable&#x27;</span>)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/023.png"
                      alt="photo"
                ></p>
<p>可以看到 有糖尿病的患者各项指标均比非糖尿病的患者高</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.corr()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/014.png"
                      alt="photo"
                ></p>
<p>我们重点关系class variable行 可以看到 Plasma glucose concentration的相关性最高，为0.492928 但仍然不能算作强相关<br>尽管数据中的值在真实世界中都是合理的 但一些特别大的值在进行机器学习时会影响模型的泛化能力，使用IQR方法将异常值替换成边界值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">dat.plot_all_boxplots(<span class="built_in">df</span>,exclude_columns=[<span class="string">&#x27;Class variable&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    <span class="comment"># 计算 IQR</span></span><br><span class="line">    Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">    Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义上下界</span></span><br><span class="line">    lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">    upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line">    <span class="built_in">df</span>[col] = np.where(</span><br><span class="line">    <span class="built_in">df</span>[col] &lt; lower_bound,  </span><br><span class="line">    lower_bound,            </span><br><span class="line">    np.where(</span><br><span class="line">        <span class="built_in">df</span>[col] &gt; upper_bound,  </span><br><span class="line">        upper_bound,           </span><br><span class="line">        <span class="built_in">df</span>[col]                </span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">dat.plot_all_boxplots(<span class="built_in">df</span>,exclude_columns=[<span class="string">&#x27;Class variable&#x27;</span>])</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/024.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/025.png"
                      alt="photo"
                ></p>
<h2 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop(columns=[<span class="string">&#x27;Class variable&#x27;</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;Class variable&#x27;</span>]  <span class="comment"># 目标变量</span></span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">dat.plot_feature_distributions(<span class="built_in">df</span>)</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/026.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">dat.detect_skewness(<span class="built_in">df</span>)</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/05/18/027.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">std = dat.DataStandardizer(method=<span class="string">&#x27;boxcox&#x27;</span>, cols=[<span class="string">&#x27;Number of times pregnant&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Plasma glucose concentration&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Triceps skin fold thickness (mm)&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;2-Hour serum insulin (mu U/ml)&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Body mass index (kg/m^2)&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Diabetes pedigree function&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Age (years)&#x27;</span>])</span><br><span class="line">std.fit(X_train,cols=[<span class="string">&#x27;Number of times pregnant&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Plasma glucose concentration&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Triceps skin fold thickness (mm)&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;2-Hour serum insulin (mu U/ml)&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Body mass index (kg/m^2)&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Diabetes pedigree function&#x27;</span>, </span><br><span class="line">                               <span class="string">&#x27;Age (years)&#x27;</span>])</span><br><span class="line">X_train = std.transform(X_train)</span><br><span class="line">X_test = std.transform(X_test)</span><br></pre></td></tr></table></figure></div>

<h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">models = &#123;</span><br><span class="line">    <span class="string">&quot;RandomForestClassifier&quot;</span>: RandomForestClassifier(n_estimators=100, random_state=42,class_weight=<span class="string">&#x27;balanced&#x27;</span>),</span><br><span class="line">    <span class="string">&quot;LogisticRegression&quot;</span>: LogisticRegression(max_iter=1000, random_state=42,class_weight=<span class="string">&#x27;balanced&#x27;</span>),</span><br><span class="line">    <span class="string">&quot;SVM&quot;</span>: SVC(probability=True, random_state=42,class_weight=<span class="string">&#x27;balanced&#x27;</span>),</span><br><span class="line">    <span class="string">&quot;KNN&quot;</span>: KNeighborsClassifier(),</span><br><span class="line">    <span class="string">&quot;XGBoost&quot;</span>: XGBClassifier(eval_metric=<span class="string">&#x27;logloss&#x27;</span>, random_state=42)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化结果字典</span></span><br><span class="line">results = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历每个模型</span></span><br><span class="line"><span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():  <span class="comment"># 假设 models 是一个字典，键为模型名称，值为模型对象</span></span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    model.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测测试集</span></span><br><span class="line">    y_pred = model.predict(X_test)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取分类报告</span></span><br><span class="line">    report = classification_report(y_test, y_pred, output_dict=True)  <span class="comment"># 返回字典格式</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 存储结果</span></span><br><span class="line">    results[name] = &#123;</span><br><span class="line">        <span class="string">&#x27;accuracy&#x27;</span>: accuracy,</span><br><span class="line">        <span class="string">&#x27;report&#x27;</span>: report</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出每个模型的结果</span></span><br><span class="line"><span class="keyword">for</span> name, result <span class="keyword">in</span> results.items():</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;模型: &#123;name&#125;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;准确率: &#123;result[&#x27;accuracy&#x27;]:.4f&#125;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;分类报告:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(classification_report(y_test, models[name].predict(X_test)))  <span class="comment"># 打印格式化的分类报告</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * 50)</span><br></pre></td></tr></table></figure></div>

<p>模型: RandomForestClassifier<br>准确率: 0.7597<br>分类报告:<br>              precision    recall  f1-score   support</p>
<pre><code>     0.0       0.79      0.84      0.81        97
     1.0       0.69      0.63      0.66        57

accuracy                           0.76       154
</code></pre>
<p>   macro avg       0.74      0.73      0.74       154<br>weighted avg       0.76      0.76      0.76       154</p>
<hr>
<p>模型: LogisticRegression<br>准确率: 0.7468<br>分类报告:<br>              precision    recall  f1-score   support</p>
<pre><code>     0.0       0.83      0.75      0.79        97
     1.0       0.64      0.74      0.68        57

accuracy                           0.75       154
</code></pre>
<p>   macro avg       0.73      0.74      0.74       154<br>weighted avg       0.76      0.75      0.75       154</p>
<hr>
<p>模型: SVM<br>准确率: 0.5779<br>分类报告:<br>              precision    recall  f1-score   support</p>
<pre><code>     0.0       0.68      0.62      0.65        97
     1.0       0.44      0.51      0.47        57

accuracy                           0.58       154
</code></pre>
<p>   macro avg       0.56      0.56      0.56       154<br>weighted avg       0.59      0.58      0.58       154</p>
<hr>
<p>模型: KNN<br>准确率: 0.6558<br>分类报告:<br>              precision    recall  f1-score   support</p>
<pre><code>     0.0       0.71      0.77      0.74        97
     1.0       0.54      0.46      0.50        57

accuracy                           0.66       154
</code></pre>
<p>   macro avg       0.62      0.61      0.62       154<br>weighted avg       0.65      0.66      0.65       154</p>
<hr>
<p>模型: XGBoost<br>准确率: 0.7597<br>分类报告:<br>              precision    recall  f1-score   support</p>
<pre><code>     0.0       0.82      0.79      0.81        97
     1.0       0.67      0.70      0.68        57

accuracy                           0.76       154
</code></pre>
<p>   macro avg       0.74      0.75      0.75       154<br>weighted avg       0.76      0.76      0.76       154</p>
<hr>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>由于我们是要预测糖尿病，要做到减少漏诊，因此我们更关心召回率，提高召回率，精确率不必在意</p>
<p><strong>随机森林的优化</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义参数搜索空间</span></span><br><span class="line">param_space = &#123;</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: Integer(50, 300),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: Integer(3, 30),</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: Integer(2, 20),</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: Integer(1, 10),</span><br><span class="line">    <span class="string">&#x27;max_features&#x27;</span>: Real(0.1, 1.0, prior=<span class="string">&#x27;uniform&#x27;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">rf = RandomForestClassifier(random_state=42, class_weight=<span class="string">&#x27;balanced&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 贝叶斯优化搜索</span></span><br><span class="line">opt = BayesSearchCV(</span><br><span class="line">    rf,</span><br><span class="line">    search_spaces=param_space,</span><br><span class="line">    scoring=<span class="string">&#x27;recall&#x27;</span>,</span><br><span class="line">    n_iter=30,  <span class="comment"># 搜索的步数（越大越好）</span></span><br><span class="line">    cv=StratifiedKFold(n_splits=5),</span><br><span class="line">    random_state=42,</span><br><span class="line">    n_jobs=-1,</span><br><span class="line">    verbose=2</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合模型</span></span><br><span class="line">opt.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best Recall Score:&quot;</span>, opt.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best Parameters:&quot;</span>, opt.best_params_)</span><br></pre></td></tr></table></figure></div>

<p><strong>XGBoost的优化</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算类别不平衡比例，用于 scale_pos_weight</span></span><br><span class="line">neg, pos = (y_train == 0).<span class="built_in">sum</span>(), (y_train == 1).<span class="built_in">sum</span>()</span><br><span class="line">scale_pos_weight = neg / pos</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搜索空间</span></span><br><span class="line">param_space = &#123;</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: Integer(50, 300),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: Integer(3, 15),</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: Real(0.01, 0.3, prior=<span class="string">&#x27;log-uniform&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;subsample&#x27;</span>: Real(0.5, 1.0),</span><br><span class="line">    <span class="string">&#x27;colsample_bytree&#x27;</span>: Real(0.5, 1.0),</span><br><span class="line">    <span class="string">&#x27;gamma&#x27;</span>: Real(0, 5),</span><br><span class="line">    <span class="string">&#x27;min_child_weight&#x27;</span>: Integer(1, 10)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">xgb = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;logloss&#x27;</span>,</span><br><span class="line">    use_label_encoder=False,</span><br><span class="line">    random_state=42,</span><br><span class="line">    scale_pos_weight=scale_pos_weight  <span class="comment"># 处理类别不平衡</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 贝叶斯优化器</span></span><br><span class="line">opt = BayesSearchCV(</span><br><span class="line">    xgb,</span><br><span class="line">    search_spaces=param_space,</span><br><span class="line">    scoring=<span class="string">&#x27;recall&#x27;</span>,  <span class="comment"># 重点优化召回率</span></span><br><span class="line">    cv=StratifiedKFold(n_splits=5),</span><br><span class="line">    n_iter=30,  <span class="comment"># 迭代次数（越大越好）</span></span><br><span class="line">    n_jobs=-1,</span><br><span class="line">    verbose=2,</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行搜索</span></span><br><span class="line">opt.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best Recall Score:&quot;</span>, opt.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best Parameters:&quot;</span>, opt.best_params_)</span><br></pre></td></tr></table></figure></div>

<h2 id="打印最佳召回率"><a href="#打印最佳召回率" class="headerlink" title="打印最佳召回率"></a>打印最佳召回率</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">best_rf = opt.best_estimator_</span><br><span class="line">y_pred = best_rf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Recall:&quot;</span>, recall_score(y_test, y_pred))</span><br><span class="line"></span><br><span class="line">best_xgb = opt.best_estimator_</span><br><span class="line">y_pred = best_xgb.predict(X_test)</span><br><span class="line">recall = recall_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Recall:&quot;</span>, recall)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>Recall: 0.7719298245614035<br>Test Recall: 0.7719298245614035</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>data_analysis_tools介绍</title>
    <url>/zhihaojiang.github.io/2025/05/21/20250521data_analysis_tools%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p>GitHub地址：<a class="link"   href="https://github.com/super-213/dataanalysistools" >https://github.com/super-213/dataanalysistools<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="information"><a href="#information" class="headerlink" title="information"></a>information</h1><h2 id="summarize-df"><a href="#summarize-df" class="headerlink" title="summarize_df()"></a>summarize_df()</h2><p>汇总 DataFrame 的基本信息，包括 head, describe, info 等内容。</p>
<p><strong>参数:</strong><br>        df (pd.DataFrame): 需要汇总的 DataFrame<br>        head_rows (int): 显示前几行数据,默认5行</p>
<p><strong>返回:</strong><br>        dict: 包含 head, tail, describe, info, dtypes, missing 的字典结果</p>
<h1 id="clean"><a href="#clean" class="headerlink" title="clean"></a>clean</h1><h2 id="drop-columns"><a href="#drop-columns" class="headerlink" title="drop_columns()"></a>drop_columns()</h2><p>删除 DataFrame 中的指定列或指定类型的列。</p>
<p><strong>参数</strong><br>    df : pd.DataFrame<br>        要处理的数据框<br>    cols_to_drop : 可迭代[str], optional<br>        要删除的列名列表（如 [‘id’, ‘name’]）<br>    dtypes_to_drop : 可迭代[str], optional<br>        要删除的数据类型（如 [‘object’, ‘datetime64[ns]’]）<br>    verbose : bool, default False<br>        是否打印删除的列名</p>
<p><strong>返回</strong><br>    pd.DataFrame<br>        删除列后的副本</p>
<h2 id="impute"><a href="#impute" class="headerlink" title="impute()"></a>impute()</h2><p>通用缺失值填补函数。</p>
<p><strong>参数</strong><br>    df : DataFrame<br>        原始数据<br>    strategy : {“mean”, “median”, “mode”, “constant”}<br>        填补策略<br>    constant_value : 任意<br>        strategy&#x3D;”constant” 时使用</p>
<p><strong>返回:</strong><br>    DataFrame<br>        填补后的副本</p>
<h2 id="detect-outliers-zscore"><a href="#detect-outliers-zscore" class="headerlink" title="detect_outliers_zscore()"></a>detect_outliers_zscore()</h2><p>使用 Z-Score 方法检测并可剔除异常值。</p>
<p><strong>参数</strong><br>    df : pd.DataFrame<br>        原始数据<br>    cols : list[str], optional<br>        要检测的列（默认全部数值列）<br>    threshold : float<br>        Z 分数阈值，超过即视为异常<br>    method : {‘both’, ‘high’, ‘low’}<br>        检测异常值方向：<br>            - ‘both’: 正负两侧都检测（默认）<br>            - ‘high’: 仅检测高值异常（z &gt; threshold）<br>            - ‘low’:  仅检测低值异常（z &lt; -threshold）<br>    return_zscore : bool<br>        是否返回异常值的 Z 分数（附加在结果中）<br>    drop : bool<br>        是否直接剔除异常值行（返回清洗后的 DataFrame）<br>    verbose : bool<br>        是否输出每列异常值数量<br><strong>返回</strong><br>    如果 drop&#x3D;False 且 return_zscore&#x3D;False:<br>        返回异常值的行（pd.DataFrame）<br>    如果 drop&#x3D;False 且 return_zscore&#x3D;True:<br>        返回包含 Z 分数的异常值 DataFrame<br>    如果 drop&#x3D;True:<br>        返回剔除后的 DataFrame（无异常值）</p>
<h2 id="detect-outliers-iqr"><a href="#detect-outliers-iqr" class="headerlink" title="detect_outliers_iqr()"></a>detect_outliers_iqr()</h2><p>使用 IQR（四分位数）方法检测异常值，并可选择剔除。</p>
<p><strong>参数</strong><br>    df : pd.DataFrame<br>        原始数据<br>    cols : list[str], optional<br>        要检测的列（默认全部数值列）<br>    multiplier : float<br>        IQR 倍数阈值（默认 1.5）<br>    method : {“both”, “high”, “low”}<br>        异常方向控制：<br>            - “both”: 上下两端都检测<br>            - “high”: 仅检测上异常（值 &gt; Q3 + 1.5×IQR）<br>            - “low” : 仅检测下异常（值 &lt; Q1 - 1.5×IQR）<br>    return_bounds : bool<br>        是否返回每列的上下界（Q1 和 Q3 基础上的判断线）<br>    drop : bool<br>        是否直接剔除异常值行（返回清洗后的 df）<br>    verbose : bool<br>        是否打印每列异常数量<br><strong>返回</strong><br>    如果 drop&#x3D;False:<br>        返回异常值 DataFrame<br>    如果 drop&#x3D;True:<br>        返回剔除异常值后的 DataFrame<br>    如果 return_bounds&#x3D;True:<br>        返回 (异常值DataFrame或清洗后df, bounds字典)</p>
<h2 id="detect-outliers-boxplot"><a href="#detect-outliers-boxplot" class="headerlink" title="detect_outliers_boxplot()"></a>detect_outliers_boxplot()</h2><p>用箱线图批量可视化异常值<br>    df: pandas DataFrame<br>    features: 要检查的特征列表（数值型）<br>    max_per_page: 每页最多显示的子图数<br>    figsize: 每页图像尺寸<br>    dpi: 图像清晰度</p>
<h2 id="handle-outliers"><a href="#handle-outliers" class="headerlink" title="handle_outliers()"></a>handle_outliers()</h2><p>处理异常值：删除、替换或裁剪。<br><strong>参数：</strong><br>    - df : 原始 DataFrame<br>    - cols : 指定处理列（默认数值列）<br>    - method : 异常检测方法（zscore 或 iqr）<br>    - strategy : 处理策略（删除、替换、裁剪）<br>    - z_thresh : Z-Score 阈值<br>    - iqr_mult : IQR 倍数<br>    - direction : 异常检测方向（上下）<br>    - verbose : 是否打印信息</p>
<h1 id="EAD"><a href="#EAD" class="headerlink" title="EAD"></a>EAD</h1><h2 id="pairwise-plot"><a href="#pairwise-plot" class="headerlink" title="pairwise_plot()"></a>pairwise_plot()</h2><p>批量绘制特征两两组合的图表，每张大图包含最多9张子图。</p>
<p><strong>参数:</strong><br>    - df: DataFrame 数据<br>    - features: 要组合的特征列名列表<br>    - plot_type: 图表类型：’scatter’, ‘box’, ‘violin’, ‘hist’<br>    - hue: 分类变量（可选）<br>    - max_per_figure: 每页最多显示几个子图<br>    - figsize: 每张图的整体大小<br>    - save: 是否保存图像<br>    - save_prefix: 图像保存的前缀</p>
<h2 id="plot-all-barplots"><a href="#plot-all-barplots" class="headerlink" title="plot_all_barplots()"></a>plot_all_barplots()</h2><p> 将 DataFrame 中所有列（除 except）按类别分组绘制为子图中的柱状图</p>
<p><strong>参数:</strong><br>    - df: pandas DataFrame，包含数据和类别列<br>    - hue: str，表示分类的列名<br>    - n_cols: int，每行显示多少个图</p>
<p><strong>返回:</strong><br>    - 无（直接显示整张图）</p>
<h2 id="plot-feature-distributions"><a href="#plot-feature-distributions" class="headerlink" title="plot_feature_distributions()"></a>plot_feature_distributions()</h2><p>批量绘制特征分布图（直方图 + KDE）。</p>
<p><strong>参数：</strong><br>    - df: pandas DataFrame<br>    - features: 要查看分布的列（默认选择数值型列）<br>    - hue: 分组变量（分类列名）<br>    - bins: 直方图的 bin 数量<br>    - kde: 是否绘制 KDE 曲线<br>    - max_per_figure: 每页显示的图表数<br>    - figsize: 每页图像大小<br>    - save: 是否保存图像<br>    - save_prefix: 保存图像的文件名前缀</p>
<h2 id="plot-all-boxplots"><a href="#plot-all-boxplots" class="headerlink" title="plot_all_boxplots()"></a>plot_all_boxplots()</h2><p>将 DataFrame 中所有数值列绘制为子图中的箱线图</p>
<p><strong>参数:</strong><br>    - df: pandas DataFrame<br>    - n_cols: 每行显示的图数量<br>    - exclude_columns: 要排除的列名列表，例如类别列</p>
<p><strong>返回:</strong><br>    - 无（直接显示整张图）</p>
<h1 id="features"><a href="#features" class="headerlink" title="features"></a>features</h1><h2 id="bin-continuous-variable"><a href="#bin-continuous-variable" class="headerlink" title="bin_continuous_variable()"></a>bin_continuous_variable()</h2><p>对连续变量进行分箱处理。</p>
<p><strong>参数:</strong><br>        df (pd.DataFrame): 输入 DataFrame。<br>        column (str): 要分箱的列名。<br>        method (str): 分箱方法，’equal_width’（等宽）、’equal_freq’（等频）、’custom’（自定义）。<br>        bins (int or List[float]): 分箱数量或自定义边界。<br>        labels (List[str], optional): 分箱标签。如果不传将使用默认区间或数字编号。<br>        return_interval (bool): 是否显示区间（仅对默认 label 生效）。<br>        new_col_name (str): 分箱后新列的名称，默认为原列名+”_binned”。<br>        drop_original (bool): 是否删除原始列。<br>        inplace (bool): 是否在原df上修改。</p>
<p><strong>返回:</strong><br>        pd.DataFrame: 处理后的 DataFrame。</p>
<h1 id="使用案例："><a href="#使用案例：" class="headerlink" title="使用案例："></a>使用案例：</h1><p><a href="https://super-213.github.io/zhihaojiang.github.io/2025/05/18/20250518%E7%B3%96%E5%B0%BF%E7%97%85%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/">https://super-213.github.io/zhihaojiang.github.io/2025/05/18/20250518%E7%B3%96%E5%B0%BF%E7%97%85%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/</a></p>
<p><strong>具体详见GitHub</strong></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>survey lung cancer</title>
    <url>/zhihaojiang.github.io/2025/05/26/20250526survey%20lung%20cancer/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/datasets/aagambshah/lung-cancer-dataset" >https://www.kaggle.com/datasets/aagambshah/lung-cancer-dataset<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h1><p>This dataset contains responses from individuals who participated in a survey to identify behavioral and demographic factors associated with lung cancer. The dataset can be used for exploratory data analysis, statistical modeling, and machine learning classification tasks to predict lung cancer risk.</p>
<h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><h2 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import accuracy_score, roc_auc_score</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line"></span><br><span class="line">import data_analysis_tools as dat</span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;survey lung cancer.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<p>我们查看数据特征的意思是什么:</p>
<ul>
<li>GENDER	受访者性别（男&#x2F;女）</li>
<li>AGE	受访者年龄</li>
<li>SMOKING	吸烟习惯（是&#x2F;否）</li>
<li>YELLOW_FINGERS	手指是否变黄（是&#x2F;否）</li>
<li>ANXIETY	存在焦虑（是&#x2F;否）</li>
<li>PEER_PRESSURE	经历过同伴压力（是&#x2F;否）</li>
<li>CHRONIC DISEASE	现有慢性疾病（是&#x2F;否）</li>
<li>FATIGUE	是否疲劳（是&#x2F;否）</li>
<li>ALLERGY	过敏情况（是&#x2F;否）</li>
<li>WHEEZING	喘息症状（是&#x2F;否）</li>
<li>ALCOHOL CONSUMING	饮酒习惯（是&#x2F;否）</li>
<li>COUGHING	经常咳嗽（是&#x2F;否）</li>
<li>SHORTNESS OF BREATH	呼吸困难症状（是&#x2F;否）</li>
<li>SWALLOWING DIFFICULTY	吞咽困难（是&#x2F;否）</li>
<li>CHEST PAIN	有无胸痛（是&#x2F;否）</li>
<li>LUNG_CANCER	肺癌诊断（是&#x2F;否）</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.describe()</span><br></pre></td></tr></table></figure></div>


<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>GENDER                   0<br>AGE                      0<br>SMOKING                  0<br>YELLOW_FINGERS           0<br>ANXIETY                  0<br>PEER_PRESSURE            0<br>CHRONIC DISEASE          0<br>FATIGUE                  0<br>ALLERGY                  0<br>WHEEZING                 0<br>ALCOHOL CONSUMING        0<br>COUGHING                 0<br>SHORTNESS OF BREATH      0<br>SWALLOWING DIFFICULTY    0<br>CHEST PAIN               0<br>LUNG_CANCER              0<br>dtype: int64</p>
</blockquote>
<p>由以上信息可知 该数据集的特征值有15个，target有1个，该数据集是一个二分类问题。<br>该数据集合没有缺失值 数据集用1、2表示是和否</p>
<h2 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h2><p>我们将数据的二分类使用0，1表示</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.columns.to_list()</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>[‘GENDER’,<br> ‘AGE’,<br> ‘SMOKING’,<br> ‘YELLOW_FINGERS’,<br> ‘ANXIETY’,<br> ‘PEER_PRESSURE’,<br> ‘CHRONIC DISEASE’,<br> ‘FATIGUE ‘,<br> ‘ALLERGY ‘,<br> ‘WHEEZING’,<br> ‘ALCOHOL CONSUMING’,<br> ‘COUGHING’,<br> ‘SHORTNESS OF BREATH’,<br> ‘SWALLOWING DIFFICULTY’,<br> ‘CHEST PAIN’,<br> ‘LUNG_CANCER’]</p>
</blockquote>
 <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"> <span class="built_in">df</span>[<span class="string">&#x27;GENDER&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;GENDER&#x27;</span>].map(&#123;<span class="string">&#x27;M&#x27;</span>: 1, <span class="string">&#x27;F&#x27;</span>: 0&#125;)</span><br><span class="line"> </span><br><span class="line"> columns = [</span><br><span class="line"> <span class="string">&#x27;SMOKING&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;YELLOW_FINGERS&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ANXIETY&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;PEER_PRESSURE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;CHRONIC DISEASE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;FATIGUE &#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ALLERGY &#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;WHEEZING&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ALCOHOL CONSUMING&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;COUGHING&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;SHORTNESS OF BREATH&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;SWALLOWING DIFFICULTY&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;CHEST PAIN&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> columns:</span><br><span class="line">    <span class="built_in">df</span>[column] = <span class="built_in">df</span>[column].map(&#123;1: 0, 2: 1&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;LUNG_CANCER&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;LUNG_CANCER&#x27;</span>].map(&#123;<span class="string">&#x27;YES&#x27;</span>: 1, <span class="string">&#x27;NO&#x27;</span>: 0&#125;)</span><br></pre></td></tr></table></figure></div>
<h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2> <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">dat.plot_all_barplots(<span class="built_in">df</span>, hue=<span class="string">&#x27;LUNG_CANCER&#x27;</span>)</span><br></pre></td></tr></table></figure></div>
<p> 可以看到 患有肺癌的人各项水平均比不患有肺癌的人要高</p>
 <div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.corr()</span><br></pre></td></tr></table></figure></div>
<p> 从上述相关性矩阵中我们发现GENDER和ALCOHOL CONSUMING的相关性系数比较高 我们查看他们的关系</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.barplot(<span class="built_in">df</span>, x = <span class="string">&#x27;GENDER&#x27;</span>,y = <span class="string">&#x27;ALCOHOL CONSUMING&#x27;</span>, hue = <span class="string">&#x27;LUNG_CANCER&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p>可以看到 在男性中 不饮酒的男性患肺癌的概率比饮酒的男性要低<br>在女性中 </p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">feature_importance = df.corr()[<span class="string">&#x27;LUNG_CANCER&#x27;</span>].sort_values(ascending=False)</span><br><span class="line">feature_importance = feature_importance[1:]</span><br><span class="line">plt.figure(figsize=(10, 6))</span><br><span class="line">sns.barplot(x=feature_importance.values, y=feature_importance.index)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Correlation with Lung Cancer&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Features&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<h2 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop([<span class="string">&#x27;LUNG_CANCER&#x27;</span>], axis=1)</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;LUNG_CANCER&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br></pre></td></tr></table></figure></div>

<h2 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h2><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">rf = RandomForestClassifier(n_estimators=100, random_state=42)</span><br><span class="line"></span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line"></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br></pre></td></tr></table></figure></div>
<pre><code>            precision    recall  f1-score   support

       0       0.50      0.50      0.50         2
       1       0.98      0.98      0.98        60

accuracy                           0.97        62
macro avg       0.74      0.74      0.74        62
weighted avg       0.97      0.97      0.97        62
</code></pre>
<h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 转换为 NumPy 数组</span></span><br><span class="line">X = df.drop(columns=[<span class="string">&#x27;LUNG_CANCER&#x27;</span>]).values.astype(np.float32)</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;LUNG_CANCER&#x27;</span>].values.astype(np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征缩放</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train).astype(np.float32)</span><br><span class="line">X_test = scaler.transform(X_test).astype(np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为 PyTorch 张量</span></span><br><span class="line">X_train_tensor = torch.tensor(X_train, dtype=torch.float32)</span><br><span class="line">y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  <span class="comment"># 增加一维</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修正部分：确保 y_test 是 NumPy 数组</span></span><br><span class="line">X_test_tensor = torch.tensor(X_test, dtype=torch.float32)</span><br><span class="line">y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)  <span class="comment"># 增加一维</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BinaryClassifier(nn.Module):</span><br><span class="line">    def __init__(self, input_dim):</span><br><span class="line">        super(BinaryClassifier, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, 16)  <span class="comment"># 第一个隐藏层</span></span><br><span class="line">        self.fc2 = nn.Linear(16, 8)         <span class="comment"># 第二个隐藏层</span></span><br><span class="line">        self.fc3 = nn.Linear(8, 1)          <span class="comment"># 输出层</span></span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = torch.relu(self.fc1(x))  <span class="comment"># ReLU 激活函数</span></span><br><span class="line">        x = torch.relu(self.fc2(x))</span><br><span class="line">        x = torch.sigmoid(self.fc3(x))  <span class="comment"># Sigmoid 激活函数</span></span><br><span class="line">        <span class="built_in">return</span> x</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">input_dim = X_train.shape[1]</span><br><span class="line">model = BinaryClassifier(input_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.BCELoss()  <span class="comment"># 二分类交叉熵损失</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.001)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练参数</span></span><br><span class="line">epochs = 50</span><br><span class="line">batch_size = 32</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    model.train()  <span class="comment"># 设置为训练模式</span></span><br><span class="line">    running_loss = 0.0</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 小批量训练</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(0, len(X_train_tensor), batch_size):</span><br><span class="line">        inputs = X_train_tensor[i:i+batch_size]</span><br><span class="line">        labels = y_train_tensor[i:i+batch_size]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播和优化</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;Epoch [&#123;epoch+1&#125;/&#123;epochs&#125;], Loss: &#123;running_loss:.4f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>Epoch [1&#x2F;50], Loss: 5.3979<br>Epoch [2&#x2F;50], Loss: 5.2241<br>Epoch [3&#x2F;50], Loss: 5.0661<br>Epoch [4&#x2F;50], Loss: 4.9229<br>Epoch [5&#x2F;50], Loss: 4.7911<br>Epoch [6&#x2F;50], Loss: 4.6619<br>Epoch [7&#x2F;50], Loss: 4.5310<br>Epoch [8&#x2F;50], Loss: 4.3962<br>Epoch [9&#x2F;50], Loss: 4.2550<br>Epoch [10&#x2F;50], Loss: 4.1069<br>Epoch [11&#x2F;50], Loss: 3.9532<br>Epoch [12&#x2F;50], Loss: 3.7950<br>Epoch [13&#x2F;50], Loss: 3.6341<br>Epoch [14&#x2F;50], Loss: 3.4730<br>Epoch [15&#x2F;50], Loss: 3.3150<br>Epoch [16&#x2F;50], Loss: 3.1634<br>Epoch [17&#x2F;50], Loss: 3.0199<br>Epoch [18&#x2F;50], Loss: 2.8862<br>Epoch [19&#x2F;50], Loss: 2.7630<br>Epoch [20&#x2F;50], Loss: 2.6512<br>Epoch [21&#x2F;50], Loss: 2.5504<br>Epoch [22&#x2F;50], Loss: 2.4604<br>Epoch [23&#x2F;50], Loss: 2.3804<br>Epoch [24&#x2F;50], Loss: 2.3079<br>Epoch [25&#x2F;50], Loss: 2.2413<br>…<br>Epoch [47&#x2F;50], Loss: 1.3242<br>Epoch [48&#x2F;50], Loss: 1.3006<br>Epoch [49&#x2F;50], Loss: 1.2785<br>Epoch [50&#x2F;50], Loss: 1.2578</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在测试集上评估模型</span></span><br><span class="line">model.eval()  <span class="comment"># 设置为评估模式</span></span><br><span class="line">with torch.no_grad():</span><br><span class="line">    y_pred_prob = model(X_test_tensor).numpy().flatten()  <span class="comment"># 预测概率</span></span><br><span class="line">    y_pred = (y_pred_prob &gt; 0.5).astype(int)              <span class="comment"># 转换为类别标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率和 AUC-ROC</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line">auc = roc_auc_score(y_test, y_pred_prob)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分类报告:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;测试集准确率: &#123;accuracy:.4f&#125;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;测试集 AUC-ROC: &#123;auc:.4f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<p>分类报告:</p>
<pre><code> precision    recall  f1-score   support

     0.0       0.50      0.50      0.50         2
     1.0       0.98      0.98      0.98        60

accuracy                           0.97        62
macro avg       0.74      0.74      0.74        62
weighted avg       0.97      0.97      0.97        62
</code></pre>
<p>测试集准确率: 0.9677<br>测试集 AUC-ROC: 0.9500</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>2025 年数学建模竞赛论文</title>
    <url>/zhihaojiang.github.io/2025/05/19/20250519%202025%20%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[
<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="55d834f4c5aeaa6fbb6fb1910b0155a970aafbb4189a9ff951dbb6d292d5e8e9">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<link href="/zhihaojiang.github.io/css/hbe.style.css" rel="stylesheet" type="text/css"><script data-swup-reload-script type="module" src="/zhihaojiang.github.io/js/plugins/hbe.js"></script>
<script data-swup-reload-script type="module">
import {initHBE} from "/zhihaojiang.github.io/js/plugins/hbe.js";
  console.log("hexo-blog-encrypt: loaded.");
    initHBE();
</script>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>搞懂互补松弛性--从册那到不册那</title>
    <url>/zhihaojiang.github.io/2025/06/02/20250526%E5%88%86%E9%92%9F%E6%90%9E%E6%87%82%E4%BA%92%E8%A1%A5%E6%9D%BE%E5%BC%9B%E6%80%A7--%E4%BB%8E%E5%86%8C%E9%82%A3%E5%88%B0%E4%B8%8D%E5%86%8C%E9%82%A3/</url>
    <content><![CDATA[<p><a href="https://www.bilibili.com/video/BV1YA7kzAEgQ?vd_source=bc448494c13de3dddfcff371ac637813"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/02/001.png"
                      alt="点击观看视频"
                ></a></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>运筹学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习--长尾分布</title>
    <url>/zhihaojiang.github.io/2025/05/26/20250526%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0--%E9%95%BF%E5%B0%BE%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<p><strong>长尾分布（Long-Tail Distribution）</strong> 是指数据集中少数类别（头部）占据大量样本，而多数类别（尾部）只有极少样本的现象。这种分布广泛存在于现实场景（如推荐系统、图像分类、自然语言处理等），对模型训练和评估带来显著挑战。</p>
<h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a><strong>特点</strong></h1><ol>
<li><p><strong>头部类别（Head Classes）</strong>  </p>
<ul>
<li>数量少但样本占比极高（如20%的类别覆盖80%的数据）。</li>
<li>模型容易过拟合这些类别，导致对尾部类别表现差。</li>
</ul>
</li>
<li><p><strong>尾部类别（Tail Classes）</strong>  </p>
<ul>
<li>数量多但样本极少（如每个类别仅几个样本）。</li>
<li>因数据不足，模型难以学习有效特征，导致欠拟合。</li>
</ul>
</li>
</ol>
<h1 id="常见场景"><a href="#常见场景" class="headerlink" title="常见场景"></a><strong>常见场景</strong></h1><ul>
<li><strong>图像分类</strong>：大规模数据集（如ImageNet）中稀有物体类别。</li>
<li><strong>推荐系统</strong>：热门商品点击量巨大，冷门商品极少被交互。</li>
<li><strong>自然语言处理</strong>：高频词汇vs.低频长尾词汇。</li>
<li><strong>异常检测</strong>：异常样本通常远少于正常样本。</li>
</ul>
<h1 id="解决长尾分布的方法"><a href="#解决长尾分布的方法" class="headerlink" title="解决长尾分布的方法"></a><strong>解决长尾分布的方法</strong></h1><h2 id="1-数据层面"><a href="#1-数据层面" class="headerlink" title="1. 数据层面"></a>1. <strong>数据层面</strong></h2><ul>
<li><p><strong>重采样（Re-sampling）</strong>  </p>
<ul>
<li><strong>过采样（Oversampling）</strong>：对尾部类别重复样本或生成新样本（如SMOTE、GANs）。  </li>
<li><strong>欠采样（Undersampling）</strong>：减少头部类别的样本，可能丢失信息。</li>
<li><strong>混合采样</strong>：结合过采样和欠采样。</li>
</ul>
</li>
<li><p><strong>数据增强（Data Augmentation）</strong>  </p>
<ul>
<li>对尾部类别使用增强技术（如旋转、裁剪、Mixup、CutMix）生成多样化样本。</li>
</ul>
</li>
</ul>
<p>代码:</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from torch.utils.data import WeightedRandomSampler, Dataset</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># `labels`是类别标签列表</span></span><br><span class="line">labels = [0, 0, 0, 1, 1, 2, 2, 2, 2, 3]  <span class="comment"># 类别0和2样本多，1和3样本少</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个类别的样本数</span></span><br><span class="line">class_counts = np.bincount(labels)</span><br><span class="line">num_samples = len(labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法1：过采样（对少数类样本增加权重）</span></span><br><span class="line">class_weights = 1. / class_counts  <span class="comment"># 逆频率权重</span></span><br><span class="line">sample_weights = class_weights[labels]  <span class="comment"># 每个样本的权重</span></span><br><span class="line">sampler = WeightedRandomSampler(sample_weights, num_samples, replacement=True)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法2：欠采样（对多数类样本降权）</span></span><br><span class="line"><span class="comment"># 设置每个类别的采样数量为最小类别的样本数</span></span><br><span class="line">min_samples = min(class_counts)</span><br><span class="line">sample_weights = np.array([1.0 / class_counts[label] <span class="keyword">for</span> label <span class="keyword">in</span> labels])</span><br><span class="line">sampler = WeightedRandomSampler(sample_weights, min_samples * len(class_counts), replacement=False)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在DataLoader中使用sampler</span></span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from imblearn.over_sampling import SMOTE</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设特征X和标签y</span></span><br><span class="line">X = np.random.rand(100, 10)  <span class="comment"># 100个样本，10维特征</span></span><br><span class="line">y = np.array([0]*80 + [1]*15 + [2]*5)  <span class="comment"># 长尾分布</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用SMOTE生成少数类样本</span></span><br><span class="line">smote = SMOTE(sampling_strategy=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">X_resampled, y_resampled = smote.fit_resample(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Original counts: &#123;np.bincount(y)&#125;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Resampled counts: &#123;np.bincount(y_resampled)&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<h2 id="2-损失函数设计"><a href="#2-损失函数设计" class="headerlink" title="2. 损失函数设计"></a>2. <strong>损失函数设计</strong></h2><ul>
<li><strong>类别加权损失（Class-Weighted Loss）</strong>  <ul>
<li>为不同类别分配权重（如逆类别频率），使模型更关注尾部类别。</li>
<li>例如：<code>weight = 1 / sqrt(class_count)</code>。<br>代码：</li>
</ul>
</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">  import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设类别数量为4，计算每个类别的权重（逆频率）</span></span><br><span class="line">class_counts = torch.tensor([1000, 100, 10, 1])  <span class="comment"># 长尾分布</span></span><br><span class="line">weights = 1.0 / class_counts</span><br><span class="line">weights = weights / weights.sum()  <span class="comment"># 归一化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义加权交叉熵损失</span></span><br><span class="line">criterion = nn.CrossEntropyLoss(weight=weights)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line">logits = torch.randn(4, 4)  <span class="comment"># 模型输出（batch_size=4, num_classes=4）</span></span><br><span class="line">targets = torch.tensor([0, 1, 2, 3])  <span class="comment"># 真实标签</span></span><br><span class="line">loss = criterion(logits, targets)</span><br></pre></td></tr></table></figure></div>
<ul>
<li><strong>焦点损失（Focal Loss）</strong>  <ul>
<li>降低易分类样本（通常是头部类别）的损失权重，聚焦难样本（尾部）。  </li>
<li>公式：<code>FL(p_t) = -α_t (1 - p_t)^γ log(p_t)</code>，其中γ调节难易样本权重。</li>
</ul>
</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class FocalLoss(nn.Module):</span><br><span class="line">    def __init__(self, alpha=1.0, gamma=2.0):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.alpha = alpha  <span class="comment"># 类别平衡参数</span></span><br><span class="line">        self.gamma = gamma  <span class="comment"># 难易样本调节参数</span></span><br><span class="line"></span><br><span class="line">    def forward(self, inputs, targets):</span><br><span class="line">        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">        pt = torch.exp(-ce_loss)  <span class="comment"># 模型对真实类别的预测概率</span></span><br><span class="line">        loss = self.alpha * (1 - pt) ** self.gamma * ce_loss</span><br><span class="line">        <span class="built_in">return</span> loss.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line">focal_loss = FocalLoss(alpha=[1.0, 2.0, 5.0, 10.0], gamma=2)  <span class="comment"># alpha可对不同类别加权</span></span><br><span class="line">loss = focal_loss(logits, targets)</span><br></pre></td></tr></table></figure></div>
<ul>
<li><strong>解耦训练（Decoupling）</strong>  <ul>
<li>先学习特征表示（均匀采样），再调整分类器（重采样或重加权）。</li>
</ul>
</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第一阶段：均匀采样学习特征</span></span><br><span class="line">uniform_sampler = WeightedRandomSampler(</span><br><span class="line">    weights=torch.ones(len(dataset)),  <span class="comment"># 均匀权重</span></span><br><span class="line">    num_samples=len(dataset),</span><br><span class="line">    replacement=True</span><br><span class="line">)</span><br><span class="line">dataloader_stage1 = DataLoader(dataset, batch_size=32, sampler=uniform_sampler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二阶段：冻结特征层，调整分类器（使用类别加权损失）</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.feature_extractor.parameters():</span><br><span class="line">    param.requires_grad = False  <span class="comment"># 冻结特征层</span></span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss(weight=class_weights)  <span class="comment"># 使用加权损失</span></span><br><span class="line">optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)</span><br></pre></td></tr></table></figure></div>
<h2 id="3-模型结构改进"><a href="#3-模型结构改进" class="headerlink" title="3. 模型结构改进"></a>3. <strong>模型结构改进</strong></h2><ul>
<li><strong>解耦框架（Decoupling Framework）</strong>  <ul>
<li>如<strong>Decoupling</strong>（NeurIPS 2019）分离特征学习和分类器调整。</li>
</ul>
</li>
<li><strong>两阶段训练</strong>  <ul>
<li>第一阶段：正常训练；第二阶段：冻结骨干网络，微调分类器（使用重采样或加权）。</li>
</ul>
</li>
<li><strong>专家混合（Mixture of Experts, MoE）</strong>  <ul>
<li>为不同类别分配专用子模型（专家）。</li>
</ul>
</li>
</ul>
<h2 id="4-迁移学习-自监督学习"><a href="#4-迁移学习-自监督学习" class="headerlink" title="4. 迁移学习 &amp; 自监督学习"></a>4. <strong>迁移学习 &amp; 自监督学习</strong></h2><ul>
<li><strong>预训练 + 微调</strong>：在大规模平衡数据上预训练，再在长尾数据上微调。</li>
<li><strong>自监督学习</strong>：通过对比学习（如SimCLR）学习通用特征，减少对标签的依赖。</li>
</ul>
<h2 id="5-评估指标优化"><a href="#5-评估指标优化" class="headerlink" title="5. 评估指标优化"></a>5. <strong>评估指标优化</strong></h2><ul>
<li>避免单一准确率（Accuracy），采用更全面的指标：  <ul>
<li><strong>宏平均（Macro-F1）</strong>：各类别F1的均值，平等对待所有类别。</li>
</ul>
</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import f1_score</span><br><span class="line"></span><br><span class="line">def macro_f1(y_true, y_pred):</span><br><span class="line">    <span class="built_in">return</span> f1_score(y_true, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">y_true = [0, 1, 2, 0, 1, 2]</span><br><span class="line">y_pred = [0, 1, 1, 0, 0, 2]</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Macro-F1: &#123;macro_f1(y_true, y_pred)&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<ul>
<li><strong>平衡准确率（Balanced Accuracy）</strong>：各类别召回率的均值。  </li>
<li><strong>AUC-ROC</strong>：衡量模型在不同阈值下的整体性能。</li>
</ul>
<h1 id="经典论文与模型"><a href="#经典论文与模型" class="headerlink" title="经典论文与模型"></a><strong>经典论文与模型</strong></h1><ul>
<li><strong>Decoupling</strong>（NeurIPS 2019）：解耦表示学习和分类器调整。  </li>
<li><strong>BBN</strong>（CVPR 2020）：双分支网络平衡重采样和原始分布。  </li>
<li><strong>Logit Adjustment</strong>（ICML 2020）：通过调整logit偏移解决类别不平衡。  </li>
<li><strong>Balanced Softmax</strong>（NeurIPS 2020）：修改Softmax适应长尾分布。</li>
</ul>
<h1 id="方向"><a href="#方向" class="headerlink" title="方向"></a><strong>方向</strong></h1><ul>
<li><strong>过拟合与泛化</strong>：尾部数据不足易导致过拟合，需更好的正则化或小样本学习技术。  </li>
<li><strong>动态长尾分布</strong>：现实世界中类别分布可能随时间变化（如热门商品更替）。  </li>
<li><strong>无监督长尾学习</strong>：探索自监督或半监督方法减少对标签的依赖。</li>
</ul>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torch.utils.data import Subset</span><br><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 CIFAR-10 原始训练集</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor()])</span><br><span class="line">train_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=True, download=True, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计每类索引</span></span><br><span class="line">class_indices = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> range(10)]</span><br><span class="line"><span class="keyword">for</span> idx, (_, label) <span class="keyword">in</span> enumerate(train_dataset):</span><br><span class="line">    class_indices[label].append(idx)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 人为制造长尾分布，例如类0有5000个样本，类9只有10个样本</span></span><br><span class="line">long_tail_counts = [5000, 2000, 1000, 500, 200, 100, 50, 30, 20, 10]</span><br><span class="line">selected_indices = []</span><br><span class="line"><span class="keyword">for</span> i, count <span class="keyword">in</span> enumerate(long_tail_counts):</span><br><span class="line">    selected_indices.extend(class_indices[i][:count])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建新的训练子集</span></span><br><span class="line">long_tail_dataset = Subset(train_dataset, selected_indices)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取子集标签</span></span><br><span class="line">labels = [train_dataset[i][1] <span class="keyword">for</span> i <span class="keyword">in</span> selected_indices]</span><br><span class="line">class_counts = np.bincount(labels, minlength=10)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每类样本数量：&quot;</span>, class_counts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算类别权重（样本越少权重越大）</span></span><br><span class="line">weights = 1.0 / (class_counts + 1e-6)</span><br><span class="line">weights = weights / weights.sum() * len(class_counts)</span><br><span class="line">class_weights = torch.FloatTensor(weights)</span><br><span class="line"></span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简单CNN模型</span></span><br><span class="line">class SimpleCNN(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(3, 32, 3)</span><br><span class="line">        self.conv2 = nn.Conv2d(32, 64, 3)</span><br><span class="line">        self.fc1 = nn.Linear(64 * 6 * 6, 128)</span><br><span class="line">        self.fc2 = nn.Linear(128, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = F.relu(self.conv1(x))    <span class="comment"># [batch, 32, 30, 30]</span></span><br><span class="line">        x = F.max_pool2d(x, 2)       <span class="comment"># [batch, 32, 15, 15]</span></span><br><span class="line">        x = F.relu(self.conv2(x))    <span class="comment"># [batch, 64, 13, 13]</span></span><br><span class="line">        x = F.max_pool2d(x, 2)       <span class="comment"># [batch, 64, 6, 6]</span></span><br><span class="line">        x = x.view(-1, 64 * 6 * 6)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="built_in">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用权重定义加权损失函数</span></span><br><span class="line">criterion = nn.CrossEntropyLoss(weight=class_weights)</span><br><span class="line"></span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch import optim</span><br><span class="line"></span><br><span class="line">model = SimpleCNN()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.001)</span><br><span class="line">loader = DataLoader(long_tail_dataset, batch_size=64, shuffle=True)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(10):</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> loader:</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;Epoch &#123;epoch&#125;: loss = &#123;loss.item():.4f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>Epoch 0: loss &#x3D; 1.9016<br>Epoch 1: loss &#x3D; 1.7739<br>Epoch 2: loss &#x3D; 1.4057<br>Epoch 3: loss &#x3D; 1.8090<br>Epoch 4: loss &#x3D; 1.6333<br>Epoch 5: loss &#x3D; 1.5193<br>Epoch 6: loss &#x3D; 0.8202<br>Epoch 7: loss &#x3D; 0.5897<br>Epoch 8: loss &#x3D; 0.7408<br>Epoch 9: loss &#x3D; 1.2246</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
      </tags>
  </entry>
  <entry>
    <title>Extrovert vs. Introvert Behavior Data</title>
    <url>/zhihaojiang.github.io/2025/06/04/20250604Extrovert%20vs.%20Introvert%20Behavior%20Data/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/datasets/rakeshkapilavai/extrovert-vs-introvert-behavior-data/data" >https://www.kaggle.com/datasets/rakeshkapilavai/extrovert-vs-introvert-behavior-data/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h1><p>关于数据集<br>概述</p>
<p>深入研究“外向与内向性格特征数据集”，这是一个丰富的行为和社交数据集合，旨在探索人类性格谱系。该数据集涵盖了外向和内向的关键指标，是心理学家、数据科学家以及研究社会行为、性格预测或数据预处理技术的研究人员的宝贵资源。</p>
<p>语境</p>
<p>外向和内向等性格特征塑造了个体与社交环境的互动方式。该数据集提供了对个人行为的洞察，例如独处时间、社交活动参与度以及社交媒体参与度，从而为心理学、社会学、市场营销和机器学习等领域的应用提供支持。无论您是预测性格类型还是分析社交模式，该数据集都能助您发现引人入胜的洞见。</p>
<p>数据集详细信息</p>
<p>大小：数据集包含 2,900 行和 8 列。</p>
<h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><h2 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;personality_dataset.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.columns</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>Index([‘Time_spent_Alone’, ‘Stage_fear’, ‘Social_event_attendance’,<br>       ‘Going_outside’, ‘Drained_after_socializing’, ‘Friends_circle_size’,<br>       ‘Post_frequency’, ‘Personality’],<br>      dtype&#x3D;’object’)</p>
</blockquote>
<ul>
<li>Time_spent_Alone: 独处时间 – 一个人每天通常独自度过的小时数</li>
<li>Stage_fear: 舞台恐惧 – 是否经历过舞台恐惧症</li>
<li>Social_event_attendance: 社交活动出席率 – 参加社交活动的频率（0-10 级）</li>
<li>Going_outside: 外出 – 个人外出的频率（0-10 级）</li>
<li>Drained_after_socializing:社交后精疲力竭 – 社交后是否感觉精疲力尽</li>
<li>Friends_circle_size:好友圈大小 – 亲密朋友数量</li>
<li>Post_frequency:帖子频率 – 在社交媒体上发帖的频率</li>
<li>Personality: 性格 – 目标变量：内向或外向</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>&lt;class ‘pandas.core.frame.DataFrame’&gt;<br>RangeIndex: 2900 entries, 0 to 2899<br>Data columns (total 8 columns):</p>
<h1 id="Column-Non-Null-Count-Dtype"><a href="#Column-Non-Null-Count-Dtype" class="headerlink" title="Column                     Non-Null Count  Dtype"></a>Column                     Non-Null Count  Dtype</h1><hr>
<p> 0   Time_spent_Alone           2837 non-null   float64<br> 1   Stage_fear                 2827 non-null   object<br> 2   Social_event_attendance    2838 non-null   float64<br> 3   Going_outside              2834 non-null   float64<br> 4   Drained_after_socializing  2848 non-null   object<br> 5   Friends_circle_size        2823 non-null   float64<br> 6   Post_frequency             2835 non-null   float64<br> 7   Personality                2900 non-null   object<br>dtypes: float64(5), object(3)<br>memory usage: 181.4+ KB</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/001.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.describe()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/002.png"
                      alt="photo"
                ></p>
<h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>Time_spent_Alone             63<br>Stage_fear                   73<br>Social_event_attendance      62<br>Going_outside                66<br>Drained_after_socializing    52<br>Friends_circle_size          77<br>Post_frequency               65<br>Personality                   0<br>dtype: int64</p>
</blockquote>
<p>数值型用均值填充<br>类别型用众数填充</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">df</span>[col].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        <span class="built_in">df</span>[col] = <span class="built_in">df</span>[col].fillna(<span class="built_in">df</span>[col].mode()[0])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">df</span>[col] = <span class="built_in">df</span>[col].fillna(<span class="built_in">df</span>[col].mean())</span><br></pre></td></tr></table></figure></div>

<h2 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Stage_fear&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;Stage_fear&#x27;</span>].map(&#123;<span class="string">&#x27;Yes&#x27;</span>: 1, <span class="string">&#x27;No&#x27;</span>: 0&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Drained_after_socializing&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;Drained_after_socializing&#x27;</span>].map(&#123;<span class="string">&#x27;Yes&#x27;</span>: 1, <span class="string">&#x27;No&#x27;</span>: 0&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Personality&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;Personality&#x27;</span>].map(&#123;<span class="string">&#x27;Introvert&#x27;</span>: 0, <span class="string">&#x27;Extrovert&#x27;</span>: 1&#125;)</span><br></pre></td></tr></table></figure></div>

<h2 id="异常值检测"><a href="#异常值检测" class="headerlink" title="异常值检测"></a>异常值检测</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">    Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line">    lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">    upper_bound = Q3 + 1.5 * IQR</span><br><span class="line">    outliers = <span class="built_in">df</span>[(<span class="built_in">df</span>[col] &gt;= lower_bound) &amp; (<span class="built_in">df</span>[col] &lt;= upper_bound)]</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;列&#123;col&#125;的异常值:&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>列Time_spent_Alone的异常值:<br>列Stage_fear的异常值:<br>列Social_event_attendance的异常值:<br>列Going_outside的异常值:<br>列Drained_after_socializing的异常值:<br>列Friends_circle_size的异常值:<br>列Post_frequency的异常值:<br>列Personality的异常值:</p>
</blockquote>
<p>说明没有异常值 我们通过箱线图也没发现异常值</p>
<h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><h3 id="工具代码"><a href="#工具代码" class="headerlink" title="工具代码"></a>工具代码</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def pairwise_plot(</span><br><span class="line">    <span class="built_in">df</span>: pd.DataFrame,</span><br><span class="line">    features: list,</span><br><span class="line">    plot_type: str = <span class="string">&#x27;scatter&#x27;</span>,  <span class="comment"># 可选: &#x27;scatter&#x27;, &#x27;box&#x27;, &#x27;bar&#x27;, &#x27;violin&#x27;, &#x27;hist&#x27;</span></span><br><span class="line">    hue: str = None,</span><br><span class="line">    max_per_figure: int = 9,</span><br><span class="line">    figsize: tuple = (15, 12),</span><br><span class="line">    fill: bool = None,</span><br><span class="line">    save: bool = False,</span><br><span class="line">    save_prefix: str = <span class="string">&quot;pairplot&quot;</span></span><br><span class="line">):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    批量绘制特征两两组合的图表，每张大图包含最多9张子图。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    - df: DataFrame 数据</span></span><br><span class="line"><span class="string">    - features: 要组合的特征列名列表</span></span><br><span class="line"><span class="string">    - plot_type: 图表类型：&#x27;scatter&#x27;, &#x27;box&#x27;, &#x27;violin&#x27;, &#x27;hist&#x27;, &#x27;kde&#x27;, &#x27;bar&#x27;</span></span><br><span class="line"><span class="string">    - fill: 是否填充 KDE 图（仅适用于 &#x27;kde&#x27; 类型）</span></span><br><span class="line"><span class="string">    - hue: 分类变量（可选）</span></span><br><span class="line"><span class="string">    - max_per_figure: 每页最多显示几个子图</span></span><br><span class="line"><span class="string">    - figsize: 每张图的整体大小</span></span><br><span class="line"><span class="string">    - save: 是否保存图像</span></span><br><span class="line"><span class="string">    - save_prefix: 图像保存的前缀</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    import itertools</span><br><span class="line">    import math</span><br><span class="line">    import matplotlib.pyplot as plt</span><br><span class="line">    import seaborn as sns</span><br><span class="line">    combs = list(itertools.combinations(features, 2))</span><br><span class="line">    total_figures = math.ceil(len(combs) / max_per_figure)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> fig_idx <span class="keyword">in</span> range(total_figures):</span><br><span class="line">        fig, axs = plt.subplots(3, 3, figsize=figsize)</span><br><span class="line">        axs = axs.flatten()</span><br><span class="line">        start = fig_idx * max_per_figure</span><br><span class="line">        end = start + max_per_figure</span><br><span class="line">        current_combs = combs[start:end]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ax_idx, (x, y) <span class="keyword">in</span> enumerate(current_combs):</span><br><span class="line">            ax = axs[ax_idx]</span><br><span class="line">            <span class="keyword">if</span> plot_type == <span class="string">&#x27;scatter&#x27;</span>:</span><br><span class="line">                sns.scatterplot(data=<span class="built_in">df</span>, x=x, y=y, hue=hue, ax=ax)</span><br><span class="line">            <span class="keyword">elif</span> plot_type == <span class="string">&#x27;box&#x27;</span>:</span><br><span class="line">                sns.boxplot(data=<span class="built_in">df</span>, x=x, y=y, hue=hue, ax=ax)</span><br><span class="line">            <span class="keyword">elif</span> plot_type == <span class="string">&#x27;violin&#x27;</span>:</span><br><span class="line">                sns.violinplot(data=<span class="built_in">df</span>, x=x, y=y, hue=hue, ax=ax)</span><br><span class="line">            <span class="keyword">elif</span> plot_type == <span class="string">&#x27;bar&#x27;</span>:</span><br><span class="line">                sns.barplot(data=<span class="built_in">df</span>, x=x, y=y, hue=hue, ax=ax)</span><br><span class="line">            <span class="keyword">elif</span> plot_type == <span class="string">&#x27;hist&#x27;</span>:</span><br><span class="line">                sns.histplot(data=<span class="built_in">df</span>, x=x, hue=hue, ax=ax, kde=True)</span><br><span class="line">            <span class="keyword">elif</span> plot_type == <span class="string">&#x27;kde&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> hue :</span><br><span class="line">                    <span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">df</span>[hue].dropna().unique():</span><br><span class="line">                            subset = <span class="built_in">df</span>[<span class="built_in">df</span>[hue] == label]</span><br><span class="line">                            sns.kdeplot(data=subset, x=x, y=y, ax=ax, fill=fill, label=str(label), alpha=0.5)</span><br><span class="line">                            ax.legend()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    sns.kdeplot(data=<span class="built_in">df</span>, x=x, y=y, ax=ax, fill=fill)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ax.set_title(f<span class="string">&quot;Unsupported plot type: &#123;plot_type&#125;&quot;</span>)</span><br><span class="line">            ax.set_title(f<span class="string">&quot;&#123;y&#125; vs &#123;x&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 隐藏多余的子图</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(current_combs), max_per_figure):</span><br><span class="line">            fig.delaxes(axs[j])</span><br><span class="line"></span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        <span class="keyword">if</span> save:</span><br><span class="line">            plt.savefig(f<span class="string">&quot;&#123;save_prefix&#125;_&#123;fig_idx+1&#125;.png&quot;</span>, dpi=300)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure></div>

<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.pairplot(<span class="built_in">df</span>, diag_kind=<span class="string">&#x27;hist&#x27;</span>, hue=<span class="string">&#x27;Personality&#x27;</span>)</span><br><span class="line">plt.suptitle(<span class="string">&#x27;Pair Plot of Numeric Features by Personality&#x27;</span>, y=1.02)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/003.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">pairwise_plot(<span class="built_in">df</span>, df.columns, plot_type=<span class="string">&#x27;hist&#x27;</span>, hue=<span class="string">&#x27;Personality&#x27;</span>, max_per_figure=9)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/004.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/005.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/006.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/007.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">pairwise_plot(<span class="built_in">df</span>, df.columns, plot_type=<span class="string">&#x27;scatter&#x27;</span>, hue=<span class="string">&#x27;Personality&#x27;</span>, max_per_figure=9)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/008.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/009.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/010.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/011.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">pairwise_plot(<span class="built_in">df</span>, df.columns, plot_type=<span class="string">&#x27;kde&#x27;</span>, max_per_figure=9)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/012.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/013.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/014.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/015.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.corr()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/04/016.png"
                      alt="photo"
                ></p>
<p>我们发现这些变量与目标变量的相关性的绝对值均大于0.6 说明这些特征都很重要 从上面的可视化结果来看也是如此</p>
<h2 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop(<span class="string">&#x27;Personality&#x27;</span>, axis=1)</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;Personality&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h2 id="标准化-模型训练"><a href="#标准化-模型训练" class="headerlink" title="标准化+模型训练"></a>标准化+模型训练</h2><h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.metrics import accuracy_score, classification_report, confusion_matrix</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">&#x27;svm&#x27;</span>, SVC(kernel=<span class="string">&#x27;linear&#x27;</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">pipeline.fit(X_train, y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y_pred = pipeline.predict(X_test)</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_matrix)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>0.9293103448275862<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.92      0.94      0.93       278
       1       0.94      0.92      0.93       302

accuracy                           0.93       580
</code></pre>
<p>   macro avg       0.93      0.93      0.93       580<br>weighted avg       0.93      0.93      0.93       580<br>[[261  17]<br> [ 24 278]]</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建Pipeline</span></span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">&#x27;svm&#x27;</span>, SVC())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;svm__C&#x27;</span>: [0.1, 1, 10],</span><br><span class="line">    <span class="string">&#x27;svm__kernel&#x27;</span>: [<span class="string">&#x27;linear&#x27;</span>, <span class="string">&#x27;rbf&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;svm__gamma&#x27;</span>: [<span class="string">&#x27;scale&#x27;</span>, <span class="string">&#x27;auto&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(pipeline, param_grid, cv=5)</span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(grid_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(grid_search.best_score_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y_pred = grid_search.predict(X_test)</span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_matrix)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>{‘svm__C’: 0.1, ‘svm__gamma’: ‘scale’, ‘svm__kernel’: ‘rbf’}<br>0.9357758620689655<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.92      0.94      0.93       278
       1       0.94      0.92      0.93       302

accuracy                           0.93       580
</code></pre>
<p>   macro avg       0.93      0.93      0.93       580<br>weighted avg       0.93      0.93      0.93       580<br>[[261  17]<br> [ 24 278]]</p>
</blockquote>
<h3 id="XGboost"><a href="#XGboost" class="headerlink" title="XGboost"></a>XGboost</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line">XGB = XGBClassifier()</span><br><span class="line">XGB.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = XGB.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;XGBoost Accuracy:&quot;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_matrix)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>XGBoost Accuracy: 0.9172413793103448<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.90      0.93      0.91       278
       1       0.93      0.91      0.92       302

accuracy                           0.92       580
</code></pre>
<p>   macro avg       0.92      0.92      0.92       580<br>weighted avg       0.92      0.92      0.92       580</p>
<p>[[258  20]<br> [ 28 274]]</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;XGB&#x27;</span>, XGBClassifier(use_label_encoder=False, eval_metric=<span class="string">&#x27;logloss&#x27;</span>)),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;XGB__max_depth&#x27;</span>: [3, 5, 7],</span><br><span class="line">    <span class="string">&#x27;XGB__learning_rate&#x27;</span>: [0.01, 0.1, 0.2],</span><br><span class="line">    <span class="string">&#x27;XGB__n_estimators&#x27;</span>: [50, 100, 200],</span><br><span class="line">    <span class="string">&#x27;XGB__subsample&#x27;</span>: [0.8, 1.0],</span><br><span class="line">    <span class="string">&#x27;XGB__colsample_bytree&#x27;</span>: [0.8, 1.0],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=<span class="string">&#x27;recall&#x27;</span>)</span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(grid_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(grid_search.best_score_)</span><br><span class="line"></span><br><span class="line">y_pred = grid_search.predict(X_test)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Accuracy: &#123;accuracy&#125;&quot;</span>)</span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_matrix)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>Accuracy: 0.9293103448275862<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.92      0.94      0.93       278
       1       0.94      0.92      0.93       302

accuracy                           0.93       580
</code></pre>
<p>   macro avg       0.93      0.93      0.93       580<br>weighted avg       0.93      0.93      0.93       580</p>
<p>[[261  17]<br> [ 24 278]]</p>
</blockquote>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rf = RandomForestClassifier(n_estimators=100, random_state=42)</span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Random Forest Accuracy:&quot;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_matrix)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>Random Forest Accuracy: 0.9224137931034483<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.91      0.93      0.92       278
       1       0.94      0.91      0.92       302

accuracy                           0.92       580
</code></pre>
<p>   macro avg       0.92      0.92      0.92       580<br>weighted avg       0.92      0.92      0.92       580</p>
<p>[[259  19]<br> [ 26 276]]</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;rf&#x27;</span>, RandomForestClassifier(random_state=42)),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;rf__n_estimators&#x27;</span>: [50, 100, 200],</span><br><span class="line">    <span class="string">&#x27;rf__max_depth&#x27;</span>: [None, 10, 20, 30],</span><br><span class="line">    <span class="string">&#x27;rf__min_samples_split&#x27;</span>: [2, 5, 10],</span><br><span class="line">    <span class="string">&#x27;rf__min_samples_leaf&#x27;</span>: [1, 2, 4],</span><br><span class="line">&#125;</span><br><span class="line">grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=<span class="string">&#x27;accuracy&#x27;</span>, n_jobs=-1)</span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line">best_model = grid_search.best_estimator_</span><br><span class="line"></span><br><span class="line">y_pred = best_model.predict(X_test)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Best Random Forest Accuracy: &#123;accuracy&#125;&quot;</span>)</span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_matrix)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>Best Random Forest Accuracy: 0.9293103448275862<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.92      0.94      0.93       278
       1       0.94      0.92      0.93       302

accuracy                           0.93       580
</code></pre>
<p>   macro avg       0.93      0.93      0.93       580<br>weighted avg       0.93      0.93      0.93       580</p>
<p>[[261  17]<br> [ 24 278]]</p>
</blockquote>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>我们通过可视化图表可以看到 数据的分布呈现集中分布 说明特征与特征之间的关系较为紧密 说明内向与外向的人他们具有明显的区分度</p>
<p>SVM的准确率为：0.9357758620689655<br>预测的召回率为：0.93</p>
<p>其中预测内向的召回率为：0.94<br>其中预测外向的召回率为：0.92<br>说明其对内向的确诊率较高</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>Global Internet Adoption &amp; Digital Growth Analysis</title>
    <url>/zhihaojiang.github.io/2025/06/05/20250605Global%20Internet%20Adoption%20&amp;%20Digital%20Growth%20Analysis/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/datasets/sudipde25/global-internet-adoption-trends/data" >https://www.kaggle.com/datasets/sudipde25/global-internet-adoption-trends/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>此数据集主要为探索 以可视化为主</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">from matplotlib import font_manager</span><br><span class="line"><span class="comment"># 设置字体路径</span></span><br><span class="line">font_path = <span class="string">&#x27;/System/Library/Fonts/STHeiti Medium.ttc&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载字体</span></span><br><span class="line">my_font = font_manager.FontProperties(fname=font_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = my_font.get_name()</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = False  <span class="comment"># 正确显示负号</span></span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;#d7fbe8&#x27;</span>,<span class="string">&#x27;#9df3c4&#x27;</span>,<span class="string">&#x27;#62d2a2&#x27;</span>,<span class="string">&#x27;#1fab89&#x27;</span>,<span class="string">&#x27;#a6d0e4&#x27;</span>, <span class="string">&#x27;#f9ffea&#x27;</span>, <span class="string">&#x27;#ffecda&#x27;</span>, <span class="string">&#x27;#d4a5a5&#x27;</span>, <span class="string">&#x27;#fbafaf&#x27;</span>, <span class="string">&#x27;#f2c6b4&#x27;</span>, <span class="string">&#x27;#f3e8cb&#x27;</span>, <span class="string">&#x27;#99e1e5&#x27;</span>]</span><br></pre></td></tr></table></figure></div>

<ul>
<li>Country 国家</li>
<li>Date 日期</li>
<li>Internet_Penetration (%) 互联网普及率（%）</li>
<li>Broadband_Speed (Mbps) 宽带速度（Mbps）</li>
<li>GDP_Per_Capita (USD) 人均GDP（美元）</li>
<li>Education_Level (%) 教育水平（%）</li>
<li>Mobile_Data_Usage (GB) 移动数据使用量（GB）</li>
<li>Digital_Investment (M USD) 数字投资（百万美元）</li>
<li>Digital_Literacy (%) 数字素养（%）</li>
<li>X_Sentiment_Score X情绪评分</li>
<li>5G_Rollout 5G部署</li>
<li>Urban_Rural 城乡（城市&#x2F;农村）</li>
<li>Latitude 纬度</li>
<li>Longitude 经度</li>
<li>Anomaly 异常</li>
</ul>
<h1 id="分析每月数据"><a href="#分析每月数据" class="headerlink" title="分析每月数据"></a>分析每月数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;global_internet_adoption_monthly_2010_2025_with_clusters.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;Date&#x27;</span>] = pd.to_datetime(<span class="built_in">df</span>[<span class="string">&#x27;Date&#x27;</span>])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.pairplot(<span class="built_in">df</span>, diag_kind=<span class="string">&#x27;hist&#x27;</span>)</span><br><span class="line">plt.suptitle(<span class="string">&#x27;EDA&#x27;</span>, y=1.02)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/05/001.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选出所有数值型列（排除 &#x27;Country&#x27;）</span></span><br><span class="line">num_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> <span class="built_in">df</span>[col].dtype <span class="keyword">in</span> [<span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置子图布局（比如每行显示2个图）</span></span><br><span class="line">n_cols = 3</span><br><span class="line">n_rows = math.ceil(len(num_cols) / n_cols)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图尺寸</span></span><br><span class="line">fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若 axes 是 1D，需要变成 2D 统一处理</span></span><br><span class="line">axes = axes.flatten()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, col <span class="keyword">in</span> enumerate(num_cols):</span><br><span class="line">    sns.boxplot(data=<span class="built_in">df</span>, x=<span class="string">&#x27;Country&#x27;</span>, y=col, ax=axes[i], palette=colors)</span><br><span class="line">    axes[i].set_title(col)</span><br><span class="line">    axes[i].tick_params(axis=<span class="string">&#x27;x&#x27;</span>, rotation=45)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多余的子图隐藏</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(i+1, len(axes)):</span><br><span class="line">    fig.delaxes(axes[j])</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/05/002.png"
                      alt="photo"
                ></p>
<p>上述是不同国家的互联网相关的各项数据的箱线图</p>
<ul>
<li>从互联网普及率来看 中国 美国和德国的互联网普及率在一个水平 其他国家的在另一个水平 说明中国 美国和德国的互联网普及率较其他国家领先</li>
<li>从宽带速度来看 各国的宽带速度有差别 但差别不算太大</li>
<li>从国家GDP来看 各国的GDP的差别较大</li>
<li>从教育水平来看 各国的教育水平有差别 与互联网普及率的关系不大</li>
<li>从移动数据使用量来看 各国的移动数据使用量基本一致</li>
<li>从数字投资来看 各国的数字投资有差别 其中美国的数字投资最高 个人认为由于美国的互联网发展最早 了解其中的的投资回报率 并且可以投资的资金十分丰厚 所以其数字投资最高 第二高的是中国 由于中国作为世界第二大经济体 也了解其中的投资回报率 第三高的是南非 作为一个非洲国家 其互联网发展较晚 但是却有如此的投资 应该是因为作为一个发展中国家 要想在国际市场上获得成功 其要抓住机会 因此政府大力投资</li>
<li>从数字素养来看 各国的数字素养有差别 数字素养的高低反应了国家互联网发展水平与先后关系</li>
<li>从X情绪评分来看 各国的X情绪评分几乎一致</li>
<li>从5G部署来看 各国的5G部署有差别 只有中国、美国和德国全面部署了5G 由于5G的部署需要大量的投资 因此只有少数国家负担得起 其他国家那些有5G的应该是私人部署</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import plotly.express as px</span><br><span class="line"></span><br><span class="line">fig = px.line(<span class="built_in">df</span>, x=<span class="string">&#x27;Date&#x27;</span>, y=<span class="string">&#x27;Internet_Penetration (%)&#x27;</span>, color=<span class="string">&#x27;Country&#x27;</span>,</span><br><span class="line">              title=<span class="string">&#x27;Internet Penetration Over Time&#x27;</span>,</span><br><span class="line">              labels=&#123;<span class="string">&#x27;Internet_Penetration (%)&#x27;</span>: <span class="string">&#x27;Internet Penetration (%)&#x27;</span>, <span class="string">&#x27;Date&#x27;</span>: <span class="string">&#x27;Date&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图例放到图外右侧</span></span><br><span class="line">fig.update_layout(</span><br><span class="line">    legend_title_text=<span class="string">&#x27;Country&#x27;</span>,</span><br><span class="line">    legend=dict(</span><br><span class="line">        x=1.05,</span><br><span class="line">        y=1,</span><br><span class="line">        xanchor=<span class="string">&#x27;left&#x27;</span>,</span><br><span class="line">        yanchor=<span class="string">&#x27;top&#x27;</span>,</span><br><span class="line">        bgcolor=<span class="string">&#x27;rgba(0,0,0,0)&#x27;</span>,  <span class="comment"># 图例背景透明</span></span><br><span class="line">    ),</span><br><span class="line">    margin=dict(r=150)  <span class="comment"># 右边距留够空间放图例</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/05/003.png"
                      alt="photo"
                ></p>
<p>可以看到 随着时间的推移 互联网的普及率呈现阶梯式上升的趋势</p>
<p>不同国家的互联网普及率也有一定的差异 这是由于国家的发展导致的 有些国家发展得早 互联网普及率就高一些 有些国家发展得晚 互联网普及率就低一些</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(2, 2, figsize=(14, 10))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 城乡互联网渗透率</span></span><br><span class="line">ax1 = axes[0, 0]</span><br><span class="line">sns.lineplot(data=<span class="built_in">df</span>, x=<span class="string">&#x27;Date&#x27;</span>, y=<span class="string">&#x27;Internet_Penetration (%)&#x27;</span>,</span><br><span class="line">             hue=<span class="string">&#x27;Urban_Rural&#x27;</span>, ci=None, ax=ax1)</span><br><span class="line">ax1.set_title(<span class="string">&quot;城乡互联网渗透率&quot;</span>)</span><br><span class="line">ax1.legend(title=<span class="string">&#x27;Urban/Rural&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数字投资 vs GDP</span></span><br><span class="line">ax2 = axes[0, 1]</span><br><span class="line">sns.scatterplot(data=<span class="built_in">df</span>, x=<span class="string">&#x27;GDP_Per_Capita (USD)&#x27;</span>, y=<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>,</span><br><span class="line">                hue=<span class="string">&#x27;Country&#x27;</span>, ax=ax2, legend=False)</span><br><span class="line">ax2.set_title(<span class="string">&quot;数字投资与人均GDP的关系&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 各国互联网渗透率分布</span></span><br><span class="line">ax3 = axes[1, 0]</span><br><span class="line">sns.violinplot(data=<span class="built_in">df</span>, x=<span class="string">&#x27;Country&#x27;</span>, y=<span class="string">&#x27;Internet_Penetration (%)&#x27;</span>,</span><br><span class="line">               palette=colors, ax=ax3)</span><br><span class="line">ax3.set_title(<span class="string">&quot;各国互联网渗透率分布&quot;</span>)</span><br><span class="line">ax3.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, rotation=45)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 饼图</span></span><br><span class="line">ax4 = axes[1, 1]</span><br><span class="line">investment_by_country = df.groupby(<span class="string">&#x27;Country&#x27;</span>)[<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">top10 = investment_by_country.sort_values(ascending=False).<span class="built_in">head</span>(10)</span><br><span class="line"></span><br><span class="line">ax4.pie(top10,</span><br><span class="line">        labels=top10.index,</span><br><span class="line">        autopct=<span class="string">&#x27;%1.1f%%&#x27;</span>,</span><br><span class="line">        startangle=140,</span><br><span class="line">        colors=colors[:10],</span><br><span class="line">        wedgeprops=&#123;<span class="string">&#x27;edgecolor&#x27;</span>: <span class="string">&#x27;white&#x27;</span>&#125;)</span><br><span class="line">ax4.set_title(<span class="string">&quot;国家数字投资占比&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/05/004.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import plotly.express as px</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">df_map = df.groupby(<span class="string">&#x27;Country&#x27;</span>, as_index=False)[<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">df_map[<span class="string">&#x27;Investment (%)&#x27;</span>] = df_map[<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>] / df_map[<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>].<span class="built_in">sum</span>() * 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 Plotly 画 Choropleth 地图</span></span><br><span class="line">fig = px.choropleth(df_map,</span><br><span class="line">                    locations=<span class="string">&#x27;Country&#x27;</span>,</span><br><span class="line">                    locationmode=<span class="string">&#x27;country names&#x27;</span>,</span><br><span class="line">                    color=<span class="string">&#x27;Investment (%)&#x27;</span>,</span><br><span class="line">                    hover_name=<span class="string">&#x27;Country&#x27;</span>,</span><br><span class="line">                    color_continuous_scale=<span class="string">&#x27;Blues&#x27;</span>,</span><br><span class="line">                    title=<span class="string">&#x27;各国数字投资占比（%）&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig.update_geos(showframe=False, showcoastlines=False)</span><br><span class="line">fig.update_layout(margin=&#123;<span class="string">&quot;r&quot;</span>:0,<span class="string">&quot;t&quot;</span>:50,<span class="string">&quot;l&quot;</span>:0,<span class="string">&quot;b&quot;</span>:0&#125;)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/05/005.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import plotly.express as px</span><br><span class="line">import plotly.graph_objects as go</span><br><span class="line">from plotly.subplots import make_subplots</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">investment_by_country = df.groupby(<span class="string">&#x27;Country&#x27;</span>)[<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">top10 = investment_by_country.sort_values(ascending=False).<span class="built_in">head</span>(10)</span><br><span class="line">top10_percent = top10 / top10.sum() * 100  <span class="comment"># 转为百分比</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df_map = investment_by_country.reset_index()</span><br><span class="line">df_map[<span class="string">&#x27;Percent&#x27;</span>] = df_map[<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>] / df_map[<span class="string">&#x27;Digital_Investment (M USD)&#x27;</span>].<span class="built_in">sum</span>() * 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 subplot: 1行2列，第1列地图，第2列饼图</span></span><br><span class="line">fig = make_subplots(rows=1, cols=2, </span><br><span class="line">                    column_widths=[0.6, 0.4],</span><br><span class="line">                    specs=[[&#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;choropleth&quot;</span>&#125;, &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;domain&quot;</span>&#125;]],</span><br><span class="line">                    subplot_titles=(<span class="string">&quot;各国数字投资地图&quot;</span>, <span class="string">&quot;前10国家投资占比饼图&quot;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">map_fig = px.choropleth(df_map,</span><br><span class="line">                        locations=<span class="string">&#x27;Country&#x27;</span>,</span><br><span class="line">                        locationmode=<span class="string">&#x27;country names&#x27;</span>,</span><br><span class="line">                        color=<span class="string">&#x27;Percent&#x27;</span>,</span><br><span class="line">                        color_continuous_scale=<span class="string">&#x27;Blues&#x27;</span>,</span><br><span class="line">                        hover_name=<span class="string">&#x27;Country&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> trace <span class="keyword">in</span> map_fig.data:</span><br><span class="line">    fig.add_trace(trace, row=1, col=1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig.add_trace(go.Pie(</span><br><span class="line">    labels=top10.index,</span><br><span class="line">    values=top10.values,</span><br><span class="line">    hole=0,  </span><br><span class="line">    textinfo=<span class="string">&#x27;percent+label&#x27;</span>,</span><br><span class="line">    marker=dict(colors=colors),</span><br><span class="line">), row=1, col=2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig.update_layout(</span><br><span class="line">    title_text=<span class="string">&quot;数字投资地图 + Top10 国家饼图&quot;</span>,</span><br><span class="line">    showlegend=False,</span><br><span class="line">    margin=dict(t=60, l=30, r=30)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/05/006.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(6, 5))</span><br><span class="line">sns.heatmap(df.select_dtypes(include=<span class="string">&#x27;number&#x27;</span>).corr(), annot=True, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, square=True)</span><br><span class="line">plt.title(<span class="string">&quot;变量相关性热力图&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/05/007.png"
                      alt="photo"
                ></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>数学建模论文</title>
    <url>/zhihaojiang.github.io/2025/06/06/20250606%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>学院</th>
<th>班级</th>
<th>姓名</th>
</tr>
</thead>
<tbody><tr>
<td>数据科学学院</td>
<td>大数据231</td>
<td>陈佳妮</td>
</tr>
<tr>
<td>数据科学学院</td>
<td>大数据231</td>
<td>许薇</td>
</tr>
<tr>
<td>数据科学学院</td>
<td>大数据232</td>
<td>姜智浩</td>
</tr>
<tr>
<td>数据科学学院</td>
<td>大数据232</td>
<td>马子楦</td>
</tr>
<tr>
<td>数据科学学院</td>
<td>大数据232</td>
<td>王靖侃</td>
</tr>
</tbody></table>
<h1 id="一、问题重述"><a href="#一、问题重述" class="headerlink" title="一、问题重述"></a>一、问题重述</h1><p>青少年时期是人生发展的重要阶段，良好的饮食习惯对学生的知识学习和身体发育具有深远影响。然而当前学生群体普遍存在饮食结构不合理的问题，主要表现为早餐质量不佳、过度依赖外卖快餐以及不科学的节食行为等。这些不良饮食习惯可能导致营养摄入不均衡，进而影响学生的健康状态和学习效率。针对这一现状，本研究基于科学营养学原理，旨在通过系统性的饮食评估和优化设计，帮助学生建立更加合理的膳食结构。<br>根据题目和所提供附件，建立合理的数学模型解决以下问题<br><strong>问题1. 饮食营养分析与调整</strong><br>对两份提供的日常饮食记录进行全面营养评价。通过参照健康饮食的基本标准和营养素参考摄入量，系统评估其饮食结构的合理性。在完成评价后，将根据评价结果给出针对性的调整建议。<br><strong>问题2. 日常健康饮食的优化设计</strong><br>在完成基础评价后，本研究将重点探讨三种不同优化目标的饮食方案设计。第一种方案以蛋白质氨基酸评分最大化为核心目标，着重提升饮食的营养质量，确保优质蛋白质的摄入。第二种方案以经济性为导向，在保证基本营养需求的前提下实现成本最小化。第三种方案设计一个综合优化模型，同时考虑蛋白质氨基酸评分和成本效益。最后，通过对这三种优化模型的比较分析，从营养达标率、经济成本、可行性等多个维度进行综合评估，为不同需求的学生提供个性化的膳食建议。</p>
<h1 id="二、基本假设"><a href="#二、基本假设" class="headerlink" title="二、基本假设"></a>二、基本假设</h1><p>为了方便模型的建立与模型的可行性，这里首先对模型提出一些假设，使得模型更加完备，预测的结果更加合理。</p>
<ol>
<li>假设附件1-4提供的数据（如食物成分、价格、营养素推荐量）准确可靠，可直接用于建模。</li>
<li>在食谱设计时，忽略食物在存储和烹饪过程中可能发生的营养成分损失，假设食物的营养成分与原材料表中的数据一致。</li>
<li>假设每日的餐次固定，例如早餐、午餐、晚餐，每餐的能量分配比例固定，便于食谱的规范化设计.</li>
<li>所有食谱设计都必须满足大学生的基本营养需求，包括蛋白质、脂肪、碳水化合物、维生素和矿物质的日推荐摄入量。</li>
<li>食谱的总成本应适合学生的经济能力，确保食谱的经济可行性。</li>
<li>在模型设计时，假设所有大学生的营养需求和偏好是均一的，不考虑个体之间的生理差异和个人偏好。</li>
<li>假设食堂提供的所有食物（附件3）均可无限量供应，且价格稳定。</li>
<li>假设食物成本仅考虑食材价格，忽略加工、人力等附加成本。</li>
<li>假设每日饮食方案独立设计，不考虑长期营养累积效应</li>
<li>假设模型的计算和响应时间在可接受范围内，适合实际应用中的快速决策需求。</li>
</ol>
<h1 id="三、问题分析"><a href="#三、问题分析" class="headerlink" title="三、问题分析"></a>三、问题分析</h1><p>膳食食谱的营养分析与优化是一个典型的营养学与数据科学交叉问题，其核心在于通过定量分析食谱的营养成分，评估其是否符合健康膳食标准，并基于数学模型进行优化调整。题目提供了61种常见食物的详细营养成分数据，包括蛋白质、脂肪、碳水化合物、维生素及矿物质含量，以及8种必需氨基酸的组成信息。这些数据构成了问题分析的基础，而评价与调整的关键在于如何将这些数据转化为可计算的营养指标，并建立合理的优化模型。<br>该问题可抽象为一个多目标优化问题，主要涉及食谱中各类食物的摄入量作为决策变量，目标函数包括营养均衡性、氨基酸评分和经济性，约束条件则涵盖能量需求、营养素下限、餐次比和食物多样性等。由于氨基酸评分涉及最小值函数，导致目标函数呈现非线性特征，同时食物选择存在离散与连续变量混合的情况，这增加了问题的复杂性。针对这些特点，本文采用差分进化算法进行优化，该算法能够有效处理非线性问题，具有全局搜索能力，并能灵活应对混合变量类型。<br>通过模型求解，可以得到调整后的优化食谱方案。具体优化策略包括增加优质蛋白来源以提升氨基酸评分，减少高脂肪食物来改善宏量营养素比例，补充微量营养素以满足最低摄入要求，以及优化餐次分配确保能量供给合理。最终通过营养计算和可视化手段验证优化效果，确保调整后的食谱既科学合理又具有实际可操作性。这一方法不仅解决了当前食谱的营养均衡问题，也为后续个性化膳食推荐提供了可扩展的模型框架。</p>
<h1 id="四、符号说明"><a href="#四、符号说明" class="headerlink" title="四、符号说明"></a>四、符号说明</h1><h1 id="五、模型的建立与求解"><a href="#五、模型的建立与求解" class="headerlink" title="五、模型的建立与求解"></a>五、模型的建立与求解</h1><h2 id="5-1男女生一天饮食评价"><a href="#5-1男女生一天饮食评价" class="headerlink" title="5.1男女生一天饮食评价"></a>5.1男女生一天饮食评价</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p><strong>评价模型</strong><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/016.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/017.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/018.png"
                      alt="photo"
                ></p>
<p><strong>优化模型</strong><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/019.png"
                      alt="photo"
                ></p>
<h3 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h3><p>本研究基于《中国食物成分表》的61种食材数据，对某校学生食堂提供的男女膳食方案进行了系统性评估。如图1（某校学生食堂食物类别分布）所示，男生食谱中谷薯类占比达35.7%，显著高于女生的28.6%（χ²&#x3D;4.32，p&lt;0.05），而女生食谱中蔬菜菌藻水果类占比41.2%则明显优于男生的33.3%。这种结构性差异直接影响了后续的营养素摄入分布。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/001.png"
                      alt="photo"
                ><br><em>图1 某校学生食堂食物类别分布</em></p>
<p>通过图2（男生食物类别统计）和图3（女生食物类别统计）的对比分析发现，男生每日摄入的畜禽鱼蛋类食物达到4种，比女生多出1种，但奶豆坚果类仅2种，较女生少1种。这种不均衡分布导致了两者在微量元素摄入上的显著差异。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/002.png"
                      alt="photo"
                ><br><em>图2 男生食物类别统计</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/003.png"
                      alt="photo"
                ><br><em>图3 女生食物类别统计</em></p>
<p>图4（男生膳食微量元素分布特征）显示，钙、铁、锌的摄入量分别为578.5mg、18.77mg和9.99mg，而图5（女生膳食微量元素分布特征）则显示相应数值为346.0mg、8.56mg和5.38mg，均低于男生水平（t&#x3D;3.21，p&lt;0.01）。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/004.png"
                      alt="photo"
                ><br><em>图4 男生膳食微量元素分布特征</em><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/005.png"
                      alt="photo"
                ><br><em>图5 女生膳食微量元素分布特征</em></p>
<p>在宏量营养素方面，图6（男生宏量营养素能量占比）左图清晰地展示了蛋白质、脂肪和碳水化合物的供能比分别为11.58%、43.35%和45.07%，其中脂肪占比远超推荐上限。图6（女生宏量营养素能量占比）右图则显示其脂肪占比为27.6%，虽然处于合理区间，但碳水化合物占比达57.3%，反映出主食过量的倾向。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/006.png"
                      alt="photo"
                ><br><strong>图6 男生(左)、女生（右）宏量营养素能量占比</strong></p>
<p>这种差异在图7（男生实际摄入量与推荐摄入量比较）和图8（女生实际摄入量与推荐摄入量比较）中得到了进一步验证，男生总能量摄入2602.99kcal基本达标，但女生1347.98kcal的总能量仅达到推荐值的74.6%。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/007.png"
                      alt="photo"
                ><br><em>图7 男生实际摄入量与推荐摄入量比较</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/008.png"
                      alt="photo"
                ><br><em>图8 女生实际摄入量与推荐摄入量比较</em></p>
<p>氨基酸评分分析揭示了更深层次的问题。图9（男生必需氨基酸评分（AAS））显示含硫氨基酸评分仅为40.16，成为限制蛋白质质量的首要因素；图10（女生必需氨基酸评分（AAS））虽然赖氨酸评分达92.90，但含硫氨基酸68.41的评分仍低于安全阈值。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/009.png"
                      alt="photo"
                ><br><em>图9 男生必需氨基酸评分（AAS）</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/010.png"
                      alt="photo"
                ><br><em>图10 女生必需氨基酸评分（AAS）</em></p>
<p>通过图11（男生、女生三餐氨基酸摄入均衡性评估）的时间维度分析发现，晚餐的氨基酸评分普遍低于其他餐次，这与图12（男生、女生每餐能量占总能量的百分比）中显示的晚餐营养密度不足直接相关。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/011.png"
                      alt="photo"
                ><br><em>图11 男生（左）、女生（右）三餐氨基酸摄入均衡性评估</em><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/012.png"
                      alt="photo"
                ><br><em>图12 男生（左）、女生（右）每餐能量占总能量的百分比</em></p>
<p>微量元素摄入的均衡性评估结果同样值得关注。图13（男生微量元素摄入均衡性评估）左图表明铁和锌的摄入充足，但钙和维生素C明显不足；图13（女生微量元素摄入均衡性评估）右图则显示所有微量元素的摄入量均低于推荐值，其中钙的缺口达45.3%。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/013.png"
                      alt="photo"
                ><br><em>图13 男生（左）、女生（右）微量元素摄入均衡性评估</em></p>
<p>这种差异在图14（男生膳食氨基酸与营养成分的分布特征）和图15（女生膳食氨基酸与营养成分的分布特征）的散点图中表现得尤为明显，女生数据点的分布更加偏离理想区间。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/014.png"
                      alt="photo"
                ><br><em>图14 男生膳食氨基酸与营养成分的分布特征</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/015.png"
                      alt="photo"
                ><br><em>图15 女生膳食氨基酸与营养成分的分布特征</em></p>
<p>基于上述发现，本研究提出了针对性的优化方案。首先调整食物类别占比，增加男生奶制品和女生豆制品的摄入；其次重新分配餐次能量，将男生晚餐能量占比从32%提升至35%，女生早餐占比从30%增至33%；最后优化食材组合，采用氨基酸互补原则，如将男生食谱中的豆油部分替换为芝麻油，女生增加蛋奶混合食材。通过这些调整，最终使男生的含硫氨基酸评分提升至47.94，女生的钙摄入量达到649.1mg，显著改善了整体营养质量。</p>
<h2 id="5-2男女生氨基酸优先推荐饮食"><a href="#5-2男女生氨基酸优先推荐饮食" class="headerlink" title="5.2男女生氨基酸优先推荐饮食"></a>5.2男女生氨基酸优先推荐饮食</h2><h3 id="食谱"><a href="#食谱" class="headerlink" title="食谱"></a>食谱</h3><p><strong>男生食谱</strong></p>
<table>
<thead>
<tr>
<th>时间</th>
<th>食物名称</th>
</tr>
</thead>
<tbody><tr>
<td>早餐</td>
<td>酸奶</td>
</tr>
<tr>
<td>早餐</td>
<td>煎鸡蛋</td>
</tr>
<tr>
<td>早餐</td>
<td>蒸地瓜</td>
</tr>
<tr>
<td>午餐</td>
<td>海带炖白菜</td>
</tr>
<tr>
<td>午餐</td>
<td>鸡肉炖土豆胡萝卜</td>
</tr>
<tr>
<td>午餐</td>
<td>白菜炖豆腐</td>
</tr>
<tr>
<td>午餐</td>
<td>干炸黄花鱼</td>
</tr>
<tr>
<td>晚餐</td>
<td>砂锅面</td>
</tr>
<tr>
<td>晚餐</td>
<td>萝卜粉丝汤</td>
</tr>
<tr>
<td>晚餐</td>
<td>炒肉扁豆</td>
</tr>
<tr>
<td>晚餐</td>
<td>茄汁沙丁鱼</td>
</tr>
</tbody></table>
<p><strong>女生食谱</strong></p>
<table>
<thead>
<tr>
<th>时间</th>
<th>食物名称</th>
</tr>
</thead>
<tbody><tr>
<td>早餐</td>
<td>大米粥</td>
</tr>
<tr>
<td>早餐</td>
<td>油条</td>
</tr>
<tr>
<td>早餐</td>
<td>煮鸡蛋</td>
</tr>
<tr>
<td>早餐</td>
<td>蒸地瓜</td>
</tr>
<tr>
<td>早餐</td>
<td>水煎包</td>
</tr>
<tr>
<td>午餐</td>
<td>鱼丸汤</td>
</tr>
<tr>
<td>午餐</td>
<td>红烧牛肉面</td>
</tr>
<tr>
<td>晚餐</td>
<td>红烧肉</td>
</tr>
<tr>
<td>晚餐</td>
<td>干炸黄花鱼</td>
</tr>
<tr>
<td>晚餐</td>
<td>炖海带白菜豆腐</td>
</tr>
<tr>
<td>晚餐</td>
<td>柚子</td>
</tr>
</tbody></table>
<h3 id="可视化评价"><a href="#可视化评价" class="headerlink" title="可视化评价"></a>可视化评价</h3><p><strong>男生</strong><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/020.png"
                      alt="photo"
                ><br><em>男生三餐氨基酸摄入均衡性评估</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/021.png"
                      alt="photo"
                ><br><em>男生膳食微量元素分布特征</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/022.png"
                      alt="photo"
                ><br><em>全天氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/023.png"
                      alt="photo"
                ><br><em>三餐氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/024.png"
                      alt="photo"
                ><br><em>三餐营养供能占比</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/025.png"
                      alt="photo"
                ><br><em>三餐营养热力图</em></p>
<p><strong>女生</strong><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/026.png"
                      alt="photo"
                ><br><em>女生三餐氨基酸摄入均衡性评估</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/027.png"
                      alt="photo"
                ><br><em>女生膳食微量元素分布特征</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/028.png"
                      alt="photo"
                ><br><em>全天氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/029.png"
                      alt="photo"
                ><br><em>三餐氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/030.png"
                      alt="photo"
                ><br><em>三餐营养供能占比</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/031.png"
                      alt="photo"
                ><br><em>三餐营养热力图</em></p>
<h2 id="5-3男女生价格优先推荐饮食"><a href="#5-3男女生价格优先推荐饮食" class="headerlink" title="5.3男女生价格优先推荐饮食"></a>5.3男女生价格优先推荐饮食</h2><h3 id="食谱-1"><a href="#食谱-1" class="headerlink" title="食谱"></a>食谱</h3><p><strong>男生食谱</strong></p>
<table>
<thead>
<tr>
<th>时间</th>
<th>食物名称</th>
</tr>
</thead>
<tbody><tr>
<td>早餐</td>
<td>牛奶</td>
</tr>
<tr>
<td>早餐</td>
<td>蒸地瓜</td>
</tr>
<tr>
<td>午餐</td>
<td>白菜炖豆腐</td>
</tr>
<tr>
<td>午餐</td>
<td>香蕉</td>
</tr>
<tr>
<td>午餐</td>
<td>蜜瓜</td>
</tr>
<tr>
<td>晚餐</td>
<td>炖海带白菜豆腐</td>
</tr>
<tr>
<td>晚餐</td>
<td>柚子</td>
</tr>
</tbody></table>
<p><strong>女生食谱</strong></p>
<table>
<thead>
<tr>
<th>时间</th>
<th>食物名称</th>
</tr>
</thead>
<tbody><tr>
<td>早餐</td>
<td>牛奶</td>
</tr>
<tr>
<td>早餐</td>
<td>蒸地瓜</td>
</tr>
<tr>
<td>早餐</td>
<td>拌土豆丝</td>
</tr>
<tr>
<td>午餐</td>
<td>菠菜汤</td>
</tr>
<tr>
<td>午餐</td>
<td>白菜炖豆腐</td>
</tr>
<tr>
<td>午餐</td>
<td>香蕉</td>
</tr>
<tr>
<td>午餐</td>
<td>蜜瓜</td>
</tr>
<tr>
<td>晚餐</td>
<td>炖海带白菜豆腐</td>
</tr>
<tr>
<td>晚餐</td>
<td>柚子</td>
</tr>
</tbody></table>
<h3 id="可视化评价-1"><a href="#可视化评价-1" class="headerlink" title="可视化评价"></a>可视化评价</h3><p><strong>男生</strong><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/032.png"
                      alt="photo"
                ><br><em>男生三餐氨基酸摄入均衡性评估</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/033.png"
                      alt="photo"
                ><br><em>男生膳食微量元素分布特征</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/034.png"
                      alt="photo"
                ><br><em>全天氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/035.png"
                      alt="photo"
                ><br><em>三餐氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/036.png"
                      alt="photo"
                ><br><em>三餐营养供能占比</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/037.png"
                      alt="photo"
                ><br><em>三餐营养热力图</em></p>
<p><strong>女生</strong><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/038.png"
                      alt="photo"
                ><br><em>女生三餐氨基酸摄入均衡性评估</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/039.png"
                      alt="photo"
                ><br><em>女生膳食微量元素分布特征</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/040.png"
                      alt="photo"
                ><br><em>全天氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/041.png"
                      alt="photo"
                ><br><em>三餐氨基酸摄入评分柱状图</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/042.png"
                      alt="photo"
                ><br><em>三餐营养供能占比</em></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/06/043.png"
                      alt="photo"
                ><em>三餐营养热力图</em></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>移动房车险购买倾向预测分析</title>
    <url>/zhihaojiang.github.io/2025/06/05/20250607%E7%A7%BB%E5%8A%A8%E6%88%BF%E8%BD%A6%E9%99%A9%E8%B4%AD%E4%B9%B0%E5%80%BE%E5%90%91%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>保险已成为“高净值人士”的青睐之选。在当前投资机会较少、股市&#x2F;楼市&#x2F;实体经济风险较高的背景下，保险业迎来蓬勃发展，大量保险公司推出人寿型、医疗型、投资理财型等产品，竞争激烈。传统的保险模型往往依赖于历史数据和经验法则，易出现险种推荐错配、过度推销等问题，引发客户信任危机和抵触情绪，损害企业品牌信誉。<br>本案例旨在通过机器学习技术分析家庭购买保险的历史数据，帮助保险公司更好地理解客户的购买行为和风险偏好。完成数据清洗、特征选择、模型构建、模型评估、模型优化和模型解释等数据分析任务，挖掘影响客户购买移动放车险的重要因素，构建移动房车险购买倾向预测模型，提升推荐准确度，从而在竞争激烈的市场中获得优势。</p>
<h1 id="基本库导入"><a href="#基本库导入" class="headerlink" title="基本库导入"></a>基本库导入</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">from matplotlib import font_manager</span><br><span class="line"><span class="comment"># 设置字体路径</span></span><br><span class="line">font_path = <span class="string">&#x27;/System/Library/Fonts/STHeiti Medium.ttc&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载字体</span></span><br><span class="line">my_font = font_manager.FontProperties(fname=font_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = my_font.get_name()</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = False  <span class="comment"># 正确显示负号</span></span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;#d7fbe8&#x27;</span>,<span class="string">&#x27;#9df3c4&#x27;</span>,<span class="string">&#x27;#62d2a2&#x27;</span>,<span class="string">&#x27;#1fab89&#x27;</span>,<span class="string">&#x27;#a6d0e4&#x27;</span>, <span class="string">&#x27;#f9ffea&#x27;</span>, <span class="string">&#x27;#ffecda&#x27;</span>, <span class="string">&#x27;#d4a5a5&#x27;</span>, <span class="string">&#x27;#fbafaf&#x27;</span>, <span class="string">&#x27;#f2c6b4&#x27;</span>, <span class="string">&#x27;#f3e8cb&#x27;</span>, <span class="string">&#x27;#99e1e5&#x27;</span>]</span><br></pre></td></tr></table></figure></div>

<h1 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">&#x27;train.xlsx&#x27;</span>)</span><br><span class="line">df_test = pd.read_excel(<span class="string">&#x27;test.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br><span class="line"></span><br><span class="line">df.shape</span><br><span class="line"></span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>&lt;class ‘pandas.core.frame.DataFrame’&gt;<br>RangeIndex: 1756 entries, 0 to 1755<br>Data columns (total 86 columns):</p>
<h1 id="Column-Non-Null-Count-Dtype"><a href="#Column-Non-Null-Count-Dtype" class="headerlink" title="Column      Non-Null Count  Dtype"></a>Column      Non-Null Count  Dtype</h1><hr>
<p> 0   客户次类别       1756 non-null   int64<br> 1   房产数         1756 non-null   int64<br> 2   每房人数        1756 non-null   int64<br> 3   平均年龄        1756 non-null   int64<br> 4   客户主类别       1756 non-null   int64<br> 5   罗马天主教比例     1756 non-null   int64<br> 6   新教比例        1756 non-null   int64<br> 7   其它宗教比例      1756 non-null   int64<br> 8   无宗教比例       1756 non-null   int64<br> 9   已婚占比        1756 non-null   int64<br> 10  同居占比        1756 non-null   int64<br> 11  其它关系占比      1756 non-null   int64<br> 12  单身占比        1756 non-null   int64<br> 13  无子女         1756 non-null   int64<br> 14  有子女         1756 non-null   int64<br> 15  高等教育        1756 non-null   int64<br> 16  中等教育        1756 non-null   int64<br> 17  低等教育        1756 non-null   int64<br> 18  高管          1756 non-null   int64<br> 19  企业家         1756 non-null   int64<br>…<br> 84  投保社会安全险数量   1756 non-null   int64<br> 85  移动房车险数量     1756 non-null   int64<br>dtypes: int64(86)<br>memory usage: 1.2 MB</p>
<p>(1756, 86)</p>
</blockquote>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/07/001.png"
                      alt="photo"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/07/002.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.countplot(x=<span class="string">&#x27;移动房车险数量&#x27;</span>, data=<span class="built_in">df</span>, palette=colors)</span><br><span class="line">plt.title(<span class="string">&#x27;移动房车险数量分布&#x27;</span>, fontproperties=my_font, fontsize=16)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;移动房车险数量&#x27;</span>, fontproperties=my_font, fontsize=14)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;数量&#x27;</span>, fontproperties=my_font, fontsize=14)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/07/003.png"
                      alt="photo"
                ></p>
<p>我们查看训练集数据的分布 发现其数量较均匀（也查看了测试集的分布 其购买保险的人数远少于未买保险的人数）</p>
<h1 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h1><h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;存在缺失值的列：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df.columns[df.isnull().any()])</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>存在缺失值的列：<br>Index([], dtype&#x3D;’object’)</p>
</blockquote>
<p>发现数据中没有缺失值</p>
<h2 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h2><h3 id="检测数据分布"><a href="#检测数据分布" class="headerlink" title="检测数据分布"></a>检测数据分布</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">import scipy.stats as stats</span><br><span class="line"></span><br><span class="line">numeric_cols = df.select_dtypes(include=<span class="string">&#x27;number&#x27;</span>).columns</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> numeric_cols:</span><br><span class="line">    plt.figure(figsize=(14, 5))</span><br><span class="line"></span><br><span class="line">    plt.subplot(1, 2, 1)</span><br><span class="line">    sns.histplot(<span class="built_in">df</span>[col], kde=True, bins=30, color=<span class="string">&#x27;skyblue&#x27;</span>)</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(1, 2, 2)</span><br><span class="line">    stats.probplot(<span class="built_in">df</span>[col], dist=<span class="string">&quot;norm&quot;</span>, plot=plt)</span><br><span class="line">    plt.title(col)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/07/004.png"
                      alt="photo"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/07/005.png"
                      alt="photo"
                ><br>我们可视化了各个特征的分布 发现在前半部份的特征（非投保）数据分布较为正常 在投保部分的特征 数据呈现非常明显的偏态分布 这种情况在进行异常检测时可能是异常值 但考虑到我们这个数据集是预测移动房车险购买倾向 有可能这些异常值就是那些购买保险的人 因此我们可以标记异常值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> col == <span class="string">&#x27;移动房车险数量&#x27;</span> or <span class="built_in">df</span>[col].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    </span><br><span class="line">    Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">    Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line">    lower = Q1 - 1.5 * IQR</span><br><span class="line">    upper = Q3 + 1.5 * IQR</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">df</span>[col + <span class="string">&#x27;_outlier&#x27;</span>] = <span class="built_in">df</span>[col].apply(lambda x: 1 <span class="keyword">if</span> (x &lt; lower or x &gt; upper) <span class="keyword">else</span> 0)</span><br></pre></td></tr></table></figure></div>

<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>我们计算方差和皮尔逊相关系数 删除方差过小的特征和p&gt;0.05的特征</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">low_var = df.var(numeric_only=True)</span><br><span class="line"><span class="built_in">df</span> = df.drop(columns=low_var[low_var &lt;= 0.1].index)</span><br><span class="line"></span><br><span class="line">from scipy.stats import pearsonr</span><br><span class="line"></span><br><span class="line">target_col = <span class="string">&quot;移动房车险数量&quot;</span></span><br><span class="line">numeric_cols = df.select_dtypes(include=<span class="string">&#x27;number&#x27;</span>).columns</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> col == target_col:</span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    <span class="keyword">if</span> col not <span class="keyword">in</span> numeric_cols:</span><br><span class="line">        <span class="built_in">df</span> = df.drop(columns=[col])</span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    try:</span><br><span class="line">        corr, p = pearsonr(<span class="built_in">df</span>[col], <span class="built_in">df</span>[target_col])</span><br><span class="line">        <span class="keyword">if</span> p &gt; 0.05:</span><br><span class="line">            <span class="built_in">df</span> = df.drop(columns=[col])</span><br><span class="line">    except Exception as e:</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;Error on &#123;col&#125;: &#123;e&#125;&quot;</span>)</span><br><span class="line">        <span class="built_in">df</span> = df.drop(columns=[col])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df.columns.tolist())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;剩余变量数量:&quot;</span>, len(df.columns))</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>[‘客户次类别’, ‘每房人数’, ‘客户主类别’, ‘新教比例’, ‘无宗教比例’, ‘已婚占比’, ‘同居占比’, ‘其它关系占比’, ‘单身占比’, ‘高等教育’, ‘中等教育’, ‘低等教育’, ‘高管’, ‘农场主’, ‘中层管理者’, ‘技术工人’, ‘非熟练劳工’, ‘社会阶层A’, ‘社会阶层B1’, ‘社会阶层C’, ‘社会阶层D’, ‘租房子’, ‘房主’, ‘一辆车’, ‘无车’, ‘公共社保’, ‘私人社保’, ‘收入低于30’, ‘收入45-75’, ‘收入75-122’, ‘平均收入’, ‘购买力水平’, ‘个人第三方保险’, ‘投保车险’, ‘投保机动自行车险’, ‘投保身残险’, ‘投保火险’, ‘投保船险’, ‘投保社会安全险’, ‘第三方私人险数量’, ‘投保车险数量’, ‘投保寿险数量’, ‘投保火险数量’, ‘移动房车险数量’, ‘社会阶层D_outlier’]<br>剩余变量数量: 45</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">selected_cols = df.columns.tolist()</span><br><span class="line">df_test = <span class="built_in">df</span>[selected_cols]</span><br></pre></td></tr></table></figure></div>

<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop(columns=[<span class="string">&#x27;移动房车险数量&#x27;</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;移动房车险数量&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train = df.drop(columns=[<span class="string">&#x27;移动房车险数量&#x27;</span>])</span><br><span class="line">y_train = <span class="built_in">df</span>[<span class="string">&#x27;移动房车险数量&#x27;</span>]</span><br><span class="line">X_test = df_test.drop(columns=[<span class="string">&#x27;移动房车险数量&#x27;</span>])</span><br><span class="line">y_test = df_test[<span class="string">&#x27;移动房车险数量&#x27;</span>]</span><br></pre></td></tr></table></figure></div>

<h1 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h1><p>我们使用了两种模型处理并优化 第一个使用了朴素贝叶斯模型 使用网格优化 得到<br>recall&#x3D;0.73 f1&#x3D;0.67<br>相较与只使用朴素贝叶斯 其召回率提高了5%<br>我们又使用多层感知机进行训练并用adam进行优化并且设置了早停 其准确率和召回率达到了0.95和0.96 并且我们更关注模型预测会购买保险的召回率：0.98 说明模型了解了购买保险人的画像</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import Binarizer</span><br><span class="line">from sklearn.naive_bayes import BernoulliNB</span><br><span class="line">from sklearn.metrics import accuracy_score, recall_score, classification_report</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;nb&#x27;</span>, BernoulliNB())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">pipeline.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = pipeline.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率：&#x27;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;召回率：&#x27;</span>, recall_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>准确率： 0.6822323462414579<br>召回率： 0.617816091954023<br>分类报告：<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.74      0.72      0.73      1060
       1       0.60      0.62      0.61       696

accuracy                           0.68      1756
macro avg      0.67      0.67      0.67      1756
weighted avg   0.68      0.68      0.68      1756
</code></pre>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">from sklearn.naive_bayes import BernoulliNB</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;nb&#x27;</span>, BernoulliNB())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;nb__alpha&#x27;</span>: [0.1, 0.5, 1.0, 2.0],</span><br><span class="line">    <span class="string">&#x27;nb__binarize&#x27;</span>: [0.0, 0.5, 1.0, 2.0],</span><br><span class="line">    <span class="string">&#x27;nb__class_prior&#x27;</span>: [None, [0.3, 0.7], [0.4, 0.6]]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=<span class="string">&#x27;f1&#x27;</span>, n_jobs=-1)</span><br><span class="line"></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = grid_search.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳参数：&quot;</span>, grid_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳模型得分：&quot;</span>, grid_search.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>最佳参数： {‘nb__alpha’: 0.1, ‘nb__binarize’: 0.0, ‘nb__class_prior’: [0.4, 0.6]}<br>最佳模型得分： 0.6235479451448764</p>
<p>分类报告：<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.78      0.63      0.70      1060
       1       0.57      0.73      0.64       696

accuracy                           0.67      1756
macro avg      0.67      0.68      0.67      1756
weighted avg   0.70      0.67      0.68      1756
</code></pre>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.neural_network import MLPClassifier</span><br><span class="line">from sklearn.metrics import accuracy_score, recall_score, classification_report</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">&#x27;mlp&#x27;</span>, MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500,</span><br><span class="line">                          solver=<span class="string">&#x27;adam&#x27;</span>, early_stopping=True,</span><br><span class="line">                          validation_fraction=0.1, n_iter_no_change=10,</span><br><span class="line">                          random_state=42))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">pipeline.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = pipeline.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率：&#x27;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;召回率（宏平均）：&#x27;</span>, recall_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line">plt.plot(pipeline.named_steps[<span class="string">&#x27;mlp&#x27;</span>].loss_curve_)</span><br><span class="line">plt.title(<span class="string">&quot;Loss Curve&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Iterations&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p>准确率： 0.9595671981776766<br>召回率（宏平均）： 0.9635491216655823<br>分类报告：<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.99      0.94      0.97      1060
       1       0.92      0.98      0.95       696

accuracy                           0.96      1756
macro avg      0.95      0.96      0.96      1756
weighted avg   0.96      0.96      0.96      1756
</code></pre>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/07/006.png"
                      alt="photo"
                ></p>
<h1 id="特征重要性"><a href="#特征重要性" class="headerlink" title="特征重要性"></a>特征重要性</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import shap</span><br><span class="line"></span><br><span class="line">scaler = pipeline.named_steps[<span class="string">&#x27;scaler&#x27;</span>]</span><br><span class="line">model = pipeline.named_steps[<span class="string">&#x27;mlp&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train_scaled = scaler.transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line">explainer = shap.KernelExplainer(model.predict, X_train_scaled[:100])</span><br><span class="line">shap_values = explainer.shap_values(X_test_scaled[:100])</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, X_test_scaled[:100], feature_names=X.columns)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/07/007.png"
                      alt="photo"
                ></p>
<h1 id="推荐建议"><a href="#推荐建议" class="headerlink" title="推荐建议"></a>推荐建议</h1><p>我们使用shap画出了summary_plot<br>可以看到投保车险 租房子 投保身残险 已婚占比的重要度较高<br>说明那些会购买移动房车险的客户会给自己的车购买保险 喜欢租房（爱好周游世界）看中自己的生命 已婚<br>这类人群的用户画像基本可以如此描述：他们喜欢周游世界 有足够的精力去欣赏世界的美好 有着足够的资金去支持自己的爱好<br>用户群体可能为：退休的老两口 他们的孩子有足够的独立性不需要他们去操心 他们可以安心享受退休生活 他们有着足够的资金去周游世界 去弥补年轻时没空干的事</p>
<p>同时 我们注意到 第三方社会阶层B1 私人险数量和投保船险的影响力较大 虽然在全局中不是特别重要 但是这些也起到关键作用<br>这类客户的用户画像为40岁以上 公司董事长 其公司十分成熟 在行业内有着举足轻重的地位 其无需担心自己的商业帝国会面临困难 拥有着自己的游艇 为人比较低调 不喜欢显露自己的财富<br>这类人属于高端客户 他们见过的世面很广 十分精明 虽然数量稀少 但是若成功售出 会给公司带来巨大利润</p>
<p>因此 我们的营销策略为：主要对退休的老两口进行营销 可以在房车经销商处宣发广告 在财经频道 新闻频道宣发广告<br>同时要打造高端化产品 提供足够的情绪价值 尽可能地打造几个高端的产品以吸引高端客户</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>Apriori算法原理</title>
    <url>/zhihaojiang.github.io/2025/06/13/20250613Apriori%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="Apriori"><a href="#Apriori" class="headerlink" title="Apriori"></a>Apriori</h1><p>Apriori 算法是<strong>关联规则学习</strong>中最经典的算法之一，用于在大规模交易记录中发现<strong>频繁项集</strong>和<strong>关联规则</strong>。</p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h1><p>这是 Apriori 原理（反单调性）<br><strong>“如果一个项集是频繁的，它的所有子集也一定是频繁的”</strong><br>→ 反过来说：<strong>如果某个项集不频繁，那它的所有超集一定也不频繁</strong>。</p>
<h1 id="Apriori流程"><a href="#Apriori流程" class="headerlink" title="Apriori流程"></a>Apriori流程</h1><ol>
<li>初始化：找出所有频繁的1项集。</li>
</ol>
<ul>
<li>扫描数据，统计每个单品的支持度。</li>
<li>只保留支持度 ≥ 最小阈值（min_sup）的项。</li>
</ul>
<ol start="2">
<li>迭代生成 k 项集。</li>
</ol>
<ul>
<li>用频繁的 (k−1) 项集 生成候选 k 项集（两两组合）。</li>
<li>继续扫描数据集，统计每个候选项集的支持度。</li>
<li>只保留支持度 ≥ min_sup 的项集。</li>
</ul>
<ol start="3">
<li>重复直到无法产生更大的频繁项集。</li>
</ol>
<h1 id="找频繁项集后-→-生成关联规则"><a href="#找频繁项集后-→-生成关联规则" class="headerlink" title="找频繁项集后 → 生成关联规则"></a>找频繁项集后 → 生成关联规则</h1><p> 对每个频繁项集 L：</p>
<ul>
<li>枚举其所有非空子集 A，令 B &#x3D; L − A</li>
<li>构造规则：A → B</li>
<li>计算置信度 confidence &#x3D; support(L) &#x2F; support(A)</li>
<li>若 confidence ≥ min_conf，则保留规则<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/13/001.jpg"
                      alt="photo"
                ></li>
</ul>
<h2 id="举例："><a href="#举例：" class="headerlink" title="举例："></a>举例：</h2><p>假设发现以下频繁项集：</p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>info</p>

    </div>
    <div class="notel-content">
      <p>{牛奶, 面包}，support &#x3D; 0.6<br>{牛奶}，support &#x3D; 0.8</p>

    </div>
  </div>

<p>则可以生成规则：</p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>info</p>

    </div>
    <div class="notel-content">
      <p>牛奶 → 面包，confidence &#x3D; 0.6 &#x2F; 0.8 &#x3D; 0.75</p>

    </div>
  </div>
<p>如果最小置信度设为 0.7，这条规则会被保留。</p>
<h2 id="典型应用"><a href="#典型应用" class="headerlink" title="典型应用"></a>典型应用</h2><p>超市推荐系统<br>电商商品搭配<br>网页点击路径分析<br>疾病共现分析</p>
<h1 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h1><h2 id="项（Item）"><a href="#项（Item）" class="headerlink" title="项（Item）"></a>项（Item）</h2><p>数据中的一个元素，比如：商品“牛奶”、“面包”。</p>
<h2 id="事务（Transaction）"><a href="#事务（Transaction）" class="headerlink" title="事务（Transaction）"></a>事务（Transaction）</h2><p>一组一起出现的项。例如：某一次购物记录是[牛奶, 面包, 鸡蛋]。</p>
<h2 id="项集（Itemset）"><a href="#项集（Itemset）" class="headerlink" title="项集（Itemset）"></a>项集（Itemset）</h2><p>一组项的组合。例如：{牛奶, 面包} 是一个 2-项集。</p>
<h1 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h1><h2 id="支持度（Support）"><a href="#支持度（Support）" class="headerlink" title="支持度（Support）"></a>支持度（Support）</h2><p>一个规则在数据集中出现的频率 表示某项集在整个数据中出现的频率。<br><code>\text&#123;Support&#125;(X) = \frac&#123;\text&#123;包含 X 的事务数&#125;&#125;&#123;\text&#123;总事务数&#125;&#125;</code></p>
<h2 id="置信度（Confidence）"><a href="#置信度（Confidence）" class="headerlink" title="置信度（Confidence）"></a>置信度（Confidence）</h2><p>规则的可靠性程度 表示在买了 X 的前提下买 Y 的概率。<br><code>\text&#123;Confidence&#125;(X \rightarrow Y) = \frac&#123;\text&#123;Support&#125;(X \cup Y)&#125;&#123;\text&#123;Support&#125;(X)&#125; </code></p>
<h2 id="提升度（Lift）"><a href="#提升度（Lift）" class="headerlink" title="提升度（Lift）"></a>提升度（Lift）</h2><p>衡量 X 和 Y 是否真正有关联<br><code>\text&#123;Lift&#125;(X \rightarrow Y) = \frac&#123;\text&#123;Confidence&#125;(X \rightarrow Y)&#125;&#123;\text&#123;Support&#125;(Y)&#125;</code></p>
<ul>
<li>若 Lift &gt; 1：X 和 Y 正相关</li>
<li>若 Lift &#x3D; 1：X 和 Y 独立</li>
<li>若 Lift &lt; 1：X 和 Y 负相关</li>
</ul>
<h1 id="Apriori算法实现–mlxtend"><a href="#Apriori算法实现–mlxtend" class="headerlink" title="Apriori算法实现–mlxtend"></a>Apriori算法实现–mlxtend</h1><p>必要的库</p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>info</p>

    </div>
    <div class="notel-content">
      <p>pip install mlxtend pandas</p>

    </div>
  </div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from mlxtend.preprocessing import TransactionEncoder</span><br><span class="line">from mlxtend.frequent_patterns import apriori, association_rules</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模拟购物篮数据</span></span><br><span class="line">dataset = [</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;面包&#x27;</span>, <span class="string">&#x27;鸡蛋&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;面包&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;面包&#x27;</span>, <span class="string">&#x27;鸡蛋&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;鸡蛋&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;面包&#x27;</span>, <span class="string">&#x27;鸡蛋&#x27;</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 编码转换：把列表数据转为布尔型 DataFrame</span></span><br><span class="line">te = TransactionEncoder()</span><br><span class="line">te_ary = te.fit(dataset).transform(dataset)</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(te_ary, columns=te.columns_)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2. 使用 Apriori 找出频繁项集（设置最小支持度为0.5）</span></span><br><span class="line">frequent_itemsets = apriori(<span class="built_in">df</span>, min_support=0.5, use_colnames=True)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3. 生成关联规则（设置最小置信度为0.6）</span></span><br><span class="line">rules = association_rules(frequent_itemsets, metric=<span class="string">&quot;confidence&quot;</span>, min_threshold=0.6)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 4. 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;【频繁项集】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(frequent_itemsets)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n【关联规则】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(rules[[<span class="string">&#x27;antecedents&#x27;</span>, <span class="string">&#x27;consequents&#x27;</span>, <span class="string">&#x27;support&#x27;</span>, <span class="string">&#x27;confidence&#x27;</span>, <span class="string">&#x27;lift&#x27;</span>]])</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>【频繁项集】<br>   support  itemsets<br>0      0.8      (牛奶)<br>1      0.8      (面包)<br>2      0.8      (鸡蛋)<br>3      0.6  (牛奶, 面包)<br>4      0.6  (鸡蛋, 牛奶)<br>5      0.6  (鸡蛋, 面包)</p>
<p>【关联规则】<br>  antecedents consequents  support  confidence    lift<br>0        (牛奶)        (面包)      0.6        0.75  0.9375<br>1        (面包)        (牛奶)      0.6        0.75  0.9375<br>2        (鸡蛋)        (牛奶)      0.6        0.75  0.9375<br>3        (牛奶)        (鸡蛋)      0.6        0.75  0.9375<br>4        (鸡蛋)        (面包)      0.6        0.75  0.9375<br>5        (面包)        (鸡蛋)      0.6        0.75  0.9375</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>科技</tag>
        <tag>算法原理</tag>
      </tags>
  </entry>
  <entry>
    <title>一周科技资讯第二期</title>
    <url>/zhihaojiang.github.io/2025/06/22/20250622%E4%B8%80%E5%91%A8%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF%E7%AC%AC%E4%BA%8C%E6%9C%9F/</url>
    <content><![CDATA[<h1 id="SpaceX-的下一艘星际飞船刚刚在德克萨斯州南部的试验台上爆炸"><a href="#SpaceX-的下一艘星际飞船刚刚在德克萨斯州南部的试验台上爆炸" class="headerlink" title="SpaceX 的下一艘星际飞船刚刚在德克萨斯州南部的试验台上爆炸"></a>SpaceX 的下一艘星际飞船刚刚在德克萨斯州南部的试验台上爆炸</h1><h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://arstechnica.com/space/2025/06/starships-rough-year-gets-worse-after-a-late-night-explosion-in-south-texas/" >https://arstechnica.com/space/2025/06/starships-rough-year-gets-worse-after-a-late-night-explosion-in-south-texas/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>周三晚间，SpaceX 的下一代星际飞船火箭在南德克萨斯州的地面测试中发生爆炸，这对近几个月来一直在努力克服三次连续失败的计划又一次造成了打击。</p>
<p>深夜，位于德克萨斯州星际基地的SpaceX火箭研发中心发生爆炸，摧毁了原定于下一次星际飞船试飞中发射的子弹形上面级火箭。强大的爆炸引发了SpaceX位于梅西试验场周围的火灾，该试验场距离该公司的星际飞船工厂和发射台仅几英里。</p>
<p>NASASpaceflight.com 和 LabPadre 媒体机构在 Starbase 周围部署的摄像机拍摄的现场直播视频显示，这枚 15 层楼高的火箭在当地时间晚上 11 点（美国东部时间凌晨 12 点；世界协调时凌晨 4 点）后不久爆炸起火。据报告，远至 30 英里外的当地居民都看到并感受到了爆炸。</p>
<p>SpaceX 证实，该公司库存中编号为 36 的星际飞船在测试台上“出现了重大异常”，当时该飞船正准备点燃其六台猛禽发动机进行静态点火测试。这些压紧式点火测试通常是星际飞船发射活动的最后里程碑之一，之后 SpaceX 将火箭移至发射台。</p>
<p>爆炸发生时，SpaceX正将超冷甲烷和液氧推进剂装入星际飞船，准备进行静态点火测试。该公司表示，测试场地周围的所有人员均已疏散，事故发生后，所有人员均安全无虞。布朗斯维尔消防局的消防员已被派往现场。</p>
<p>SpaceX 在 X 上发布消息称：“我们的 Starbase 团队正与当地官员合作，积极努力确保试验场及其周边地区的安全。周边社区的居民不会受到任何威胁，我们请求个人在安全作业继续进行期间不要试图接近该区域。”</p>
<p>SpaceX 创始人兼首席执行官埃隆·马斯克在 X 的另一篇文章中写道，初步数据显示，星际飞船有效载荷舱内的高压氮气罐发生故障。许多火箭都配备这样的氮气罐，即复合材料包裹的压力容器，内含用于吹扫和加压火箭内部不同舱室的高压气体。这些氮气罐（简称 COPV）可能非常不稳定。SpaceX 工程师将猎鹰 9 号火箭在 2015 年和 2016 年发生的仅有的两次灾难性故障归咎于与 COPV 相关的硬件。</p>
<p>马斯克写道，氮气COPV似乎在低于其耐压值的情况下失效，而这种情况本不该损坏储罐。“如果进一步调查证实确实发生了这种情况，那么这将是该设计首次出现这种情况，”马斯克补充道。</p>
<h2 id="收拾残局"><a href="#收拾残局" class="headerlink" title="收拾残局"></a>收拾残局</h2><p>周三早些时候，就在星际基地发生深夜爆炸的几个小时前，美国联邦航空管理局（FAA）发布的一份公告显示，SpaceX 已将 6 月 29 日定为下一次星际飞船试飞的暂定发射日期。目前还无法确定，SpaceX 何时才能准备好另一艘星际飞船进行试飞，目前还不得而知。</p>
<p>梅西试验场因曾经占据该地产的射击场而得名，位于格兰德河的一个河湾处，距离墨西哥边境仅几百英尺。该试验场目前是SpaceX在宣布火箭准备发射之前，唯一可以对星际飞船进行验证测试和静态点火测试的地方。</p>
<p>梅西试验场地面设备的损坏程度目前尚不清楚，因此现在判断该试验场将停用多久还为时过早。不过，目前爆炸导致SpaceX失去了支持星际飞船飞行前测试的设施。</p>
<p>梅西百货的爆炸事件，让人想起SpaceX在将星际飞船推进到如今这个阶段的坎坷历程。2020年和2021年，SpaceX在地面和飞行测试中因故障损失了数艘星际飞船原型。36号飞船起火的画面，让人想起了之前的爆炸，以及2016年猎鹰9号火箭在发射台上因类似周三晚间事件的情况而燃烧殆尽的惨剧。</p>
<p>自2023年4月以来，SpaceX已发射了9枚全尺寸的星际飞船（Starship）火箭。爆炸发生前，该公司原本计划于本月晚些时候进行第10次试飞。今年迄今为止，星际飞船的业绩惨淡，最近三次试飞均提前结束。然而，在2024年取得辉煌胜利之后，SpaceX在星际飞船的每次亚轨道试飞中都取得了显著进展，并最终在发射台塔架上首次用巨型机械臂成功接住了火箭的巨型超重型助推器。</p>
<p>超重型火箭助推级和星际飞船上面级叠放在一起，高度超过400英尺，是迄今为止建造的最大火箭。SpaceX已经成功发射过一枚可重复使用的超重型火箭助推器，该公司还设计了可回收和重复使用的星际飞船。</p>
<p>在去年取得成功之后，SpaceX 似乎有望在 2025 年实现一次完整的轨道飞行、尝试捕获并回收星际飞船本身，以及进行一次重要的太空加油演示。加油演示已正式推迟到 2026 年，SpaceX 能否在未来几个月取得足够的进展，以便在年底前尝试回收飞船，这一点仍值得怀疑。</p>
<h2 id="雄心与现实的碰撞"><a href="#雄心与现实的碰撞" class="headerlink" title="雄心与现实的碰撞"></a>雄心与现实的碰撞</h2><p>SpaceX 于今年 1 月试飞，首次展示了升级版的星际飞船设计，称为“版本 2”或“Block 2”。但自那以后，它却接连遭遇挫折。</p>
<p>新的星际飞船设计比SpaceX在2023年和2024年试飞的星际飞船略高。它配备了改进的隔热罩，以更好地抵御重返大气层时的极端高温。SpaceX还安装了新的燃料输送管线系统，将甲烷燃料输送到飞船的猛禽发动机，并安装了改进的推进航空电子模块，用于控制飞船的阀门和读取传感器。</p>
<p>尽管（或许正是因为）星际飞船二号（Starship Version 2）进行了所有这些改进，SpaceX 仍未能复制过去两年星际飞船的成功。今年 1 月和 3 月进行试飞的飞船在升空几分钟后就失控旋转，碎片散落在海面上，至少有一次还砸到了特克斯和凯科斯群岛的一辆汽车上。</p>
<p>SpaceX 工程师得出结论，1 月份的故障很可能是由剧烈震动引起的，这种震动引发了火箭发动机舱的燃料泄漏和起火，最终导致火箭发动机提前关闭。工程师们表示，这些震动很可能与火箭的固有频率产生共振，导致震动强度超出了 SpaceX 的预期。</p>
<p>三月份的飞行也出现了类似的故障，但 SpaceX 的调查人员确定，最可能的根本原因是飞船一台发动机出现硬件故障，与两个月前的故障模式不同。</p>
<p>在上个月SpaceX最新一次星际飞船试飞中，火箭按计划完成了任务的上升阶段，似乎克服了前两次发射中遇到的难题。然而，猛禽发动机关闭后不久，燃料泄漏导致飞船开始在太空中翻滚，导致其无法完成引导再入，从而无法测试新型隔热材料的性能。</p>
<p>SpaceX 正在研发第三代星际飞船（Starship）的设计，名为“星际飞船3号”（Version 3），该公司表示，该飞船可能在今年年底前完成试飞。升级后的“星际飞船3号”设计将能够将更重的货物（重达200公吨）送入轨道，这得益于更大的推进剂箱和更强大的猛禽发动机。“星际飞船3号”还将具备在近地轨道加油的能力。</p>
<p>版本 3 预计将永久性地解决目前拖慢 SpaceX 星际飞船研发进度的问题。SpaceX 的工程师们还有无数问题需要解决，从发动机可靠性和飞船的共振频率，到加强飞船的隔热罩，再到修复其不稳定的有效载荷舱门。</p>
<p>一旦官员们解决了这些问题，SpaceX就可以将星际飞船从近地轨道送回地面。之后，SpaceX还有更多酷炫的计划，比如轨道加油以及与NASA的阿尔忒弥斯计划合作执行月球任务。NASA与SpaceX签订了价值超过40亿美元的合同，用于开发一艘载人星际飞船，能够将宇航员送上月球并安全送回太空。</p>
<p>特朗普政府为NASA提出的预算方案将取消阿尔忒弥斯计划中极其昂贵的SLS火箭和猎户座载人舱，这些火箭将在完成两次飞行后继续执行，而商用重型运载火箭将接管宇航员从地球到月球的发射任务。SpaceX的星际飞船已经与NASA签订了载人着陆器合同，根据特朗普提出的预算方案，它最终可能会赢得更多政府合同，以取代SLS和猎户座火箭。其他火箭，例如蓝色起源的“新格伦”火箭，也有望在载人太空探索中发挥更大作用。</p>
<p>NASA官方计划将首批阿尔忒弥斯宇航员登陆月球的时间安排在2027年左右，届时将使用SLS火箭和猎户座火箭将宇航员运送到月球附近，与SpaceX的“星际飞船”月球着陆器汇合。在这次被称为“阿尔忒弥斯三号”的任务之后，NASA将转向使用埃隆·马斯克的SpaceX和杰夫·贝佐斯的蓝色起源的商用火箭来取代太空发射系统（SLS）。</p>
<p>与此同时，SpaceX的创始人兼首席执行官马斯克也把目光投向了火星。上个月，马斯克告诉员工，他计划在2026年底向这颗红色星球发射首批星际飞船，届时地球和火星在太阳系中的位置将使直接旅行成为可能。他乐观地​​表示，希望从2028年开始用星际飞船将人类送上火星。</p>
<p>所有这些任务都取决于 SpaceX 掌握星际飞船的常规发射操作、飞船和助推器的快速重复使用、在轨低温加油，以及适应星际旅行的生命支持、通信和深空导航等系统。</p>
<p>SpaceX 的星际飞船计划任务繁重，以至于在未来几年内实现火星登陆似乎不太可能。NASA 2027 年的阿尔忒弥斯三号登月任务计划也很紧凑，这不仅仅是因为星际飞船的延误。宇航员在月球上穿着的新型宇航服的研发也可能使阿尔忒弥斯三号的计划面临风险。NASA 的 SLS 火箭和猎户座飞船在其历史上都曾遭遇过重大延误，因此它们能否在 2027 年准备就绪尚不确定。</p>
<p>虽然现在还无法知道周三晚上爆炸的具体影响，但我们可以有信心地说，星际飞船今天完成这些大胆计划的可能性比昨天要低。</p>
<h1 id="可靠的量子计算就在这里”：微软科学家称，新的纠错方法可以将未来系统中的错误减少-1000-倍"><a href="#可靠的量子计算就在这里”：微软科学家称，新的纠错方法可以将未来系统中的错误减少-1000-倍" class="headerlink" title="可靠的量子计算就在这里”：微软科学家称，新的纠错方法可以将未来系统中的错误减少 1000 倍"></a>可靠的量子计算就在这里”：微软科学家称，新的纠错方法可以将未来系统中的错误减少 1000 倍</h1><h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://www.livescience.com/technology/computing/reliable-quantum-computing-is-here-new-approach-error-correction-reduce-errors-up-to-1000-times-microsoft-scientists-say" >https://www.livescience.com/technology/computing/reliable-quantum-computing-is-here-new-approach-error-correction-reduce-errors-up-to-1000-times-microsoft-scientists-say<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>微软科学家开发出一种 4D 几何编码方法，可将量子计算机中的错误减少 1,000 倍。</p>
<p>计算机科学家表示，借助新的“4D 代码”，他们已经破解了量子计算机纠错背后的科学原理。</p>
<p>这些新代码由微软开发，于 6 月 19 日发布的一篇博客文章中披露，旨在解决容错问题——这可以说是量子计算的最大瓶颈。</p>
<p>所有计算机都可能出错。在传统计算中，纠错是通过对发送的每一位信息进行多份复制来实现的。即使一个或多个位丢失或损坏，剩余的位仍然包含原始信息。</p>
<p>然而，量子比特无法复制。如果不经历所谓的“坍缩”，它们就无法被测量。这使得在错误发生时检测和缓解错误（错误发生的频率远高于传统比特）变得更加困难。</p>
<p>典型的量子纠错装置涉及在系统中添加额外的“物理”量子比特。这些量子比特与通常承载量子信息的“逻辑”量子比特纠缠在一起。科学家无需测量逻辑量子比特，从而避免发生这种坍缩，而是可以通过测量纠缠的物理量子比特来检查错误。这使得计算过程能够继续进行。</p>
<p>科学家通常在量子纠错过程中使用四维码，通过在四维晶格上重建量子处理表面的拓扑结构。这创造了一种自校正形式的量子记忆。</p>
<p>问题在于，目前大多数纠错技术要么难以扩展，要么资源密集，或者两者兼而有之。为量子系统提供容错能力所需的物理量子比特越多，需要的纠错次数越多，计算所需的能量就越大。</p>
<p>微软量子高级量子开发技术研究员 Krysta Svore 在博客文章中表示：“微软的新型四维几何代码每个逻辑量子位只需要很少的物理量子位，可以一次性检查错误，并将错误率降低 1,000 倍。 ”</p>
<h2 id="量子纠错的转折"><a href="#量子纠错的转折" class="headerlink" title="量子纠错的转折"></a>量子纠错的转折</h2><p>该研究结果于 6 月 18 日上传至arXiv预印本数据库，主要研究如何对某些量子计算系统中用于纠错的环面形 4D 几何代码进行字面扭曲。</p>
<p>科学家们开发了几何代码，可以叠加在系统中，利用四维拓扑结构检测错误。该四维代码通过纠缠将样本空间（运行校正代码的地方）与操作空间（量子比特包含信息的地方）连接起来。</p>
<p>它使用数学表达式在四维空间中工作，本质上允许纠缠点在“圆环”的表面上建立连接，可以想象成甜甜圈形状。</p>
<p>虽然 4D 代码在过去曾被用来创建自校正量子存储器，但它们在这里的使用被认为是新颖的，因为研究人员计算了几何中的“扭曲”，使得相同数量的代码能够使用更少的物理量子位纠缠覆盖相同数量的系统空间。</p>
<p>通过“扭曲”几何结构，4D代码叠加层创建了一个更大的表征空间，可以反映实际使用量子比特的更大一部分量子态。这样做可以让研究人员在不干扰系统内实际发生的量子过程的情况下检测代码中的错误。</p>
<p>研究人员在现有的量子计算机上运行了新的“扭曲”代码，并通过实验证实了他们的理论，并在另一篇预印本论文中进行了验证。该论文于6月13日发表在arXiv预印本服务器上。两篇论文均未经过同行评审。</p>
<p>科学家在研究中表示：“通用容错量子计算机可以使用 4D 几何代码来实现，这种代码旨在利用适量的物理量子比特有效地实现越来越多的逻辑量子比特，同时实现低深度逻辑循环和通用容错。”</p>
<p>此外，研究人员据称还展示了一项突破性的技术，用于在量子比特原子丢失时“替换”它们。在某些量子计算系统中，量子比特是通过用激光镊子捕获中性原子并将其捕获到位而产生的。在计算过程中，这些原子可能会丢失或掉落。</p>
<p>研究人员表示，他们可以使用原子束取代在循环中期丢失的原子，从而迫使新原子进入阵列，而不会中断计算——科学家在研究中表示，这是第一次。</p>
<p>根据这些发现，新的4D码系列可能代表着短短几周内量子纠错领域的第二次突破。6月10日，IBM也发表了类似的声明，宣布其已开发出量子纠错技术，这将推动到2029年开发出可证明实用的量子计算机。</p>
<p>IBM 的新方法采用自上而下的开发方法，充分利用其定制的硬件，而微软的方法则是自下而上地构建来解决容错问题，所采用的方法可能具有超出其测试的硬件和用例的其他应用程序。</p>
<h1 id="创纪录的-DDoS-攻击使网站遭受了曾经难以想象的-7-3Tbps-垃圾流量的重创、"><a href="#创纪录的-DDoS-攻击使网站遭受了曾经难以想象的-7-3Tbps-垃圾流量的重创、" class="headerlink" title="创纪录的 DDoS 攻击使网站遭受了曾经难以想象的 7.3Tbps 垃圾流量的重创、"></a>创纪录的 DDoS 攻击使网站遭受了曾经难以想象的 7.3Tbps 垃圾流量的重创、</h1><h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://arstechnica.com/security/2025/06/record-ddos-pummels-site-with-once-unimaginable-7-3tbps-of-junk-traffic/" >https://arstechnica.com/security/2025/06/record-ddos-pummels-site-with-once-unimaginable-7-3tbps-of-junk-traffic/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<blockquote>
<p>攻击者在短短 45 秒内就下载了相当于 9,300 部完整高清电影的数据。</p>
</blockquote>
<p>大规模攻击旨在通过向互联网服务发送超过其处理能力的流量来使其瘫痪，其规模越来越大，迄今为止最大的一次攻击流量达到每秒 7.3 太比特，这是互联网安全和性能提供商 Cloudflare 于周五报告的。</p>
<p>此次 7.3Tbps 的攻击总计 37.4TB 的垃圾流量，仅用 45 秒就击中目标。这几乎是一个难以想象的数据量，相当于在不到一分钟的时间内传输了超过 9,300 部完整高清电影或 7,500 小时的高清流媒体内容。</p>
<h2 id="不分皂白的目标轰炸"><a href="#不分皂白的目标轰炸" class="headerlink" title="不分皂白的目标轰炸"></a>不分皂白的目标轰炸</h2><p>Cloudflare表示，攻击者“地毯式轰炸”了目标 IP 地址平均近 22,000 个目标端口，而该 IP 地址仅被确认为 Cloudflare 客户。总计有 34,500 个端口成为攻击目标，这表明此次攻击的彻底性和精心策划的性质。</p>
<p>此次攻击的绝大部分内容是以用户数据报协议 (UDP) 数据包的形式进行的。合法的 UDP 传输通常用于对时间特别敏感的通信，例如视频播放、游戏应用程序和 DNS 查询。UDP 通过在数据传输前不正式建立连接来加快通信速度。与更常见的传输控制协议 (TCP) 不同，UDP 不会等待两台计算机通过握手建立连接，也不会检查对方是否正确接收了数据。相反，它会立即将数据从一台计算机发送到另一台计算机。</p>
<p>UDP 洪水攻击会向目标 IP 上的随机或特定端口发送大量数据包。此类洪水攻击可能会导致目标的互联网链路饱和，或使内部资源因数据包数量超过其处理能力而不堪重负。</p>
<p>由于 UDP 无需握手，攻击者可以利用它向目标服务器发送大量流量，而无需事先获得服务器的传输许可。UDP 泛洪攻击通常会向目标系统的多个端口发送大量数据报。目标系统则必须发送相同数量的数据包，以表明端口无法访问。最终，目标系统不堪重负，导致合法流量被拒绝。</p>
<p>一小部分攻击（占比仅为 0.004%）是通过反射攻击发起的。反射攻击会将恶意流量导向一个或多个第三方中介，例如用于同步服务器时钟的网络时间协议 (NTP) 服务。攻击者会伪造恶意数据包的发送方 IP，使其看起来像是由最终目标发送的。当第三方发送响应时，响应会被发送到目标，而不是原始流量来源的目的地。</p>
<p>反射攻击为攻击者提供了多重好处。首先，此类攻击使得 DDoS 攻击从各种各样的目的地发起。这使得目标更难抵御攻击。此外，通过选择已知会生成比原始请求大数千倍的响应的中间服务器，攻击者可以将可用的攻击火力放大千倍甚至更多。Cloudflare 和其他公司经常建议服务器管理员锁定服务器，以防止它们响应欺骗数据包，但不可避免的是，许多人并没有听从这些建议。</p>
<p>Cloudflare 表示，创纪录的 DDoS 攻击利用了各种反射或放大向量，包括前面提到的网络时间协议、每日报价协议（它在 UDP 端口 17 上监听并以简短的报价或消息进行响应）、Echo 协议（它使用接收到的相同数据进行响应）以及用于识别通过远程过程调用连接的应用程序可用资源的 Portmapper 服务。</p>
<p>Cloudflare 表示，此次攻击还通过一个或多个基于 Mirai 的僵尸网络发起。此类僵尸网络通常由家庭和小型办公室路由器、网络摄像头以及其他已遭入侵的物联网设备组成。</p>
<p>过去三十年来，DDoS 规模持续稳步攀升。今年3 月，诺基亚报告称，一个名为 Eleven11bot 的僵尸网络发起了一次峰值流量达 6.5Tbps 的 DDoS 攻击。5 月，KrebsonSecurity表示其遭受了一次峰值流量达 6.3Tbps 的 DDoS 攻击。</p>
<h1 id="苹果公司高管称其计划利用人工智能设计芯片"><a href="#苹果公司高管称其计划利用人工智能设计芯片" class="headerlink" title="苹果公司高管称其计划利用人工智能设计芯片"></a>苹果公司高管称其计划利用人工智能设计芯片</h1><h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://www.ctvnews.ca/business/article/apple-eyes-using-ai-to-design-its-chips-technology-executive-says/" >https://www.ctvnews.ca/business/article/apple-eyes-using-ai-to-design-its-chips-technology-executive-says/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>旧金山——苹果公司高级硬件技术主管上个月在私下表示，苹果有意利用生成人工智能来帮助加快其设备核心定制芯片的设计。</p>
<p>苹果硬件技术高级副总裁约翰尼·斯鲁吉 (Johny Srouji) 在比利时发表演讲时发表了上述言论，当时他正在接受 Imec 颁发的奖项。Imec 是一家独立的半导体研发集团，与全球大多数最大的芯片制造商都有密切的合作。</p>
<p>路透社查阅了此次演讲的录音，斯鲁吉在演讲中概述了苹果定制芯片的开发情况，从 2010 年 iPhone 中的第一款 A4 芯片到最新为 Mac 台式电脑和 Vision Pro 耳机供电的芯片。</p>
<p>他说，苹果学到的一个重要教训是，需要使用最先进的工具来设计芯片，包括电子设计自动化 (EDA) 公司的最新芯片设计软件。</p>
<p>该行业的两大参与者 Cadence Design Systems 和 Synopsys 一直在竞相将人工智能添加到其产品中。</p>
<p>Srouji 在发言中表示：“EDA 公司对于我们芯片设计的复杂性至关重要。生成式 AI 技术具有在更短时间内完成更多设计工作的巨大潜力，可以大幅提高生产力。”</p>
<p>斯鲁吉表示，苹果在设计自己的芯片时学到的另一个重要教训是大胆尝试，不要回头。</p>
<p>2020 年，当苹果公司将其历史最悠久的活跃产品线 Mac 电脑从英特尔芯片转换为自家芯片时，并没有制定任何应急计划，以防转换失败。</p>
<p>“将 Mac 迁移到 Apple Silicon 平台对我们来说是一次巨大的赌注。我们没有备用方案，也没有拆分产品线的计划，所以我们全力以赴，包括投入了巨大的软件开发精力，”斯鲁吉说道。</p>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>科技前沿</tag>
        <tag>新闻</tag>
      </tags>
  </entry>
  <entry>
    <title>关于1999C煤矸石堆积的研读报告</title>
    <url>/zhihaojiang.github.io/2025/07/01/20250701%E5%85%B3%E4%BA%8E1999C%E7%85%A4%E7%9F%B8%E7%9F%B3%E5%A0%86%E7%A7%AF%E7%9A%84%E7%A0%94%E8%AF%BB%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<h1 id="题目背景"><a href="#题目背景" class="headerlink" title="题目背景"></a>题目背景</h1><p>此竞赛题目解决的是煤矸石堆积的问题 在面对矸石山不断堆积的情况下 需要制定合理的年度征地计划和给出在不同出矸率的情况下处理矸石的最低费用</p>
<h1 id="模型假设"><a href="#模型假设" class="headerlink" title="模型假设"></a>模型假设</h1><p>为了简化问题 此文章做了如下假设<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/01/001.png"
                      alt="photo"
                ></p>
<p>我认为这些假设是比较合理的 通过查询相关资料 其假设的数据符合实际生活中的数据</p>
<h1 id="建模准备"><a href="#建模准备" class="headerlink" title="建模准备"></a>建模准备</h1><p>在建模前他们首先给出了轨道长度与体积的关系、矸石山占地面积与体积的关系、占地面积与安息角的关系 在阅读的时候 我一开始不理解为什么要列出这些公式 在后续的阅读中我了解到了 轨道长度决定了运矸车运输的距离 从而影响能耗 成本 矸石堆积体积越大 轨道需要延伸得越长 建立轨道长度与体积的关系是为了后续计算运输成本 能量消耗等提供基础 占地面积决定率征地需求</p>
<p>征地费用是主要经济支出之一 因此需要知道给定体积下 占地多少土地 安息角决定了矸石自然堆积的最大坡度 坡度不同 相同体积下的占地面积就不同<br>我使用python对轨道长度与体积的关系、矸石山占地面积与体积的关系、占地面积与安息角的关系进行了复现 在假设体积为1000 安息角为35 轨道倾角为5时 得到轨道长度为61.3176 占地面积为35853292.5453 占地面积与安息角的关系如图所示：<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/01/002.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">V = 1000  <span class="comment"># 矸石山体积</span></span><br><span class="line">beta_deg = 1  <span class="comment"># 轨道倾角（度）</span></span><br><span class="line">alpha_deg_range = np.linspace(1, 55, 500)  <span class="comment"># 安息角范围</span></span><br><span class="line"></span><br><span class="line">beta = np.deg2rad(beta_deg)</span><br><span class="line">alpha_rad = np.deg2rad(alpha_deg_range)</span><br><span class="line"></span><br><span class="line">def compute_a(alpha, beta):</span><br><span class="line">    tan_alpha_sq = np.tan(alpha)**2</span><br><span class="line">    tan_beta_sq = np.tan(beta)**2</span><br><span class="line">    <span class="built_in">return</span> tan_beta_sq / (tan_alpha_sq - tan_beta_sq)</span><br><span class="line"></span><br><span class="line">def compute_a1(a):</span><br><span class="line">    sqrt_a = np.sqrt(a)</span><br><span class="line">    <span class="built_in">return</span> 1 + (np.pi / 2 + np.arctan(sqrt_a)) * sqrt_a</span><br><span class="line"></span><br><span class="line">def compute_S(V, alpha, beta):</span><br><span class="line">    a = compute_a(alpha, beta)</span><br><span class="line">    a1 = compute_a1(a)</span><br><span class="line">    numerator = 9 * a1 * V**2</span><br><span class="line">    denominator = np.sqrt(a) * np.tan(alpha)**2</span><br><span class="line">    S = (numerator / denominator)**(1/3)</span><br><span class="line">    <span class="built_in">return</span> S</span><br><span class="line"></span><br><span class="line">S_values = compute_S(V, alpha_rad, beta)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(10, 6))</span><br><span class="line">plt.plot(alpha_deg_range, S_values, label=r<span class="string">&#x27;$S(\alpha)$&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.xlabel(r<span class="string">&#x27;$\alpha$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;S&#x27;</span>)</span><br><span class="line">plt.title(r<span class="string">&#x27;S VS $\alpha$&#x27;</span>)</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p>这与论文中的图标几乎一致 论文中的\alpha范围应该进行了归一化处理 我这里没有进行处理 有些许不同 但无关紧要</p>
<h1 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h1><p>为了制定合理的年度征地计划 该论文建立了土地需求量公式 地价公式 电费公式 每年计划征地经费公式 征地规划模型<br>这些模型不是孤立存在的 而是环环相扣的 其最终目标优化土地使用 控制成本 合理安排资金流</p>
<h2 id="土地需求量公式"><a href="#土地需求量公式" class="headerlink" title="土地需求量公式"></a>土地需求量公式</h2><p>在论文中 通过几何分析与经验拟合 得到矸石山占地面积：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">S_i\ =\ 0.0015\left(\frac&#123;9a_ii^2V_0^2&#125;&#123;\sqrt a&#123;tan&#125;^2\alpha&#125;\right)^\frac&#123;1&#125;&#123;3&#125;</span><br></pre></td></tr></table></figure></div>
<p>此公式中参数a和a1来源于对堆积体形状的几何分析<br>a受\alpha，β的影响 反映了轨道倾角\beta与安息角\alpha对堆积形态的影响 a1可以看成一个修正因子 用于描述此煤矸石底面积变化趋势 0.0015是一个系数 由于体积的单位是立方米 而占地面积要转换成亩 因此乘以0.0015用于系数转换<br>∆Si &#x3D; Si - Si-1<br>这是一个显而易见的公式 表明了增加的变化量<br>因此土地需求量公式为<br>Si‘ &#x3D; 1+b∆Si<br>通过python复现当\beta&#x3D;25°时S1‘为10.663024317273257这与论文中的数值是一样的<br>不过我认为论文中的\beta&#x3D;25°不妥当此数值设置得并不合理 可能要讨论不同仰角的变化 不过在后续的灵敏度分析中讨论了不同轨道仰角的效率和经费剩余</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def compute_a(alpha_deg, beta_deg):</span><br><span class="line">    alpha = np.deg2rad(alpha_deg)</span><br><span class="line">    beta = np.deg2rad(beta_deg)</span><br><span class="line">    tan_alpha_sq = np.tan(alpha)**2</span><br><span class="line">    tan_beta_sq = np.tan(beta)**2</span><br><span class="line">    a = tan_beta_sq / (tan_alpha_sq - tan_beta_sq)</span><br><span class="line">    <span class="built_in">return</span> a</span><br><span class="line"></span><br><span class="line">def compute_a1(a):</span><br><span class="line">    sqrt_a = np.sqrt(a)</span><br><span class="line">    a1 = 1 + (np.pi / 2 + np.arctan(sqrt_a)) * sqrt_a</span><br><span class="line">    <span class="built_in">return</span> a1</span><br><span class="line"></span><br><span class="line">def compute_G0(d, e):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    求g0:每年产生的煤矸石质量</span></span><br><span class="line"><span class="string">    d:原煤年产量</span></span><br><span class="line"><span class="string">    e:出矸率</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    g0 = (10000 * d * e) / (1 - e)</span><br><span class="line">    <span class="built_in">return</span> g0</span><br><span class="line"></span><br><span class="line">def compute_V0(g0, rho):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    求v0:每年产生的煤矸石体积</span></span><br><span class="line"><span class="string">    g0:每年产生的煤矸石质量</span></span><br><span class="line"><span class="string">    rho:煤矸石容量</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    v0 = g0 / rho</span><br><span class="line">    <span class="built_in">return</span> v0</span><br><span class="line">def compute_Vi(i, v0):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    求vi:第i年产生的煤矸石体积</span></span><br><span class="line"><span class="string">    i:第i年</span></span><br><span class="line"><span class="string">    v0:每年产生的煤矸石体积</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    vi = i * v0</span><br><span class="line">    <span class="built_in">return</span> vi</span><br><span class="line">def compute_Si(i, v0, alpha, beta):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    求Si:第i年煤矸石占地面积</span></span><br><span class="line"><span class="string">    i:第i年</span></span><br><span class="line"><span class="string">    v0:每年产生的煤矸石体积</span></span><br><span class="line"><span class="string">    alpha:安息角</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    a:计算参数a 根据compute_a可以计算得到</span></span><br><span class="line"><span class="string">    a1:计算参数a1 根据compute_a1可以计算得到</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    a = compute_a(alpha, beta)</span><br><span class="line">    a1 = compute_a1(a)</span><br><span class="line">    tan_alpha = np.tan(np.deg2rad(alpha))</span><br><span class="line">    si = 0.0015 * ((<span class="number">9</span> * a1 * i**<span class="number">2</span> * v0**<span class="number">2</span>) / (np.sqrt(a) * tan_alpha**<span class="number">2</span>)) ** (1/3)</span><br><span class="line">    <span class="built_in">return</span> si</span><br><span class="line"></span><br><span class="line">def compute_delta_Si(i, v0, alpha, beta):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    求第i年末煤矸石占地面积的增量</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> i == 0:</span><br><span class="line">        <span class="built_in">return</span> 0</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">return</span> compute_Si(i, v0, alpha, beta) - compute_Si(i - 1, v0, alpha, beta)</span><br><span class="line"></span><br><span class="line">def compute_S_dot_i(i, v0, alpha, beta, b):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    求第i年土地需求量</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    delta_Si = compute_delta_Si(i, v0, alpha, beta)</span><br><span class="line">    s_dot_i = (1 + b) * delta_Si</span><br><span class="line">    <span class="built_in">return</span> s_dot_i</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">beta = 25 <span class="comment"># 轨道倾角</span></span><br><span class="line">d = 300 <span class="comment"># 原煤年产量</span></span><br><span class="line">e = 0.07 <span class="comment"># 出矸率</span></span><br><span class="line">rho = 2 <span class="comment"># 煤矸石容量</span></span><br><span class="line">alpha = 55 <span class="comment"># 安息角</span></span><br><span class="line">i = 1 <span class="comment"># 第 i 年</span></span><br><span class="line">b = 0.1# 土地预留系数</span><br><span class="line">g0 = compute_G0(d, e)</span><br><span class="line">v0 = compute_V0(g0, rho)</span><br><span class="line"></span><br><span class="line">result = compute_S_dot_i(i, v0, alpha, beta, b)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line">def compute_C1i(i):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    求第i年的地价</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    c0 = 8 <span class="comment">#手动输入 根据假设6给定</span></span><br><span class="line">    lam = 0.1 <span class="comment">#手动输入 根据假设6给定</span></span><br><span class="line">    c1i = c0 * (1 + lam) ** (i - 1)</span><br><span class="line">    <span class="built_in">return</span> c1i</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">i = 1  <span class="comment"># 第 i 年</span></span><br><span class="line">c1i = compute_C1i(i)</span><br><span class="line"><span class="built_in">print</span>(c1i)</span><br></pre></td></tr></table></figure></div>
<h2 id="征地规划模型"><a href="#征地规划模型" class="headerlink" title="征地规划模型"></a>征地规划模型</h2><p>通过复现征地规划模型 我们得到了其结果 这个结果与论文中的一致 值得注意的是 在年数少于20时 其前几年得到的结果与论文中的不一致 经过排查得到在不同年数时资金时间价值累积效应 贷款安排策略 囤地策略会受到影响 本论文并未讨论不同年数对征地规划的影响 我认为此讨论是有必要的 为了增强论文的鲁棒性以及案例的迁移性 应该增加不同年份的征地策略 经过我的验证 当n&#x3D;5时 只有前两年会选择贷款 并且每年的累计余额也不同 随着年数的增加 贷款会越来越激进 说明征地的短期与长期规划是截然不同的 在前期时利润是偏低的 但到了后期利润是巨大的<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/01/003.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pulp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">n = 20</span><br><span class="line">R1 = 0.05  <span class="comment"># 自有资金利率</span></span><br><span class="line">R2 = 0.05  <span class="comment"># 贷款利率</span></span><br><span class="line">c1 = [8, 8.8, 9.68, 10.648, 11.7128,</span><br><span class="line">      12.88, 14.17, 15,59, 17,15, 18.86,</span><br><span class="line">      20.75, 22.82, 25.11, 27.62, 30.38,</span><br><span class="line">      33.42, 36.76, 40.44, 44.48, 48.93]           <span class="comment"># 每年土地价格（万元/亩）</span></span><br><span class="line"></span><br><span class="line">f1 = [97.11, 92.33, 90.31, 88.68, 87.26,</span><br><span class="line">      85.97, 84.78, 83.67, 82.61, 81.6,</span><br><span class="line">      80.62, 79.69, 78.78, 77.89, 77.03,</span><br><span class="line">      76.19, 75.37, 74.56, 73.77, 72.99]        <span class="comment"># 每年收入（万元）</span></span><br><span class="line"></span><br><span class="line">S_given = [10.66, 6.26, 5.25, 4.69, 4.31,</span><br><span class="line">           4.03, 3.81, 3.63, 3.48, 3.36,</span><br><span class="line">           3.25, 3.15, 3.06, 2.99, 2.92,</span><br><span class="line">           2.85, 2.79, 2.74, 2.69, 2.64]       <span class="comment"># 每年实际围地面积</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型</span></span><br><span class="line">model = pulp.LpProblem(<span class="string">&quot;1999C_Coal_Gangue_Model&quot;</span>, pulp.LpMaximize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策变量</span></span><br><span class="line">g = pulp.LpVariable.dicts(<span class="string">&quot;g&quot;</span>, range(n + 1), lowBound=0)         <span class="comment"># 实际支出</span></span><br><span class="line">u = pulp.LpVariable.dicts(<span class="string">&quot;u&quot;</span>, range(n + 1), lowBound=0)         <span class="comment"># 贷款金额</span></span><br><span class="line">w = pulp.LpVariable.dicts(<span class="string">&quot;w&quot;</span>, range(n + 1), lowBound=0)         <span class="comment"># 征地费用</span></span><br><span class="line">S_star = pulp.LpVariable.dicts(<span class="string">&quot;S_star&quot;</span>, range(n + 1), lowBound=0)  <span class="comment"># 累计囤地</span></span><br><span class="line">p = pulp.LpVariable.dicts(<span class="string">&quot;p&quot;</span>, range(n + 1), lowBound=0)         <span class="comment"># 经费余额</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始约束</span></span><br><span class="line">model += p[0] == 0, <span class="string">&quot;初始经费&quot;</span></span><br><span class="line">model += S_star[0] == 0, <span class="string">&quot;初始囤地&quot;</span></span><br><span class="line">model += u[0] == 0, <span class="string">&quot;初始贷款&quot;</span></span><br><span class="line">model += u[n] == 0, <span class="string">&quot;最后一年不贷款&quot;</span></span><br><span class="line">model += S_star[n] == 0, <span class="string">&quot;最终囤地为0&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 目标函数</span></span><br><span class="line">model += p[n], <span class="string">&quot;最终经费最大&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 逐年约束</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(1, n + 1):</span><br><span class="line">    <span class="comment"># 征地费用计算</span></span><br><span class="line">    model += w[i] == g[i] - u[i - 1] * (1 + R2) + u[i], f<span class="string">&quot;征地费用_&#123;i&#125;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 囤地数量递推</span></span><br><span class="line">    model += S_star[i] == S_star[i - 1] + w[i] * (1.0 / c1[i - 1]) - S_given[i - 1], f<span class="string">&quot;囤地数量递推_&#123;i&#125;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 经费余额</span></span><br><span class="line">    model += p[i] == (p[i - 1] + f1[i - 1] - g[i]) * (1 + R1), f<span class="string">&quot;经费累计余额_&#123;i&#125;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 支出限制</span></span><br><span class="line">    model += g[i] &lt;= p[i - 1] + f1[i - 1], f<span class="string">&quot;支出限制_&#123;i&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不能超额围地</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(1, n):</span><br><span class="line">    model += S_star[i] &lt;= <span class="built_in">sum</span>(S_given[k] <span class="keyword">for</span> k <span class="keyword">in</span> range(i, n)), f<span class="string">&quot;围地策略_&#123;i&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 求解</span></span><br><span class="line">model.solve(pulp.PULP_CBC_CMD(msg=0))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> pulp.LpStatus[model.status] != <span class="string">&#x27;Optimal&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;求解失败，状态：&quot;</span>, pulp.LpStatus[model.status])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;求解成功，目标函数值（第20年末经费余额）:&quot;</span>, round(p[n].varValue, 2), <span class="string">&quot;万元&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(1, n + 1):</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;\n第&#123;i&#125;年：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;  支出 g_&#123;i&#125; = &#123;g[i].varValue:.2f&#125;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;  贷款 u_&#123;i&#125; = &#123;u[i].varValue:.2f&#125;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;  囤地 S*_i = &#123;S_star[i].varValue:.2f&#125;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;  征地费用 w_&#123;i&#125; = &#123;w[i].varValue:.2f&#125;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;  经费余额 p_&#123;i&#125; = &#123;p[i].varValue:.2f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<h1 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h1><p>我们同样复现了此模型 得到：	<br>Optimal - objective value -35.832721<br>这个结果与论文中的一致 同样 我们发现 在不同的年数其最优解存在不同因此 我认为该论文添加上对不同年份的经费讨论</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pulp</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">d = 3000000      <span class="comment"># 原煤年产量（吨）</span></span><br><span class="line">rho = 2          <span class="comment"># 煤矸石容量（吨/立方米）</span></span><br><span class="line">alpha = 55       <span class="comment"># 安息角（度）</span></span><br><span class="line">beta = 25        <span class="comment"># 轨道倾角（度）</span></span><br><span class="line">n = 20           <span class="comment"># 规划年限</span></span><br><span class="line">R1 = 0.05        <span class="comment"># 经费累计余额利率</span></span><br><span class="line">R2 = 0.05        <span class="comment"># 贷款利率</span></span><br><span class="line"></span><br><span class="line">c1 = [8, 8.8, 9.68, 10.648, 11.7128,</span><br><span class="line">      12.88, 14.17, 15,59, 17,15, 18.86,</span><br><span class="line">      20.75, 22.82, 25.11, 27.62, 30.38,</span><br><span class="line">      33.42, 36.76, 40.44, 44.48, 48.93]         <span class="comment"># 每年土地价格（万元/亩）</span></span><br><span class="line"></span><br><span class="line">f1 = [97.11, 92.33, 90.31, 88.68, 87.26,</span><br><span class="line">      85.97, 84.78, 83.67, 82.61, 81.6,</span><br><span class="line">      80.62, 79.69, 78.78, 77.89, 77.03,</span><br><span class="line">      76.19, 75.37, 74.56, 73.77, 72.99]        <span class="comment"># 每年收入（万元）</span></span><br><span class="line"></span><br><span class="line">S_prime = [10.66, 6.26, 5.25, 4.69, 4.31,</span><br><span class="line">           4.03, 3.81, 3.63, 3.48, 3.36,</span><br><span class="line">           3.25, 3.15, 3.06, 2.99, 2.92,</span><br><span class="line">           2.85, 2.79, 2.74, 2.69, 2.64]       <span class="comment"># 每年实际围地面积</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 a 和 a1</span></span><br><span class="line">def compute_a(alpha_deg, beta_deg):</span><br><span class="line">    alpha = np.deg2rad(alpha_deg)</span><br><span class="line">    beta = np.deg2rad(beta_deg)</span><br><span class="line">    tan_alpha_sq = np.tan(alpha)**2</span><br><span class="line">    tan_beta_sq = np.tan(beta)**2</span><br><span class="line">    a = tan_beta_sq / (tan_alpha_sq - tan_beta_sq)</span><br><span class="line">    <span class="built_in">return</span> a</span><br><span class="line"></span><br><span class="line">def compute_a1(a):</span><br><span class="line">    sqrt_a = np.sqrt(a)</span><br><span class="line">    a1 = 1 + (np.pi / 2 + np.arctan(sqrt_a)) * sqrt_a</span><br><span class="line">    <span class="built_in">return</span> a1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算第 i 年的占地面积 Si</span></span><br><span class="line">def compute_Si(i, v0, alpha):</span><br><span class="line">    a = compute_a(alpha, beta)</span><br><span class="line">    a1 = compute_a1(a)</span><br><span class="line">    si = 0.0015 * ((<span class="number">9</span> * a1 * i**<span class="number">2</span> * v0**<span class="number">2</span>) / (np.sqrt(a) * np.tan(np.deg2rad(alpha))**2)) ** (1/3)</span><br><span class="line">    <span class="built_in">return</span> si</span><br><span class="line"></span><br><span class="line">def solve_model(v0, e):</span><br><span class="line">    <span class="comment"># 计算第一年占地 S1</span></span><br><span class="line">    S1 = compute_Si(1, v0, alpha)</span><br><span class="line"></span><br><span class="line">    model = pulp.LpProblem(<span class="string">&quot;Minimum_Delta_q&quot;</span>, pulp.LpMinimize)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 决策变量</span></span><br><span class="line">    delta_q = pulp.LpVariable(<span class="string">&quot;delta_q&quot;</span>, lowBound=None, upBound=None)</span><br><span class="line">    g_vars = pulp.LpVariable.dicts(<span class="string">&quot;g&quot;</span>, range(1, n+1), lowBound=0)</span><br><span class="line">    u_vars = pulp.LpVariable.dicts(<span class="string">&quot;u&quot;</span>, range(n+1), lowBound=0)</span><br><span class="line">    S_star = pulp.LpVariable.dicts(<span class="string">&quot;S_star&quot;</span>, range(n+1), lowBound=0)</span><br><span class="line">    p_vars = pulp.LpVariable.dicts(<span class="string">&quot;p&quot;</span>, range(n+1), lowBound=0)</span><br><span class="line">    w_vars = pulp.LpVariable.dicts(<span class="string">&quot;w&quot;</span>, range(1, n+1), lowBound=0)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 目标 最小化经费增量</span></span><br><span class="line">    model += delta_q, <span class="string">&quot;Minimize_Delta_q&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 约束条件</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(1, n+1):</span><br><span class="line">        <span class="comment"># 经费余额公式</span></span><br><span class="line">        model += p_vars[i] == (p_vars[i-1] + f1[i-1] - g_vars[i] + delta_q) * (1 + R1)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 支出额限制</span></span><br><span class="line">        model += g_vars[i] &lt;= p_vars[i-1] + f1[i-1] + delta_q</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 征地费用公式</span></span><br><span class="line">        model += w_vars[i] == g_vars[i] - u_vars[i-1] * (1 + R2) + u_vars[i]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 围地数量递推关系</span></span><br><span class="line">        inv_c1 = 1.0 / c1[i-1]</span><br><span class="line">        model += S_star[i-1] + w_vars[i] * inv_c1 - S_prime[i-1] == S_star[i]</span><br><span class="line"></span><br><span class="line">        model += S_star[i] &gt;= 0, f<span class="string">&quot;Non-negative_S_star_&#123;i&#125;&quot;</span></span><br><span class="line">        model += g_vars[i] &gt;= 0, f<span class="string">&quot;Non-negative_g_&#123;i&#125;&quot;</span></span><br><span class="line">        model += u_vars[i] &gt;= 0, f<span class="string">&quot;Non-negative_u_&#123;i&#125;&quot;</span></span><br><span class="line">        model += w_vars[i] &gt;= 0, f<span class="string">&quot;Non-negative_w_&#123;i&#125;&quot;</span></span><br><span class="line">        model += p_vars[i] &gt;= 0, f<span class="string">&quot;Non-negative_p_&#123;i&#125;&quot;</span></span><br><span class="line"></span><br><span class="line">    model += p_vars[0] == 0</span><br><span class="line">    model += p_vars[n] == 0 </span><br><span class="line">    model += S_star[0] == 0</span><br><span class="line">    model += S_star[n] == 0</span><br><span class="line">    model += u_vars[0] == 0</span><br><span class="line">    model += u_vars[n] == 0</span><br><span class="line"></span><br><span class="line">    model.solve()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> delta_q.varValue, S1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历不同出矸率</span></span><br><span class="line">e_values = np.arange(0.07, 0.11, 0.01)  <span class="comment"># 出矸率从 5% 到 15%</span></span><br><span class="line">results = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> e_values:</span><br><span class="line">    g0 = (d * e) / (1 - e)</span><br><span class="line">    v0 = g0 / rho</span><br><span class="line"></span><br><span class="line">    delta_q_opt, S1 = solve_model(v0, e)</span><br><span class="line"></span><br><span class="line">    results.append(&#123;</span><br><span class="line">        <span class="string">&#x27;e&#x27;</span>: round(e, 2),</span><br><span class="line">        <span class="string">&#x27;v0&#x27;</span>: round(v0, 2),</span><br><span class="line">        <span class="string">&#x27;S1&#x27;</span>: round(S1, 2),</span><br><span class="line">        <span class="string">&#x27;delta_q&#x27;</span>: round(delta_q_opt, 2)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;:&lt;6&#125; &#123;:&lt;12&#125; &#123;:&lt;10&#125; &#123;:&lt;12&#125;&quot;</span>.format(<span class="string">&quot;e (%)&quot;</span>, <span class="string">&quot;v0 (m³)&quot;</span>, <span class="string">&quot;S1 (亩)&quot;</span>, <span class="string">&quot;Δq (万元)&quot;</span>))</span><br><span class="line"><span class="keyword">for</span> res <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;&#123;res[&#x27;e&#x27;]*100:.0f&#125;%\t&#123;res[&#x27;v0&#x27;]&#125;\t\t&#123;res[&#x27;S1&#x27;]&#125;\t\t&#123;res[&#x27;delta_q&#x27;]&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<h1 id="灵敏度稳健性分析"><a href="#灵敏度稳健性分析" class="headerlink" title="灵敏度稳健性分析"></a>灵敏度稳健性分析</h1><p>该论文讨论了地价涨幅 矸石容量 机械效率 电费增长 贷款利率变化 对经费的变化 通过调整相应的参数 发现地价涨幅 矸石容量 机械效率 电费增长对结果影响不大 这与论文结果一致 然而该论文并未讨论安息角与轨道仰角的灵敏度分析 并且论文中的安息角均取55°通过查询得知55°为最大安息角 论文中均取的最大安息角会导致模型高估了堆料稳定性 低估了实际占地面积 这会使模型不具推广性 仅适用于特定场景 模型得到的经费剩余偏低 我认为安息角的设置应该用保守的估计策略 例如40°左右 我们需要考虑到实际操作时产生的误差<br>我们通过分析安息角对经费和占地面积的影响得到了如下图表<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/01/005.png"
                      alt="photo"
                ></p>
<p>分析发现这个增长率蛮大的 因此 我认为在进行灵敏度分析的时候应该加上安息角的灵敏度分析 </p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def run_model(c1, f1, S_given, R1=0.05, R2=0.05, n=5):</span><br><span class="line">    model = pulp.LpProblem(<span class="string">&quot;1999C_Coal_Gangue_Model&quot;</span>, pulp.LpMaximize)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 决策变量</span></span><br><span class="line">    g = pulp.LpVariable.dicts(<span class="string">&quot;g&quot;</span>, range(n + 1), lowBound=0)</span><br><span class="line">    u = pulp.LpVariable.dicts(<span class="string">&quot;u&quot;</span>, range(n + 1), lowBound=0)</span><br><span class="line">    w = pulp.LpVariable.dicts(<span class="string">&quot;w&quot;</span>, range(n + 1), lowBound=0)</span><br><span class="line">    S_star = pulp.LpVariable.dicts(<span class="string">&quot;S_star&quot;</span>, range(n + 1), lowBound=0)</span><br><span class="line">    p = pulp.LpVariable.dicts(<span class="string">&quot;p&quot;</span>, range(n + 1), lowBound=0)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始约束</span></span><br><span class="line">    model += p[0] == 0</span><br><span class="line">    model += S_star[0] == 0</span><br><span class="line">    model += u[0] == 0</span><br><span class="line">    model += u[n] == 0</span><br><span class="line">    model += S_star[n] == 0</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 目标函数</span></span><br><span class="line">    model += p[n]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 约束条件</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(1, n + 1):</span><br><span class="line">        model += w[i] == g[i] - u[i - 1] * (1 + R2) + u[i]</span><br><span class="line">        model += S_star[i] == S_star[i - 1] + w[i] * (1.0 / c1[i - 1]) - S_given[i - 1]</span><br><span class="line">        model += p[i] == (p[i - 1] + f1[i - 1] - g[i]) * (1 + R1)</span><br><span class="line">        model += g[i] &lt;= p[i - 1] + f1[i - 1]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i &lt; n:</span><br><span class="line">            model += S_star[i] &lt;= <span class="built_in">sum</span>(S_given[k] <span class="keyword">for</span> k <span class="keyword">in</span> range(i, n))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 求解</span></span><br><span class="line">    model.solve(pulp.PULP_CBC_CMD(msg=False))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回最终经费余额</span></span><br><span class="line">    <span class="keyword">if</span> pulp.LpStatus[model.status] == <span class="string">&#x27;Optimal&#x27;</span>:</span><br><span class="line">        <span class="built_in">return</span> p[n].varValue</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">return</span> None</span><br><span class="line"></span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">def compute_S_given(alpha_deg, base_S):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;根据安息角调整土地需求&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    alpha_rad = math.radians(alpha_deg)</span><br><span class="line">    scale_factor = 1 / (math.tan(alpha_rad)**2)</span><br><span class="line">    <span class="built_in">return</span> [s * scale_factor <span class="keyword">for</span> s <span class="keyword">in</span> base_S]</span><br><span class="line"></span><br><span class="line">base_S = S_given[:n]  <span class="comment"># 原始占地需求</span></span><br><span class="line">alphas = np.linspace(30, 55, 10)  <span class="comment"># 安息角从30°~55°</span></span><br><span class="line">alpha_results = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alphas:</span><br><span class="line">    S_given_alpha = compute_S_given(alpha, base_S)</span><br><span class="line">    final_balance = run_model(c1=c1[:n], f1=f1[:n], S_given=S_given_alpha, n=n)</span><br><span class="line">    alpha_results.append(&#123;</span><br><span class="line">        <span class="string">&quot;alpha&quot;</span>: alpha,</span><br><span class="line">        <span class="string">&quot;final_balance&quot;</span>: final_balance,</span><br><span class="line">        <span class="string">&quot;scale_factor&quot;</span>: 1 / (math.tan(math.radians(alpha)) ** 2)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取绘图数据</span></span><br><span class="line">x_alphas = [r[<span class="string">&quot;alpha&quot;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> alpha_results]</span><br><span class="line">y_balances = [r[<span class="string">&quot;final_balance&quot;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> alpha_results]</span><br><span class="line">y_scales = [r[<span class="string">&quot;scale_factor&quot;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> alpha_results]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安息角 vs 最终经费</span></span><br><span class="line">plt.figure(figsize=(12, 5))</span><br><span class="line">plt.subplot(1, 2, 1)</span><br><span class="line">plt.plot(x_alphas, y_balances, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;安息角对最终经费的影响&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;安息角 α (°)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;最终经费余额（万元）&quot;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安息角 vs 占地规模因子</span></span><br><span class="line">plt.subplot(1, 2, 2)</span><br><span class="line">plt.plot(x_alphas, y_scales, marker=<span class="string">&#x27;x&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;安息角对占地规模的影响&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;安息角 α (°)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;占地缩放因子&quot;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<h1 id="模型拓展"><a href="#模型拓展" class="headerlink" title="模型拓展"></a>模型拓展</h1><p>该论文讨论了仰角\beta的最优解 其最优解为29°<br>我认为可以在此基础上添加上仰角对占地面积的关系 再由占地面积推导出对经费的影响</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原始参数</span></span><br><span class="line">base_S = [10.66, 6.26, 5.25, 4.69, 4.31][:5]  <span class="comment"># 原始占地需求</span></span><br><span class="line">c1 = [8, 8.8, 9.68, 10.648, 11.7128][:5]      <span class="comment"># 地价</span></span><br><span class="line">f1 = [97.11, 92.33, 90.31, 88.68, 87.26][:5]  <span class="comment"># 每年收入</span></span><br><span class="line">n = 5                                           <span class="comment"># 年数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 β 的变化范围</span></span><br><span class="line">beta_values = np.linspace(15, 43, 10)  <span class="comment"># 从 5° 到 25°，共 10 个点</span></span><br><span class="line"></span><br><span class="line">results = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> beta <span class="keyword">in</span> beta_values:</span><br><span class="line">    S_given_beta = compute_S_given(beta, base_S)</span><br><span class="line">    final_balance = run_model(c1=c1, f1=f1, S_given=S_given_beta, n=n)</span><br><span class="line">    </span><br><span class="line">    results.append(&#123;</span><br><span class="line">        <span class="string">&quot;beta&quot;</span>: beta,</span><br><span class="line">        <span class="string">&quot;final_balance&quot;</span>: final_balance,</span><br><span class="line">        <span class="string">&quot;avg_land&quot;</span>: <span class="built_in">sum</span>(S_given_beta) / len(S_given_beta),</span><br><span class="line">        <span class="string">&quot;total_land&quot;</span>: <span class="built_in">sum</span>(S_given_beta)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取绘图数据</span></span><br><span class="line">x_betas = [r[<span class="string">&quot;beta&quot;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> results]</span><br><span class="line">y_balance = [r[<span class="string">&quot;final_balance&quot;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> results]</span><br><span class="line">y_total_land = [r[<span class="string">&quot;total_land&quot;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> results]</span><br><span class="line"></span><br><span class="line">plt.plot(x_betas, y_total_land, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;轨道仰角 vs 总占地面积&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;轨道仰角 β (°)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;总占地面积（亩）&quot;</span>)</span><br><span class="line">plt.grid(True)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>《煤矿安全规程》<br>第三百七十五条规定：采用轨道运输的巷道，其坡度不宜超过 15°<br>矿山机械设计手册》<br>一般矿用机车最大允许坡度为 15°~20° ；<br>超过 20° 的轨道需采取特殊措施</p>
</blockquote>
<p>因此 我认为 这个最优解只是一个理想的最优解</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>关于2003D抢渡长江的研读报告</title>
    <url>/zhihaojiang.github.io/2025/07/02/20250702%E5%85%B3%E4%BA%8E2003D%E6%8A%A2%E6%B8%A1%E9%95%BF%E6%B1%9F%E7%9A%84%E7%A0%94%E8%AF%BB%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<h1 id="题目背景"><a href="#题目背景" class="headerlink" title="题目背景"></a>题目背景</h1><p>本论文一抢渡长江为背景 需要完成在已知江宽 水流速度分布 选手游泳速度的前提下 建立模型计算出选手应采取的最佳游泳方向或路径 </p>
<h1 id="建模准备"><a href="#建模准备" class="headerlink" title="建模准备"></a>建模准备</h1><p>建模前先推导了正弦定理和余弦定理</p>
<h1 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h1><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/02/001.jpg" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/02/002.jpg" alt="photo"></p>
<p>我对论文中的相关公式进行了推导<br>由论文中给出的参数得知<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.577ex;" xmlns="http://www.w3.org/2000/svg" width="15.729ex" height="4.106ex" role="img" focusable="false" viewBox="0 -1118 6952.2 1815"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(389,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(889,0)"></path></g><g data-mml-node="mo" transform="translate(1445,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(1611.7,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2333.7,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(3092.7,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(3842.7,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(4884.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(5940.2,0)"><g data-mml-node="mi" transform="translate(220,676)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(289.5,-686)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><rect width="772" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<h2 id="10-4"><a href="#10-4" class="headerlink" title="(10-4)"></a>(10-4)</h2><p>theta是游泳者的合成速度方向<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.577ex;" xmlns="http://www.w3.org/2000/svg" width="45.403ex" height="4.178ex" role="img" focusable="false" viewBox="0 -1149.5 20068.2 1846.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(746.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1802.6,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2524.6,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(3273.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(4023.6,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(5065.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6121.1,0)"><g data-mml-node="mi" transform="translate(220,676)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mn" transform="translate(255,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="770" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(7353.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(8353.6,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(9075.6,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(9834.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(10584.6,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(11626.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(12682.1,0)"><g data-mml-node="mi" transform="translate(220,676)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mn" transform="translate(255,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="770" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(13914.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(14914.6,0)"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(892,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1336,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1725,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2225,0)"></path></g><g data-mml-node="mo" transform="translate(17695.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(17862.2,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="mfrac" transform="translate(597,0)"><g data-mml-node="mi" transform="translate(220,676)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(289.5,-686)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><rect width="772" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1609,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g></g></g></svg></mjx-container></p>
<p>论文中的<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.172ex;" xmlns="http://www.w3.org/2000/svg" width="20.516ex" height="4.704ex" role="img" focusable="false" viewBox="0 -1119 9068.2 2079"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="msub" transform="translate(1949.1,676)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(1394.7,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2116.7,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(2866.7,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(3630.7,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g><rect width="4579.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(5097.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6153.2,0)"><g data-mml-node="msub" transform="translate(996.7,676)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1617,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(2086,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><rect width="2675" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>用到了正弦定理<br>在三角形AEF中<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.172ex;" xmlns="http://www.w3.org/2000/svg" width="26.209ex" height="5.321ex" role="img" focusable="false" viewBox="0 -1392 11584.2 2352"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(1660.3,676)"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(750,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(1394.7,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2116.7,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(2866.7,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(3630.7,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g><rect width="4579.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(5097.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6153.2,0)"><g data-mml-node="mrow" transform="translate(1959,676)"><g data-mml-node="mi"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1617,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2339,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(3088,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(3838,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(4602,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><rect width="5191" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>由于</p>
<blockquote>
<p>EF = DA = v1<br>sin(theta) = sin(∠FAE)</p>
</blockquote>
<p>因此推导出<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.172ex;" xmlns="http://www.w3.org/2000/svg" width="20.516ex" height="4.704ex" role="img" focusable="false" viewBox="0 -1119 9068.2 2079"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="msub" transform="translate(1949.1,676)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(1394.7,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2116.7,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(2866.7,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(3630.7,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g><rect width="4579.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(5097.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6153.2,0)"><g data-mml-node="msub" transform="translate(996.7,676)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1617,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(2086,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><rect width="2675" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>经过变换得<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.148ex;" xmlns="http://www.w3.org/2000/svg" width="26.953ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 11913.1 2399"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(722,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(1472,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(2236,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mo" transform="translate(3262.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(4318.6,0)"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(892,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(1336,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1730,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2008,0)"></path></g><g data-mml-node="mo" transform="translate(6882.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(7049.2,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(1088.2,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(2316.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(2482.9,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="msub" transform="translate(1235.2,-686)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><rect width="3151.9" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(4127.9,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g></g></g></svg></mjx-container></p>
<h2 id="10-5"><a href="#10-5" class="headerlink" title="(10-5)"></a>(10-5)</h2><p>游泳者的速度方向角<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="30.832ex" height="1.805ex" role="img" focusable="false" viewBox="0 -716 13627.6 798"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(917.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1973.6,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2695.6,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(3444.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(4194.6,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mo" transform="translate(5300.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(6356.1,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(7078.1,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(7827.1,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(8577.1,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(9563.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(10563.6,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(11285.6,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(12049.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(12799.6,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g></g></g></svg></mjx-container><br>观察四边形ADEF<br>此处的合成速度v2（对应向量 AE）由两个分速度v0和v1​通过矢量相加的方式合成 作为矢量 速度的合成遵循平行四边形法则 即以v0和v1为邻边构成的平行四边形 其对角线表示合速度v2的大小和方向<br>因此∠AEF = ∠EAD(对顶角相等)<br>得到<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="24.961ex" height="1.805ex" role="img" focusable="false" viewBox="0 -716 11032.6 798"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(917.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1973.6,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(2695.6,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(3444.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(4194.6,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mo" transform="translate(5300.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(6356.1,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(7047.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(8047.6,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(8769.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(9519.6,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(10283.6,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g></g></svg></mjx-container></p>
<p>在三角形AEF中 根据余弦定理<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.33ex;" xmlns="http://www.w3.org/2000/svg" width="41.802ex" height="2.851ex" role="img" focusable="false" viewBox="0 -1114.2 18476.5 1260"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(750,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(1791.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msqrt" transform="translate(2847.6,0)"><g transform="translate(1020,0)"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="msup" transform="translate(750,0)"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mn" transform="translate(837.3,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(2213.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(3213.3,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="msup" transform="translate(3977.3,0)"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mn" transform="translate(837.3,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(5440.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(6440.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(6940.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(7690.6,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(8439.6,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(9203.6,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(10119.3,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(11457.3,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(11623.9,0)"><path data-c="2220" d="M71 0L68 2Q65 3 63 5T58 11T55 20Q55 22 57 28Q67 43 346 361Q397 420 474 508Q595 648 616 671T647 694T661 688T666 674Q666 668 663 663Q662 662 627 622T524 503T390 350L120 41L386 40H653Q666 30 666 20Q666 8 651 0H71Z"></path></g><g data-mml-node="mi" transform="translate(12345.9,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(13095.9,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(13859.9,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g><g data-mml-node="mo" transform="translate(0,204.2)"><path data-c="221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path></g><rect width="14608.9" height="60" x="1020" y="994.2"></rect></g></g></g></svg></mjx-container><br>又由于<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="21.685ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9584.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(944.7,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2282.7,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(2282.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2671.7,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(3311.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3978.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(5034.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(6372.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(6372.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6761.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7555.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(8555.7,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(9195.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<h2 id="10-6"><a href="#10-6" class="headerlink" title="(10-6)"></a>(10-6)</h2><p>因此<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.197ex;" xmlns="http://www.w3.org/2000/svg" width="27.642ex" height="4.208ex" role="img" focusable="false" viewBox="0 -1331.1 12217.5 1860"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1199.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msqrt" transform="translate(2255.1,0)"><g transform="translate(1020,0)"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,353.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mn" transform="translate(518,-297.3) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1143.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2144,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,353.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mn" transform="translate(518,-297.3) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3287.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(4288,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msub" transform="translate(4788,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="msub" transform="translate(5709.5,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(6797.8,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(8135.8,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(8302.4,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g></g><g data-mml-node="mo" transform="translate(0,121.1)"><path data-c="221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path></g><rect width="8942.4" height="60" x="1020" y="1211.1"></rect></g></g></g></svg></mjx-container></p>
<h2 id="10-7"><a href="#10-7" class="headerlink" title="(10-7)"></a>(10-7)</h2><p>根据速度公式t = s/v<br>在论文中其将路程分为了AP PC两段 因此公式中前半部份是AP的时间 后半部份是PC的时间 由于在PC时v0 v1方向同向 因此是v0+v1<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.927ex;" xmlns="http://www.w3.org/2000/svg" width="24.471ex" height="5.643ex" role="img" focusable="false" viewBox="0 -1642.5 10816.1 2494"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(638.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1694.6,0)"><g data-mml-node="msqrt" transform="translate(220,676)"><g transform="translate(853,0)"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1091.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(2092,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,106.5)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="3100.6" height="60" x="853" y="846.5"></rect></g><g data-mml-node="msub" transform="translate(1736,-686)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><rect width="4153.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(6310.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mfrac" transform="translate(7310.6,0)"><g data-mml-node="mrow" transform="translate(591.1,676)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(751.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(1751.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1143.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2144,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="3265.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<h2 id="代码复现"><a href="#代码复现" class="headerlink" title="代码复现"></a>代码复现</h2><p>通过一下代码求的相对应的结果</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 已知参数</span></span><br><span class="line">a = 1000</span><br><span class="line">c = 1160</span><br><span class="line">v0 = 1.89  <span class="comment"># 水的流速</span></span><br><span class="line">v1 = 1.5  <span class="comment"># 游泳速度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 公式</span></span><br><span class="line">def calculate_theta(x, c):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    计算theta</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    <span class="comment"># 计算theta</span></span><br><span class="line">    theta = math.pi / 2 - math.atan(x / c)</span><br><span class="line">    <span class="comment"># 返回theta</span></span><br><span class="line">    <span class="built_in">return</span> theta</span><br><span class="line"></span><br><span class="line">def calculate_AEF(theta, v0, v1):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    计算AEF</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    AEF = math.asin(v0 * math.sin(theta) / v1)</span><br><span class="line">    <span class="built_in">return</span> AEF</span><br><span class="line"></span><br><span class="line">def calculate_alpha(theta, AEF):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    计算alpha</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    alpha = theta + AEF</span><br><span class="line">    <span class="built_in">return</span> alpha</span><br><span class="line"></span><br><span class="line">def calculate_v2(v0, v1, alpha):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    计算v2</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    cos_alpha = math.cos(alpha)</span><br><span class="line">    v2 = math.sqrt(v0**2 + v1**2 + 2 * v0 * v1 * cos_alpha)</span><br><span class="line">    <span class="built_in">return</span> v2</span><br></pre></td></tr></table></figure></div>

<p>通过一下代码可以得到当v1 = 1.5 1.89 2.11 v0 = 1.89时游泳时间与x的趋势</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">a = 1000</span><br><span class="line">c = 1160</span><br><span class="line">v0 = 1.89</span><br><span class="line">v1 = 1.5  <span class="comment"># 给定游泳速度</span></span><br><span class="line"></span><br><span class="line">model = SwimModel(a=a, c=c, v0=v0, v1=v1)</span><br><span class="line"></span><br><span class="line">x_values = list(range(900, 1001, 5))</span><br><span class="line">t_values = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_values:</span><br><span class="line">    result = model.forward(x)</span><br><span class="line">    t_values.append(result[<span class="string">"time"</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 5))</span><br><span class="line">plt.plot(x_values, t_values, marker=<span class="string">'o'</span>, linestyle=<span class="string">'-'</span>, color=<span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">"t VS x"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"t"</span>)</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<p>通过以下代码可以解得在x = 1000时游泳者的速度 方向 时间</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line">from scipy.optimize import fsolve</span><br><span class="line"></span><br><span class="line"><span class="comment"># 已知参数</span></span><br><span class="line">T_target = 910</span><br><span class="line">x = 1000</span><br><span class="line">c = 1160</span><br><span class="line">v0 = 1.89</span><br><span class="line">a = 1000</span><br><span class="line"><span class="comment"># 求theta</span></span><br><span class="line">theta = math.atan(c / x)</span><br><span class="line"></span><br><span class="line">def time_equation(v1):</span><br><span class="line"></span><br><span class="line">    ratio = (v0 * math.sin(theta)) / v1</span><br><span class="line">    <span class="keyword">if</span> abs(ratio) &gt; 1:</span><br><span class="line">        <span class="built_in">return</span> 1e9</span><br><span class="line"></span><br><span class="line">    AEF = math.asin(ratio)</span><br><span class="line">    alpha = theta + AEF</span><br><span class="line">    v2 = math.sqrt(v0**2 + v1**2 + 2 * v0 * v1 * math.cos(alpha))</span><br><span class="line">    T_computed = math.sqrt(x**2 + c**2) / v2 + (a - x) / (v0 + v1)</span><br><span class="line">    <span class="built_in">return</span> T_computed - T_target</span><br><span class="line"></span><br><span class="line">v1_guess = 1.0</span><br><span class="line">v1_solution = fsolve(time_equation, v1_guess)[0]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"所需的游泳者速度 v1 ≈ {v1_solution:.4f} m/s"</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>所需的游泳者速度 v1 ≈ 1.5003 m/s</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line">from scipy.optimize import fsolve</span><br><span class="line"></span><br><span class="line">class SwimModel:</span><br><span class="line">    def __init__(self, a, c, v0, v1=None):</span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        a: 终点</span></span><br><span class="line"><span class="string">        c: 距离</span></span><br><span class="line"><span class="string">        v0: 水流速度</span></span><br><span class="line"><span class="string">        v1: 游泳速度</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        self.a = a</span><br><span class="line">        self.c = c</span><br><span class="line">        self.v0 = v0</span><br><span class="line">        self.v1 = v1</span><br><span class="line"></span><br><span class="line">    def theta(self, x):</span><br><span class="line">        <span class="built_in">return</span> math.pi / 2 - math.atan(x / self.c)</span><br><span class="line"></span><br><span class="line">    def AEF(self, theta, v1):</span><br><span class="line">        ratio = self.v0 * math.sin(theta) / v1</span><br><span class="line">        <span class="built_in">return</span> math.asin(ratio)</span><br><span class="line"></span><br><span class="line">    def alpha(self, theta, AEF):</span><br><span class="line">        <span class="built_in">return</span> theta + AEF</span><br><span class="line"></span><br><span class="line">    def v2(self, v1, alpha):</span><br><span class="line">        <span class="built_in">return</span> math.sqrt(self.v0**2 + v1**2 + 2 * self.v0 * v1 * math.cos(alpha))</span><br><span class="line"></span><br><span class="line">    def total_time(self, v2, v1, x):</span><br><span class="line">        swim_time = math.sqrt(self.c**2 + x**2) / v2</span><br><span class="line">        flow_time = (self.a - x) / (self.v0 + v1)</span><br><span class="line">        <span class="built_in">return</span> swim_time + flow_time</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        <span class="string">""</span><span class="string">"前向：已知 x 和 v1，输出 α, v2, t"</span><span class="string">""</span></span><br><span class="line">        <span class="keyword">if</span> self.v1 is None:</span><br><span class="line">            raise ValueError(<span class="string">"请先设置 v1"</span>)</span><br><span class="line"></span><br><span class="line">        theta = self.theta(x)</span><br><span class="line">        AEF = self.AEF(theta, self.v1)</span><br><span class="line">        alpha = self.alpha(theta, AEF)</span><br><span class="line">        v2 = self.v2(self.v1, alpha)</span><br><span class="line">        t = self.total_time(v2, self.v1, x)</span><br><span class="line">        <span class="built_in">return</span> {</span><br><span class="line">            <span class="string">"theta_rad"</span>: theta,</span><br><span class="line">            <span class="string">"alpha_rad"</span>: alpha,</span><br><span class="line">            <span class="string">"alpha_deg"</span>: math.degrees(alpha),</span><br><span class="line">            <span class="string">"v2"</span>: v2,</span><br><span class="line">            <span class="string">"time"</span>: t</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">    def inverse_solve_v1(self, x, T_target):</span><br><span class="line">        <span class="string">""</span><span class="string">"已知 T_target 和 x，求 v1"</span><span class="string">""</span></span><br><span class="line">        def equation(v1):</span><br><span class="line">            theta = self.theta(x)</span><br><span class="line">            AEF = self.AEF(theta, v1)</span><br><span class="line">            alpha = self.alpha(theta, AEF)</span><br><span class="line">            v2 = self.v2(v1, alpha)</span><br><span class="line">            t = self.total_time(v2, v1, x)</span><br><span class="line">            <span class="built_in">return</span> t - T_target</span><br><span class="line"></span><br><span class="line">        result = fsolve(equation, 1.0)[0]</span><br><span class="line">        <span class="built_in">return</span> result</span><br><span class="line"></span><br><span class="line">model = SwimModel(a=1000, c=1160, v0=1.89, v1=1.50)</span><br><span class="line">result = model.forward(x=1000)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"α: {result['alpha_deg']:.2f}"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"v2: {result['v2']:.4f}"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"t:  {result['time']:.2f}"</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>α: 121.85<br>v2: 1.6822<br>t:  910.46</p>
</blockquote>
<h1 id="选手成功到达终点的概率"><a href="#选手成功到达终点的概率" class="headerlink" title="选手成功到达终点的概率"></a>选手成功到达终点的概率</h1><p>论文中定义概率<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.172ex;" xmlns="http://www.w3.org/2000/svg" width="12.417ex" height="5.475ex" role="img" focusable="false" viewBox="0 -1460 5488.5 2420"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(780.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1836.6,0)"><g data-mml-node="mrow" transform="translate(716.2,710)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(520,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(909,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(518,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1830.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(939,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="TeXAtom" transform="translate(518,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(833,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(1333,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2822.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><rect width="3411.9" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>其意思是 在游泳速度为v1时成功的概率/在游泳速度最大时成功的概率<br>检测在2002年时的最低游泳成功的速度</p>
<h2 id="代码复现-1"><a href="#代码复现-1" class="headerlink" title="代码复现"></a>代码复现</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">u = 1.89  <span class="comment"># 流速</span></span><br><span class="line">X = 1000.0</span><br><span class="line">Y = 1160.0</span><br><span class="line"></span><br><span class="line">def v_min(u, X, Y):</span><br><span class="line">    <span class="built_in">return</span> np.sqrt(u**2 + (X/Y)**2)</span><br><span class="line"></span><br><span class="line">v_thresh = v_min(u, X, Y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"2002 阈值速度 v_min ="</span>, v_thresh, <span class="string">"m/s"</span>)  <span class="comment"># ~2.08 m/s</span></span><br><span class="line"></span><br><span class="line">vs = np.linspace(0.5, 4.0, 36)</span><br><span class="line">results = [<span class="string">"可成功"</span> <span class="keyword">if</span> v&gt;=v_thresh <span class="keyword">else</span> <span class="string">"失败"</span> <span class="keyword">for</span> v <span class="keyword">in</span> vs]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> v, res <span class="keyword">in</span> zip(vs, results):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"速度 {v:.2f} m/s: {res}"</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def v_min(u, Y, X):</span><br><span class="line">    <span class="built_in">return</span> u * Y / X</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数设置</span></span><br><span class="line">u_2002 = 1.3</span><br><span class="line">Y_2002 = 1160 <span class="comment"># 江宽</span></span><br><span class="line">X_2002 = 1000 <span class="comment"># 起点到终点的水平距离</span></span><br><span class="line"></span><br><span class="line">v_threshold_1934 = v_min(u_2002, Y_2002, X_2002)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"2002 年成功游过江所需最低速度为：{v_threshold_1934:} m/s"</span>)</span><br><span class="line"></span><br><span class="line">def v_min(u, Y, X):</span><br><span class="line">    <span class="built_in">return</span> u * Y / X</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数设置</span></span><br><span class="line">u_1934 = 1.2</span><br><span class="line">Y_1934 = 1400 <span class="comment"># 江宽</span></span><br><span class="line">X_1934 = 3800 <span class="comment"># 起点到终点的水平距离</span></span><br><span class="line"></span><br><span class="line">v_threshold_1934 = v_min(u_1934, Y_1934, X_1934)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"1934 年成功游过江所需最低速度为：{v_threshold_1934:} m/s"</span>)  <span class="comment"># 约 0.44</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>2002 年成功游过江所需最低速度为：1.508 m/s<br>1934 年成功游过江所需最低速度为：0.4421052631578947 m/s</p>
</blockquote>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def d(v1, a, c):</span><br><span class="line">    v0 = 1.89  <span class="comment"># 水的流速</span></span><br><span class="line">    upper = a - c * math.tan(math.acos(v1 / v0))</span><br><span class="line">    d = upper / a</span><br><span class="line">    <span class="built_in">return</span> d</span><br><span class="line">p_2002 = d(1.5, 1000, 1160) / d(1.7, 1000, 1160)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"2002 年成功游过江的概率 p_2002 = {p_2002}"</span>)</span><br><span class="line">p_1934 = d(1.5, 3800, 1400) / d(1.7, 3800, 1400)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"1934 年成功游过江的概率 p_1934 = {p_1934}"</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>2002 年成功游过江的概率 p_2002 = 0.2538695839819621<br>1934 年成功游过江的概率 p_1934 = 0.8740249877014562</p>
</blockquote>
<h1 id="问题三"><a href="#问题三" class="headerlink" title="问题三"></a>问题三</h1><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/02/003.jpg" alt="photo"></p>
<h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>求最优的成绩 因此目标函数就是最小时间(最小半江宽时间*2)</p>
<h2 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h2><p><strong>第1个约束</strong><br>每段的游泳时间</p>
<p><strong>第2个约束</strong><br>游泳者的速度 &gt;= 水流在垂直方向的分量<br>v1 &gt; v0说明游泳者能能克服水流的影响</p>
<p><strong>第3个约束</strong><br>游泳者相对水流方向的夹角</p>
<p><strong>第4个约束</strong><br>速度与水速的夹角即抵消水流的角度</p>
<p><strong>第5个约束</strong><br>每一段的合成速度约束</p>
<p><strong>第6个约束</strong><br>自由变量</p>
<p><strong>第7个约束</strong><br>半江宽约束</p>
<h2 id="代码复现-2"><a href="#代码复现-2" class="headerlink" title="代码复现"></a>代码复现</h2><p>通过代码复现得</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from scipy.optimize import minimize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数设置</span></span><br><span class="line">c1, c2 = 200, 380</span><br><span class="line">v01, v02 = 1.47, 2.11</span><br><span class="line">v1 = 1.5</span><br><span class="line">a_total = 500</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 目标函数</span></span><br><span class="line">def objective(a):</span><br><span class="line">    <span class="comment"># min f</span></span><br><span class="line">    a1, a2 = a</span><br><span class="line">    t1 = time_segment(a1, c1, v01)</span><br><span class="line">    t2 = time_segment(a2, c2, v02)</span><br><span class="line">    <span class="built_in">return</span> 2 * (t1 + t2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 约束条件</span></span><br><span class="line">def time_segment(ai, ci, v0i):</span><br><span class="line">    <span class="comment"># ti(ai)</span></span><br><span class="line">    theta = np.pi / 2 - np.arctan(ai / ci)</span><br><span class="line">    alpha = theta + np.arcsin((v0i * np.sin(theta)) / v1)</span><br><span class="line">    v2i = np.sqrt(v0i**2 + v1**2 + 2 * v0i * v1 * np.cos(alpha))</span><br><span class="line">    s = np.sqrt(ai**2 + ci**2)</span><br><span class="line">    <span class="built_in">return</span> s / v2i</span><br><span class="line"></span><br><span class="line">def eq_constraint(a):</span><br><span class="line">    <span class="comment"># a1 + a2 = 0.5a</span></span><br><span class="line">    <span class="built_in">return</span> a[0] + a[1] - a_total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def ineq_constraint1(a):</span><br><span class="line">    <span class="comment"># v0i * c_i / sqrt(ai^2 + ci^2) ≤ v1</span></span><br><span class="line">    a1 = a[0]</span><br><span class="line">    <span class="built_in">return</span> v1 - v01 * c1 / np.sqrt(a1**2 + c1**2)</span><br><span class="line"></span><br><span class="line">def ineq_constraint2(a):</span><br><span class="line">    a2 = a[1]</span><br><span class="line">    <span class="built_in">return</span> v1 - v02 * c2 / np.sqrt(a2**2 + c2**2)</span><br><span class="line"></span><br><span class="line">def compute_alpha(ai, ci, v0i):</span><br><span class="line">    <span class="comment"># alpha(i)</span></span><br><span class="line">    theta = np.pi / 2 - np.arctan(ai / ci)</span><br><span class="line">    alpha = theta + np.arcsin((v0i * np.sin(theta)) / v1)</span><br><span class="line">    <span class="built_in">return</span> np.degrees(alpha)</span><br><span class="line"></span><br><span class="line">a_init = [100, 400]</span><br><span class="line">bounds = [(10, 490), (10, 490)]</span><br><span class="line"></span><br><span class="line">constraints = [</span><br><span class="line">    {<span class="string">'type'</span>: <span class="string">'eq'</span>, <span class="string">'fun'</span>: eq_constraint},</span><br><span class="line">    {<span class="string">'type'</span>: <span class="string">'ineq'</span>, <span class="string">'fun'</span>: ineq_constraint1},</span><br><span class="line">    {<span class="string">'type'</span>: <span class="string">'ineq'</span>, <span class="string">'fun'</span>: ineq_constraint2},</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">res = minimize(objective, a_init, bounds=bounds, constraints=constraints, method=<span class="string">'SLSQP'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> res.success:</span><br><span class="line">    a1, a2 = res.x</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"最优解：a1 = {a1:.2f}, a2 = {a2:.2f}, a1 + a2 = {a1 + a2:.2f}"</span>)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"总时间 = {res.fun:.2f} 秒"</span>)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"α1 = {compute_alpha(a1, c1, v01):.2f}°, α2 = {compute_alpha(a2, c2, v02):.2f}°"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"优化失败："</span>, res.message)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>最优解：a1 = 96.84, a2 = 403.16, a1 + a2 = 500.00<br>总时间 = 904.02 秒<br>α1 = 126.06°, α2 = 118.06°</p>
</blockquote>
<h1 id="问题四"><a href="#问题四" class="headerlink" title="问题四"></a>问题四</h1><p>问题四的公式和问题三的类似 主要的不同点是问题三的速度v0i是两个离散的数值 问题四的v0i是连续数值离散化 可以有n个<br>论文中给出的v0i的公式<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="24.798ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10960.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="TeXAtom" transform="translate(518,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1443.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(2499.1,0)"><g data-mml-node="mo"><path data-c="7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path></g><g data-mml-node="mtable" transform="translate(500,0)"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(521,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(910,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1477.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2477.4,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(3755.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msub" transform="translate(4144.4,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="TeXAtom" transform="translate(466,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mtext" transform="translate(5367.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(5617.6,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mi" transform="translate(6138.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(6738.6,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="TeXAtom" transform="translate(466,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></g><g data-mml-node="mo" transform="translate(8461.7,0) translate(0 250)"></g></g></g></g></svg></mjx-container></p>
<p>其中k为水速斜率 其公式为<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="13.313ex" height="2.084ex" role="img" focusable="false" viewBox="0 -716 5884.4 921"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mtext" transform="translate(521,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(1048.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(2104.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(2576.8,0)"><path data-c="2206" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="mi" transform="translate(3632,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(4339.2,0)"><path data-c="2206" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="mi" transform="translate(5394.4,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container><br>意思是水速在∆y内变化了∆v<br>论文中由于水速是分段给出的连续分布 因此水速的变化是线性的 因此其水速斜率是一个常数<br>水速在200米内变化了2.28 （岸边速度为0 ～水速最大为2.28）<br>因此<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="10.345ex" height="4.638ex" role="img" focusable="false" viewBox="0 -1342 4572.6 2050"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mtext" transform="translate(521,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(1048.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(2104.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mfrac" transform="translate(2354.6,0)"><g data-mml-node="mn" transform="translate(220,676)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(778,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1278,0)"></path></g><g data-mml-node="mn" transform="translate(359,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><rect width="1978" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<h2 id="代码复现-3"><a href="#代码复现-3" class="headerlink" title="代码复现"></a>代码复现</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def time_segment(a_i, c1i, v0i, debug=False):</span><br><span class="line">    theta_i = np.pi / 2 - np.arctan(a_i / c1i)</span><br><span class="line">    sin_theta = v0i * np.sin(theta_i) / v1</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> np.abs(sin_theta) &gt; 1:</span><br><span class="line">        <span class="keyword">if</span> debug:</span><br><span class="line">            <span class="built_in">print</span>(f<span class="string">"[警告] sin_theta={sin_theta:.4f} 超出 [-1, 1]"</span>)</span><br><span class="line">        sin_theta = np.clip(sin_theta, -1, 1)</span><br><span class="line"></span><br><span class="line">    alpha_i = theta_i + np.arcsin(sin_theta)</span><br><span class="line">    v2i = np.sqrt(v0i**2 + v1**2 + 2 * v0i * v1 * np.cos(alpha_i))</span><br><span class="line">    s = np.sqrt(a_i**2 + c1i**2)</span><br><span class="line">    <span class="keyword">time</span> = s / v2i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug:</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">"a = {a_i:.2f}, c1 = {c1i}, v0 = {v0i:.3f}"</span>)</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">"θ = {np.degrees(theta_i):.2f}°, α = {np.degrees(alpha_i):.2f}°, v2 = {v2i:.3f}, s = {s:.2f}, time = {time:.2f}\n"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> <span class="keyword">time</span></span><br><span class="line"></span><br><span class="line">a_list = [-30, 80, 420]</span><br><span class="line">c1_list = [100, 100, 380]</span><br><span class="line">v0i_list = [0.57, 1.71, 2.28]</span><br><span class="line">v1 = 1.5</span><br><span class="line">total_time = 0</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(3):</span><br><span class="line">    t = time_segment(a_list[i], c1_list[i], v0i_list[i])</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"t{i+1}: {t:.2f} s"</span>)</span><br><span class="line">    total_time += t</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"总时间：{2 * total_time:} 秒"</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>t1: 84.65 s<br>t2: 73.11 s<br>t3: 334.95 s<br>总时间：985.430963388645 秒</p>
</blockquote>
<p>可以在论文中看到其路径是先往上游游在往下游游<br>这有点不符合直觉<br>我们假设若按照直线游<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/02/004.jpg" alt="photo"></p>
<p>通过代码可以得到</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">alpha = np.arctan(1160 / 1000)</span><br><span class="line"></span><br><span class="line">d = 1160/ np.sin(alpha)</span><br><span class="line"></span><br><span class="line">v = 1.79/np.cos(alpha)</span><br><span class="line"></span><br><span class="line">t = d/v</span><br><span class="line"></span><br><span class="line">2 * t</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>1117.31843575419</p>
</blockquote>
<p>这不是最短的时间 因此该路径看似不符合直觉但是确实是最短的时间</p>
<h1 id="灵敏度分析"><a href="#灵敏度分析" class="headerlink" title="灵敏度分析"></a>灵敏度分析</h1><p>调整上述代码中的参数<br>将v1速度改为1.515和1.48</p>
<blockquote>
<p>t1: 83.56 s<br>t2: 71.79 s<br>t3: 334.99 s<br>总时间：980.6787856865337 秒</p>
</blockquote>
<blockquote>
<p>t1: 85.77 s<br>t2: 74.54 s<br>t3: 334.89 s<br>总时间：990.4005321378754 秒</p>
</blockquote>
<p><strong>T对v1敏感</strong></p>
<p>将k的值改为0.011和0.0118</p>
<blockquote>
<p>t1: 84.65 s<br>t2: 73.11 s<br>t3: 334.95 s<br>总时间：985.430963388645 秒</p>
</blockquote>
<p><strong>t对k不敏感</strong></p>
<h1 id="模型拓展"><a href="#模型拓展" class="headerlink" title="模型拓展"></a>模型拓展</h1><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/07/02/005.jpg" alt="photo"></p>
<p>由于问题四中的模型的速度建模思路为：将连续分布所在的江宽等分为若干区间 使得水速在每个区间近似为常数<br>因此在问题四中k是常数 水速是线性的<br>当水速不是线性的时候<br>其定义了v关于y的公式<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="72.532ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 32059 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(485,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(874,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1364,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2030.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(3086.6,0)"><g data-mml-node="mo"><path data-c="7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path></g><g data-mml-node="mtable" transform="translate(500,0)"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(926.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1315.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1805.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2194.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(3472.6,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(777.8,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(1833.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2601.3,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(3657.1,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mtext" transform="translate(5157.1,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mn" transform="translate(5407.1,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(778,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1278,0)"></path></g><g data-mml-node="mo" transform="translate(7185.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(11935.7,0)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1777.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mi" transform="translate(2833.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3601.3,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(4657.1,0)"><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mtext" transform="translate(6157.1,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(6407.1,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(7333.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7722.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(8212.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(8601.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(21815.3,0)"><g data-mml-node="mn"><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1777.8,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(2833.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3601.3,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(4657.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></g><g data-mml-node="mo" transform="translate(28972.4,0) translate(0 250)"></g></g></g></g></svg></mjx-container></p>
<p>在[0,200]区间中水流满足</p>
<blockquote>
<p>v(0) = 0<br>v(200) = 2.28</p>
</blockquote>
<p>为了满足此条件 其选择了一个开口向上的抛物线形式<br>解得 k = 2.28/200^2</p>
<p>由于f1(y)和f2(y)关于江心中心对称<br>在[960,1160]区间同理</p>
<p>选择抛物线函数的原因（论文中未提及 可以添加）<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="11.389ex" height="2.565ex" role="img" focusable="false" viewBox="0 -883.9 5034.1 1133.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(485,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(874,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1364,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mtext" transform="translate(1753,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(2280.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(3336.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(3586.6,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="msup" transform="translate(4107.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
<p>物理现象水流速度分布 在自然河流中 靠近岸边的地方水流较慢 越靠近江心水流越快 江心处水流速度达到最大值<br>这种分布不是连续且平滑变化的 抛物线是一种最简单的非线性函数 能够很好地模拟这种先慢后快再慢的对称分布趋势</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--IT行业收入表</title>
    <url>/zhihaojiang.github.io/2025/09/18/20250918%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--IT%E8%A1%8C%E4%B8%9A%E6%94%B6%E5%85%A5%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><h2 id="导入一些必要库"><a href="#导入一些必要库" class="headerlink" title="导入一些必要库"></a>导入一些必要库</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line"></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th></th>
<th>工龄</th>
<th>薪水</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.0</td>
<td>10808</td>
</tr>
<tr>
<td>1</td>
<td>0.1</td>
<td>13611</td>
</tr>
<tr>
<td>2</td>
<td>0.2</td>
<td>12306</td>
</tr>
<tr>
<td>3</td>
<td>0.3</td>
<td>12151</td>
</tr>
<tr>
<td>4</td>
<td>0.4</td>
<td>13057</td>
</tr>
</tbody></table>
<p>工龄    0<br>薪水    0<br>dtype: int64</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter(<span class="built_in">df</span>[<span class="string">'工龄'</span>], <span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/007.png" alt="photo"></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(10, 4))</span><br><span class="line">plt.subplot(1,2,1)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'工龄'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/008.png" alt="photo"><br>发现数据无异常值和缺失值，接下来我们直接使用各种模型进行应用</p>
<h2 id="拆分数据"><a href="#拆分数据" class="headerlink" title="拆分数据"></a>拆分数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(<span class="built_in">df</span>[[<span class="string">'工龄'</span>]], <span class="built_in">df</span>[<span class="string">'薪水'</span>], test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line">y_pred = lr.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 4855442.658615259<br>r2: 0.8815705091563912</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestRegressor()</span><br><span class="line">rm.fit(x_train, y_train)</span><br><span class="line">y_pred = rm.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 2389839.0208794717<br>r2: 0.9417092449977235</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor(random_state=42)</span><br><span class="line">xgb.fit(x_train, y_train)</span><br><span class="line">y_pred_xgb = xgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_xgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_xgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 3569750.747018099<br>r2: 0.9129299235657095</p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line"></span><br><span class="line">lgb = LGBMRegressor(random_state=42)</span><br><span class="line">lgb.fit(x_train, y_train)</span><br><span class="line">y_pred_lgb = lgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_lgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_lgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 3749728.9875734868<br>r2: 0.9085400598827179</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.svm import SVR</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line">svr_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">'svr'</span>, SVR(kernel=<span class="string">'rbf'</span>, C=100, gamma=<span class="string">'scale'</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">svr_pipeline.fit(x_train, y_train)</span><br><span class="line">y_pred = svr_pipeline.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 19519338.352298636<br>r2: 0.5239022546038833<br>发现其效果并不好 SVM需要进行调参 使用网格优化</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = {</span><br><span class="line">    <span class="string">'svr__C'</span>: [0.1, 1, 10, 100, 1000],</span><br><span class="line">    <span class="string">'svr__gamma'</span>: [<span class="string">'scale'</span>, <span class="string">'auto'</span>, 0.001, 0.01, 0.1, 1],</span><br><span class="line">    <span class="string">'svr__kernel'</span>: [<span class="string">'rbf'</span>, <span class="string">'poly'</span>, <span class="string">'linear'</span>]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">grid = GridSearchCV(svr_pipeline, param_grid, cv=5, scoring=<span class="string">'r2'</span>, n_jobs=-1)</span><br><span class="line">grid.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳参数:"</span>, grid.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳交叉验证r2:"</span>, grid.best_score_)</span><br><span class="line"></span><br><span class="line">y_pred = grid.predict(x_test)</span><br></pre></td></tr></table></figure></div>
<p>最佳参数: {‘svr__C’: 1000, ‘svr__gamma’: ‘scale’, ‘svr__kernel’: ‘rbf’}<br>最佳交叉验证r2: 0.8533151968605445</p>
<h1 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h1><p>上述五种模型的成绩为</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>r2</th>
</tr>
</thead>
<tbody><tr>
<td>线性回归</td>
<td>0.881</td>
</tr>
<tr>
<td>随机森林</td>
<td>0.941</td>
</tr>
<tr>
<td>XGBoost</td>
<td>0.912</td>
</tr>
<tr>
<td>LGBM</td>
<td>0.908</td>
</tr>
<tr>
<td>SVM</td>
<td>0.853</td>
</tr>
</tbody></table>
<p>我们看到 面对同一份数据 不同的模型 其成绩各不相同<br>在使用线性回归的时候 我们通常假定变量和目标之间存在线性关系 即y=kx 当变量和目标之间的确是存在线性关系时 模型得分会很高 若变量和目标之间不是线性关系 例如 y=kx^2 那线性回归的得分肯定不高<br>线性回归的特点是<strong>简单 复杂性低 泛化稳定 但容易欠拟合</strong></p>
<p>随机森林属于集成算法 训练大量决策树 每颗树用不同的有放回抽烟者 每次分裂时在随机子集特征上寻找最优划分 回归任务就取树预测的平均值<br>随机森林的特点是<strong>鲁棒性好 对异常值不敏感 免交叉验证 对低维数据表现有限</strong></p>
<p>XGBoost是基于梯度提升对思想 逐步构建决策树 每棵树拟合前一轮的残差 采用二阶泰勒展开来加速优化 加入正则化项控制复杂度<br>XGBoost的特点是<strong>准确率高 适用性强 超参数多 调参麻烦</strong></p>
<p>LGBM是一种高效的梯度提升框架<br>LGBM的特点是<strong>训练和预测速度快 内存占用小 适合稀疏数据 容易过拟合</strong></p>
<p>SVM原理是在高维空间中找到一个<strong>最优超平面</strong> 使得不同类别的样本间隔最大 在回归时 使预测函数在一定容忍范围内尽量平滑<br>SVM的特点是<strong>泛化能力强 适合高维小样本 核函数灵活 计算复杂度高 参数敏感 可解释性差</strong></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>一周科技资讯第一期</title>
    <url>/zhihaojiang.github.io/2025/06/15/20250615%E4%B8%80%E5%91%A8%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF%E7%AC%AC%E4%B8%80%E6%9C%9F/</url>
    <content><![CDATA[<h1 id="大模型强化学习新突破——SPO新范式助力大模型推理能力提升！"><a href="#大模型强化学习新突破——SPO新范式助力大模型推理能力提升！" class="headerlink" title="大模型强化学习新突破——SPO新范式助力大模型推理能力提升！"></a>大模型强化学习新突破——SPO新范式助力大模型推理能力提升！</h1><h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>机器之心<br><a class="link"   href="https://www.jiqizhixin.com/articles/2025-06-08-6" >https://www.jiqizhixin.com/articles/2025-06-08-6<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>当前，强化学习（RL）在提升大语言模型（LLM）推理能力方面展现出巨大潜力。DeepSeek R1、Kimi K1.5 和 Qwen 3 等模型充分证明了 RL 在增强 LLM 复杂推理能力方面的有效性。</p>
<p>然而，要实现有效的强化学习，需要解决一个根本性的挑战，即信用分配问题（credit assignment）：在大语言模型的场景下，如何将整个序列（LLM 的回复）最终的评估结果，归因到序列中具体的决策动作（token）上。</p>
<p>这一问题的困难在于奖励信号非常稀疏 — 只能在序列结束时才能获得明确的成功或失败反馈。</p>
<h2 id="当前主要方法"><a href="#当前主要方法" class="headerlink" title="当前主要方法"></a>当前主要方法</h2><p>在强化学习中，通常采用优势值估计（advantage estimation）的方法来解决信用分配问题。目前针对大语言模型的强化学习方法主要分为两类，它们之间的区别在于优势值估计的粒度不同。</p>
<p>粗粒度的轨迹级 (trajectory-level) 方法，如 DeepSeek R1 使用的 GRPO，只根据最终的奖励为整个序列计算一个优势值。这种方法虽然高效但反馈信号过于粗糙，LLM 无法对错误回答中正确的部分进行奖励，也无法对正确回答中冗余的部分进行惩罚。</p>
<p>另一种极端是细粒度的 token 级（token-level）方法，如经典的 PPO。这类方法为每个 token 估计优势值，需要依赖额外的 critic 模型来预测每个 token 的状态价值（V 值）。然而，在大语言模型的强化学习任务中，不同 prompt 对应的轨迹分布差异很大，而且在训练过程中每个 prompt 采样出来的模型回复数量非常有限，critic 模型难以训练好，造成 token 级的优势值估计误差很大。</p>
<h2 id="新的-SPO-框架"><a href="#新的-SPO-框架" class="headerlink" title="新的 SPO 框架"></a>新的 SPO 框架</h2><p>为突破这一瓶颈，来自中科院软件所和香港城市大学的的研究团队创新性提出了 Segment Policy Optimization (SPO) 框架。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-0.png"
                      alt="photo"
                ></p>
<blockquote>
<p>论文题目：Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models</p>
<p>作者：Yiran Guo, Lijie Xu, Jie Liu, Dan Ye, Shuang Qiu</p>
<p>链接：<a class="link"   href="https://arxiv.org/abs/2505.23564" >https://arxiv.org/abs/2505.23564<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>代码链接：<a class="link"   href="https://github.com/AIFrameResearch/SPO" >https://github.com/AIFrameResearch/SPO<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> </p>
</blockquote>
<p>SPO 使用了一种中等粒度的段级（segment-level）优势值估计方式。它不像轨迹级方法只在最后一步计算优势，也不像 token 级方法每步都计算优势，而是将生成的序列划分为若干相连的段，计算每个段的优势值。</p>
<p>这种段级的优势值估计方式具有几个明显的优势：</p>
<p>(1) 更优的信用分配：相比轨迹级方法，段级方法能够提供更局部化的优势反馈，让模型能够奖励错误回答中仍然有价值的部分，同时也能惩罚正确回答中冗余和无效的片段。</p>
<p>(2) 更准确的优势值估计：相比 token 级方法，段级方法所需的估计点数量更少，从而能够有效利用蒙特卡洛（Monte Carlo, MC）采样得到更加准确且无偏的优势值估计，而无需再依赖额外且不稳定的 critic 模型。</p>
<p>(3) 更灵活、更易调整：段级的划分方式可以任意定义，并不要求语义上的完整性，因此可以灵活地在 token 级与轨迹级之间自由调整粒度，并且可以适应不同的任务和应用场景。</p>
<p>SPO 框架主要包含三个核心部分：(1) 灵活的段级划分策略；(2) 基于蒙特卡洛采样的段级优势值估计；(3) 利用段级优势值进行策略优化。</p>
<p>这种模块化的设计使框架具备高度的灵活性，不同的部分可以有不同的实现策略，以适用不同的应用场景。</p>
<p>该团队进一步针对不同的推理场景提出 SPO 框架的两个具体实例：对于短的思维链（chain-of-thought, CoT）场景，提出了 SPO-chain，该方法使用基于切分点（cutpoint-based）的段划分和链式优势值估计；对于长 CoT 场景，提出极大提升 MC 采样效率的树形结构优势值估计方法。</p>
<p>此外，该团队还提出了一种 token 概率掩码（token probability-mask）策略优化方法，选择性的对段内的低概率 token 计算损失而非段内的所有 token。作者认为这些 token 是模型推理轨迹可能发生分叉的地方，是段级优势值产生的主要原因。这种方法可以用于 SPO-chain 和 SPO-tree，从而进一步强化信用分配。</p>
<h2 id="框架及核心技术"><a href="#框架及核心技术" class="headerlink" title="框架及核心技术"></a>框架及核心技术</h2><p>SPO 框架主要围绕以下三个具有挑战性的问题进行设计：(1) 如何将生成的序列划分为多个段？(2) 如何准确且高效地估计每个段对应的优势值？(3) 如何利用段级优势值来更新策略？SPO 的三个核心模块分别解答上面三个问题，每个模块包含多种可选策略，来适用于不同的场景：<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-1.png"
                      alt="photo"
                ></p>
<ol>
<li>段划分 (Segment Partition):</li>
</ol>
<p>a) 基于切分点的段划分 (Cutpoint-based Partition): 为短思维链场景设计，将段划分点放置在状态值（V 值）更有可能发生变化的地方。根据 token 概率动态确定段边界，优先在模型 “犹豫” 或可能改变推理路径的关键点（cutpoints）进行划分，使信用分配更精确。比如，在下图例子中，标记为红色的 token 是关键点，而标记为蓝色的竖杠是分段结果。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-2.png"
                      alt="photo"
                ><br>b) 固定 token 数量段划分 (Fixed Token Count Partition): 将序列划分为固定长度的段，便于树形结构的组织和优势值估计，为 SPO-tree 设计。</p>
<ol start="2">
<li>段级优势值估计（Segment Advantage Estimation）：</li>
</ol>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-3.png"
                      alt="photo"
                ><br>a) 链式优势值估计 (Chain-based) 方法：在短思维链场景下，MC 采样的成本不高，该团队采用一种直接的段级优势值估计方式，独立估计每个段边界的状态值（V 值），然后计算段级优势值。以下公式展示了链式优势值的估计方法。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-4.png"
                      alt="photo"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-5.png"
                      alt="photo"
                ><br>b) 树形优势值估计 (Tree-based): 在长思维链场景下，MC 估计的代价很高，团队提出了一种高效的树形估计方法：将采样轨迹组织成树形结构，通过自底向上的奖励聚合计算状态价值（V 值），同一个父节点的子节点形成一个组，在组内计算每个段的优势值。这种方式将用于 V 值估计的样本同时用于策略优化，极大提高了样本效率。以下公式展示了树形优势值估计方法。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-6.png"
                      alt="photo"
                ><br>3. 基于段级优势值 token 概率掩码策略优化（Policy Optimization Using Segment Advantages with Token Probability-mask）：<br>在得到段级优势值以后，为了进一步提高信用分配，团队创新性地提出 token 概率掩码策略优化方法，在策略更新仅将段级优势值分配给该段内的低概率（关键）token，而非所有 token。这种方法能更精确地将奖励 &#x2F; 惩罚赋予关键的决策点，提升学习效率和效果。下面分别展示了 SPO-chain 和 SPO-tree 的优化目标。</p>
<p>a) SPO-chain 优化目标：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-7.png"
                      alt="photo"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-8.png"
                      alt="photo"
                ><br>b) SPO-tree 优化目标：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-9.png"
                      alt="photo"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-10.png"
                      alt="photo"
                ></p>
<h2 id="对比基线方法"><a href="#对比基线方法" class="headerlink" title="对比基线方法"></a>对比基线方法</h2><p>如下图所示，在短思维链场景，使用 RhoMath1.1B 作为基座模型，使用 GSM8K 训练集进行训练，对比各种训练算法，使用 SPO 训练得到的模型测试集正确率更高。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-11.png"
                      alt="photo"
                ><br>对于长思维链场景，如下图所示，使用 DeepSeek-R1-Distill-Qwen-1.5B 作为基座模型，使用 MATH 数据集进行训练，在相同的训练时间下，测试集正确率比 GRPO 更高。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-12.png"
                      alt="photo"
                ><br>下表展示了在长思维链场景下的更多对比结果：与同期基于相同基座模型（DeepSeek-R1-Distill-Qwen-1.5B）并使用 GRPO 方法训练得到的模型（DeepScaleR、STILL-3）相比，尽管 SPO 仅使用 MATH 数据集且仅使用 4K 的最大上下文长度进行训练，SPO-tree 在各个上下文长度评测下表现优秀。值得注意的是，尽管 DeepScaleR 在 32K 上下文长度评测下表现最佳，但它在较短上下文长度（2K 与 4K）下却表现最差，甚至不及原始基座模型。这表明，GRPO 训练方法可能未有效优化模型的 token 效率，导致输出存在较多冗余，从而在上下文长度有限的情形下出现正确率下降的问题。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-13.png"
                      alt="photo"
                ></p>
<h2 id="分段粒度的影响"><a href="#分段粒度的影响" class="headerlink" title="分段粒度的影响"></a>分段粒度的影响</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-14.png"
                      alt="photo"
                ><br>通过实验发现，很细的粒度 (int2，每个两个切分点进行分段)，相比于中等粒度 (int5)，仅有微小提升，但是过粗的粒度 (int100)，相比于中等粒度 (int5)，正确率下降很大。证明了 SPO 采用中等粒度优势值的有效性。</p>
<h2 id="段划分方式的影响"><a href="#段划分方式的影响" class="headerlink" title="段划分方式的影响"></a>段划分方式的影响</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-15.png"
                      alt="photo"
                ><br>实验表明，在短思维链场景下，采用提出的基于切分点的段划分方式效果最好，优于采用换行符进行划分（VinePPO）以及固定 token 数量划分（Fixed-token-count）。</p>
<h2 id="Token-概率掩码消融"><a href="#Token-概率掩码消融" class="headerlink" title="Token 概率掩码消融"></a>Token 概率掩码消融</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-16.png"
                      alt="photo"
                ><br>实验表明，将 token 概率掩码去除会导致 SPO-chain 正确率下降，更值得注意的是：将 token 概率掩码应用到 GRPO 上，会让其正确率有明显上升。</p>
<h2 id="不同树结构的影响"><a href="#不同树结构的影响" class="headerlink" title="不同树结构的影响"></a>不同树结构的影响</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/640-17.png"
                      alt="photo"
                ><br>实验表明，更小的树结构在早期正确率更高，可能因为更快扫过更多的数据样本。然而随着训练的进行，更大的树结构会有更好的正确率，因为更大的树结构对于段级优势值的估计更加准确。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>该工作提出了一种基于中间粒度段级优势值的 RL 训练框架 SPO，在 token 级和轨迹级之间更好的平衡，具有比轨迹级更好的信用分配，同时仅需要少量优势值估计点，可以使用有效无偏的 MC 方式进行估计，不需要额外的 critic 模型。</p>
<p>文章同时提出了 SPO 的两个实例，为短思维链场景设计的 SPO-chain 以及为长思维链场景设计的 SPO-tree，通过实验证明了 SPO 框架和两个实例的有效性。</p>
<h1 id="通过扩展费马大定理背后的关键见解的范围，四位数学家在构建数学“大统一理论”方面取得了巨大进步。"><a href="#通过扩展费马大定理背后的关键见解的范围，四位数学家在构建数学“大统一理论”方面取得了巨大进步。" class="headerlink" title="通过扩展费马大定理背后的关键见解的范围，四位数学家在构建数学“大统一理论”方面取得了巨大进步。"></a>通过扩展费马大定理背后的关键见解的范围，四位数学家在构建数学“大统一理论”方面取得了巨大进步。</h1><h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://www.quantamagazine.org/the-core-of-fermats-last-theorem-just-got-superpowered-20250602/%E3%80%81" >https://www.quantamagazine.org/the-core-of-fermats-last-theorem-just-got-superpowered-20250602/、<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>1994年，一个震撼数学界的证明——数学家安德鲁·怀尔斯终于解决了费马大定理——这个数论领域的核心问题，三个多世纪以来一直悬而未决。这个证明不仅让数学家们着迷，还登上了《纽约时报》的头版。<br>但为了实现它，怀尔斯（在数学家理查德泰勒的帮助下）首先必须证明一个更微妙的中间陈述——其含义超出了费马难题。</p>
<p>这个中间证明涉及证明一种名为椭圆曲线的重要方程总是可以与一个完全不同的数学对象（称为模形式）联系起来。怀尔斯和泰勒本质上打开了连接不同数学领域的大门，揭示了每个领域看起来都像是另一个领域的扭曲镜像。怀尔斯和泰勒表明，如果数学家想要理解椭圆曲线，他们可以进入模形式的世界，找到并研究该对象的镜像，然后将他们的结论带回原处。</p>
<p>这种世界之间的联系被称为“模块化”，它不仅帮助怀尔斯证明了费马大定理，数学家们也很快利用它在各种先前难以解决的问题上取得了进展。</p>
<p>模块化也构成了朗兰兹纲领的基础。朗兰兹纲领是一套旨在发展数学“大统一理论”的宏大猜想。如果这些猜想成立，那么椭圆曲线以外的各种方程都将同样与其镜像域中的对象相联系。数学家将能够随心所欲地在两个世界之间跳跃，从而解答更多问题。</p>
<p>然而，证明椭圆曲线与模形式之间的对应关系却异常困难。许多研究人员认为，建立一些更为复杂的对应关系几乎是不可能的。</p>
<p>现在，一个由四位数学家组成的团队证明了他们错了。今年二月，他们终于成功扩展了模块化连接从椭圆曲线到更复杂的方程式，即阿贝尔曲面。团队——弗兰克·卡莱加里芝加哥大学乔治·博克瑟和托比·吉伦敦帝国理工学院和Vincent Pilloni法国国家科学研究中心的研究人员证明了，属于某一主要类别的每个阿贝尔曲面总是可以与一个模形式相关联。</p>
<p>Ana Caraiani表示：“我们大多相信所有的猜测都是正确的，但看到它真正实现，我们感到非常兴奋。”伦敦帝国理工学院的数学家。“而且这是你真的以为遥不可及的事情。”</p>
<p>这只是一场耗时多年的探索的开始——数学家们最终希望证明每个阿贝尔曲面都具有模性。但这一结果已经能够帮助解答许多悬而未决的问题，就像证明椭圆曲线的模性开辟了各种新的研究方向一样。</p>
<h2 id="挑战数学界的「禁区」"><a href="#挑战数学界的「禁区」" class="headerlink" title="挑战数学界的「禁区」"></a>挑战数学界的「禁区」</h2><p>椭圆曲线是一种非常基本的方程类型，它只包含两个变量——x和y 。如果你画出它的解，你会看到一些看似简单的曲线。但这些解之间有着丰富而复杂的相互关联，并且它们出现在数论的许多重要问题中。例如，伯奇和斯温纳顿-戴尔猜想——数学中最难的开放性问题之一，第一个证明它的人将获得100万美元的奖励——就是关于椭圆曲线解的性质的。</p>
<p>椭圆曲线很难直接研究。因此，数学家有时喜欢从不同的角度来研究它们。</p>
<p>这就是模形式发挥作用的地方。模形式是一种高度对称的函数，它出现在一个表面上独立的数学研究领域——分析。由于模形式表现出如此多的良好对称性，因此更容易处理。</p>
<p>乍一看，这些对象似乎毫无关联。但泰勒和怀尔斯的证明表明，每条椭圆曲线都对应一个特定的模形式。它们具有某些共同的性质——例如，描述椭圆曲线解的一组数字也会出现在其对应的模形式中。因此，数学家可以利用模形式对椭圆曲线获得新的见解。</p>
<p>但数学家们认为泰勒和怀尔斯的模定理只是一个普遍事实的例子。除了椭圆曲线之外，还有一类更为普遍的对象。所有这些对象在更广阔的对称函数世界（例如模形式）中也应该有一个伙伴。这本质上就是朗兰兹纲领的全部内容。</p>
<p>椭圆曲线只有两个变量——x和y——因此可以画在平面纸上。但如果添加另一个变量z，就会得到一个存在于三维空间中的曲面。这种更复杂的物体被称为阿贝尔曲面，与椭圆曲线一样，它的解也具有数学家们渴望理解的复杂结构。</p>
<p>阿贝尔曲面对应着更复杂的模形式，这似乎很自然。但额外的变量使得它们的构造更加困难，解也更加难求。证明它们也满足模性定理似乎完全遥不可及。“这是一个众所周知的问题，人们不去思考，因为人们思考过却陷入了困境，”吉说道。</p>
<p>但 Boxer、Calegari、Gee 和 Pilloni 想要尝试。</p>
<h2 id="寻找桥梁"><a href="#寻找桥梁" class="headerlink" title="寻找桥梁"></a>寻找桥梁</h2><p>这四位数学家都参与了朗兰兹纲领的研究，他们想要用“现实生活中真正出现的物体，而不是某种奇怪的东西”来证明其中一个猜想，卡莱加里说。</p>
<p>阿贝尔曲面不仅在现实生活中出现——确切地说，在数学家的生活中——而且证明关于它们的模性定理将打开新的数学大门。“如果你有了这个命题，你就能做很多事情，而如果没有这个命题，你就无法做到，”卡莱加里说。</p>
<p>这两位数学家于2016年开始合作，希望遵循泰勒和怀尔斯证明椭圆曲线时的步骤。但对于阿贝尔曲面来说，这些步骤中的每一个都复杂得多。</p>
<p>因此，他们专注于一种特殊类型的阿贝尔曲面，称为普通阿贝尔曲面，这种曲面更容易处理。任何这样的曲面，都有一组数字描述其解的结构。如果他们能证明同一组数字也能从模形式推导出来，那就大功告成了。这些数字将充当一个独特的标签，让他们能够将每个阿贝尔曲面与一个模形式配对。</p>
<p>问题在于，虽然对于给定的阿贝尔曲面，这些数字很容易计算，但数学家们却不知道如何构造一个具有完全相同标记的模形式。当需求如此受限时，模形式实在太难构建了。“你正在寻找的对象，你并不知道它们真的存在，”皮洛尼说。</p>
<p>相反，数学家们证明了，只需构造一个模形式，其数值在较弱的意义上与阿贝尔曲面的数值相匹配就足够了。该模形式的数值只需在所谓的时钟算术领域等价即可。</p>
<p>想象一个时钟：如果时针从 10 开始，经过四个小时，时钟将指向 2。但是时钟算术可以用任何数字来完成，而不仅仅是（就像现实世界的时钟一样）数字 12。</p>
<p>Boxer、Calegari、Gee 和 Pilloni 只需要证明，当他们使用一个精确到 3 的时钟时，他们的两组数字相匹配。这意味着，对于给定的阿贝尔曲面，数学家在构建相关模形式时具有更大的灵活性。</p>
<p>但事实证明，即便如此，这也太难了。</p>
<p>然后，他们偶然发现了大量模形式，其对应的数字很容易计算——只要他们根据最高可达 2 的时钟来定义它们的数字。但阿贝尔曲面需要一个最高可达 3 的时钟。</p>
<p>数学家们对如何粗略地连接这两个不同的时钟已经有了想法。但他们不知道如何使这种连接严密无懈可击，以便在模形式的世界中找到与阿贝尔曲面真正匹配的公式。后来，一个新的数学概念出现了，结果证明这正是他们所需要的。</p>
<h2 id="惊喜帮助"><a href="#惊喜帮助" class="headerlink" title="惊喜帮助"></a>惊喜帮助</h2><p>2020 年，数论学家潘略发布了证明关于模块化形式的研究，起初似乎与四人组的问题无关。但他们很快意识到，他所开发的技术出奇地相关。“我没想到，”潘说。</p>
<p>经过多年的定期会议（主要通过Zoom），数学家们开始在应用潘建伟的技术方面取得进展，但主要的障碍仍然存在。后来，在2023年夏天，Boxer、Gee和Pilloni认为在德国波恩举行的一次会议是他们聚在一起的绝佳机会。唯一的问题是，Calegari原计划在同一时间前往中国发表演讲。但一次前往芝加哥中国领事馆的艰难旅程让他重新考虑了这个想法。“八小时后，我的签证被拒签了，我的车也被拖走了，”他说。他决定放弃在中国的演讲，前往德国与他的同事们会合。</p>
<p>吉为团队在豪斯多夫研究所的地下室安排了一间房间，这样他们就不太可能被四处奔波的数学家打扰。在那里，他们花了整整一周的时间研究潘氏定理，日复一日，连续工作12个小时，只是偶尔上到地面喝咖啡。“喝完咖啡后，我们总是开玩笑说，我们得回矿井了，”皮洛尼说。</p>
<p>努力终有回报。“后来虽然有很多波折，”卡莱加里说，“但到那一周结束的时候，我觉得我们差不多成功了。”</p>
<p>又花了一年半的时间，才将卡莱加里的定罪证明整理成长达 230 页的证据，并于 2 月份将其发布到网上. 把所有的碎片放在一起，他们证明了任何普通的阿贝尔曲面都有一个相关的模形式。</p>
<p>他们的新门户未来或许能像泰勒和怀尔斯的成果一样强大，揭示出比任何人想象的都更多的关于阿贝尔曲面的信息。但首先，团队必须将他们的成果扩展到非常规阿贝尔曲面。他们已经与潘合作继续探索。“十年后，如果我们还没能找到几乎所有的阿贝尔曲面，那我才惊讶，”吉说道。</p>
<p>这项工作也使数学家们得以提出新的猜想——例如伯奇和斯温纳顿-戴尔猜想的类似猜想，它涉及阿贝尔曲面而非椭圆曲线。安德鲁·萨瑟兰说：“现在我们至少知道，对于这些普通曲面来说，这种类似猜想是合理的。”麻省理工学院的数学家。“以前我们不知道这一点。”</p>
<p>“我曾经梦想有一天能够证明的很多事情，现在都因为这个定理而触手可及了，”他补充道，“它改变了一切。”</p>
<h1 id="第一张由固体秘密量子几何构成的地图"><a href="#第一张由固体秘密量子几何构成的地图" class="headerlink" title="第一张由固体秘密量子几何构成的地图"></a>第一张由固体秘密量子几何构成的地图</h1><h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="http://quantamagazine.org/first-map-made-of-a-solids-secret-quantum-geometry-20250606/" >http://quantamagazine.org/first-map-made-of-a-solids-secret-quantum-geometry-20250606/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>物理学家最近利用一种有望普及的新方法绘制出了晶体量子行为背后的隐藏形状。</p>
<p>众所周知，在量子尺度上，粒子可以同时处于多个可能的位置。粒子的状态像波一样向外扩散，在其可能出现的位置达到峰值。当你测量它的位置时，这种扩散状态（称为波函数）会转变为一个确定的位置。</p>
<p>波函数的完整形状长期以来一直难以探测，因为试图测量它会破坏它。但在20世纪80年代，物理学家开始开发测量和控制简单系统波函数的方法——这些进步后来构成了量子计算的基础。而在过去几年里，一种新的方法使物理学家能够更进一步，了解整个材料的波函数。</p>
<p>里卡多·科明说：“我们正处于第二次量子革命。”麻省理工学院实验物理学家，也是这项工作的领导者之一。“现在，我们拥有了真正探索量子粒子波函数的工具。”</p>
<p>新框架将波函数描述为一个在隐藏景观中移动的物体——这个空间被称为物质的“量子几何”。这个看不见的世界的山丘和山谷决定了给定物质的波函数如何变化，以及物质可以处于什么状态。</p>
<p>马克·博克拉斯说：“你可以深入了解量子材料中发生的事情，这可能会加速新现象的发现。”他是俄亥俄州立大学的物理学家，也是量子几何学领域的领军人物。</p>
<p>Comin 和他的同事最近测量了晶体的完整量子几何形状— 首次窥视真实材料的波函数。</p>
<p>让我们探索一下即将出现的隐藏景观。</p>
<h2 id="秘密几何"><a href="#秘密几何" class="headerlink" title="秘密几何"></a>秘密几何</h2><p>物理学家通常将粒子的波函数想象成一支箭头。如果粒子有两种可能的状态，他们就把这些选项表示为箭头指向的相反方向——比如向上和向下。如果粒子同时处于两种状态，那么箭头指向球体周围的某个位置，这两种状态分别对应极点。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/000.jpg"
                      alt="photo"
                ></p>
<p>箭头的方向反映了每种可能性的相对可能性。测量粒子会使箭头指向正上方或正下方，而每种结果的概率取决于它最接近哪个极点。</p>
<p>许多粒子拥有两种以上的可能状态，在这种情况下，箭头占据着一个高维空间。这无法直观地呈现，但数学知识能让物理学家了解粒子在特定时刻的波函数。</p>
<p>对于由许多粒子构成的材料，一个高维箭头可以表示其内部所有电子的组合状态。随着材料周围环境条件（例如温度或周围磁场强度）的改变，这个集合箭头会随之摆动。为了控制一种材料，物理学家需要知道在转动这些不同的旋钮时，箭头会如何旋转。</p>
<p>为了追踪，他们绘制了一张地图。例如，想象一下，你改变施加于材料上的磁场强度。在你的地图上，你将使东西方向与磁场强度相对应。当磁场较弱时（对应地图上的西），电子的波函数会处于某种状态，你可以用箭头表示。当磁场较强时，你的位置会更靠东，波函数也会呈现不同的状态。当你在地图上从西向东移动时，箭头会旋转，显示电子的波函数如何随着磁场的增减而变化。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/001.png"
                      alt="photo"
                ><br>此图可扩展，捕捉所有可调整材质的方式。每个可调节的旋钮或参数都会在图中增加一个可移动的新维度。</p>
<p>想象一下，当你在地图上移动时，追踪箭头旋转的速度。有了这些信息，地图就变成了3D，就像你在绘制山脉一样。地图上每个部分的地势越陡峭，电子的波函数围绕这些参数值的变化就越大。如果变化很大，你就在山上。如果一点变化都没有，你就在平地上。</p>
<p>一种名为量子度量的数学对象捕捉了这种景观的形状。它通过描述两点之间最短距离的路径来实现这一点。正如从纽约飞往北京的飞机不会穿过地球，而是会在地球表面弯曲飞行一样，两个量子态之间的路径揭示了它们所处的底层几何形状。</p>
<p>波函数的这种神秘几何结构几十年来一直未被发现。但当量子材料开始以其难以解释的行为让物理学家们感到惊讶时，20世纪80年代的物理学家们意识到，其中一些行为可以用材料波函数绕弯曲形状传播来解释。</p>
<p>想象一下，一支箭在平面上移动。它的方向不会改变。但在曲面上，当它绕着一个闭合的圆环移动后，箭头指向的方向会与它开始时不同。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/002.png"
                      alt="photo"
                ><br>同样的事情也可能发生在量子态上。想象一下，改变一种材料的条件，使波函数在图中移动，然后再将材料恢复到其初始状态。如果现在它的箭头指向一个新的方向，那么这种材料就是“拓扑的”：它隐藏的底层形状迫使材料进入了一种新的状态。</p>
<p>由底层拓扑结构引起的方向变化被称为贝里相，以推广这一概念的英国理论物理学家迈克尔·贝里的名字命名这个相位在循环路径上累积的方式称为贝里曲率，指的是箭秘密穿越的弯曲形状。</p>
<p>对科明来说，贝里相是“固体量子理论中最迷人的概念之一”。尽管贝里相长期以来未被实验者发现，但它却能产生奇异的物理后果。</p>
<h2 id="撒糖甜甜圈"><a href="#撒糖甜甜圈" class="headerlink" title="撒糖甜甜圈"></a>撒糖甜甜圈</h2><p>这种抽象的几何学在像科明这样的物理学家研究晶体（原子以重复模式排列的晶格）的实验室中变得栩栩如生。近年来，他们发现二维晶体（原子的扁平晶格，电子可以在其中双向移动）具有各种各样的量子行为。让我们看看为什么二维晶体的量子几何图会呈现出一种甜甜圈状的形状，称为环面。</p>
<p>一般来说，晶体中重复的模式限制了其中电子的可能状态。电子可以快速流动、缓慢流动，或者根本不流动，每种选择都对应着不同的集体波函数。对于二维晶体，​​物理学家可以在一张纸上绘制出可能状态的图：每个坐标对应于电子在垂直和水平方向上可能的动量。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/003.png"
                      alt="photo"
                ><br>由于晶体状态图会重复出现，因此沿着平面图边缘的一个方向移动会将你带回到另一侧。为了证明这一点，物理学家将平面图卷绕两次。首先，平面图变成圆柱体，然后圆柱体的两端相接，形成一个圆环。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/004.png"
                      alt="photo"
                ><br>改变条件，例如通过晶体运行电流，将改变电子的运动，这将推动这个圆环状地图上的箭头。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/005.png"
                      alt="photo"
                ><br>尤其是对于拓扑材料来说，调节旋钮，然后回到初始条件——换句话说，沿着环面追踪一条循环路径——会使电子的箭头指向与之前不同的方向。这意味着多个箭头，或者说波函数，可以在环面上的同一点共存，从而形成一个“不连续点”。</p>
<p>当电子经过这样的点时，它们的集体箭头突然翻转，材料的状态发生剧烈变化。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/09/006.png"
                      alt="photo"
                ><br>这种效应类似于电荷通过时，电子所受的力也会发生翻转。因此，拓扑材料可以被解读为承载着幽灵电荷，这些电荷会导致电子移动，就像感受到一个并不存在的力场一样。</p>
<p>20世纪80年代发现的“幽灵场”巩固了量子态隐藏几何结构与材料行为之间的联系。这项研究成果荣获2016年诺贝尔物理学奖。</p>
<h2 id="未知领域"><a href="#未知领域" class="headerlink" title="未知领域"></a>未知领域</h2><p>拓扑材料已不再神秘：物理学家们通常利用它们来发现物质的新相，并探索其在量子计算中的潜力。但直到最近，他们才开始欣赏量子几何的更完整图景，它不仅包括贝里曲率，还包括量子度规——一种存在于环面形地图顶部的崎岖地形的形状。几年前，量子度规帮助研究人员理解了二维晶体中发生的情况，这种晶体中存在着一种奇特的新型超导性。— 无阻力的电流流动。</p>
<h1 id="新的量子算法用一个量子比特分解数字"><a href="#新的量子算法用一个量子比特分解数字" class="headerlink" title="新的量子算法用一个量子比特分解数字"></a>新的量子算法用一个量子比特分解数字</h1><p>量子计算机目前仍然能力有限。几乎每次研究人员发现这些高科技机器未来应该擅长的领域时，总会有一种经典算法在普通计算机上也能同样出色地完成。一个值得注意的例外？分解数字。1994年，数学家彼得·肖尔（Peter Shor）设计了一种算法，使量子计算机能够以比传统机器更快的速度对大数进行因式分解。这种加速至关重要，因为快速因式分解算法可以使大多数数据加密方法失效。30多年来，研究人员一直在努力提升未来量子计算机的性能，并防范其进一步发展。</p>
<p>但Shor的因式分解算法也有局限性：要分解的数字越大，所需的量子计算机就越大、性能就越好。破解一个加密方案需要一台量子计算机在数十万台计算机上运行Shor的算法。高效量子比特（qubits）的计算能力。而如今的机器还远远达不到这个水平。</p>
<p>但一篇论文发布在科学预印本网站arxiv.org上的一篇论文描述了如何用少得多的量子比特（仅需一个）对任意数进行因式分解。在这项新研究中，研究人员展示了如何用一个量子比特和三个被称为振荡器的组件（振荡器是一种通常与其他量子技术（如光学系统）相关的现成设备）对任意大小的整数进行因式分解。</p>
<p>需要明确的是，这并非一项实用的进步：这个过程所需的能量比百万量子比特的量子计算机高出数倍。但它确实阐明了解决这类问题的新方法。“这不同于我们对计算的典型思考方式——不仅是量子计算，还有经典计算，” Ulysse Chabaud说。巴黎高等师范学院的计算机科学家，他没有参与这项新方法的研究。“这看起来很疯狂，甚至是不可能的。”</p>
<h2 id="良好的振荡"><a href="#良好的振荡" class="headerlink" title="良好的振荡"></a>良好的振荡</h2><p>归根结底，新方法之所以有效，在于其信息编码方式。经典计算机使用比特，比特可以取两个值之一。而量子比特，由于量子力学的复杂性，可以取多个值。但即使是量子比特，一旦被测量，也只能取两个值之一：0 或 1。</p>
<p>但罗伯特·科尼格表示，这并不是在量子设备中编码数据的唯一方法和卢卡斯·布伦纳慕尼黑工业大学。他们的工作重点是研究如何利用连续变量对信息进行编码，这意味着它们可以采用给定范围内的任意值，而不仅仅是某些特定的值。</p>
<p>过去，研究人员曾尝试改进Shor的因式分解算法，方法是使用连续系统模拟量子比特，并扩展其可能值集。但即使你的系统使用连续量子比特进行计算，它仍然需要大量的量子比特来分解数字，而且计算速度不一定更快。“我们想知道是否有更好的方法来使用连续变量系统，”König说。</p>
<p>他们决定回归本源。肖尔算法的秘诀在于，它利用被分解的数生成一个研究人员称之为周期函数的函数，该函数的值会以固定的间隔重复出现。然后，它使用一种名为量子傅里叶变换的数学工具来确定该周期的值——也就是函数重复一次所需的时间。由此，一些简单的代数运算就能揭示出原始数的因数。</p>
<p>当 König 和 Brenner 尝试寻找另一种连续的因式分解方法时，他们很快想到了量子振荡器。量子振荡器产生的重复模式，在测量后可以呈现任何连续值（这与量子比特不同）。König 表示，这些模式就像内置的量子傅里叶变换一样。</p>
<p>“我和卢卡斯开始讨论这个混合量子比特振荡器系统，”柯尼格说。但他们当时的想法还很模糊，于是两人请来同事利博·卡哈（Libor Caha）和泽维尔·科伊特-罗伊（Xavier Coiteux-Roy）来设计基于该系统的量子算法。</p>
<p>几个月后，König 团队证明，在使用量子振荡器而非量子比特的系统中，这些物理组件的动态特性确实可以执行因式分解的数学运算——无需模拟量子比特的离散值。他们系统中的单个量子比特读取并组织振荡器中的信息，但并不像其他量子计算机中的量子比特那样执行实际的计算。与 Shor 算法一样，新方法能够在合理的时间内分解整数。</p>
<p>这项研究还指出了在量子计算中实现连续方法的新可能性。“这篇论文表明，通过使用感觉非常合理的操作，他们成功地实现了一些感觉完全不合理的事情，”Chabaud 说。“这是一件非常酷的事情，当结果出来时，我非常兴奋。”</p>
<h2 id="足够短"><a href="#足够短" class="headerlink" title="足够短"></a>足够短</h2><p>但这种方法也有一个陷阱：需要分解的数越大，振荡器进行运算所需的能量就越大。因此，分解一个大数虽然只使用一个量子比特，但却需要几乎难以想象的能量。“如果我给你一个大数进行分解，你就必须利用多颗恒星的能量才能运行算法，更不用说控制发生的一切了，”Chabaud 说。</p>
<p>对于阿拉姆·哈罗麻省理工学院的物理学家认为，这使得新的结果毫无用处。“我不明白用这种方式进行整个计算有什么意义。”</p>
<p>但慕尼黑团队已开始着手通过微调振荡器的数量及其运作方式来降低能耗。“或许，使用更多的振荡器就能降低能耗，”柯尼希说道。</p>
<p>因式分解只是这种新计算方法的应用示例之一；该团队正在寻找其他方法。“我们可以尝试将任何量子计算转化为这种装置，”König 说，“不一定非得是 Shor 算法。”他的团队已经证明，量子比特并非计算的唯一引擎，振荡器也可以充当基本的信息载体。而且，量子设备中现有的其他组件也可能被用来执行计算。</p>
<p>“对我来说，这就是这篇论文真正的创新之处，”Chabaud说。“你实际上可以使用连续变量系统运行一些有趣的算法。”</p>
<h1 id="苹果推出-iPadOS-26，带来全新外观和更强大的多任务处理功能"><a href="#苹果推出-iPadOS-26，带来全新外观和更强大的多任务处理功能" class="headerlink" title="苹果推出 iPadOS 26，带来全新外观和更强大的多任务处理功能"></a>苹果推出 iPadOS 26，带来全新外观和更强大的多任务处理功能</h1><p>iPad 迎来关键软件更新，实现其真正潜力。15年来，iPad 终于获得了可调整大小和移动窗口等重要功能。这些改进使其更像一台真正的电脑，标志着iPad发展的一个重要里程碑。<br>苹果在WWDC上发布了全新的iPadOS 26，带来了重大更新。主要亮点是改进的多任务处理功能，包括全新的窗口系统，允许用户自由调整应用窗口大小和位置。新系统还包含新的文件应用、更多Apple Intelligence功能，以及类似Mac的预览应用，用于查看和编辑PDF。iPadOS 26也采用了受Vision Pro启发的“Liquid Glass”视觉语言，并延续了苹果的命名方式，从版本号改为年份。新的窗口系统可以在Stage Manager中使用，并支持多显示器。<br>iPad 今年迎来了重大更新：苹果刚刚在 WWDC 上发布了其平板电脑操作系统 iPadOS 的新版本。iPadOS 的旗舰功能是用于跨应用多任务处理的全新窗口系统，此外还有全新的文件应用、更多 Apple Intelligence 功能，以及类似 Mac 的预览应用，可用于查看和编辑 PDF。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/10/001.png"
                      alt="photo"
                ><br>与往常一样，新 iPadOS 与新 iOS 有很多共同之处，包括受 Vision Pro 启发的新视觉语言“液态玻璃”。更新后的名称也遵循了苹果的整体方案，从版本号改为年份。iPad 在多任务处理方式、应用程序之间移动方式以及操作系统方面往往有所不同。在 iPadOS 26 中，这种差异比以往任何时候都更加明显：苹果表示，它将允许您“流畅地调整应用程序窗口大小”并将窗口放置在屏幕上的任何位置。窗口系统也可以在 Stage Manager 中使用，并且可以跨显示器工作。Stage Manager 并不总是最直观的 iPad 软件，但这看起来是朝着正确的多任务处理迈出的坚实一步。</p>
<p>iPad 一直以来都横跨 Mac 和 iPhone，有人认为它应该更像其中之一，而不是完全处于两者之间。今年 WWDC 前的传闻似乎暗示了它更以 Mac 为中心，事实也确实如此。iPad 现在有一个菜单栏，你可以从显示屏顶部向下滑动来访问，其中会显示你正在查看的应用程序的各种控制按钮。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/10/002.png"
                      alt="photo"
                ><br>此外，还有一款新的预览应用，苹果称它既可以查看 PDF，也可以标记 PDF（当然，它支持 Apple Pencil）。文件应用中也采用了更 Mac 风格的列表视图。开发者甚至可以让他们的应用在后台运行得更高效，并显示在 Live Activities 中，让你了解当前运行情况。</p>
<p>除了所有高级用户功能外，iPad 还将获得此前仅适用于 iPhone 的 Journal 应用，以及访问 Apple Games hub 的权限，方便用户畅玩所有 Apple 游戏产品。iPad 还新增了一项游戏覆盖功能，让用户无需切换应用即可更新设置并与好友聊天。</p>
<p>新操作系统今日起面向开发者开放。苹果表示，公测版将于下个月发布，更新将于今年秋季正式发布。以下是苹果官方发布的支持设备列表：</p>
<ul>
<li>iPad Pro (M4)</li>
<li>iPad Pro 12.9 英寸（第 3 代及更新机型）、iPad Pro 11 英寸（第 1 代及更新机型）</li>
<li>iPad Air（M2 及更高版本）、iPad Air（第三代及更高版本）</li>
<li>iPad (A16)、iPad（第八代及更高版本）</li>
<li>iPad mini（A17 Pro）、iPad mini（第五代及更高版本）。</li>
</ul>
<h1 id="地球望远镜为宇宙黎明提供了新的视角"><a href="#地球望远镜为宇宙黎明提供了新的视角" class="headerlink" title="地球望远镜为宇宙黎明提供了新的视角"></a>地球望远镜为宇宙黎明提供了新的视角</h1><h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://phys.org/news/2025-06-earth-based-telescopes-fresh-cosmic.html" >https://phys.org/news/2025-06-earth-based-telescopes-fresh-cosmic.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>科学家首次利用地球望远镜回顾过去 130 亿年，以了解宇宙中的第一批恒星如何影响大爆炸发出的光。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/11/001.jpg"
                      alt="photo"
                ><br>天体物理学家利用位于智利北部安第斯山脉高处的望远镜测量了这种偏振微波，从而更清晰地描绘出宇宙历史上最不为人所知的时期之一——宇宙黎明。</p>
<p>“人们认为这不可能在地面上完成。天文学是一个技术受限的领域，而‘宇宙黎明’号发出的微波信号以难以测量而闻名，”项目负责人、约翰·霍普金斯大学物理学和天文学教授托拜厄斯·马里奇说道。“与太空观测相比，地面观测面临着额外的挑战。克服这些障碍使这次测量成为一项重大成就。”</p>
<p>宇宙微波的波长仅为几毫米，非常微弱。偏振微波信号则要弱上百万倍。地球上的无线电广播、雷达和卫星信号可能会掩盖它们的信号，而大气、天气和温度的变化也会使其失真。即使在理想条件下，测量这种微波也需要极其灵敏的设备。</p>
<p>美国国家科学基金会宇宙学大角度尺度探测器（CLASS）项目的科学家使用独特设计的望远镜探测到宇宙大爆炸遗迹中第一批恒星留下的“指纹”——这一壮举此前只有部署在太空的技术才能实现，例如美国国家航空航天局威尔金森微波各向异性探测器（WMAP）和欧洲航天局普朗克太空望远镜。</p>
<p>这项由约翰·霍普金斯大学和芝加哥大学领导的新研究发表在《天体物理学杂志》上。</p>
<p>通过将 CLASS 望远镜的数据与普朗克和 WMAP 太空任务的数据进行比较，研究人员发现了干扰，并缩小了来自偏振微波光的共同信号范围。</p>
<p>当光波遇到某物然后散射时，就会发生偏振。</p>
<p>“当光线照射到汽车引擎盖上时，你会看到眩光，这就是偏振。为了看得清楚，你可以戴上偏光眼镜来消除眩光，”第一作者李云阳（Yunyang Li）说道。李云阳曾是约翰·霍普金斯大学的博士生，后来在研究期间担任芝加哥大学的研究员。</p>
<p>“利用新的通用信号，我们可以确定我们所看到的有多少是从宇宙黎明号引擎盖反射出来的宇宙眩光。”</p>
<p>大爆炸之后，宇宙是一团电子雾，密度之高以至于光能无法逃逸。随着宇宙膨胀和冷却，质子捕获电子形成中性氢原子，微波由此得以自由地穿过其间的空间。在宇宙黎明时期，当第一批恒星形成时，它们强大的能量将电子从氢原子中剥离出来。研究小组测量了来自大爆炸的光子在穿越电离气体云时遇到其中一个被释放的电子并偏离轨道的概率。</p>
<h1 id="中国的复合极端事件与健康风险：综述"><a href="#中国的复合极端事件与健康风险：综述" class="headerlink" title="中国的复合极端事件与健康风险：综述"></a>中国的复合极端事件与健康风险：综述</h1><h2 id="文章来源-4"><a href="#文章来源-4" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="http://sciencedirect.com/science/article/pii/S1674283425000595?via=ihub" >http://sciencedirect.com/science/article/pii/S1674283425000595?via%3Dihub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>中国一项研究表明，复合型极端天气事件正在中国构成潜在的健康危机。这些复合事件，如干旱与热浪并存，或洪涝与空气污染齐至，其综合影响对公众健康构成日益严重的威胁。研究揭示了这些复合事件发生的频率增加，以及它们对不同地区人口健康的影响。该研究强调了应对气候变化和减轻复合极端事件对健康影响的必要性。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/11/002.jpg"
                      alt="photo"
                ><br>在全球恐慌的背景下，中国面临严峻的严酷和严重的极端气候天气事件，其中以多种气候驱动因子和&#x2F;或灾害应对而导致的复合型极端事件风险亟待突出。 本文首先回顾了中国区域复合型极端事件的定义与划分型； 然后综述了不同类型复合型极端事件的演变特征，形成了机制以及未来股票等方面的研究进展； 探讨了日夜持续型极端高温事件、温湿复合事件以及高温复合事件等三类事件对我国人群健康的潜在风险及可能的影响途径； 最后，风险阐述了复合型极端事件灾害评估框架，并在此基础上提出了基于碳中和目标的应对策略。 在总结上述研究成果的基础上，提出了五个未来预测需关注的研究方向：（1）复合事件灾害风险链的识别问题； (2)安装数据和连接模式性能的抵消问题； (3)复合型极端事件的归因与成因问题； (4)碳排放与空气质量改善的最优化路径问题； (5)多学科、多区域、多部门的合作问题。 加强上述方向的研究有助于深入对复合型极端事件的理解，并为我国气候变化适应和健康风险应对提供科技支撑</p>
<p>近百年来，受全球变暖影响，中国气候发生了显著变化。随着地表温度升高，热浪、极端降雨、干旱、台风、风暴潮等区域极端事件发生的频率和强度都有所增加，对公众健康、生态系统、粮食安全和社会经济系统构成了重大挑战。极端事件通常分为天气极端事件和气候极端事件。极端天气是指在特定时间和地点发生的罕见气象事件，具有统计概率低的特点。而气候极端事件是指气象变量在较长时期内持续异常，有可能导致极端的季节平均值或总量（IPCC，2021）。为推动全球变暖背景下极端事件的研究，世界气象组织和世界气候研究计划成立了气候变化检测和指数专家组（ETCCDI）。该团队基于统一的框架定义了27个具有代表性的极端温度和降水指数（张建军等，2011），广泛应用于全球和区域极端天气气候事件的研究。极端事件的定义通常有两种：基于固定值的绝对阈值和基于百分位数的相对阈值。例如，中国的气象业务系统将连续三天气温超过35℃的时段定义为热浪。但由于气候变量的时空异质性，研究中倾向于使用基于百分位数的相对阈值或基于极值理论的参数估计方法来定义极端事件。<br>近年来，中国极端事件呈现出三个新特点。一是极端事件分布范围不断扩大，高影响低概率事件频发，灾害影响不再局限于特定区域，而是波及范围越来越广。二是极端事件发生突发性增强，不可预见事件增多，并出现了前所未有的灾害组合。三是极端事件的极端化趋势明显，极端事件发生的频率和强度均有所增加。这些新特点对中国的民生、经济发展和社会公平产生了负面影响，也对气象灾害风险管理、应急响应和气候适应战略提出了重大挑战。与单一驱动因素引发的极端事件相比，两个或多个极端事件同时或连续发生往往造成更为严重的社会和环境后果。这种由多种气候驱动因素和&#x2F;或灾害共同作用，造成社会或环境风险的现象被称为复合极端事件。这些已经发展成为气候变化研究领域的前沿问题和重大科学挑战( Zscheischler 等，2018；Yu 等，2023 )。<br>随着中国城镇化和工业化的快速推进，大气污染已成为重大环境问题和居民健康威胁（Zheng et al.，2023）。为解决这些问题，中国政府实施了各种监管措施，例如自2013年以来实施的第一个五年清洁空气行动和蓝天保卫战计划。这些努力使PM 2.5污染明显减少，尽管水平仍未达到世界卫生组织设定的高标准（Xue et al.，2019）。然而，在暖季，中国东部地区近地面臭氧浓度仍然很高，持续性臭氧污染事件发生频率增加。这已成为影响中国夏季空气质量的主要因素。臭氧属于二次污染物，主要通过光化学反应形成，其前体物包括挥发性有机化合物、一氧化碳和氮氧化物。在人口密集的中国东部地区，供暖和交通运输严重依赖化石燃料和生物燃料，导致臭氧前体物排放急剧增加，不仅导致臭氧浓度升高，还催化光化学烟雾的形成，对公众健康、生态系统和农业生产构成严重威胁。</p>
<h1 id="数十年来AlCl偶极矩之谜得以解决"><a href="#数十年来AlCl偶极矩之谜得以解决" class="headerlink" title="数十年来AlCl偶极矩之谜得以解决"></a>数十年来AlCl偶极矩之谜得以解决</h1><h2 id="文章来源-5"><a href="#文章来源-5" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://phys.org/news/2025-06-decades-mystery-alcl-dipole-moment.html" >https://phys.org/news/2025-06-decades-mystery-alcl-dipole-moment.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>在一项填补基础科学领域长期存在的知识空白的研究中，加州大学河滨分校的研究人员 Boerge Hemmerling 和 Stephen Kane 成功测量了氯化铝 (AlCl) 的电偶极矩，AlCl 是一种简单但在科学上至关重要的双原子分子。</p>
<p>他们的研究成果发表在《物理评论A》上，对量子技术、天体物理学和行星科学具有重要意义。论文题为《利用斯塔克能级光谱法测量氯化铝的电偶极矩》。</p>
<p>到目前为止，AlCl的偶极矩仅被估算，而没有实验证实。这项研究的精确测量如今用可靠的实验数据取代了理论预测。</p>
<p>当分子内部正负电荷分离，导致电子分布不均匀时，就会产生电偶极矩。对于像氯化铝这样的分子来说，它决定了分子之间以及与周围环境的相互作用。</p>
<p>“在化学中，偶极矩影响从键合行为到溶剂相互作用的一切，”物理学和天文学副教授赫默林说。</p>
<p>在生物学中，它们影响着水中氢键等现象。在物理学和天文学中，可以利用偶极矩使相邻分子相互作用，例如，在它们之间建立量子纠缠。</p>
<p>Hemmerling解释说，AlCl在多个科学领域发挥着至关重要的作用。他表示，这种分子已成为超冷量子计算平台开发中一个很有希望的候选材料，而精确理解由偶极矩驱动的分子间相互作用至关重要。</p>
<p>“之前假设的约1.5德拜只是一个历史性的占位符，”Hemmerling说。“我们的实验结果提供的约1.68德拜的最终值可以用于规划高精度实验，并提高理论模型的准确性。”</p>
<p>在渐近巨星支（AGB）恒星的大气中检测到了氯化铝（AlCl），这些恒星正处于恒星演化的晚期阶段。AGB恒星经历了显著的质量损失和元素重新分布；了解它们的化学成分对于追踪恒星和行星的演化至关重要。</p>
<p>地球与行星科学系行星天体物理学教授凯恩说：“准确的偶极矩数据可以改善我们对星光中分子特征的解读。”</p>
<p>我们的发现将有助于改进迄今为止依赖于替代值或估计值的天体物理模型。这包括用于分析詹姆斯·韦伯太空望远镜等尖端天文台数据的模型。</p>
<p>凯恩认为，铝和氯在行星形成的地球化学中分别扮演着不同的角色。他表示，放射性铝同位素有助于核心分化，而氯的分布则有助于绘制行星演化图。</p>
<p>他说：“通过 AlCl 测量揭示的恒星中铝与氯的比例为恒星核合成和这些天体的物质历史提供了关键线索。”</p>
<p>该研究采用了加州大学河滨分校历时七年开发的复杂实验装置，包括定制激光器、真空系统和专为高精度光谱设计的电子设备。</p>
<p>通过在真空中产生 AlCl 光束并分析其光谱行为，该团队与康涅狄格大学的 Daniel McCarron 合作，此前首次能够确定该分子的超精细结构和同位素位移。</p>
<p>加州大学河滨分校的研究小组旨在继续探索 AlCl。</p>
<p>赫默林说：“从提高我们对遥远恒星的理解到实现下一代量子计算机，精确测量 AlCl 的电偶极矩是迈向未来发现的基础性一步。”</p>
<p>“我们现在还可以高精度地研究其他分子和原子，为天体化学、基础物理学和材料科学领域激动人心的新发现铺平道路。”</p>
<p>该团队的下一个目标之一是 HoF，一种可能有助于测试物理学标准模型边界的分子。</p>
<p>“这项研究提醒我们，我们对哪怕是最基本的分子也并非完全了解，”赫默林说，“但现代技术为我们提供了探索的工具。”</p>
<p>该项目与洛斯阿拉莫斯国家实验室的理论家 Brian Kendrick 合作。</p>
<blockquote>
<p>更多信息： Li-Ren Liu 等人，利用斯塔克能级光谱测量 AlCl 的电偶极矩，《物理评论 A》（2025 年）。DOI ：10.1103&#x2F;hwwm-1mn7</p>
<p>期刊信息： Physical Review A </p>
</blockquote>
<h1 id="苹果的一项新研究质疑人工智能模型是否真正通过问题进行“推理”"><a href="#苹果的一项新研究质疑人工智能模型是否真正通过问题进行“推理”" class="headerlink" title="苹果的一项新研究质疑人工智能模型是否真正通过问题进行“推理”"></a>苹果的一项新研究质疑人工智能模型是否真正通过问题进行“推理”</h1><h2 id="文章来源-6"><a href="#文章来源-6" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://arstechnica.com/ai/2025/06/new-apple-study-challenges-whether-ai-models-truly-reason-through-problems/" >https://arstechnica.com/ai/2025/06/new-apple-study-challenges-whether-ai-models-truly-reason-through-problems/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>6月初，苹果研究人员发布了一项研究，表明模拟推理 (SR) 模型（例如 OpenAI 的o1和o3、DeepSeek-R1和Claude 3.7 Sonnet Thinking）在面对需要系统性思维的新型问题时，其输出结果与训练数据的模式匹配结果一致。研究人员的发现与美国数学奥林匹克(USAMO) 4 月份的一项研究结果类似，表明这些模型在新型数学证明方面得分较低。</p>
<p>这项新研究名为“思考的错觉：通过问题复杂性的视角理解推理模型的优势和局限性”，由苹果公司的 Parshin Shojaee 和 Iman Mirzadeh 领导的团队完成，Keivan Alizadeh、Maxwell Horton、Samy Bengio 和 Mehrdad Farajtabar 也参与其中。</p>
<p>研究人员研究了他们所谓的“大型推理模型”（LRM），该模型试图通过生成有时被称为“思路链推理”的审议性文本输出来模拟逻辑推理过程，表面上以逐步的方式帮助解决问题。</p>
<p>为了做到这一点，他们让人工智能模型对抗四个经典谜题——汉诺塔（在桩之间移动圆盘）、跳棋（消除棋子）、过河（在限制条件下运输物品）和积木世界（堆叠积木）——从非常简单（比如一个圆盘的汉诺塔）到极其复杂（20 个圆盘的汉诺塔需要超过一百万次移动）。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/12/001.png"
                      alt="photo"
                ><br>研究人员写道：“目前的评估主要侧重于已建立的数学和编码基准，强调最终答案的准确性。” 换句话说，如今的测试只关心模型是否能够正确回答可能已经存在于其训练数据中的数学或编码问题——它们并不考察模型是否真正推理出了答案，还是仅仅根据之前见过的例子进行了模式匹配。</p>
<p>最终，研究人员得出的结果与前述USAMO 的研究一致：这些模型在新型数学证明上的准确率大多低于 5%，只有一个模型达到了 25%，并且在近 200 次尝试中没有一个模型能达到完美证明。两个研究团队都记录了在需要扩展系统推理的问题上性能的严重下降。</p>
<h2 id="已知的怀疑论者和新证据"><a href="#已知的怀疑论者和新证据" class="headerlink" title="已知的怀疑论者和新证据"></a>已知的怀疑论者和新证据</h2><p>人工智能研究员加里·马库斯（Gary Marcus）长期以来一直认为神经网络难以实现分布外的泛化，他称苹果的研究结果“对法学硕士（LLM）来说相当具有毁灭性”。尽管马库斯多年来一直提出类似的论点，并以对人工智能的怀疑态度而闻名，但这项新研究为他独特的批评观点提供了新的实证支持。</p>
<p>马库斯写道：“法学硕士无法可靠地解决汉诺塔问题，这真是令人尴尬。”他指出，人工智能研究员赫伯·西蒙早在1957年就解决了这个难题，而且网络上也有很多算法解决方案。马库斯指出，即使研究人员提供了解决汉诺塔问题的明确算法，模型性能也没有提高——该研究的联合负责人伊曼·米尔扎德认为，这一发现表明“他们的流程既不合逻辑，也不智能”。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/12/002.jpg"
                      alt="photo"
                ><br>苹果团队发现，模拟推理模型的表现与“标准”模型（如 GPT-4o）根据谜题难度的不同而有所不同。在简单任务（例如只有几个圆盘的汉诺塔）中，标准模型实际上胜出，因为推理模型会“过度思考”，并产生导致错误答案的长串思维。在中等难度的任务中，SR 模型的系统性方法使其更具优势。但在真正困难的任务（例如拥有 10 个或更多圆盘的汉诺塔）中，两种模型都彻底失败，无论给予多少时间都无法完成谜题。</p>
<p>研究人员还发现了所谓的“反直觉扩展极限”。随着问题复杂性的增加，模拟推理模型最初会产生更多的思考标记，但随后会在超过阈值后减少推理努力，尽管拥有足够的计算资源。</p>
<p>该研究还揭示了模型失败过程中令人费解的不一致之处。Claude 3.7 Sonnet 在汉诺塔游戏中最多可以完成 100 步正确移动，但在过河游戏中仅移动 5 步就失败了——尽管后者所需的总移动步数更少。这表明，这些失败可能与特定任务有关，而非纯粹的计算问题。</p>
<h2 id="出现相互竞争的解释"><a href="#出现相互竞争的解释" class="headerlink" title="出现相互竞争的解释"></a>出现相互竞争的解释</h2><p>然而，并非所有研究人员都认同这些结果体现了基本推理能力的局限性。多伦多大学经济学家凯文·A·布莱恩（Kevin A. Bryan）在X上指出，观察到的局限性可能反映的是刻意的训练限制，而非内在的缺陷。</p>
<p>“如果你让我解决一个需要用纸笔写一个小时的问题，但给我五分钟，我可能会给你一个近似解或启发式方法。这正是强化学习（RL）所要求具备思维的基础模型所做的事情。”布莱恩写道，他建议通过强化学习（RL）对模型进行专门训练，以避免过度计算。</p>
<p>Bryan 认为，一些未指定的行业基准测试表明，“在几乎每个尝试过的问题领域，随着用于推理的 token 数量的增加，性能都会严格提升”，但他指出，部署的模型会刻意限制这种性能，以防止对简单查询进行“过度思考”。这种观点表明，苹果的论文衡量的可能是人为设定的约束，而非基本的推理极限。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/06/12/003.jpg"
                      alt="photo"
                ><br>软件工程师Sean Goedecke在他的博客上对苹果的论文提出了类似的批评，他指出，当面对需要超过 1000 步移动的汉诺塔游戏时，DeepSeek-R1“立即认定‘手动生成所有这些移动是不可能的’，因为这需要追踪超过一千步移动。因此，它不停地寻找捷径，最终失败了。” Goedecke 认为，这代表模型选择不尝试这项任务，而不是无法完成它。</p>
<p>其他研究人员也质疑这些基于谜题的评估方法是否适用于法学硕士（LLM）。独立人工智能研究员西蒙·威利森（Simon Willison）在接受Ars Technica采访时表示，汉诺塔方法“无论是否具备推理能力，都并非应用LLM的合理方法”，并指出失败可能仅仅反映了上下文窗口（AI模型能够处理的最大文本量）中标记耗尽，而非推理能力不足。他认为这篇论文可能存在夸大其词的现象，之所以受到关注，主要是因为其“令人无法抗拒的标题”——苹果声称LLM不具备推理能力。</p>
<p>苹果研究人员本人也警告不要过度推断他们的研究结果，并在其局限性部分承认，“谜题环境只代表了推理任务的一小部分，可能无法捕捉现实世界或知识密集型推理问题的多样性。” 该论文还承认，推理模型在“中等复杂度”范围内有所改进，并继续在一些现实世界的应用中展现出实用性。</p>
<h2 id="其影响仍有争议"><a href="#其影响仍有争议" class="headerlink" title="其影响仍有争议"></a>其影响仍有争议</h2><p>这两项研究是否彻底摧毁了关于人工智能推理模型的论断的可信度？未必。</p>
<p>这些研究或许表明，SR 模型所使用的扩展上下文推理技巧或许并非像某些人所希望的那样，成为通往通用智能的途径。在这种情况下，通往更稳健推理能力的道路可能需要从根本上改变方法，而不是对现有方法进行改进。</p>
<p>正如威利森上文所述，苹果公司的研究结果迄今为止在人工智能界引起了轰动。生成式人工智能是一个备受争议的话题，围绕该模型的普遍实用性展开的意识形态之争中，许多人倾向于极端立场。许多生成式人工智能的支持者对苹果公司的研究结果提出了质疑，而批评者则认为这项研究是对法学硕士（LLM）可信度的致命一击。</p>
<p>苹果的成果，加上USAMO的发现，似乎强化了像马库斯这样的批评者的观点，即这些系统依赖于复杂的模式匹配，而不是其营销宣传中暗示的那种系统性推理。公平地说，生成式人工智能领域的大部分内容都比较新，甚至连其发明者都还不完全理解这些技术的工作原理和原理。与此同时，人工智能公司或许可以通过缓和一些关于推理和智能突破的宣传来建立信任。</p>
<p>然而，这并不意味着这些人工智能模型毫无用处。即使是复杂的模式匹配机器，只要了解它们的缺点和虚构性，也能为使用者节省不少体力。正如 Marcus 所承认的：“至少在未来十年，法学硕士（无论是否具备推理时间）仍将有其用处，尤其是在编程、头脑风暴和写作方面。”</p>
<h1 id="如果公司愿意，每周工作四天可以提高效率"><a href="#如果公司愿意，每周工作四天可以提高效率" class="headerlink" title="如果公司愿意，每周工作四天可以提高效率"></a>如果公司愿意，每周工作四天可以提高效率</h1><h2 id="文章来源-7"><a href="#文章来源-7" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://phys.org/news/2025-06-day-week-productive-company-committed.html" >https://phys.org/news/2025-06-day-week-productive-company-committed.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>如果企业真正致力于推行四天工作制，那么每周四天工作制可以提高生产力，改善工作与生活的平衡，并留住人才。这些是“创新工作”（InnovaWorking）项目的部分结论。该项目由马德里卡洛斯三世大学（卡三）协调，是一个欧洲科研项目。该项目今天在欧洲议会提交了这项研究。其研究重点关注欧盟各国工会与雇主之间协商制定的创新工作时间政策。</p>
<p>“我们得出的结论是，每周四天工作制以及远程办公、假期购物和弹性工作时间等灵活的工作时间安排非常有效。最重要的是，当公司或实体真正致力于此时，”InnovaWorking 项目首席研究员、卡三法学院经济与法律研究所 (IUDEC) 的安娜·贝伦·穆尼奥斯·鲁伊斯 (Ana Belén Muñoz Ruiz) 解释道。</p>
<p>在本研究项目中，我们对六个欧洲国家的公共和私营部门的工作与生活平衡政策进行了分析：西班牙、芬兰、法国、匈牙利、爱尔兰和荷兰。</p>
<p>这项科学项目已确定，工作时间安排的创新变革可以提高生产力，改善员工的工作与生活平衡，并留住人才。“每周四天工作制吸引了众多技术工人。率先实施该制度的公司将拥有更加敬业的员工，并且更不愿意跳槽到竞争对手那里。”</p>
<p>参与 InnovaWorking 项目的另一位研究人员、马德里康普顿斯大学劳动和社会保障法系的 Pablo Gimeno Díaz de Atauri 表示：“因此，对于先锋公司来说，在这些措施成为普遍规则之前选择这些措施是具有战略意义的。”</p>
<p>研究人员还分析了工人通过工会参与的重要性，但他们指出，最好避免使用“神奇公式”。“并非所有行业都能提供相同的解决方案。为了使一切顺利进行，重要的是企业要考虑到其具体的生产、组织和轮班条件，并让工人代表表达他们的需求，”卡三社会与国际私法系教授安娜·贝伦·穆尼奥斯·鲁伊斯（Ana Belén Muñoz Ruiz）说道。</p>
<h2 id="科技领域以外的劳动力创新"><a href="#科技领域以外的劳动力创新" class="headerlink" title="科技领域以外的劳动力创新"></a>科技领域以外的劳动力创新</h2><p>该项目研究的案例表明，这些措施可以应用于科技行业以外的领域，例如建筑、金属或餐饮业。然而，研究发现，并非所有国家对弹性工作时间的反应都相同。</p>
<p>例如，在法国和西班牙等国家立法保障集体谈判且集体协议具有约束力的国家，集体谈判模式更具创新性。另一方面，在匈牙利和爱尔兰，社会对话较弱，法律僵化程度较高，谈判传统也较弱，因此集体谈判的倡议往往来自企业。</p>
<p>欧洲大多数国家人口老龄化持续加剧，导致劳动力年龄结构发生变化。一些公司正在采取各种举措，例如减少每周工作时间，以鼓励年长员工留在公司。</p>
<p>研究人员认为，在这种新形势下，有必要重新思考工作时间的安排，使其适应多元化劳动力的需求以及当前的社会和经济挑战。事实上，InnovaWorking 的研究成果可能会对欧洲关于工作场所数字化扩展的劳工政策产生影响，同时也证明了有必要规范劳动者的数字脱节权。</p>
<h1 id="你的呼吸方式就像指纹一样，可以识别你"><a href="#你的呼吸方式就像指纹一样，可以识别你" class="headerlink" title="你的呼吸方式就像指纹一样，可以识别你"></a>你的呼吸方式就像指纹一样，可以识别你</h1><h2 id="文章来源-8"><a href="#文章来源-8" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://www.nature.com/articles/d41586-025-01835-0" >https://www.nature.com/articles/d41586-025-01835-0<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>研究表明，你的吸气和呼气模式不仅是独一无二的，它还可以作为你身体和精神状态的标志。<br>就像指纹中的漩涡一样，一个人的呼吸模式可能是独一无二的——这不仅可以用来识别个人，还可以识别他们的一些身体和心理特征。</p>
<p>一组研究人员对97名健康受试者进行了24小时的呼吸测量，发现仅凭呼吸模式就能相对准确地识别参与者。此外，他们还发现这些模式与体质指数（BMI）以及抑郁和焦虑的迹象存在关联。</p>
<p>“某种程度上，我们是通过鼻子来读心的，”该研究的共同作者、以色列雷霍沃特魏茨曼科学研究所的神经生物学家诺姆·索贝尔（Noam Sobel）说道。“这可能是一种非常强大的诊断工具。” 该团队的研究成果今天发表在《当代生物学》1期上。</p>
<h2 id="深吸一口气"><a href="#深吸一口气" class="headerlink" title="深吸一口气"></a>深吸一口气</h2><p>呼吸与大脑息息相关。每一次吸气和呼气都相互协调，为大脑提供管理身体系统所需的氧气。索贝尔和他的团队不禁思考：如果每​​个人的大脑功能都不同，那么每个人的呼吸方式是否也应该独一无二？</p>
<p>为了验证这一点，研究人员开发了一种定制的可穿戴设备，用于记录人每个鼻孔的气流。该设备安装在颈后，鼻下装有管子，可以追踪人们日常生活中的呼吸情况，无论清醒还是睡眠。<br>为了描述一个人的呼吸模式，研究团队从气流数据中提取了24个参数，包括吸气和呼气的持续时间以及鼻孔间气流的不对称性。他们将参与者的清醒和睡眠时间分开，并利用这些数据训练机器学习算法。</p>
<p>当42名参与者在几周、几个月甚至两年后回到实验室，参加另一次24小时测量时，经过训练的算法可以根据他们的呼吸模式识别他们。参与者清醒时的数据比睡眠时的数据结果更准确，但当研究人员使用包含100个参数的完整数据集（而非仅包含24个参数的数据集）时，他们能够以96.8%的准确率识别出个体。</p>
<p>鉴于这一成功，索贝尔和他的同事开始思考是否可以从呼吸模式中了解更多信息。</p>
<h2 id="健康呼吸"><a href="#健康呼吸" class="headerlink" title="健康呼吸"></a>健康呼吸</h2><p>研究人员收集了参与者的BMI数据，以及评估抑郁和焦虑程度的问卷。分析发现，尽管大多数参与者的问卷得分较低，但这些信息与呼吸模式之间存在相关性。</p>
<p>例如，BMI 较高的人睡眠时的呼吸曲线与 BMI 较低的人不同。焦虑或抑郁问卷得分较高的人，其吸气和呼气的模式也有所不同。<br>“这是一项非常酷的研究，”斯德哥尔摩卡罗琳斯卡医学院的神经科学家 Artin Arshamian 说。</p>
<p>加州大学洛杉矶分校的精神病学家海伦·拉夫雷茨基（Helen Lavretsky）表示，研究呼吸的科学家一直在尝试将呼吸特征与健康联系起来——这类似于心电图（利用放置在人体手指、手臂或其他身体部位的电极来测量心脏活动）可以揭示异常节律。索贝尔表示，这项研究是呼吸模式领域的“一项进步”，该领域通常收集较短时间段内的呼吸数据。她还表示，这项研究为设计呼吸疗法打开了大门。</p>
<p>拉夫列茨基说：“我们能用的最有效的工具就是呼吸。” 例如，美国军队的一些部门会训练军人控制呼吸，以应对压力，并在高压时刻保持专注。</p>
<p>索贝尔和他的同事们目前正在尝试找出哪种呼吸模式与低水平的压力和焦虑相关，看看能否抵消这些感觉。索贝尔说，如果成功，他们将尝试“教人们以一种能够缓解这些症状的方式呼吸”。</p>
<h1 id="介绍-V-JEPA-2-世界模型和物理推理的新基准"><a href="#介绍-V-JEPA-2-世界模型和物理推理的新基准" class="headerlink" title="介绍 V-JEPA 2 世界模型和物理推理的新基准"></a>介绍 V-JEPA 2 世界模型和物理推理的新基准</h1><h2 id="文章来源-9"><a href="#文章来源-9" class="headerlink" title="文章来源"></a>文章来源</h2><p><a class="link"   href="https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks/" >https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><ul>
<li>元视频联合嵌入预测架构 2 (V-JEPA 2) 是一个世界模型，在物理世界中的视觉理解和预测方面实现了最佳性能。我们的模型也可用于零样本机器人规划，以便在新环境中与陌生物体进行交互。</li>
<li>V-JEPA 2 代表着我们朝着实现高级机器智能 (AMI) 和构建可在物理世界中运行的有用的 AI 代理的目标迈出了下一步。</li>
<li>我们还发布了三个新的基准来评估现有模型从视频推断物理世界的能力。</li>
</ul>
<p>今天，我们很高兴地宣布 V-JEPA 2 正式发布。这是首个基于视频训练的世界模型，它能够实现最先进的理解和预测能力，以及在新环境中进行零样本规划和机器人控制。在我们努力实现高级机器智能 (AMI) 的目标的过程中，拥有能够像人类一样学习世界、规划如何执行不熟悉的任务并高效适应周围不断变化的世界的 AI 系统至关重要。</p>
<p>V-JEPA 2 是一个拥有 12 亿个参数的模型，它是使用我们在 2022 年首次分享的元联合嵌入预测架构(JEPA) 构建的。我们之前的工作表明，JEPA 在图像和3D 点云等模态下表现良好。V -JEPA是我们去年发布的第一个视频训练模型，在此基础上，V-JEPA 2 改进了动作预测和世界建模功能，使机器人能够与不熟悉的物体和环境交互以完成任务。我们还分享了三个新的基准，以帮助研究界评估他们现有的模型使用视频学习和推理世界的程度。通过分享这项工作，我们旨在让研究人员和开发人员能够访问最佳模型和基准，以帮助加速研究和进步，最终带来更优秀、更强大的 AI 系统，从而改善人们的生活。</p>
<h2 id="什么是世界模型？"><a href="#什么是世界模型？" class="headerlink" title="什么是世界模型？"></a>什么是世界模型？</h2><p>我们都知道，如果你把一个网球抛向空中，重力会把它拉回来。如果它悬空，突然在空中旋转飞向另一个方向，或者突然变成一个苹果，那真是令人惊讶。这种身体直觉并非成年人经过多年教育就能获得的——幼儿在能够说出完整句子之前，就通过观察周围的世界培养出了这种直觉。</p>
<p>预测世界将如何回应我们的行为（或他人的行为）的能力是人类一直以来都在运用的，尤其是在规划行动以及如何最好地应对新情况时。不妨想想这种生理直觉在我们日常生活中是如何体现的。当我们穿过陌生拥挤的区域时，我们会一边朝着目的地前进，一边努力避免撞到沿途的人或障碍物。打冰球时，我们会滑向冰球即将飞向的方向，而不是它当前的位置。用炉子做饭时，我们会考虑锅还要烧多久，或者是否要调低火候。我们内在的世界模型不仅为我们提供了这种直觉，还充当着一个内在模拟器，让我们能够预测假设行动的结果，最终根据我们认为最能实现目标的方式，选择最佳行动。</p>
<p>在采取行动之前，我们会使用世界模型来设想潜在的后果。在我们致力于构建能够先思考后行动的 AI 代理的过程中，让它们学习能够实现以下功能的世界模型至关重要：</p>
<ul>
<li>理解：世界模型应该能够理解对世界的观察，包括识别视频中的物体、动作和运动等。</li>
<li>预测：世界模型应该能够预测世界将如何发展，以及如果代理采取行动，世界将如何变化。</li>
<li>规划：基于预测能力，世界模型应该有助于规划实现给定目标的行动序列。</li>
</ul>
<h2 id="V-JEPA-2-简介"><a href="#V-JEPA-2-简介" class="headerlink" title="V-JEPA 2 简介"></a>V-JEPA 2 简介</h2><p>我们的长期愿景是，世界模型将使 AI 代理能够在物理世界中进行规划和推理。为了实现这一愿景，我们即将发布 V-JEPA 2，这是一个主要基于视频进行训练的世界模型——视频是丰富且易于获取的世界信息来源。通过将 V-JEPA 2 代码和模型检查点开放给商业和研究应用，我们希望围绕这项研究建立一个广泛的社区，推动我们朝着最终目标迈进，即开发能够改变 AI 与物理世界交互方式的世界模型。</p>
<p>V-JEPA 2 采用联合嵌入预测架构 (JEPA) 构建，包含两个主要组件：</p>
<ul>
<li>编码器，接收原始视频并输出嵌入，以捕获有关观察世界状态的有用语义信息。</li>
<li>预测器，它接受视频嵌入和关于要预测的内容的附加上下文，并输出预测的嵌入。</li>
</ul>
<p>我们使用基于视频的自监督学习来训练 V-JEPA 2，这使得我们无需额外的人工注释即可在视频上进行训练。V-JEPA 2 训练包含两个阶段：无动作预训练，以及后续的动作条件训练。</p>
<p>在第一阶段——预训练阶段，我们使用了来自不同来源的超过 100 万小时的视频和 100 万张图像。这些丰富的视觉数据有助于模型深入了解世界的运作方式，包括人与物体的互动方式、物体在物理世界中的移动方式以及物体与其他物体的互动方式。我们发现，在预训练阶段之后，模型已经展现出与理解和预测相关的关键能力。例如，通过在冻结编码器特征的基础上训练轻量级的注意力读出模型，V-JEPA 2 在 Something-Something v2 动作识别任务中取得了卓越的表现，该任务依赖于运动理解。同样，通过在冻结编码器和预测器特征的基础上训练注意力读出模型，V-JEPA 2 在 Epic-Kitchens-100 动作预测任务中创造了新的最高纪录，该任务可以根据以自我为中心的视频预测未来 1 秒将执行的动作（由名词和动词组成）。最后，将 V-JEPA 2 与语言模型相结合，可以在视频问答基准（例如感知测试和 TempCompass）上实现最先进的性能。</p>
<p>在无动作预训练阶段之后，模型可以预测世界未来如何演变——然而，这些预测并未直接考虑代理将采取的具体动作。在训练的第二阶段，我们专注于利用机器人数据（包括视觉观察（视频）和机器人正在执行的控制动作）来提升模型的规划能力。我们通过向预测器提供动作信息，将这些数据整合到 JEPA 训练流程中。在使用这些额外数据进行训练后，预测器学会在进行预测时考虑具体动作，然后即可用于控制。第二阶段我们不需要大量的机器人数据——在我们的技术报告中，我们展示了仅使用 62 小时的机器人数据进行训练就能构建出一个可用于规划和控制的模型。</p>
<p>我们演示了如何在新环境中使用 V-JEPA 2 进行零样本机器人规划，并涉及训练期间未见过的物体。与其他机器人基础模型（通常需要一些来自部署模型的特定机器人实例和环境的训练数据）不同，我们在开源DROID 数据集上训练该模型，然后将其直接部署到我们实验室的机器人上。我们展示了 V-JEPA 2 预测器可用于执行一些基础任务，例如伸手够到、拾取物体并将其放置在新位置。</p>
<p>对于短期任务，例如拾取或放置物体，我们以图像的形式指定目标。我们使用 V-JEPA 2 编码器获取当前状态和目标状态的嵌入。机器人从观察到的当前状态出发，利用预测器进行规划，设想采取一系列候选动作的后果，并根据候选动作与期望目标的接近程度对其进行评级。在每个时间步，机器人都会重新规划并通过模型预测控制执行排名最高的下一个动作，以实现该目标。对于长期任务，例如拾取物体并将其放置在正确位置，我们指定一系列视觉子目标，机器人会尝试按顺序实现这些目标，类似于人类观察到的视觉模仿学习。凭借这些视觉子目标，V-JEPA 2 在新环境和未知环境中拾取和放置新物体的成功率达到 65% 至 80%。</p>
<h2 id="物理理解的基准测试"><a href="#物理理解的基准测试" class="headerlink" title="物理理解的基准测试"></a>物理理解的基准测试</h2><p>随着我们在世界模型领域不断取得进展，我们很高兴与开源社区分享我们的工作成果并支持其发展。我们将发布三个新的基准测试，以评估现有模型从视频理解和推理物理世界的能力。虽然人类在这三个基准测试中都表现良好（准确率达到 85% 到 95%），但人类的表现与包括 V-JEPA 2 在内的顶级模型相比仍存在显著差距，这为模型的改进指明了重要的方向。</p>
<p>IntPhys 2专门用于衡量模型区分物理上合理和不合理场景的能力，它在早期的IntPhys 基准的基础上进行构建和扩展。我们设计 IntPhys 2 的方式类似于发展认知科学家通过违反预期范式来评估年轻人何时获得直觉物理学的方式。我们使用一个游戏引擎来实现这一点，该引擎会生成成对的视频，其中两个视频在某个点之前相同，然后两个视频中的一个视频中发生了违反物理的事件。然后，模型必须识别哪个视频发生了违反物理的事件。虽然人类在各种场景和条件下都能在这项任务上达到近乎完美的准确率，但我们发现当前的视频模型处于或接近偶然性。</p>
<p><strong>最小视频对 (MVPBench)</strong> 通过多项选择题来衡量视频语言模型的物理理解能力。与文献中的其他视频问答基准测试不同，MVPBench 旨在缓解视频语言模型中常见的捷径解决方案，例如依赖肤浅的视觉或文本线索和偏见。MVPBench 中的每个示例都包含一个最小变化对：视觉上相似的视频，以及相同的问题，但答案相反。为了获得一个示例的评分，模型也必须正确完成其最小变化对。</p>
<p><strong>CausalVQA</strong>衡量视频语言模型回答与物理因果关系相关问题的能力。该基准测试旨在关注对物理世界视频中因果关系的理解，包括反事实问题（如果……会发生什么）、预期问题（接下来可能会发生什么）以及规划问题（为了实现目标，下一步应该采取什么行动）。我们发现，虽然大型多模态模型越来越能够回答视频中“发生了什么”的问题，但它们仍然难以回答“可能发生什么”和“接下来可能会发生什么”的问题，这表明，在预测物理世界在给定动作和事件空间的情况下可能如何演变方面，人类的表现与人类存在巨大差距。</p>
<h2 id="迈向高级机器智能的下一步"><a href="#迈向高级机器智能的下一步" class="headerlink" title="迈向高级机器智能的下一步"></a>迈向高级机器智能的下一步</h2><p>随着我们继续推进世界模型的研究，我们计划在多个领域进一步探索。目前，V-JEPA 2 可以在单一时间尺度上学习并进行预测。然而，许多任务需要跨多个时间尺度进行规划。想象一下，将一个高级任务分解成更小的步骤，例如装载洗碗机或烘烤蛋糕。我们希望专注于训练能够跨多个时间和空间尺度进行学习、推理和规划的分层 JEPA 模型。另一个重要方向是多模态 JEPA 模型，这些模型可以使用多种感官进行预测，包括视觉、听觉和触觉。一如既往，我们期待在未来分享更多成果，并继续与研究界进行重要的讨论。</p>
<h1 id="《思考的错觉的错觉》"><a href="#《思考的错觉的错觉》" class="headerlink" title="《思考的错觉的错觉》"></a>《思考的错觉的错觉》</h1><p>几天前，苹果一篇《思考的错觉》论文吸睛无数又争议不断，其中研究了当今「推理模型」究竟真正能否「推理」的问题，而这里的结论是否定的。</p>
<p>论文中写到：「我们的研究表明，最先进的 LRM（例如 o3-mini、DeepSeek-R1、Claude-3.7-Sonnet-Thinking）仍然未能发展出可泛化的解决问题能力 —— 在不同环境中，当达到一定复杂度时，准确度最终会崩溃至零。」</p>
<p>不过，这篇论文的研究方法也受到了不少质疑，而现在，我们迎来了对这项研究更强有力的质疑：《思考的错觉的错觉》。是的，你没有看错，这就是这篇来自 Anthropic 和 Open Philanthropy 的评论性论文的标题！其中指出了那篇苹果论文的 3 个关键缺陷：</p>
<ol>
<li>汉诺塔实验在报告的失败点系统性地超出了模型输出 token 的限制，而模型在其输出中明确承认了这些限制；</li>
<li>苹果论文作者的自动评估框架未能区分推理失败和实际约束，导致对模型能力分类错误；</li>
<li>最令人担忧的是，由于船容量不足，当 N ≥ 6 时，他们的「过河（River Crossing）」基准测试包含在数学上不可能出现的实例，但模型却因未能解答这些本就无法解决的问题而被评为失败</li>
</ol>
<h2 id="1-研究背景与核心争议"><a href="#1-研究背景与核心争议" class="headerlink" title="1.研究背景与核心争议"></a>1.研究背景与核心争议</h2><p>Shojaee等人的研究声称，当面对复杂度超过一定阈值的规划问题（如河渡问题、汉诺塔问题）时，大型推理模型的表现会显著下降，甚至完全失效。这被解释为模型在复杂推理上存在根本性的局限。</p>
<p>本文作者对此提出了质疑，认为这些“失败”并非源于模型推理能力的不足，而是由以下三方面原因导致：</p>
<ul>
<li>输出长度限制 ：模型在处理某些问题时因生成内容超出token上限而被迫截断；</li>
<li>评估框架误判 ：自动化评估系统未能区分模型是否理解问题但选择不完整输出；</li>
<li>测试问题不可解 ：部分测试实例本身无解，模型未能得分是因为正确识别了这一点。</li>
</ul>
<h2 id="2-对Shojaee等人的主要反驳点"><a href="#2-对Shojaee等人的主要反驳点" class="headerlink" title="2.对Shojaee等人的主要反驳点"></a>2.对Shojaee等人的主要反驳点</h2><p>2.1 模型能够识别并主动应对输出限制<br>作者引用了一个Twitter上的复现案例，展示了模型在解决汉诺塔问题时明确表示“为了不过于冗长，我在这里停止”。这表明模型不仅理解解决方案的模式，还具备自我调节输出长度的能力。将这种行为归类为“推理崩溃”是对其能力的误解。</p>
<p>此外，作者通过数学建模分析了token数量与问题规模之间的关系，指出在当前上下文窗口限制下，模型无法完整输出超大规模问题的解答是预料之中的技术限制，而非推理失败。</p>
<h3 id="2-2-自动化评估系统的误分类问题"><a href="#2-2-自动化评估系统的误分类问题" class="headerlink" title="2.2 自动化评估系统的误分类问题"></a>2.2 自动化评估系统的误分类问题</h3><p>作者指出，若以字符级或token级精度来评判模型表现，即使每个token的准确率为99.9%，在生成数万个token时整体成功概率也会极低。这种统计学上的“必然失败”不应被错误解读为模型不具备解决问题的能力。</p>
<p>更进一步地，作者强调评估系统应当具备区分“不能解”与“不愿穷举”的能力，否则容易得出误导性结论。</p>
<h3 id="2-3-测试集包含不可解问题"><a href="#2-3-测试集包含不可解问题" class="headerlink" title="2.3 测试集包含不可解问题"></a>2.3 测试集包含不可解问题</h3><p>在River Crossing问题中，作者指出当N ≥ 6且船容量b &#x3D; 3时，问题本身在数学上已被证明无解。然而，Shojaee等人仍将模型未能给出答案视为“失败”，等同于惩罚一个SAT求解器在面对不可满足公式时返回“unsatisfiable”。</p>
<p>这是一个严重的评估失误，反映出程序化自动评分机制在缺乏人类判断或逻辑验证的情况下可能产生反效果。</p>
<h2 id="3-实验改进与新发现"><a href="#3-实验改进与新发现" class="headerlink" title="3. 实验改进与新发现"></a>3. 实验改进与新发现</h2><p>作者通过改变问题的输入&#x2F;输出形式，要求模型输出一个Lua函数来表示解决方案，而非逐条列出所有移动步骤。结果显示，在Tower of Hanoi N&#x3D;15的问题上，多个主流模型（包括Claude Opus、Gemini 2.5等）均能高效生成正确的递归算法实现，仅需不到5,000个token。</p>
<p>这说明：</p>
<p>模型确实具备解决高复杂度问题的推理能力；<br>问题的关键在于如何引导模型以合适的表达方式呈现其知识；<br>token预算限制应被视为工程瓶颈，而非认知瓶颈。</p>
<h2 id="4-对问题复杂度指标的再思考"><a href="#4-对问题复杂度指标的再思考" class="headerlink" title="4. 对问题复杂度指标的再思考"></a>4. 对问题复杂度指标的再思考</h2><p>作者指出，Shojaee等人使用“最小步数”作为衡量问题复杂度的标准并不恰当。他们列举了不同规划问题的特性：</p>
<table>
<thead>
<tr>
<th>问题类型</th>
<th>解决方案长度</th>
<th>分支因子</th>
<th align="left">是否需要搜索</th>
</tr>
</thead>
<tbody><tr>
<td>Tower of Hanoi</td>
<td>2^N − 1</td>
<td>1</td>
<td align="left">否</td>
</tr>
<tr>
<td>River Crossing</td>
<td>~4N</td>
<td>&gt;4</td>
<td align="left">是（NP-hard）</td>
</tr>
<tr>
<td>Blocks World</td>
<td>~2N</td>
<td>O(N²)</td>
<td align="left">是（PSPACE）</td>
</tr>
</tbody></table>
<p>这说明，尽管汉诺塔问题需要指数级的操作次数，但每一步的选择是确定的；而河渡问题虽然操作次数少，却涉及复杂的约束满足和搜索过程。因此，仅凭操作次数难以反映实际难度。</p>
<h2 id="5-结论与未来建议"><a href="#5-结论与未来建议" class="headerlink" title="5. 结论与未来建议"></a>5. 结论与未来建议</h2><p>本文有力地反驳了Shojaee等人关于模型存在“根本推理限制”的主张，指出其实验结果更多反映了技术限制和评估设计的缺陷。作者提出未来研究应注重以下几个方向：</p>
<p>区分推理能力和输出限制 ：评估系统应能识别模型是否具备解决问题的知识，即便未完整执行。<br>验证测试问题的可解性 ：避免将模型在不可解问题上的正确响应误判为失败。<br>采用合理的复杂度指标 ：应考虑问题内在的计算难度，而非仅看操作数量。<br>多样化解决方案表示方式 ：鼓励模型以抽象、函数式等方式表达解决方案，减少对穷举路径的依赖。</p>
<h2 id="6-总体评价"><a href="#6-总体评价" class="headerlink" title="6. 总体评价"></a>6. 总体评价</h2><p>这是一篇具有重要理论价值和实践意义的评论文章。它提醒我们在评估AI推理能力时，必须更加谨慎地设计实验和评估标准。模型的“失败”未必意味着其没有能力，而可能是我们尚未找到合适的方式来激发和观察其潜能。</p>
<p>正如作者所言：“问题不是模型能否推理，而是我们的评估能否区分推理与打字。”</p>
]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>科技前沿</tag>
        <tag>新闻</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--汽车制造行业收入表</title>
    <url>/zhihaojiang.github.io/2025/09/18/20250918%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E6%B1%BD%E8%BD%A6%E5%88%B6%E9%80%A0%E8%A1%8C%E4%B8%9A%E6%94%B6%E5%85%A5%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><h2 id="导入一些必要库"><a href="#导入一些必要库" class="headerlink" title="导入一些必要库"></a>导入一些必要库</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line"></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th></th>
<th>工龄</th>
<th>薪水</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.0</td>
<td>6053</td>
</tr>
<tr>
<td>1</td>
<td>0.1</td>
<td>7699</td>
</tr>
<tr>
<td>2</td>
<td>0.2</td>
<td>7692</td>
</tr>
<tr>
<td>3</td>
<td>0.3</td>
<td>7220</td>
</tr>
<tr>
<td>4</td>
<td>0.4</td>
<td>7380</td>
</tr>
</tbody></table>
<p>工龄    0<br>薪水    0<br>dtype: int64</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter(<span class="built_in">df</span>[<span class="string">'工龄'</span>], <span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/005.png" alt="photo"></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(10, 4))</span><br><span class="line">plt.subplot(1,2,1)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'工龄'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/006.png" alt="photo"><br>发现数据无异常值和缺失值，接下来我们直接使用各种模型进行应用</p>
<h2 id="拆分数据"><a href="#拆分数据" class="headerlink" title="拆分数据"></a>拆分数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(<span class="built_in">df</span>[[<span class="string">'工龄'</span>]], <span class="built_in">df</span>[<span class="string">'薪水'</span>], test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line">y_pred = lr.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 1104919.4789662324<br>r2: 0.8878977327128724</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestRegressor()</span><br><span class="line">rm.fit(x_train, y_train)</span><br><span class="line">y_pred = rm.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 1667691.4801338282<br>r2: 0.8308003437197605</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor(random_state=42)</span><br><span class="line">xgb.fit(x_train, y_train)</span><br><span class="line">y_pred_xgb = xgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_xgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_xgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 2059158.458273065<br>r2: 0.791083118480409</p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line"></span><br><span class="line">lgb = LGBMRegressor(random_state=42)</span><br><span class="line">lgb.fit(x_train, y_train)</span><br><span class="line">y_pred_lgb = lgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_lgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_lgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 1635577.080270067<br>r2: 0.8340585875156445</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.svm import SVR</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line">svr_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">'svr'</span>, SVR(kernel=<span class="string">'rbf'</span>, C=100, gamma=<span class="string">'scale'</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">svr_pipeline.fit(x_train, y_train)</span><br><span class="line">y_pred = svr_pipeline.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 3403636.0913299387<br>r2: 0.6546759016183081<br>发现其效果并不好 SVM需要进行调参 使用网格优化</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = {</span><br><span class="line">    <span class="string">'svr__C'</span>: [0.1, 1, 10, 100, 1000],</span><br><span class="line">    <span class="string">'svr__gamma'</span>: [<span class="string">'scale'</span>, <span class="string">'auto'</span>, 0.001, 0.01, 0.1, 1],</span><br><span class="line">    <span class="string">'svr__kernel'</span>: [<span class="string">'rbf'</span>, <span class="string">'poly'</span>, <span class="string">'linear'</span>]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">grid = GridSearchCV(svr_pipeline, param_grid, cv=5, scoring=<span class="string">'r2'</span>, n_jobs=-1)</span><br><span class="line">grid.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳参数:"</span>, grid.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳交叉验证r2:"</span>, grid.best_score_)</span><br><span class="line"></span><br><span class="line">y_pred = grid.predict(x_test)</span><br></pre></td></tr></table></figure></div>
<p>最佳参数: {‘svr__C’: 1000, ‘svr__gamma’: ‘scale’, ‘svr__kernel’: ‘linear’}<br>最佳交叉验证r2: 0.9047669744759188</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>古塔的变形</title>
    <url>/zhihaojiang.github.io/2025/08/28/20250828%E5%8F%A4%E5%A1%94%E7%9A%84%E5%8F%98%E5%BD%A2/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本研究针对古塔的变形监测与预测问题展开分析，主要解决三个方面的问题：层中心定位、塔体形变特征量化及未来变形趋势预测。<br>对于问题一，考虑到古塔各层在长期自然环境作用下可能发生倾斜、弯曲等复杂变形，直接采用算术平均法计算层中心会引入较大误差。本研究采用圆拟合的方法，在各层的水平投影上进行圆拟合，稳健估计各层圆形中心坐标，从而获得精确的层心位置，为后续变形分析提供基础。<br>对于问题二，在获得层心坐标后，通过线性拟合塔轴坐标得到倾角和倾向，通过计算层心到塔轴的垂直距离刻画弯曲，通过层心相对于底层中心的水平旋转角度刻画扭曲，通过顶层偏心量分析塔尖局部形变。分析结果显示，古塔在过去几十年中整体倾斜程度逐渐增加，局部弯曲和扭曲特征变化较小，而塔尖偏心量呈现缓慢上升趋势。<br>对于问题三，为了预测古塔未来的变形趋势，本研究采用Theil–Sen 稳健趋势估计与 Mann–Kendall 趋势显著性检验相结合的方法。Theil–Sen 方法通过计算观测数据成对斜率的中位数获得稳健趋势，能有效抑制异常值影响；Mann–Kendall 检验则对趋势的统计显著性进行评估。将倾角、弯曲量及最大偏心量代入模型后得到未来五年预测结果：整体倾斜、塔尖偏心量呈缓慢增加趋势，局部弯曲略有下降，趋势总体显著，说明古塔未来仍存在缓慢加剧的变形风险。</p>
<p><strong>关键词：</strong> 圆拟合；Theil–Sen 稳健趋势估计；Mann–Kendall 趋势显著性检验</p>
<h1 id="一、-问题重述"><a href="#一、-问题重述" class="headerlink" title="一、 问题重述"></a>一、 问题重述</h1><p>由于长时间承受自重、气温、风力 等各种作用，偶然还要受地震、飓风的影响，古塔会产生各种变形，诸如倾斜、弯曲、扭曲等。为保护古塔，文物部门需适时对古塔进行观测，了解各种变形量，以制定必要的保护措施。某古塔已有上千年历史，是我国重点保护文物。管理部门委托测绘公司先后于1996年7月、2006年8月、2019年3月和2021年3月对该塔进行了4次观测。请你们根据附件1提供的4次观测数据，讨论以下问题：<br>1.	给出确定古塔各层中心位置的通用方法，并列表给出各次测量的古塔各层中心坐标。<br>2.	分析该塔倾斜、弯曲、扭曲等变形情况。<br>3.	分析该塔的变形趋势。</p>
<h1 id="二、问题分析"><a href="#二、问题分析" class="headerlink" title="二、	问题分析"></a>二、	问题分析</h1><h2 id="2-1问题一的分析"><a href="#2-1问题一的分析" class="headerlink" title="2.1问题一的分析"></a>2.1问题一的分析</h2><p>古塔变形监测的首要任务是准确确定各层的中心位置，这是后续变形分析的基础。由于古塔各层在空间中大致呈圆形分布，但在长期自然环境作用下可能发生倾斜、弯曲等复杂变形，观测点不再保持理想的圆形分布，直接采用算术平均法计算中心坐标会引入较大误差。基于上述约束，确定层中心位置的关键在于在水平面上进行圆拟合，从而稳健估计圆形投影的中心，降低观测误差的干扰。</p>
<h2 id="2-2问题二的分析"><a href="#2-2问题二的分析" class="headerlink" title="2.2问题二的分析"></a>2.2问题二的分析</h2><p>在获得各层中心坐标之后，需要进一步分析古塔的整体与局部变形特征。这一问题的核心在于如何将 几何直观的变形现象如倾斜、弯曲、扭曲转化为可量化的数学指标。为此，我们的主要思路是通过 塔轴拟合分析整体倾斜趋势；通过层心偏离量计算刻画塔体的弯曲变形；通过旋转角度分析反映扭曲特征；结合塔尖偏心量，考察局部敏感部位的变形情况。</p>
<h2 id="2-3问题三的分析"><a href="#2-3问题三的分析" class="headerlink" title="2.3问题三的分析"></a>2.3问题三的分析</h2><p>问题三的重点在于：如何利用有限的监测数据，提取可靠的长期趋势；如何在存在测量误差和异常值的情况下，避免预测受到过度干扰。<br>传统的线性回归虽然简单，但对异常值敏感，且难以保证稳健性；灰色预测模型适用于小样本，但过于依只能给出拟合和预测结果，但不能统计地描述这个趋势是否显著。鉴于此，我们采用Theil–Sen稳健趋势估计与Mann–Kendall趋势检验相结合的方法。获得未来变形趋势的定量预测，对趋势的可靠性进行统计意义上的验证。</p>
<h1 id="三、模型准备"><a href="#三、模型准备" class="headerlink" title="三、	模型准备"></a>三、	模型准备</h1><h2 id="3-1模型假设"><a href="#3-1模型假设" class="headerlink" title="3.1模型假设"></a>3.1模型假设</h2><ol>
<li>   假设古塔形状对称</li>
<li>   假设塔轴是一条直线</li>
<li>   古塔变形过程在该时间尺度上可近似为线性变化</li>
<li>   层心可代表整层的几何中心</li>
<li>   测量的误差相互独立</li>
<li>   塔体材料与结构不发生突变</li>
</ol>
<h2 id="3-2符号说明"><a href="#3-2符号说明" class="headerlink" title="3.2符号说明"></a>3.2符号说明</h2><table>
<thead>
<tr>
<th>\theta</th>
<th>倾角</th>
</tr>
</thead>
<tbody><tr>
<td>\alpha</td>
<td>倾向</td>
</tr>
<tr>
<td>d_i</td>
<td>弯曲量</td>
</tr>
<tr>
<td>ecc</td>
<td>层心偏心量</td>
</tr>
<tr>
<td>\phi</td>
<td>扭曲量</td>
</tr>
</tbody></table>
<h2 id="3-3数据预处理"><a href="#3-3数据预处理" class="headerlink" title="3.3数据预处理"></a>3.3数据预处理</h2><p>在古塔变形分析的过程中，原始观测数据可能存在缺失或不一致的情况，直接影响模型建立的准确性，因此我们对1996年、2006年、2019年和2021年的四次观测数据进行了处理与填充。</p>
<p>由于附件1的数据格式不便于后续处理，我们将其重组为“年份、层号、点号、X、Y、Z坐标”的表格形式保存为temp.csv文件，便于后续分析。</p>
<p>我们发现附件1中在1996年和2006年的数据中，第13层第5个观测点的坐标值缺失。由于古塔的结构变形在垂直方向上通常具有连续性，我们采用层间差分法进行填充。该方法假设相邻层之间的变形趋势相似，通过计算下层点的坐标差分来估计缺失点的位置。填充过程如下：首先，找到缺失点所在层的前两层（即第11层和第12层）的对应点坐标；然后计算这两层之间在x、y、z方向上的差分值；最后，将这些差分值应用到第12层的点上，得到第13层缺失点的估计坐标。填充的数据为（567.984，519.5880，52.984）和（567.990，519.5816，52.983）。</p>
<h1 id="四、模型建立与求解"><a href="#四、模型建立与求解" class="headerlink" title="四、	模型建立与求解"></a>四、	模型建立与求解</h1><h2 id="4-1问题一模型建立与求解"><a href="#4-1问题一模型建立与求解" class="headerlink" title="4.1问题一模型建立与求解"></a>4.1问题一模型建立与求解</h2><h3 id="4-1问题一模型建立"><a href="#4-1问题一模型建立" class="headerlink" title="4.1问题一模型建立"></a>4.1问题一模型建立</h3><p>基于古塔的结构特点和变形特征，我们采用圆拟合相结合的方法来确定各层中心坐标。考虑到古塔各层在理想状态下应呈圆形分布，但由于长期变形和测量误差，实际观测点往往会偏离理论圆形。我们采通过最小化观测点到拟合圆的代数距离平方和，来估计最可能的圆心位置和半径。这种方法相比简单的算术平均法，能够更好地抵抗异常点的干扰，提供更加稳定的中心坐标估计。<br>为了获得完整的中心坐标信息，我们将圆拟合得到的水平中心坐标与观测点z 方向的平均值相结合。对于如塔尖层，我们采用算数平均值作为补充，确保所有层都能得到合理的中心坐标估计。<br>具体步骤如下：<br>1.圆拟合：<br>古塔第t次测量第l层的第i个水平观测点<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="152.036ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 67200 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="merror" data-mjx-error="Missing or unrecognized delimiter for \left" title="Missing or unrecognized delimiter for \left"><rect data-background="true" width="67200" height="950" y="-200"></rect><title>Missing or unrecognized delimiter for \left</title><g data-mml-node="mtext" style="font-family: serif;"><text data-variant="-explicitFont" transform="scale(1,-1)" font-size="884px"> \left{ \left(x_{t,l,i}, y_{t,l,i}\right) ,\middle|, t = 1,2,3,4 ;; l = 1,\ldots,13 ;; i = 1,2,\ldots,8 \right} </text></g></g></g></g></svg></mjx-container></p>
<p>理论上应分布在同一圆上（对应古塔水平截面），但受测量误差和古塔变形影响，实际存在偏差。因此，我们需要找到一个圆，让这些点尽可能 “贴近” 拟合圆，圆的标准方程如下：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.893ex;" xmlns="http://www.w3.org/2000/svg" width="27.461ex" height="3.038ex" role="img" focusable="false" viewBox="0 -948 12137.7 1342.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1183.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2183.4,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3458,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(3880,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4505.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(5506,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1101.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2101.4,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3276,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(3698,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(9885.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(10941.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g></g></g></svg></mjx-container><br>我们选择最小二乘法最小化观测点到圆的误差，对于每个点,它到圆心的理论距离是r_{t,l}，实际距离是<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.028ex;" xmlns="http://www.w3.org/2000/svg" width="29.411ex" height="4.208ex" role="img" focusable="false" viewBox="0 -1405.7 12999.7 1860"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msqrt"><g transform="translate(1020,0)"><g data-mml-node="msup"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2369.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(3369.5,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4644.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(5066.1,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(5691.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(6692.1,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2287.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(3287.5,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4462.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(4884.1,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,195.7)"><path data-c="221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path></g><rect width="11979.7" height="60" x="1020" y="1285.7"></rect></g></g></g></svg></mjx-container><br>两者的偏差就是拟合误差，也就是建立关于误差平方和的目标函数：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="46.344ex" height="6.712ex" role="img" focusable="false" viewBox="0 -1720.9 20484.3 2966.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo" transform="translate(848.6,0)"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(0,-657.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1274.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(1552.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1830.6,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3005.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(3283.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3561.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g></g></g><g data-mml-node="munderover" transform="translate(3530.9,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(545.2,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(5141.5,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M224 -649V1150H455V1099H275V-598H455V-649H224Z"></path></g><g data-mml-node="msup" transform="translate(472,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2369.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(3369.5,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4644.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(5066.1,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(6163.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(7164.1,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2287.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(3287.5,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4462.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(4884.1,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(12674,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msubsup" transform="translate(13674.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(14870.7,0) translate(0 -0.5)"><path data-c="5D" d="M16 1099V1150H247V-649H16V-598H196V1099H16Z"></path></g></g></g></g></svg></mjx-container><br>对于这个非线性问题，我们使用代数变换将其转化成一个线性问题求解，首先定义新变量：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.893ex;" xmlns="http://www.w3.org/2000/svg" width="44.703ex" height="2.893ex" role="img" focusable="false" viewBox="0 -883.9 19758.7 1278.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(1905.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2683.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msub" transform="translate(3183.6,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4458.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(4736.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(5902.8,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(6665.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(7721.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(8499.3,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msub" transform="translate(8999.3,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10173.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(10451.9,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(11618.6,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(12612.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(13668.1,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(562,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(15164.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(16165.1,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mn" transform="translate(462,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(17561.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msubsup" transform="translate(18562.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g></g></g></svg></mjx-container><br>将圆的标准方程展开整理后代入新变量 u,v,w ,得到线性形式：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.893ex;" xmlns="http://www.w3.org/2000/svg" width="34.762ex" height="2.893ex" role="img" focusable="false" viewBox="0 -883.9 15364.7 1278.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1980.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2980.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4878.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5879.1,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(6451.1,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8431.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(9431.6,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="msub" transform="translate(9916.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(11814.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(12815.1,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(13808.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(14864.7,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></svg></mjx-container><br>此时,圆拟合问题转化为：找到 u,v,w ,使得所有观测点 满足:<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.893ex;" xmlns="http://www.w3.org/2000/svg" width="36.774ex" height="2.893ex" role="img" focusable="false" viewBox="0 -883.9 16254 1278.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1980.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2980.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4878.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5879.1,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6451.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(6895.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8876,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(9876.3,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(10361.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(10805.9,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12704.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(13704.5,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(14698.2,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mn" transform="translate(15754,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></svg></mjx-container><br>且误差平方和最小。新的目标函数变为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="59.25ex" height="6.712ex" role="img" focusable="false" viewBox="0 -1720.9 26188.3 2966.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(10.1,-600) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(572,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(850,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(1335,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1613,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1667,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="munderover" transform="translate(2111.7,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(545.2,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g></g></g><g data-mml-node="msubsup" transform="translate(3722.3,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5637.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munder" transform="translate(6693,0)"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(10.1,-600) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(572,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(850,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(1335,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1613,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8360,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="munderover" transform="translate(8804.6,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(545.2,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(10415.3,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path></g></g><g data-mml-node="msubsup" transform="translate(10873.3,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12853.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(13853.8,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-257.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(15752.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(16752.4,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(17324.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(17769,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(19749.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(20749.6,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(21234.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(21679.2,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(23577.5,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(24577.8,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="msup" transform="translate(25293.8,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path></g></g><g data-mml-node="mn" transform="translate(491,576.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container><br>利用这些统计量，线性最小二乘问题可表示成矩阵形式：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="13.143ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 5809.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mrow" transform="translate(1217.7,0)"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mtable" transform="translate(278,0)"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mtext" transform="translate(572,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(822,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mtext" transform="translate(1307,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(1557,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(2551,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g><g data-mml-node="mo" transform="translate(4324.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(5380.2,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g></g></g></svg></mjx-container><br>其中:<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.791ex;" xmlns="http://www.w3.org/2000/svg" width="119.504ex" height="2.713ex" role="img" focusable="false" viewBox="0 -849.5 52820.6 1199"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(1328.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(2384.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M202 -349V850H394V810H242V-309H394V-349H202Z"></path></g><g data-mml-node="mtable" transform="translate(417,0)"><g data-mml-node="mtr" transform="translate(0,-20.9)"><g data-mml-node="mtd"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msubsup" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(605,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mtd" transform="translate(3231.2,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(2121.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mtd" transform="translate(7169.8,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mtext" transform="translate(2121.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(2538.3,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(3761,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(4659.9,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mtd" transform="translate(13646.6,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msubsup" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(523,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mtd" transform="translate(16795.9,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mtext" transform="translate(2039.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(2456.3,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(3679,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mtd" transform="translate(22373.8,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mtd" transform="translate(25413.4,0)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g></g></g></g><g data-mml-node="mo" transform="translate(27175.9,0) translate(0 -0.5)"><path data-c="5D" d="M22 810V850H214V-349H22V-309H174V810H22Z"></path></g></g><g data-mml-node="mo" transform="translate(29977.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(30255.5,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(31422.2,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(32128.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(33184.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mrow" transform="translate(34129.4,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M202 -349V850H394V810H242V-309H394V-349H202Z"></path></g><g data-mml-node="mtable" transform="translate(417,0)"><g data-mml-node="mtr" transform="translate(0,-20.9)"><g data-mml-node="mtd"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2121.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2510.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(605,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3741.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(4741.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(523,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(5668.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mtext" transform="translate(6057.2,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(6473.8,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(7696.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(8513.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(8902.5,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(605,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10133.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(11133.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(523,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(12060,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mtext" transform="translate(12449,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(12865.7,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mo" transform="translate(13921.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(14310.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(605,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(15541.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(16541.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(523,-284.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(17468.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(18274.2,0) translate(0 -0.5)"><path data-c="5D" d="M22 810V850H214V-349H22V-309H174V810H22Z"></path></g></g></g></g></svg></mjx-container><br>解出 u,v,w 后,恢复圆心和半径：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="46.773ex" height="4.404ex" role="img" focusable="false" viewBox="0 -1260.4 20673.7 1946.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1552.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2608.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(3386.1,0)"><g data-mml-node="mi" transform="translate(220,676)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(256,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="772" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(4398.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(4676.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(5842.8,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7295.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(8350.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(9128.9,0)"><g data-mml-node="mi" transform="translate(227.5,676)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mn" transform="translate(220,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="700" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10068.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(10346.9,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(11513.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12987.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msqrt" transform="translate(14043.7,0)"><g transform="translate(1020,0)"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(562,353.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-317.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1496.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2497,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mn" transform="translate(462,353.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-317.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3893.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(4894,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(0,50.4)"><path data-c="221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path></g><rect width="5610" height="60" x="1020" y="1140.4"></rect></g></g></g></svg></mjx-container><br>最终，各层的中心坐标由圆拟合得到的圆心坐标)和观测点z坐标的平均值组成,即为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="11.98ex" height="2.347ex" role="img" focusable="false" viewBox="0 -750 5295 1037.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1663.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(2108.2,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="TeXAtom" transform="translate(462,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3282.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3727.5,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="TeXAtom" transform="translate(466,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4906,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container><br>其中<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="15.567ex" height="6.712ex" role="img" focusable="false" viewBox="0 -1720.9 6880.5 2966.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="TeXAtom" transform="translate(466,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1456.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2512.1,0)"><g data-mml-node="mn" transform="translate(220,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mn" transform="translate(220,-686)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g><rect width="700" height="60" x="120" y="220"></rect></g><g data-mml-node="munderover" transform="translate(3618.8,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(545.2,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g></g></g><g data-mml-node="msub" transform="translate(5229.4,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="TeXAtom" transform="translate(498,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(937,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></mjx-container><br>选择观测点z坐标的平均值是因为它简单且能代表该层的平均高度。</p>
<p>4.1.2模型的求解<br>利用python求解，求得各层中心点坐标，如表4.1.1所示，将其绘制成三维图如图4.1.1和4.1.2所示</p>
<table>
<thead>
<tr>
<th>层数</th>
<th>1996年 (x,y,z)</th>
<th>2006年 (x,y,z)</th>
<th>2019年 (x,y,z)</th>
<th>2021年 (x,y,z)</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>566.664,522.709,1.787</td>
<td>566.665,522.708,1.783</td>
<td>566.744,522.700,1.764</td>
<td>566.744,522.700,1.763</td>
</tr>
<tr>
<td>2</td>
<td>566.722,522.671,7.320</td>
<td>566.723,522.670,7.314</td>
<td>566.778,522.671,7.308</td>
<td>566.779,522.671,7.290</td>
</tr>
<tr>
<td>3</td>
<td>566.778,522.634,12.755</td>
<td>566.780,522.633,12.750</td>
<td>566.811,522.645,12.732</td>
<td>566.812,522.645,12.726</td>
</tr>
<tr>
<td>4</td>
<td>566.822,522.605,17.078</td>
<td>566.824,522.603,17.075</td>
<td>566.838,522.623,17.069</td>
<td>566.838,522.622,17.052</td>
</tr>
<tr>
<td>5</td>
<td>566.869,522.574,21.720</td>
<td>566.872,522.571,21.716</td>
<td>566.866,522.600,21.709</td>
<td>566.867,522.599,21.703</td>
</tr>
<tr>
<td>6</td>
<td>566.918,522.544,26.235</td>
<td>566.922,522.540,26.229</td>
<td>566.955,522.551,26.211</td>
<td>566.956,522.550,26.204</td>
</tr>
<tr>
<td>7</td>
<td>566.952,522.527,19.836</td>
<td>566.956,522.523,29.832</td>
<td>566.989,522.529,29.824</td>
<td>566.989,522.528,29.817</td>
</tr>
<tr>
<td>8</td>
<td>566.984,522.510,33.350</td>
<td>566.988,522.506,33.345</td>
<td>566.041,522.497,33.339</td>
<td>566.042,522.496,33.336</td>
</tr>
<tr>
<td>9</td>
<td>567.017,522.493,36.854</td>
<td>567.022,522.488,36.848</td>
<td>567.094,522.464,36.843</td>
<td>567.095,522.463,36.822</td>
</tr>
<tr>
<td>10</td>
<td>567.047,522.479,40.172</td>
<td>567.052,522.473,40.167</td>
<td>567.148,522.410,40.161</td>
<td>567.149,522.409,40.144</td>
</tr>
<tr>
<td>11</td>
<td>567.101,522.438,44.440</td>
<td>567.107,522.433,44.435</td>
<td>567.190,522.370,44.432</td>
<td>567.192,522.368,44.424</td>
</tr>
<tr>
<td>12</td>
<td>567.155,522.398,48.711</td>
<td>567.161,522.392,48.707</td>
<td>567.233,522.330,48.699</td>
<td>567.234,522.328,48.683</td>
</tr>
<tr>
<td>13</td>
<td>567.207,522.360,52.853</td>
<td>567.213,522.354,52.849</td>
<td>567.281,522.284,52.818</td>
<td>567.283,522.283,52.813</td>
</tr>
<tr>
<td>塔尖</td>
<td>567.264,522.254,55.108</td>
<td>567.254,522.236,55.119</td>
<td>567.336,522.214,55.091</td>
<td>567.337,522.213,55.087</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/001.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/002.png" alt="photo"></p>
<h2 id="4-2问题二模型建立、求解与分析"><a href="#4-2问题二模型建立、求解与分析" class="headerlink" title="4.2问题二模型建立、求解与分析"></a>4.2问题二模型建立、求解与分析</h2><h3 id="4-2-1问题二模型的建立"><a href="#4-2-1问题二模型的建立" class="headerlink" title="4.2.1问题二模型的建立"></a>4.2.1问题二模型的建立</h3><p>问题二要求我们分析塔的倾斜、弯曲、扭曲等变形情况。<br>对于倾斜，我们主要分析塔轴倾角\theta和倾向\alpha来表示整个塔的倾斜方向和程度。塔体的整体倾斜可以用 塔轴方向 来描述。理想情况下，古塔应当是一条竖直线，但由于长期荷载与地基变形作用，塔体的轴线发生了偏移。我们可以假设塔轴近似为一条直线，我们将每层的层心坐标(x_i,y_i,z_i)计算出来，然后用线性回归分别拟合 x 和 y 关于 z 的关系。<br>在塔体层心坐标的测量过程中，由于不可避免的观测噪声以及各层施工误差，层心坐标往往存在一定波动。如果直接采用相邻两点连线来表示塔轴，将导致结果不稳定，难以反映塔体的整体趋势。为此，我们采用最小二乘法对塔体轴线进行拟合。具体而言，分别对x与y关于高度z的关系建立线性模型：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="13.087ex" height="1.694ex" role="img" focusable="false" viewBox="0 -583 5784.5 748.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1176.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2232.5,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(2761.5,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3775.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4775.9,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container><br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="12.49ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 5520.5 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1094.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2150.5,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="msub" transform="translate(2579.5,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3593.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4593.9,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container><br>其中，参数a,b分别表示塔在xz平面和yz平面上的倾斜率，参数x_0，y0在回归模型中为截距，同时在集合意义上对应塔底层心的投影坐标。为了求得最优的 a, b, x_0 y_0，我们采用最小二乘法，即通过最小化残差平方和来拟合模型。该方法能够在测量误差近似服从正态分布的假设下，保证所求解具有无偏性和最小方差，从而获得统计意义上的最优估计。<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.697ex;" xmlns="http://www.w3.org/2000/svg" width="25.136ex" height="4.847ex" role="img" focusable="false" viewBox="0 -950 11110.2 2142.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(191.6,-600) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(529,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(807,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g><g data-mml-node="munder" transform="translate(1833.7,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(600,-1084.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="msup" transform="translate(3444.3,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1510.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2510.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2899.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(3428.4,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4442.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(5442.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(6451.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6840.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(7262.3,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container><br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.697ex;" xmlns="http://www.w3.org/2000/svg" width="24.539ex" height="4.847ex" role="img" focusable="false" viewBox="0 -950 10846.2 2142.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(256,-657.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(429,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(707,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g><g data-mml-node="munder" transform="translate(1833.7,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(600,-1084.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="msup" transform="translate(3444.3,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1428.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2428.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2817.4,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="msub" transform="translate(3246.4,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4260.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(5260.8,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(6187.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6576.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(6998.3,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container><br>在得到拟合参数 a,b 后，可以计算塔的倾角\theta和倾向角\alpha<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="20.581ex" height="5.268ex" role="img" focusable="false" viewBox="0 -1642.5 9096.8 2328.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(746.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1802.6,0)"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(892,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1336,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1725,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2225,0)"></path></g><g data-mml-node="mo" transform="translate(4583.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mfrac" transform="translate(4750.2,0)"><g data-mml-node="msqrt" transform="translate(220,676)"><g transform="translate(853,0)"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(562,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1187.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(2188,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mn" transform="translate(462,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,106.5)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="3053.6" height="60" x="853" y="846.5"></rect></g><g data-mml-node="mn" transform="translate(1923.3,-686)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><rect width="4106.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.199ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7601.9 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(917.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1973.6,0)"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(892,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1336,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1725,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2225,0)"></path></g><g data-mml-node="mo" transform="translate(4754.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mn" transform="translate(4921.2,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(5421.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5810.2,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(6239.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(6683.9,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(7212.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br>通过对不同年份的数据计算\theta和\alpha，可以分析塔体整体倾斜的程度和方向随时间的变化趋势。<br>塔体的弯曲是指塔在某一平面内的曲线形变。我们从相对塔轴的偏离和相对塔底中心的偏移两个角度进行度量。<br>考虑层心相对于塔轴的偏离，对于每一层i，层心坐标为(x_i,y_i,z_i),塔轴的方向向量为<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="11.185ex" height="2.48ex" role="img" focusable="false" viewBox="0 -846 4943.9 1096"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mo" transform="translate(270.3,32) translate(-250 0)"><path data-c="20D7" d="M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z"></path></g></g></g><g data-mml-node="mo" transform="translate(762.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(1818.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2207.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(2736.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3181.2,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(3610.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(4054.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(4554.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br>则层心到塔轴的垂直距离——弯曲量d_i可表示为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.308ex;" xmlns="http://www.w3.org/2000/svg" width="29.432ex" height="5.611ex" role="img" focusable="false" viewBox="0 -1460 13008.9 2480"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1124.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2180.5,0)"><g data-mml-node="mrow" transform="translate(220,710)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(278,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(667,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1788.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2788.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3796.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(4185.9,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(4837.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(5837.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6226.4,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7265.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(8265.8,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(9192.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(9581.3,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(10110.3,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g></g><g data-mml-node="msqrt" transform="translate(3460.9,-926.5)"><g transform="translate(853,0)"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(562,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1187.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(2188,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mn" transform="translate(462,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,106.5)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="3053.6" height="60" x="853" y="846.5"></rect></g><rect width="10588.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>其中x_0，y_0为塔底中心坐标，该量为层心在水平方向上相对于拟合直线，即塔轴的最短距离。随着高度z_i的增加，弯曲量d_i的变化趋势反映了塔体在竖直方向上的局部弯曲情况。<br>我们又引入层心偏心量ecc来描述塔体整体弯曲特征。定义第 i 层相对塔底中心的水平偏心量为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.199ex;" xmlns="http://www.w3.org/2000/svg" width="31.131ex" height="4.208ex" role="img" focusable="false" viewBox="0 -1330.2 13760 1860"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mtext"><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(444,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(888,0)"></path></g><g data-mml-node="mi" transform="translate(1365,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1936.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msqrt" transform="translate(2992.5,0)"><g transform="translate(1020,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1510.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2510.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="msup" transform="translate(3518.9,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4566.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(5566.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(5955.9,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(6995.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(7995.3,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="msup" transform="translate(8921.9,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,120.2)"><path data-c="221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path></g><rect width="9747.5" height="60" x="1020" y="1210.2"></rect></g></g></g></svg></mjx-container><br>该指标描述了各层层心相对塔底的水平位移幅度，能够直观反映塔体整体弯曲趋势。该量随着z_i单调增大并指向一致方向时，说明塔体存在逐层整体偏移的趋势。</p>
<p>为进一步分析塔尖的局部形变，我们计算顶层偏心量<br>$$<br>\text{ecc}<em>{\text{top}} = \sqrt{(x</em>{\text{top}} - x_0)^2 + (y_{\text{top}} - y_0)^2}<br>$$<br>通过对不同年份顶层偏心量的比较，可以观察塔尖随时间的形变趋势。</p>
<p>塔的扭曲是指沿高度方向，层心在水平面上旋转或偏转角度的变化。扭曲角\phi_i可定义为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="30.029ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 13272.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mi" transform="translate(629,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1200.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2256.5,0)"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(892,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1336,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1725,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2225,0)"></path></g><g data-mml-node="mo" transform="translate(5037.5,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mn" transform="translate(5204.2,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(5704.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6093.2,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7132.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(8132.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(9059.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(9503.8,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(9753.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10875,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(11875.2,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(12883.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br>该角度表示第 i 层的水平位移方向，随高度的变化反映塔体绕竖直轴的扭转特征。若\phi_i随高度单向递增或递减，表明塔存在明显的扭曲趋势。</p>
<h3 id="4-2-2问题二模型的求解"><a href="#4-2-2问题二模型的求解" class="headerlink" title="4.2.2问题二模型的求解"></a>4.2.2问题二模型的求解</h3><p>在完成指标体系的构建后，我们基于 1996年、2006年、2019年和 2021年的测量数据，分别计算了各年份对应的倾角、倾向、平均偏心量、平均弯曲量、平均扭曲角以及顶层偏心量。结果见表 4.2.1—表 4.2.4。</p>
<p><strong>表4.2.1倾角与倾向结果</strong></p>
<table>
<thead>
<tr>
<th>年份</th>
<th>倾角（度）</th>
<th>倾向（度）</th>
</tr>
</thead>
<tbody><tr>
<td>1996</td>
<td>0.7427</td>
<td>-34.81</td>
</tr>
<tr>
<td>2006</td>
<td>0.7526</td>
<td>-34.95</td>
</tr>
<tr>
<td>2019</td>
<td>0.8434</td>
<td>-37.65</td>
</tr>
<tr>
<td>2021</td>
<td>0.8455</td>
<td>-37.68</td>
</tr>
</tbody></table>
<p><strong>表4.2.2偏心量与顶层偏心量结果</strong></p>
<table>
<thead>
<tr>
<th>年份</th>
<th>平均偏心量（米）</th>
<th>顶层偏心量（米）</th>
</tr>
</thead>
<tbody><tr>
<td>1996</td>
<td>0.3629</td>
<td>0.7464</td>
</tr>
<tr>
<td>2006</td>
<td>0.3680</td>
<td>0.7561</td>
</tr>
<tr>
<td>2019</td>
<td>0.3605</td>
<td>0.7797</td>
</tr>
<tr>
<td>2021</td>
<td>0.3614</td>
<td>0.7815</td>
</tr>
</tbody></table>
<p><strong>表4.2.3弯曲量结果</strong></p>
<table>
<thead>
<tr>
<th>年份</th>
<th>平均弯曲量（米）</th>
</tr>
</thead>
<tbody><tr>
<td>1996</td>
<td>0.0117</td>
</tr>
<tr>
<td>2006</td>
<td>0.0117</td>
</tr>
<tr>
<td>2019</td>
<td>0.0063</td>
</tr>
<tr>
<td>2021</td>
<td>0.0063</td>
</tr>
</tbody></table>
<p><strong>表4.2.4扭曲角结果</strong></p>
<table>
<thead>
<tr>
<th>年份</th>
<th>平均扭曲角（度）</th>
</tr>
</thead>
<tbody><tr>
<td>1996</td>
<td>-33.0708</td>
</tr>
<tr>
<td>2006</td>
<td>-33.1866</td>
</tr>
<tr>
<td>2019</td>
<td>-35.5721</td>
</tr>
<tr>
<td>2021</td>
<td>-35.5790</td>
</tr>
</tbody></table>
<h3 id="4-2-3问题二模型的分析"><a href="#4-2-3问题二模型的分析" class="headerlink" title="4.2.3问题二模型的分析"></a>4.2.3问题二模型的分析</h3><p>通过对各项指标的对比与分析，我们可以得到以下结论：<br><strong>（1）整体倾斜趋势：</strong><br>从表 4.2.1 可见，古塔的倾角从 1996 年的约 0.74° 增加到 2021 年的约 0.85°，说明整体倾斜程度有所加剧；同时倾向也由约 34.8° 增加至 37.7°，如图4.2.1也表明塔体倾斜方向随时间略有偏移。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/003.png" alt="photo"></p>
<p><strong>（2）整体偏移与局部弯曲：</strong><br>表 4.2.2 显示平均偏心量在 0.36 米左右，波动较小，说明塔体整体重心偏移并不显著。表 4.2.3 显示平均弯曲量在 2006 年之后下降，在 2019 年与 2021年减小至约 0.006 米，如图 4.2.2所示，不同年份塔身剖面偏心量的分布情况基本保持一致，但 2019 年和 2021 年的偏移曲线整体较为平缓，表明塔体局部弯曲程度有所减轻。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/004.png" alt="photo"></p>
<p><strong>（3）扭曲变化：</strong><br>从表 4.2.4 可见，平均扭曲角从 33.1° 增加到 35.6°，说明塔体在竖向高度方向上逐渐出现轻微的旋转或偏转，这种形变具有一定的累积效应。</p>
<p><strong>（4）塔尖偏移情况：</strong><br>表 4.2.5 和图4.2.3表明顶层偏心量从 0.746 米增加到 0.782 米，整体呈上升趋势，意味着塔尖在过去二十余年中出现了逐渐的偏移。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/005.png" alt="photo"></p>
<h2 id="4-3第三问模型的建立、求解与分析"><a href="#4-3第三问模型的建立、求解与分析" class="headerlink" title="4.3第三问模型的建立、求解与分析"></a>4.3第三问模型的建立、求解与分析</h2><h3 id="4-3-1模型的建立"><a href="#4-3-1模型的建立" class="headerlink" title="4.3.1模型的建立"></a>4.3.1模型的建立</h3><p>古塔 4 次观测数据1996-2021 年时间跨度大、仅 4 个时间点，样本量少，且观测过程中可能存在仪器误差、环境干扰，如强风、振动等导致的异常值，传统线性回归对异常值敏感，易偏离真实趋势。长期非线性模型难以建立。塔体倾斜和弯曲在短时间尺度上多表现为缓慢累积的单调趋势，我们假设其变形过程在该时间尺度上可近似为线性变化。为验证这一假设，我们绘制了残差散点图，</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/006.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/007.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/008.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/08/28/009.png" alt="photo"></p>
<p>结果显示残差范围在各变量量级的 5%~10% 内，属于合理范围，残差在零附近随机波动、无系统性模式，说明线性近似是合理的。因此选择Theil-Sen 稳健线性趋势法，这是个非参数方法，抗异常值能力强，无需数据满足正态分布。量化变形速率，搭配Mann-Kendall 检验，其适用于小样本、非正态数据判断趋势是否显著，二者结合可兼顾稳健性与统计严谨性。<br><strong>1. Theil-Sen 稳健趋势斜率估计</strong><br>核心逻辑：通过计算所有“时间–指标”成对组合的斜率,取中位数作为最终趋势斜率，它能有效剔除异常值干扰，如某次观测的仪器误差,比传统线性回归更稳健。<br>我们设形变指标:倾角、偏心量、弯曲量、扭曲角的时间序列为<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.777ex;" xmlns="http://www.w3.org/2000/svg" width="8.955ex" height="2.563ex" role="img" focusable="false" viewBox="0 -789.6 3958.2 1132.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1077,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1521.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2338.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mi" transform="translate(2760.6,477.1) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(2760.6,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container><br>其中t_i表示年份，y_i, y_j表示对应的形变量</p>
<p><strong>（1）计算所有成对斜率：</strong><br>Theil–Sen 方法首先计算所有年份对之间的斜率，对 4 次观测的“时间–指标”对<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="33.337ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14735.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mn" transform="translate(394,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1186.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1631.2,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mn" transform="translate(614,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(2648.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(3037.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(3482.4,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mrow" transform="translate(3899.1,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mn" transform="translate(394,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1186.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1631.2,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mn" transform="translate(614,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(2648.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(6936.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(7381.5,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mrow" transform="translate(7798.2,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mn" transform="translate(394,-150) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g><g data-mml-node="mo" transform="translate(1186.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1631.2,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mn" transform="translate(614,-150) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g><g data-mml-node="mo" transform="translate(2648.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(10836,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(11280.7,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mrow" transform="translate(11697.3,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mn" transform="translate(394,-150) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g></g><g data-mml-node="mo" transform="translate(1186.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1631.2,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mn" transform="translate(614,-150) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g></g><g data-mml-node="mo" transform="translate(2648.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container><br>取所有 i&lt;j(i,j=1,2,3,4) 的组合，每组斜率计算公式为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.218ex;" xmlns="http://www.w3.org/2000/svg" width="31.735ex" height="5.469ex" role="img" focusable="false" viewBox="0 -1437.2 14026.9 2417.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(502,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1365.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2420.8,0)"><g data-mml-node="mrow" transform="translate(220,754.2)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mi" transform="translate(614,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(1177.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2177.8,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mi" transform="translate(614,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(440,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(957.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(1957.8,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><rect width="3285.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(5946.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(6224.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(7391.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(7780.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(8558,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(9613.8,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(10236.6,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mi" transform="translate(11292.3,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(11982.1,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(13037.9,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(13637.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br>s_{ij} 为第 i 次到第 j 次观测的 “指标变化斜率”， t_j-t_i 为两次观测的时<br>时间差(年), Y_j-Y_i 为两次观测的指标差值。</p>
<p><strong>（2）取中位数作为趋势斜率 \hat{\mathbit{k}}：</strong><br>将6个斜率 s_{ij} 按从小到大排序<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="168.326ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 74400 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="merror" data-mjx-error="Missing or unrecognized delimiter for \left" title="Missing or unrecognized delimiter for \left"><rect data-background="true" width="74400" height="950" y="-200"></rect><title>Missing or unrecognized delimiter for \left</title><g data-mml-node="mtext" style="font-family: serif;"><text data-variant="-explicitFont" transform="scale(1,-1)" font-size="884px"> \hat{k} = \mathrm{median}\left{ s_{(1)}, s_{(2)}, s_{(3)}, s_{(4)}, s_{(5)}, s_{(6)} \right} = \frac{s_{(3)} + s_{(4)}}{2} </text></g></g></g></g></svg></mjx-container><br>\hat{k}&gt;0 ：变形指标 Y_t 随时间增大,对应“倾角变大” “偏心量增加”,即变形加剧；<br>\hat{k}&lt;0 : 变形指标 Y_t 随时间减小,对应 “倾角变小” “偏心量减少”,即变形缓解；<br>\hat{k}\approx0 : 变形指标稳定,无明显时间趋势。<br>得到最终的趋势回归模型<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="12.257ex" height="2.867ex" role="img" focusable="false" viewBox="0 -1062 5417.7 1267"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1106,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2161.8,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(260.5,268) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2905,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(3405.3,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(3988.5,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4988.7,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(214.5,268) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g></g></g></svg></mjx-container><br>其中截距\hat{b}由最小化绝对偏差原则估计。该方法在存在测量噪声和异常点时依然能给出稳定的趋势结果。</p>
<p><strong>2.Mann-Kendall 趋势显著性检验</strong><br>核心逻辑：通过统计 “后一次观测指标&gt; 前一次观测指标” 的次数,判断这种“递增 / 递减”是否为随机现象，若显著非随机，则认为趋势真实存在。<br><strong>(1)构造统计量\mathbit{S}：</strong><br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.014ex;" xmlns="http://www.w3.org/2000/svg" width="26.026ex" height="6.925ex" role="img" focusable="false" viewBox="0 -1728.7 11503.4 3060.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(922.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(1978.6,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(545.2,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g><g data-mml-node="munderover" transform="translate(3589.2,0)"><g data-mml-node="mo" transform="translate(272.5,0)"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(0,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1190,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1535,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2313,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(817.8,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(5745,0)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(672,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1172,0)"></path></g></g><g data-mml-node="mrow" transform="translate(7639.6,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mi" transform="translate(614,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(1566.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2566.8,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mi" transform="translate(614,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3474.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container><br>统计所有 i&lt;j 时 “ Y_j-Y_i “ 的符号,符号函数sign(x)定义为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="135.789ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 60018.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(672,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1172,0)"></path></g></g><g data-mml-node="mo" transform="translate(1728,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2117,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2689,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3355.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(4411.6,0)"><g data-mml-node="mo"><path data-c="7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path></g><g data-mml-node="mtable" transform="translate(500,0)"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(1778,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(1905.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mstyle" transform="translate(2405.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mtext" transform="translate(3405.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">（</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">后</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">项</text><path data-c="20" d="" transform="translate(3000,0)"></path><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z" transform="translate(3250,0)"></path><path data-c="20" d="" transform="translate(4028,0)"></path><text data-variant="normal" transform="translate(4278,0) scale(1,-1)" font-size="884px" font-family="serif">前</text><text data-variant="normal" transform="translate(5278,0) scale(1,-1)" font-size="884px" font-family="serif">项</text><text data-variant="normal" transform="translate(6278,0) scale(1,-1)" font-size="884px" font-family="serif">，</text><text data-variant="normal" transform="translate(7278,0) scale(1,-1)" font-size="884px" font-family="serif">记</text><text data-variant="normal" transform="translate(8278,0) scale(1,-1)" font-size="884px" font-family="serif">为</text><path data-c="201C" d="M128 494Q128 528 137 560T158 616T185 658T209 685T223 694T236 685T245 670Q244 668 231 654T204 622T178 571T164 501Q164 489 165 489T170 491T183 497T201 500Q226 500 244 483T262 440T245 397T202 379Q173 379 151 405T128 494ZM332 494Q332 528 341 560T362 616T389 658T413 685T427 694T439 685T449 672Q449 669 437 656T411 625T383 573T368 501Q368 489 369 489T374 491T387 497T405 500Q430 500 448 483T466 440T449 397T406 379Q377 379 355 405T332 494Z" transform="translate(9278,0)"></path><text data-variant="normal" transform="translate(9778,0) scale(1,-1)" font-size="884px" font-family="serif">逆</text><text data-variant="normal" transform="translate(10778,0) scale(1,-1)" font-size="884px" font-family="serif">增</text><path data-c="201D" d="M34 634Q34 659 50 676T93 694Q121 694 144 668T168 579Q168 525 146 476T101 403T73 379Q69 379 60 388T50 401Q50 404 62 417T88 448T116 500T131 572Q131 584 130 584T125 581T112 576T94 573Q69 573 52 590T34 634ZM238 634Q238 659 254 676T297 694Q325 694 348 668T372 579Q372 525 350 476T305 403T277 379Q273 379 264 388T254 401Q254 404 266 417T292 448T320 500T335 572Q335 584 334 584T329 581T316 576T298 573Q273 573 256 590T238 634Z" transform="translate(11778,0)"></path><text data-variant="normal" transform="translate(12278,0) scale(1,-1)" font-size="884px" font-family="serif">）</text></g><g data-mml-node="mtext" transform="translate(16683.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mn" transform="translate(16933.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(17433.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(20489.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1905.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mstyle" transform="translate(2405.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mtext" transform="translate(3405.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">（</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">后</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">项</text><path data-c="20" d="" transform="translate(3000,0)"></path><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" transform="translate(3250,0)"></path><path data-c="20" d="" transform="translate(4028,0)"></path><text data-variant="normal" transform="translate(4278,0) scale(1,-1)" font-size="884px" font-family="serif">前</text><text data-variant="normal" transform="translate(5278,0) scale(1,-1)" font-size="884px" font-family="serif">项</text><text data-variant="normal" transform="translate(6278,0) scale(1,-1)" font-size="884px" font-family="serif">，</text><text data-variant="normal" transform="translate(7278,0) scale(1,-1)" font-size="884px" font-family="serif">无</text><text data-variant="normal" transform="translate(8278,0) scale(1,-1)" font-size="884px" font-family="serif">变</text><text data-variant="normal" transform="translate(9278,0) scale(1,-1)" font-size="884px" font-family="serif">化</text><text data-variant="normal" transform="translate(10278,0) scale(1,-1)" font-size="884px" font-family="serif">）</text></g><g data-mml-node="mtext" transform="translate(14683.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(15155.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(16156,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(16656,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(38423.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(1905.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mstyle" transform="translate(2405.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mtext" transform="translate(3405.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">（</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">后</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">项</text><path data-c="20" d="" transform="translate(3000,0)"></path><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z" transform="translate(3250,0)"></path><path data-c="20" d="" transform="translate(4028,0)"></path><text data-variant="normal" transform="translate(4278,0) scale(1,-1)" font-size="884px" font-family="serif">前</text><text data-variant="normal" transform="translate(5278,0) scale(1,-1)" font-size="884px" font-family="serif">项</text><text data-variant="normal" transform="translate(6278,0) scale(1,-1)" font-size="884px" font-family="serif">，</text><text data-variant="normal" transform="translate(7278,0) scale(1,-1)" font-size="884px" font-family="serif">记</text><text data-variant="normal" transform="translate(8278,0) scale(1,-1)" font-size="884px" font-family="serif">为</text><path data-c="201C" d="M128 494Q128 528 137 560T158 616T185 658T209 685T223 694T236 685T245 670Q244 668 231 654T204 622T178 571T164 501Q164 489 165 489T170 491T183 497T201 500Q226 500 244 483T262 440T245 397T202 379Q173 379 151 405T128 494ZM332 494Q332 528 341 560T362 616T389 658T413 685T427 694T439 685T449 672Q449 669 437 656T411 625T383 573T368 501Q368 489 369 489T374 491T387 497T405 500Q430 500 448 483T466 440T449 397T406 379Q377 379 355 405T332 494Z" transform="translate(9278,0)"></path><text data-variant="normal" transform="translate(9778,0) scale(1,-1)" font-size="884px" font-family="serif">递</text><text data-variant="normal" transform="translate(10778,0) scale(1,-1)" font-size="884px" font-family="serif">减</text><path data-c="201D" d="M34 634Q34 659 50 676T93 694Q121 694 144 668T168 579Q168 525 146 476T101 403T73 379Q69 379 60 388T50 401Q50 404 62 417T88 448T116 500T131 572Q131 584 130 584T125 581T112 576T94 573Q69 573 52 590T34 634ZM238 634Q238 659 254 676T297 694Q325 694 348 668T372 579Q372 525 350 476T305 403T277 379Q273 379 264 388T254 401Q254 404 266 417T292 448T320 500T335 572Q335 584 334 584T329 581T316 576T298 573Q273 573 256 590T238 634Z" transform="translate(11778,0)"></path><text data-variant="normal" transform="translate(12278,0) scale(1,-1)" font-size="884px" font-family="serif">）</text></g></g></g></g><g data-mml-node="mo" transform="translate(55607.1,0) translate(0 250)"></g></g></g></g></svg></mjx-container><br>S&gt;0 表示整体呈递增趋势,<br>S=0 表示无趋势，<br>S&lt;0 表示整体呈递减趋势。</p>
<p><strong>（2）计算方差Var(S)：</strong><br>若存在多个 Y_t 取值相同,需修正方差以避免低估趋势显著性。设同一 Y 值出现的次数为t_g,方差公式为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="53.74ex" height="5.823ex" role="img" focusable="false" viewBox="0 -1865.9 23753.3 2573.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="56" d="M114 620Q113 621 110 624T107 627T103 630T98 632T91 634T80 635T67 636T48 637H19V683H28Q46 680 152 680Q273 680 294 683H305V637H284Q223 634 223 620Q223 618 313 372T404 126L490 358Q575 588 575 597Q575 616 554 626T508 637H503V683H512Q527 680 627 680Q718 680 724 683H730V637H723Q648 637 627 596Q627 595 515 291T401 -14Q396 -22 382 -22H374H367Q353 -22 348 -14Q346 -12 231 303Q114 617 114 620Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(750,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1250,0)"></path></g></g><g data-mml-node="mo" transform="translate(1642,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2031,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(2676,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3342.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4398.6,0)"><g data-mml-node="mrow" transform="translate(220,890.3)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(600,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(989,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1811.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2811.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3311.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3700.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(4089.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(4589.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5411.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(6411.9,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g><g data-mml-node="mo" transform="translate(6911.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7523.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="munderover" transform="translate(8523.3,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mo" transform="translate(477,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1255,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msub" transform="translate(11070,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g><g data-mml-node="mo" transform="translate(11851.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(12240.3,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g><g data-mml-node="mo" transform="translate(13243.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(14244,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(14744,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(15133,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(15522,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msub" transform="translate(16022,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g><g data-mml-node="mo" transform="translate(17025.5,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(18025.7,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g><g data-mml-node="mo" transform="translate(18525.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(9177.4,-686)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)"></path></g><rect width="19114.7" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br><strong>（3）计算检验统计量 \mathbit{Z}</strong><br>在零假设（无趋势）下，S 的期望值为 0，S 近似服从正态分布，标准化为检验统计量 Z ：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.377ex;" xmlns="http://www.w3.org/2000/svg" width="68.439ex" height="5.885ex" role="img" focusable="false" viewBox="0 -1550.5 30250.2 2601"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(1000.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(2056.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7B" d="M618 -943L612 -949H582L568 -943Q472 -903 411 -841T332 -703Q327 -682 327 -653T325 -350Q324 -28 323 -18Q317 24 301 61T264 124T221 171T179 205T147 225T132 234Q130 238 130 250Q130 255 130 258T131 264T132 267T134 269T139 272T144 275Q207 308 256 367Q310 436 323 519Q324 529 325 851Q326 1124 326 1154T332 1205Q369 1358 566 1443L582 1450H612L618 1444V1429Q618 1413 616 1411L608 1406Q599 1402 585 1393T552 1372T515 1343T479 1305T449 1257T429 1200Q425 1180 425 1152T423 851Q422 579 422 549T416 498Q407 459 388 424T346 364T297 318T250 284T214 264T197 254L188 251L205 242Q290 200 345 138T416 3Q421 -18 421 -48T423 -349Q423 -397 423 -472Q424 -677 428 -694Q429 -697 429 -699Q434 -722 443 -743T465 -782T491 -816T519 -845T548 -868T574 -886T595 -899T610 -908L616 -910Q618 -912 618 -928V-943Z"></path></g><g data-mml-node="mtable" transform="translate(750,0)"><g data-mml-node="mtr" transform="translate(0,169.5)"><g data-mml-node="mtd"><g data-mml-node="mstyle"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(1078.8,676)"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(867.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1867.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="msqrt" transform="translate(220,-937.5)"><g transform="translate(1020,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="56" d="M114 620Q113 621 110 624T107 627T103 630T98 632T91 634T80 635T67 636T48 637H19V683H28Q46 680 152 680Q273 680 294 683H305V637H284Q223 634 223 620Q223 618 313 372T404 126L490 358Q575 588 575 597Q575 616 554 626T508 637H503V683H512Q527 680 627 680Q718 680 724 683H730V637H723Q648 637 627 596Q627 595 515 291T401 -14Q396 -22 382 -22H374H367Q353 -22 348 -14Q346 -12 231 303Q114 617 114 620Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(750,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1250,0)"></path></g></g><g data-mml-node="mo" transform="translate(1642,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2031,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(2676,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(0,67.5)"><path data-c="221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path></g><rect width="3065" height="60" x="1020" y="857.5"></rect></g><rect width="4285" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mo" transform="translate(4525,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(5803,0)"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(922.8,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(1978.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mtext" fill="red" stroke="red" transform="translate(2478.6,0)"><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z"></path><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z" transform="translate(500,0)"></path></g><g data-mml-node="mn" transform="translate(3256.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(3756.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4634.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5512.6,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mn" transform="translate(5790.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(6290.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(13371.6,0)"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(922.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1978.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mtext" fill="red" stroke="red" transform="translate(2478.6,0)"><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z"></path><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z" transform="translate(500,0)"></path></g><g data-mml-node="mn" transform="translate(3256.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(3756.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4634.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5512.6,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mstyle" transform="translate(5790.6,0)"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(1078.8,676)"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(867.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1867.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="msqrt" transform="translate(220,-937.5)"><g transform="translate(1020,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="56" d="M114 620Q113 621 110 624T107 627T103 630T98 632T91 634T80 635T67 636T48 637H19V683H28Q46 680 152 680Q273 680 294 683H305V637H284Q223 634 223 620Q223 618 313 372T404 126L490 358Q575 588 575 597Q575 616 554 626T508 637H503V683H512Q527 680 627 680Q718 680 724 683H730V637H723Q648 637 627 596Q627 595 515 291T401 -14Q396 -22 382 -22H374H367Q353 -22 348 -14Q346 -12 231 303Q114 617 114 620Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(750,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1250,0)"></path></g></g><g data-mml-node="mo" transform="translate(1642,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2031,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(2676,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(0,67.5)"><path data-c="221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path></g><rect width="3065" height="60" x="1020" y="857.5"></rect></g><rect width="4285" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mo" transform="translate(10315.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g><g data-mml-node="mtd" transform="translate(24965.1,0)"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(922.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(1978.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(28193.7,0) translate(0 250)"></g></g></g></g></svg></mjx-container><br>**（4）\mathbit{\tau}的计算**<br>\tau是衡量趋势方向与强度，定义为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.333ex;" xmlns="http://www.w3.org/2000/svg" width="7.138ex" height="5.457ex" role="img" focusable="false" viewBox="0 -1381 3154.8 2412"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g><g data-mml-node="mo" transform="translate(794.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1850.6,0)"><g data-mml-node="mi" transform="translate(329.6,676)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mfrac" transform="translate(220,-686)"><g data-mml-node="mi" transform="translate(220,394) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(255.4,-345) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="624.3" height="60" x="120" y="220"></rect></g><rect width="1064.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>n 是指观测值的总数<br>\tau&gt;0 表示整体呈递增趋势,<br>\tau&lt;0 表示整体呈递减趋势，<br>\left|\tau\right|越接近1，趋势越明显。</p>
<p><strong>（5）p值的计算</strong><br>p 值用于判断趋势显著性，表示在零假设（无趋势）下，观测到统计量 S 或更极端值的概率：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.985ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7949.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(780.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1836.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mrow" transform="translate(2503.2,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1111.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(2111.4,0)"><path data-c="3A6" d="M312 622Q310 623 307 625T303 629T297 631T286 634T270 635T246 636T211 637H184V683H196Q220 680 361 680T526 683H538V637H511Q468 637 447 635T422 631T411 622V533L425 531Q525 519 595 466T665 342Q665 301 642 267T583 209T506 172T425 152L411 150V61Q417 55 421 53T447 48T511 46H538V0H526Q502 3 361 3T196 0H184V46H211Q231 46 245 46T270 47T286 48T297 51T303 54T307 57T312 61V150H310Q309 151 289 153T232 166T160 195Q149 201 136 210T103 238T69 284T56 342Q56 414 128 467T294 530Q309 532 310 533H312V622ZM170 342Q170 207 307 188H312V495H309Q301 495 282 491T231 469T186 423Q170 389 170 342ZM415 188Q487 199 519 236T551 342Q551 384 539 414T507 459T470 481T434 491T415 495H410V188H415Z"></path></g><g data-mml-node="mrow" transform="translate(3000.1,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(389,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(667,0)"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(1390,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(1668,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(5057.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container><br>其中\phi(\left|Z\right|)为标准正态分布函数。<br>	•	若 p &lt; 0.05，趋势显著<br>	•	若 p\geq0.05，趋势不显著</p>
<h3 id="4-3-2模型的求解"><a href="#4-3-2模型的求解" class="headerlink" title="4.3.2模型的求解"></a>4.3.2模型的求解</h3><p><strong>表4.3.1趋势估计</strong></p>
<table>
<thead>
<tr>
<th>指标</th>
<th>倾角 θ</th>
<th>偏心量 ecc</th>
<th>弯曲量 d_i</th>
<th>扭曲量 φ</th>
</tr>
</thead>
<tbody><tr>
<td>趋势斜率</td>
<td>0.0046/年</td>
<td>0.0015/年</td>
<td>-0.0017/年</td>
<td>0.0045/年</td>
</tr>
<tr>
<td>τ</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>0.3333</td>
</tr>
<tr>
<td>p值</td>
<td>0.0833</td>
<td>0.0833</td>
<td>0.0833</td>
<td>0.7500</td>
</tr>
</tbody></table>
<p><strong>表4.3.2趋势分析结果</strong></p>
<table>
<thead>
<tr>
<th>年份</th>
<th>倾角 θ</th>
<th>偏心量 ecc</th>
<th>弯曲量 d_i</th>
<th>扭曲量 φ</th>
</tr>
</thead>
<tbody><tr>
<td>2022</td>
<td>0.8487</td>
<td>0.7828</td>
<td>0.0119</td>
<td>38.6307</td>
</tr>
<tr>
<td>2023</td>
<td>0.8533</td>
<td>0.7843</td>
<td>0.0102</td>
<td>38.6262</td>
</tr>
<tr>
<td>2024</td>
<td>0.8578</td>
<td>0.7858</td>
<td>0.0085</td>
<td>38.6216</td>
</tr>
<tr>
<td>2025</td>
<td>0.8624</td>
<td>0.7872</td>
<td>0.0067</td>
<td>38.6171</td>
</tr>
<tr>
<td>2026</td>
<td>0.8670</td>
<td>0.7887</td>
<td>0.0050</td>
<td>38.6125</td>
</tr>
</tbody></table>
<h3 id="4-3-3模型的分析"><a href="#4-3-3模型的分析" class="headerlink" title="4.3.3模型的分析"></a>4.3.3模型的分析</h3><p>根据 Theil–Sen 趋势估计与 Mann–Kendall 检验结果，可以得到古塔在未来若干年内的形变演化趋势如下：<br><strong>在整体倾斜方面</strong>，倾角\theta的趋势斜率为 0.0046/年，M–K 检验结果\tau = 1.0，表明其具有稳定的单调上升趋势。虽然对应的 p 值为 0.0833，未在 95% 置信水平下达到显著性，但结合历年数据可见，塔体倾斜程度正逐步增强。<br><strong>在塔尖偏移方面</strong>，偏心量的趋势斜率为 0.0015 m/年，同样表现为单调递增趋势（\tau = 1.0，p=0.0833）。预测结果显示，塔尖相对底心的水平偏移量将从 2021 年的约 0.7815 m 增至 2026 年的 0.789 m，说明塔尖在缓慢外移。<br><strong>在弯曲形变方面</strong>，平均弯曲量的趋势斜率为 -0.0017 m/年，M–K 检验结果\tau = -1.0，表明其呈现单调下降趋势。虽然 p=0.0833 表明显著性不足，但整体结果仍显示塔身弯曲程度在逐步减小。预测结果显示，弯曲量将由 2021 年的 0.0063 m 降至 2026 年约 0.0050 m，说明随着时间推移，塔体在局部曲率上的形变趋缓。<br><strong>在扭曲变形方面</strong>，扭曲量\phi的趋势斜率为 0.0045/年，但\tau值仅为 0.3333，且 p 值高达 0.75，表明其趋势不显著，数据中随机波动的成分较大。因此，目前无法得出塔体扭曲存在明显长期变化的结论，未来仍需进一步长期监测以提高可靠性。</p>
<h1 id="五、模型的评价与改进"><a href="#五、模型的评价与改进" class="headerlink" title="五、	模型的评价与改进"></a>五、	模型的评价与改进</h1><p>本研究采用的 Theil–Sen 稳健趋势估计结合 Mann–Kendall 显著性检验具有几个优势。它对异常值和测量误差具有较强的抵抗力，比传统线性回归更稳健；Mann–Kendall 检验可以判断趋势是否显著，不依赖数据的分布类型；这套方法易于理解，斜率和 p 值可以直观反映变形随时间的变化；它适用于观测次数较少的情况，符合古塔监测数据量有限的实际情况。<br>该方法也存在一些局限。由于 Theil–Sen 取中位数斜率，短期或局部的非线性变化可能被忽略；趋势预测仅为线性，无法考虑突发性变形或环境因素的影响；观测年份过少或分布不均时，趋势估计可能有偏差；此外，重复观测值较多时，Mann–Kendall 的精度也会下降。另外，本研究未采用平面拟合处理各层倾斜，可能导致层心位置在水平投影上存在轻微偏差，从而影响部分局部弯曲和偏心量的计算精度。<br>为了进一步提升分析效果，可以考虑结合非线性拟合方法（如 LOESS 或多项式回归）捕捉局部波动；引入环境因素或施工信息进行多变量分析，提高预测可靠性；通过增加观测点或数据插值来改善趋势估计的精细度；并在预测结果中加入置信区间或蒙特卡洛模拟，量化不确定性，为修缮和维护提供更可靠的参考。</p>
<h1 id="六、模型的推广与应用"><a href="#六、模型的推广与应用" class="headerlink" title="六、	模型的推广与应用"></a>六、	模型的推广与应用</h1><h2 id="6-1同类古建筑的变形监测"><a href="#6-1同类古建筑的变形监测" class="headerlink" title="6.1同类古建筑的变形监测"></a>6.1同类古建筑的变形监测</h2><p>本模型的核心方法可直接推广至砖石结构、木构结构等不同类型的古建筑，只需根据结构特性微调参数与假设即可适配。对于砖石结构类古塔，其层间变形规律与本次研究的古塔高度相似，仅需沿用 “圆拟合 + z 坐标平均” 的层心定位方法，若塔身截面因风化呈现非标准圆形，如椭圆形、多边形，可将圆拟合扩展为椭圆拟合或多边形拟合。</p>
<h2 id="6-2-近现代竖向结构的健康评估"><a href="#6-2-近现代竖向结构的健康评估" class="headerlink" title="6.2 近现代竖向结构的健康评估"></a>6.2 近现代竖向结构的健康评估</h2><p>近现代高耸结构，如钢筋混凝土烟囱、输电塔、水塔，与古塔同属竖向受力结构，变形类型，如倾斜、弯曲、扭曲高度相似，本模型的变形量化与趋势分析方法可直接复用，仅需针对荷载特性调整数据预处理环节。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] 张立福, 刘经南, 陈军. 基于圆拟合的塔式建筑倾斜监测方法研究[J]. 武汉大学学报(信息科学版), 2004, 29(5): 395-398.<br>[2] 王海军, 郑兴伟, 张士斌. 古建筑结构健康监测与变形分析方法研究[J]. 测绘学报, 2012, 41(3): 431-438.<br>[3] 王锐, 韩璐, 刘庆. 基于最小二乘法的圆拟合算法研究[J]. 计算机工程与应用, 2016, 52(18): 176-180.<br>[4] 	Ahn S J, Rauh W, Warnecke H J. Least-squares orthogonal distances fitting of circle, sphere, ellipse, hyperbola, and parabola[J]. Pattern Recognition, 2001, 34(12): 2283-2303.<br>[5] Theil H. A rank-invariant method of linear and polynomial regression analysis, Part 3[J]. Nederl. Akad. Wetensch., Proc., 1950, 53: 1397–1412.<br>[6] Gilbert R. O. Statistical Methods for Environmental Pollution Monitoring[M]. New York: Wiley, 1987.<br>[7] 王玉宽, 张俊. 基于Theil–Sen估计和Mann–Kendall检验的气候趋势分析[J]. 气候与环境研究, 2011, 16(1): 90–96.</p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="附录A支撑材料文件列表"><a href="#附录A支撑材料文件列表" class="headerlink" title="附录A支撑材料文件列表"></a>附录A支撑材料文件列表</h2><table>
<thead>
<tr>
<th>文件名</th>
<th>文件内容</th>
</tr>
</thead>
<tbody><tr>
<td>模拟实战2_古塔的变形.ipynb</td>
<td>三个问题的求解</td>
</tr>
<tr>
<td>temp.csv</td>
<td>把 Excel 转换成 CSV 文件</td>
</tr>
<tr>
<td>tower.csv</td>
<td>预处理填充后的完整数据</td>
</tr>
<tr>
<td>guta_centers_circle.csv</td>
<td>第一问古塔中心坐标数据</td>
</tr>
<tr>
<td>problem3.csv</td>
<td>第二问求解得到的数据</td>
</tr>
<tr>
<td>problem3_trend.csv</td>
<td>第三问预测数据</td>
</tr>
</tbody></table>
<h2 id="附录B程序代码"><a href="#附录B程序代码" class="headerlink" title="附录B程序代码"></a>附录B程序代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def fill_missing_interlayer(<span class="built_in">df</span>, year, layer, point):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    用层间差分法填充缺失点 (适用于行存在但 xyz 缺失的情况)</span></span><br><span class="line"><span class="string">    df: DataFrame，包含 [year, layer, point, x, y, z]</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    prev_layer = layer - 1</span><br><span class="line">    prev2_layer = layer - 2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 相邻两层对应点</span></span><br><span class="line">    p1 = <span class="built_in">df</span>[(<span class="built_in">df</span>[<span class="string">"year"</span>] == year) &amp; (<span class="built_in">df</span>[<span class="string">"layer"</span>] == prev2_layer) &amp; (<span class="built_in">df</span>[<span class="string">"point"</span>] == point)]</span><br><span class="line">    p2 = <span class="built_in">df</span>[(<span class="built_in">df</span>[<span class="string">"year"</span>] == year) &amp; (<span class="built_in">df</span>[<span class="string">"layer"</span>] == prev_layer) &amp; (<span class="built_in">df</span>[<span class="string">"point"</span>] == point)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> p1.empty or p2.empty:</span><br><span class="line">        raise ValueError(f<span class="string">"{year} 年第 {prev2_layer}/{prev_layer} 层缺少第 {point} 点，无法补全 {layer} 层"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算差分</span></span><br><span class="line">    dx = <span class="built_in">float</span>(p2[<span class="string">"x"</span>].values[0] - p1[<span class="string">"x"</span>].values[0])</span><br><span class="line">    dy = <span class="built_in">float</span>(p2[<span class="string">"y"</span>].values[0] - p1[<span class="string">"y"</span>].values[0])</span><br><span class="line">    dz = <span class="built_in">float</span>(p2[<span class="string">"z"</span>].values[0] - p1[<span class="string">"z"</span>].values[0])</span><br><span class="line"></span><br><span class="line">    x_missing = <span class="built_in">float</span>(p2[<span class="string">"x"</span>].values[0] + dx)</span><br><span class="line">    y_missing = <span class="built_in">float</span>(p2[<span class="string">"y"</span>].values[0] + dy)</span><br><span class="line">    z_missing = <span class="built_in">float</span>(p2[<span class="string">"z"</span>].values[0] + dz)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 找到缺失行并填充</span></span><br><span class="line">    mask = (<span class="built_in">df</span>[<span class="string">"year"</span>] == year) &amp; (<span class="built_in">df</span>[<span class="string">"layer"</span>] == layer) &amp; (<span class="built_in">df</span>[<span class="string">"point"</span>] == point)</span><br><span class="line">    <span class="keyword">if</span> mask.sum() == 0:</span><br><span class="line">        raise ValueError(f<span class="string">"{year} 年第 {layer} 层第 {point} 点行不存在"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        df.loc[mask, [<span class="string">"x"</span>, <span class="string">"y"</span>, <span class="string">"z"</span>]] = [x_missing, y_missing, z_missing]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">df</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">file_path = <span class="string">'/Volumes/HIKSEMI/作业/数学建模集训/模拟实战2_古塔的变形/模拟实战2_古塔的变形/temp.csv'</span></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(file_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">"year"</span>] = <span class="built_in">df</span>[<span class="string">"year"</span>].astype(<span class="string">"Int64"</span>)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">"point"</span>] = <span class="built_in">df</span>[<span class="string">"point"</span>].astype(<span class="string">"Int64"</span>)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">"layer"</span>] = pd.to_numeric(<span class="built_in">df</span>[<span class="string">"layer"</span>], errors=<span class="string">"coerce"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 补全 1996 和 2006 年第 13 层第 5 点</span></span><br><span class="line"><span class="built_in">df</span> = fill_missing_interlayer(<span class="built_in">df</span>, 1996, 13, 5)</span><br><span class="line"><span class="built_in">df</span> = fill_missing_interlayer(<span class="built_in">df</span>, 2006, 13, 5)</span><br><span class="line"></span><br><span class="line">df.to_csv(<span class="string">"tower.csv"</span>, index=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"缺失点已补全 保存到 tower.csv"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"填补的数据为："</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">df</span>[(<span class="built_in">df</span>[<span class="string">"year"</span>].isin([1996, 2006])) &amp; (<span class="built_in">df</span>[<span class="string">"layer"</span>] == 13) &amp; (<span class="built_in">df</span>[<span class="string">"point"</span>] == 5)])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">file_path = <span class="string">'/Volumes/HIKSEMI/作业/数学建模集训/模拟实战2_古塔的变形/模拟实战2_古塔的变形/temp.csv'</span></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分组求中心</span></span><br><span class="line">centers = df.groupby([<span class="string">"year"</span>, <span class="string">"layer"</span>]).agg(</span><br><span class="line">    x_center=(<span class="string">"x"</span>, <span class="string">"mean"</span>),</span><br><span class="line">    y_center=(<span class="string">"y"</span>, <span class="string">"mean"</span>),</span><br><span class="line">    z_center=(<span class="string">"z"</span>, <span class="string">"mean"</span>)</span><br><span class="line">).reset_index()</span><br><span class="line"></span><br><span class="line">centers.to_csv(<span class="string">"guta_centers.csv"</span>, index=False)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各层中心坐标已保存到 guta_centers.csv"</span>)</span><br><span class="line"><span class="built_in">print</span>(centers.head(20))  <span class="comment"># 先看前20行</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from scipy.optimize import least_squares</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义最小二乘圆拟合函数</span></span><br><span class="line">def fit_circle(xs, ys):</span><br><span class="line">    x_m, y_m = np.mean(xs), np.mean(ys)</span><br><span class="line">    r0 = np.mean(np.sqrt((xs - x_m)**<span class="number">2</span> + (ys - y_m)**<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">if</span> r0 &lt;= 0 or np.isnan(r0):</span><br><span class="line">        r0 = 1.0  <span class="comment"># 给一个合理的初始半径</span></span><br><span class="line">    </span><br><span class="line">    init_params = [x_m, y_m, r0]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 残差函数</span></span><br><span class="line">    def residuals(params):</span><br><span class="line">        a, b, r = params</span><br><span class="line">        <span class="built_in">return</span> np.sqrt((xs - a)**<span class="number">2</span> + (ys - b)**<span class="number">2</span>) - r</span><br><span class="line"></span><br><span class="line">    # 设置约束：半径 &gt;= <span class="number">0</span></span><br><span class="line">    res = least_squares(residuals, init_params, bounds=([-np.inf, -np.inf, <span class="number">0</span>], [np.inf, np.inf, np.inf]))</span><br><span class="line">    a, b, r = res.x</span><br><span class="line">    <span class="built_in">return</span> a, b, r</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分组拟合每层中心</span></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> (year, layer), group <span class="keyword">in</span> df.groupby([<span class="string">"year"</span>, <span class="string">"layer"</span>]):</span><br><span class="line">    xs, ys, zs = group[<span class="string">"x"</span>].values, group[<span class="string">"y"</span>].values, group[<span class="string">"z"</span>].values</span><br><span class="line">    <span class="keyword">if</span> len(group) &gt;= 3:   <span class="comment"># 点数&gt;=3才能拟合圆</span></span><br><span class="line">        try:</span><br><span class="line">            a, b, r = fit_circle(xs, ys)</span><br><span class="line">        except Exception as e:</span><br><span class="line">            <span class="built_in">print</span>(f<span class="string">"{year}-{layer} 拟合失败，改用平均值: {e}"</span>)</span><br><span class="line">            a, b = xs.mean(), ys.mean()</span><br><span class="line">            r = np.nan</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 塔尖只有1~2点时直接取平均</span></span><br><span class="line">        a, b = xs.mean(), ys.mean()</span><br><span class="line">        r = np.nan</span><br><span class="line">    zc = zs.mean()</span><br><span class="line">    results.append([year, layer, a, b, zc, r])</span><br><span class="line"></span><br><span class="line">centers_df = pd.DataFrame(results, columns=[<span class="string">"year"</span>, <span class="string">"layer"</span>, <span class="string">"x_center"</span>, <span class="string">"y_center"</span>, <span class="string">"z_center"</span>, <span class="string">"radius"</span>])</span><br><span class="line"></span><br><span class="line">centers_df.to_csv(<span class="string">"guta_centers_circle.csv"</span>, index=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"圆拟合法结果已保存到 guta_centers_circle.csv"</span>)</span><br><span class="line"><span class="built_in">print</span>(centers_df.head(20))</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">file_path = <span class="string">'/Volumes/HIKSEMI/作业/数学建模集训/模拟实战2_古塔的变形/guta_centers_circle.csv'</span></span><br><span class="line">centers_df = pd.read_csv(file_path)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(8,12))</span><br><span class="line">ax = fig.add_subplot(111, projection=<span class="string">'3d'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, row <span class="keyword">in</span> centers_df.iterrows():</span><br><span class="line">    x0, y0, z0 = row[<span class="string">'x_center'</span>], row[<span class="string">'y_center'</span>], row[<span class="string">'z_center'</span>]</span><br><span class="line">    r = row[<span class="string">'radius'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果有有效半径，绘制圆</span></span><br><span class="line">    <span class="keyword">if</span> not np.isnan(r):</span><br><span class="line">        theta = np.linspace(0, 2*np.pi, 100)</span><br><span class="line">        x = x0 + r * np.cos(theta)</span><br><span class="line">        y = y0 + r * np.sin(theta)</span><br><span class="line">        z = np.full_like(x, z0)  <span class="comment"># 圆在该层的高度</span></span><br><span class="line">        ax.plot(x, y, z, color=<span class="string">'b'</span>)  <span class="comment"># 绘制圆边</span></span><br><span class="line">        ax.scatter(x0, y0, z0, color=<span class="string">'r'</span>, s=20)  <span class="comment"># 绘制中心点</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 没有半径的点，只画中心点</span></span><br><span class="line">        ax.scatter(x0, y0, z0, color=<span class="string">'r'</span>, s=20)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置比例和标签</span></span><br><span class="line">ax.set_xlabel(<span class="string">'X'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Y'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'Z'</span>)</span><br><span class="line">ax.set_box_aspect([1,1,2])  <span class="comment"># z轴拉长一点</span></span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">"古塔三维图"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d.art3d import Poly3DCollection</span><br><span class="line">from scipy.spatial import ConvexHull</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">'/Volumes/HIKSEMI/作业/数学建模集训/模拟实战2_古塔的变形/模拟实战2_古塔的变形/temp.csv'</span></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(file_path)</span><br><span class="line"></span><br><span class="line">def layer_sort_key(x):</span><br><span class="line">    try:</span><br><span class="line">        <span class="built_in">return</span> int(x)  <span class="comment"># 数字层按数字排序</span></span><br><span class="line">    except:</span><br><span class="line">        <span class="built_in">return</span> 1000  <span class="comment"># 非数字层（塔尖）排在最后</span></span><br><span class="line"></span><br><span class="line">layers = sorted(<span class="built_in">df</span>[<span class="string">'layer'</span>].unique(), key=layer_sort_key)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制三维塔</span></span><br><span class="line">fig = plt.figure(figsize=(10,12))</span><br><span class="line">ax = fig.add_subplot(111, projection=<span class="string">'3d'</span>)</span><br><span class="line"></span><br><span class="line">layer_points = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> layers:</span><br><span class="line">    pts = <span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">'layer'</span>]==layer][[<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>]].values</span><br><span class="line">    <span class="keyword">if</span> len(pts) &gt;= 3:</span><br><span class="line">        <span class="comment"># 用 x,y 做凸包得到该层边界</span></span><br><span class="line">        hull = ConvexHull(pts[:, :2])</span><br><span class="line">        boundary = pts[hull.vertices]</span><br><span class="line">        layer_points.append(boundary)</span><br><span class="line">        <span class="comment"># 绘制该层观测点</span></span><br><span class="line">        ax.scatter(pts[:,0], pts[:,1], pts[:,2], s=10, color=<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        layer_points.append(None)</span><br><span class="line">        ax.scatter(pts[:,0], pts[:,1], pts[:,2], s=20, color=<span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接相邻层形成塔面</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(layer_points)-1):</span><br><span class="line">    pts1 = layer_points[i]</span><br><span class="line">    pts2 = layer_points[i+1]</span><br><span class="line">    <span class="keyword">if</span> pts1 is not None and pts2 is not None:</span><br><span class="line">        n1 = len(pts1)</span><br><span class="line">        n2 = len(pts2)</span><br><span class="line">        <span class="comment"># 简单按索引对应连接，循环形成四边形面</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n1):</span><br><span class="line">            p1 = pts1[j]</span><br><span class="line">            p2 = pts1[(j+1)%n1]</span><br><span class="line">            <span class="comment"># pts2 中找到与 p1 最近的两个点</span></span><br><span class="line">            distances = np.sum((pts2[:, :<span class="number">2</span>] - p1[:<span class="number">2</span>])**<span class="number">2</span>, axis=<span class="number">1</span>)</span><br><span class="line">            idx = np.argsort(distances)[:<span class="number">2</span>]</span><br><span class="line">            p3, p4 = pts2[idx[<span class="number">0</span>]], pts2[idx[<span class="number">1</span>]]</span><br><span class="line">            verts = [[p1, p2, p4, p3]]</span><br><span class="line">            ax.add_collection3d(Poly3DCollection(verts, color='orange', alpha=<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(<span class="string">'X'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Y'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'Z'</span>)</span><br><span class="line">ax.set_box_aspect([1,1,2])</span><br><span class="line">plt.title(<span class="string">"古塔三维网格模型"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from collections import defaultdict</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">'/Volumes/HIKSEMI/作业/数学建模集训/模拟实战2_古塔的变形/模拟实战2_古塔的变形/temp.csv'</span></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求每层层心</span></span><br><span class="line">layer_centers = []  <span class="comment"># (year, layer, x, y, z)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (year, layer), group <span class="keyword">in</span> df.groupby([<span class="string">"year"</span>, <span class="string">"layer"</span>]):</span><br><span class="line">    x_mean = group[<span class="string">"x"</span>].mean()</span><br><span class="line">    y_mean = group[<span class="string">"y"</span>].mean()</span><br><span class="line">    z_mean = group[<span class="string">"z"</span>].mean()</span><br><span class="line">    layer_centers.append([year, layer, x_mean, y_mean, z_mean])</span><br><span class="line"></span><br><span class="line">centers_df = pd.DataFrame(layer_centers, columns=[<span class="string">"year"</span>, <span class="string">"layer"</span>, <span class="string">"x"</span>, <span class="string">"y"</span>, <span class="string">"z"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 塔轴拟合 + 倾角/倾向</span></span><br><span class="line">def fit_axis(centers):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    输入：某一年的层心数据 (x,y,z)</span></span><br><span class="line"><span class="string">    输出：塔轴方向向量、倾角theta、倾向alpha</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    X = centers[[<span class="string">"z"</span>]].values</span><br><span class="line">    Yx = centers[<span class="string">"x"</span>].values</span><br><span class="line">    Yy = centers[<span class="string">"y"</span>].values</span><br><span class="line"></span><br><span class="line">    regx = LinearRegression().fit(X, Yx)</span><br><span class="line">    regy = LinearRegression().fit(X, Yy)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方向向量 (dx/dz, dy/dz, 1)</span></span><br><span class="line">    a = regx.coef_[0]</span><br><span class="line">    b = regy.coef_[0]</span><br><span class="line">    c = 1.0</span><br><span class="line"></span><br><span class="line">    theta = np.arctan(np.sqrt(a**2 + b**2) / c) * 180 / np.pi</span><br><span class="line">    alpha = np.arctan2(b, a) * 180 / np.pi</span><br><span class="line">    <span class="built_in">return</span> (a, b, c), theta, alpha</span><br><span class="line"></span><br><span class="line">axis_results = {}</span><br><span class="line"><span class="keyword">for</span> year, group <span class="keyword">in</span> centers_df.groupby(<span class="string">"year"</span>):</span><br><span class="line">    vec, theta, alpha = fit_axis(group)</span><br><span class="line">    axis_results[year] = {<span class="string">"theta"</span>: theta, <span class="string">"alpha"</span>: alpha}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 偏心量计算（相对第一层）</span></span><br><span class="line">ecc_results = defaultdict(list)</span><br><span class="line"><span class="keyword">for</span> (year, group) <span class="keyword">in</span> centers_df.groupby(<span class="string">"year"</span>):</span><br><span class="line">    base_x, base_y = group[group[<span class="string">"layer"</span>] == group[<span class="string">"layer"</span>].min()][[<span class="string">"x"</span>, <span class="string">"y"</span>]].values[0]</span><br><span class="line">    <span class="keyword">for</span> _, row <span class="keyword">in</span> group.iterrows():</span><br><span class="line">        ecc = np.sqrt((row["x"] - base_x) ** <span class="number">2</span> + (row["y"] - base_y) ** <span class="number">2</span>)</span><br><span class="line">        ecc_results[year].append((row["layer"], row["z"], ecc))</span><br><span class="line"></span><br><span class="line">bending_results = defaultdict(list)</span><br><span class="line">torsion_results = defaultdict(list)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year, group <span class="keyword">in</span> centers_df.groupby(<span class="string">"year"</span>):</span><br><span class="line">    <span class="comment"># 底层中心</span></span><br><span class="line">    x0, y0 = group[group[<span class="string">"layer"</span>]==group[<span class="string">"layer"</span>].min()][[<span class="string">"x"</span>,<span class="string">"y"</span>]].values[0]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 拟合塔轴</span></span><br><span class="line">    vec, theta, alpha = fit_axis(group)</span><br><span class="line">    a, b, c = vec</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> _, row <span class="keyword">in</span> group.iterrows():</span><br><span class="line">        x, y, z = row[<span class="string">"x"</span>], row[<span class="string">"y"</span>], row[<span class="string">"z"</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 弯曲：层心到塔轴的垂直距离</span></span><br><span class="line">        d = abs((x - x0)*b - (y - y0)*a) / np.sqrt(a**<span class="number">2</span> + b**<span class="number">2</span>)</span><br><span class="line">        bending_results[year].append((row["layer"], z, d))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 扭曲：层心相对底层的偏心角</span></span><br><span class="line">        phi = np.arctan2(y - y0, x - x0) * 180/np.pi</span><br><span class="line">        torsion_results[year].append((row["layer"], z, phi))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"=== 倾角与倾向 ==="</span>)</span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> sorted(axis_results.keys()):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{year}: 倾角 θ = {axis_results[year]['theta']:.4f}°, 倾向 α = {axis_results[year]['alpha']:.2f}°"</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"=== 偏心量 ==="</span>)</span><br><span class="line"><span class="keyword">for</span> year, values <span class="keyword">in</span> ecc_results.items():</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{year}: 平均偏心量 = {np.mean([v[2] for v in values]):.4f} m"</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"=== 弯曲量 ==="</span>)</span><br><span class="line"><span class="keyword">for</span> year, values <span class="keyword">in</span> bending_results.items():</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{year}: 平均弯曲量 = {np.mean([v[2] for v in values]):.4f} m"</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"=== 扭曲量 ==="</span>)</span><br><span class="line"><span class="keyword">for</span> year, values <span class="keyword">in</span> torsion_results.items():</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{year}: 平均扭曲角 = {np.mean([v[2] for v in values]):.4f}°"</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"=== 顶层偏心量 ==="</span>)</span><br><span class="line"><span class="keyword">for</span> year, values <span class="keyword">in</span> ecc_results.items():</span><br><span class="line">    top_layer, top_z, top_ecc = values[-1]</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{year}: 顶层 {top_layer} 偏心量 = {top_ecc:.4f} m"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造 CSV 数据</span></span><br><span class="line">years = sorted(axis_results.keys())</span><br><span class="line">theta_values = [axis_results[y][<span class="string">"theta"</span>] <span class="keyword">for</span> y <span class="keyword">in</span> years]</span><br><span class="line">ecc_top = [max(ecc_results[y], key=lambda v: v[1])[2] <span class="keyword">for</span> y <span class="keyword">in</span> years]  <span class="comment"># 顶层偏心量</span></span><br><span class="line">di = [max(bending_results[y], key=lambda v: v[1])[2] <span class="keyword">for</span> y <span class="keyword">in</span> years]  <span class="comment"># 最大弯曲量</span></span><br><span class="line">phi = [max(torsion_results[y], key=lambda v: v[1])[2] <span class="keyword">for</span> y <span class="keyword">in</span> years]  <span class="comment"># 最大扭曲角</span></span><br><span class="line"><span class="comment"># 创建 DataFrame</span></span><br><span class="line">predict_df = pd.DataFrame({</span><br><span class="line">    <span class="string">"year"</span>: years,</span><br><span class="line">    <span class="string">"theta"</span>: theta_values,</span><br><span class="line">    <span class="string">"ecc"</span>: ecc_top,</span><br><span class="line">    <span class="string">"di"</span>: di,</span><br><span class="line">    <span class="string">"phi"</span>: phi</span><br><span class="line">})</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存 CSV</span></span><br><span class="line">predict_df.to_csv(<span class="string">"problem3.csv"</span>, index=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"问题3使用的数据已保存到 problem3.csv"</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可视化结果</span></span><br><span class="line"><span class="comment"># 每年的剖面偏心</span></span><br><span class="line">plt.figure(figsize=(6,8))</span><br><span class="line"><span class="keyword">for</span> year, values <span class="keyword">in</span> ecc_results.items():</span><br><span class="line">    zs = [v[1] <span class="keyword">for</span> v <span class="keyword">in</span> values]</span><br><span class="line">    eccs = [v[2] <span class="keyword">for</span> v <span class="keyword">in</span> values]</span><br><span class="line">    plt.plot(eccs, zs, marker=<span class="string">"o"</span>, label=str(year))</span><br><span class="line">plt.xlabel(<span class="string">"偏心量 (m)"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"高度 z (m)"</span>)</span><br><span class="line">plt.title(<span class="string">"塔身剖面偏心量"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.gca().invert_yaxis()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 倾角随时间变化</span></span><br><span class="line">years = sorted(axis_results.keys())</span><br><span class="line">thetas = [axis_results[y][<span class="string">"theta"</span>] <span class="keyword">for</span> y <span class="keyword">in</span> years]</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(years, thetas, marker=<span class="string">"s"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"年份"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"倾角 θ (°)"</span>)</span><br><span class="line">plt.title(<span class="string">"倾角随时间变化"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顶层偏心随时间变化</span></span><br><span class="line">top_ecc = []</span><br><span class="line"><span class="keyword">for</span> year, values <span class="keyword">in</span> ecc_results.items():</span><br><span class="line">    top_ecc.append((year, max(values, key=lambda v: v[<span class="number">1</span>])[<span class="number">2</span>]))  <span class="comment"># 最高层 ecc</span></span><br><span class="line">top_ecc.sort()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot([t[0] <span class="keyword">for</span> t <span class="keyword">in</span> top_ecc], [t[1] <span class="keyword">for</span> t <span class="keyword">in</span> top_ecc], marker=<span class="string">"^"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"年份"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"顶层偏心量 (m)"</span>)</span><br><span class="line">plt.title(<span class="string">"顶层偏心随时间变化"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">"problem3.csv"</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">"theta"</span>, <span class="string">"ecc"</span>, <span class="string">"di"</span>, <span class="string">"phi"</span>]:</span><br><span class="line">    <span class="comment"># 线性回归拟合</span></span><br><span class="line">    X = <span class="built_in">df</span>[[<span class="string">"year"</span>]].values</span><br><span class="line">    y = <span class="built_in">df</span>[col].values</span><br><span class="line">    model = LinearRegression().fit(X, y)</span><br><span class="line">    y_pred = model.predict(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算残差</span></span><br><span class="line">    residuals = y - y_pred</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 画残差散点图</span></span><br><span class="line">    plt.figure(figsize=(10,4))</span><br><span class="line"></span><br><span class="line">    plt.subplot(1,2,1)</span><br><span class="line">    plt.scatter(<span class="built_in">df</span>[<span class="string">"year"</span>], residuals, color=<span class="string">"blue"</span>, s=60)</span><br><span class="line">    plt.axhline(0, color=<span class="string">"red"</span>, linestyle=<span class="string">"--"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"Year"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Residuals"</span>)</span><br><span class="line">    plt.ylim(-1,1) </span><br><span class="line">    plt.title(f<span class="string">"{col} Residuals Scatter Plot"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 画残差直方图</span></span><br><span class="line">    plt.subplot(1,2,2)</span><br><span class="line">    plt.hist(residuals, bins=5, color=<span class="string">"orange"</span>, edgecolor=<span class="string">"black"</span>, alpha=0.7)</span><br><span class="line">    plt.xlabel(<span class="string">"Residual"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Frequency"</span>)</span><br><span class="line">    plt.title(<span class="string">"Residuals Distribution"</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd, numpy as np</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from scipy.stats import kendalltau</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">"problem3.csv"</span>)</span><br><span class="line"></span><br><span class="line">def ols_forecast(x_year, y, years_ahead=5):</span><br><span class="line">    X = x_year.reshape(-1,1)</span><br><span class="line">    reg = LinearRegression().fit(X, y)</span><br><span class="line">    y_fit = reg.predict(X)</span><br><span class="line">    future_years = np.arange(x_year.max()+1, x_year.max()+1+years_ahead)</span><br><span class="line">    y_future = reg.predict(future_years.reshape(-1,1))</span><br><span class="line">    <span class="built_in">return</span> reg.coef_[0], reg.intercept_, y_fit, future_years, y_future</span><br><span class="line"></span><br><span class="line">def mann_kendall(y):</span><br><span class="line">    t = np.arange(len(y))</span><br><span class="line">    tau, p = kendalltau(t, y)</span><br><span class="line">    <span class="built_in">return</span> tau, p</span><br><span class="line"></span><br><span class="line">series_list = [<span class="string">"theta"</span>,<span class="string">"ecc"</span>,<span class="string">"di"</span>,<span class="string">"phi"</span>]</span><br><span class="line">out = {}</span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> series_list:</span><br><span class="line">    s = <span class="built_in">df</span>[name].values</span><br><span class="line">    years = <span class="built_in">df</span>[<span class="string">"year"</span>].values</span><br><span class="line">    slope, intercept, y_fit, fy, y_pred = ols_forecast(years, s, years_ahead=5)</span><br><span class="line">    tau, p = mann_kendall(s)</span><br><span class="line">    out[name] = {</span><br><span class="line">        <span class="string">"ols_slope_per_year"</span>: slope,</span><br><span class="line">        <span class="string">"kendall_tau"</span>: tau, <span class="string">"kendall_p"</span>: p,</span><br><span class="line">        <span class="string">"future_years"</span>: fy, <span class="string">"future_pred"</span>: y_pred</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"趋势分析结果："</span>)</span><br><span class="line"><span class="keyword">for</span> name, res <span class="keyword">in</span> out.items():</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"=== {name} ==="</span>)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"OLS 斜率: {res['ols_slope_per_year']:.4f} /年"</span>)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"Mann-Kendall τ: {res['kendall_tau']:.4f}, p值: {res['kendall_p']:.4f}"</span>)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"未来预测: {list(zip(res['future_years'], res['future_pred']))}"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存结果</span></span><br><span class="line">trend_df = []</span><br><span class="line"><span class="keyword">for</span> name, res <span class="keyword">in</span> out.items():</span><br><span class="line">    <span class="keyword">for</span> year, pred <span class="keyword">in</span> zip(res[<span class="string">'future_years'</span>], res[<span class="string">'future_pred'</span>]):</span><br><span class="line">        trend_df.append([name, year, pred])</span><br><span class="line">trend_df = pd.DataFrame(trend_df, columns=[<span class="string">"name"</span>, <span class="string">"year"</span>, <span class="string">"pred"</span>])</span><br><span class="line">trend_df.to_csv(<span class="string">"problem3_trend.csv"</span>, index=False)</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--金融行业收入表</title>
    <url>/zhihaojiang.github.io/2025/09/18/20250918%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E6%94%B6%E5%85%A5%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><h2 id="导入一些必要库"><a href="#导入一些必要库" class="headerlink" title="导入一些必要库"></a>导入一些必要库</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line"></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th></th>
<th>工龄</th>
<th>薪水</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.0</td>
<td>9534</td>
</tr>
<tr>
<td>1</td>
<td>0.1</td>
<td>11667</td>
</tr>
<tr>
<td>2</td>
<td>0.2</td>
<td>11015</td>
</tr>
<tr>
<td>3</td>
<td>0.3</td>
<td>10347</td>
</tr>
<tr>
<td>4</td>
<td>0.4</td>
<td>11110</td>
</tr>
</tbody></table>
<p>工龄    0<br>薪水    0<br>dtype: int64</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter(<span class="built_in">df</span>[<span class="string">'工龄'</span>], <span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/003.png" alt="photo"></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(10, 4))</span><br><span class="line">plt.subplot(1,2,1)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'工龄'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/004.png" alt="photo"><br>发现数据无异常值和缺失值，接下来我们直接使用各种模型进行应用</p>
<h2 id="拆分数据"><a href="#拆分数据" class="headerlink" title="拆分数据"></a>拆分数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(<span class="built_in">df</span>[[<span class="string">'工龄'</span>]], <span class="built_in">df</span>[<span class="string">'薪水'</span>], test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line">y_pred = lr.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 10883546.846848322<br>r2: 0.9251860541317487</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestRegressor()</span><br><span class="line">rm.fit(x_train, y_train)</span><br><span class="line">y_pred = rm.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 3772918.5643306905<br>r2: 0.9740648035783578</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor(random_state=42)</span><br><span class="line">xgb.fit(x_train, y_train)</span><br><span class="line">y_pred_xgb = xgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_xgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_xgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 4343677.356352377<br>r2: 0.9701413843133868</p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line"></span><br><span class="line">lgb = LGBMRegressor(random_state=42)</span><br><span class="line">lgb.fit(x_train, y_train)</span><br><span class="line">y_pred_lgb = lgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_lgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_lgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 11092174.291805526<br>r2: 0.9237519405478871</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.svm import SVR</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line">svr_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">'svr'</span>, SVR(kernel=<span class="string">'rbf'</span>, C=100, gamma=<span class="string">'scale'</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">svr_pipeline.fit(x_train, y_train)</span><br><span class="line">y_pred = svr_pipeline.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 94261363.28793661<br>r2: 0.3520435360157056<br>发现其效果并不好 SVM需要进行调参 使用网格优化</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = {</span><br><span class="line">    <span class="string">'svr__C'</span>: [0.1, 1, 10, 100, 1000],</span><br><span class="line">    <span class="string">'svr__gamma'</span>: [<span class="string">'scale'</span>, <span class="string">'auto'</span>, 0.001, 0.01, 0.1, 1],</span><br><span class="line">    <span class="string">'svr__kernel'</span>: [<span class="string">'rbf'</span>, <span class="string">'poly'</span>, <span class="string">'linear'</span>]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">grid = GridSearchCV(svr_pipeline, param_grid, cv=5, scoring=<span class="string">'r2'</span>, n_jobs=-1)</span><br><span class="line">grid.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳参数:"</span>, grid.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳交叉验证r2:"</span>, grid.best_score_)</span><br><span class="line"></span><br><span class="line">y_pred = grid.predict(x_test)</span><br></pre></td></tr></table></figure></div>
<p>最佳参数: {‘svr__C’: 1000, ‘svr__gamma’: ‘scale’, ‘svr__kernel’: ‘linear’}<br>最佳交叉验证r2: 0.8618895959605389</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--餐饮服务行业收入表</title>
    <url>/zhihaojiang.github.io/2025/09/18/20250918%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E9%A4%90%E9%A5%AE%E6%9C%8D%E5%8A%A1%E8%A1%8C%E4%B8%9A%E6%94%B6%E5%85%A5%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><h2 id="导入一些必要库"><a href="#导入一些必要库" class="headerlink" title="导入一些必要库"></a>导入一些必要库</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure></div>

<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line"></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<p>工龄    0<br>薪水    0<br>dtype: int64</p>
<table>
<thead>
<tr>
<th></th>
<th>工龄</th>
<th>薪水</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.0</td>
<td>3178</td>
</tr>
<tr>
<td>1</td>
<td>0.1</td>
<td>5672</td>
</tr>
<tr>
<td>2</td>
<td>0.2</td>
<td>5361</td>
</tr>
<tr>
<td>3</td>
<td>0.3</td>
<td>5146</td>
</tr>
<tr>
<td>4</td>
<td>0.3</td>
<td>5050</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter(<span class="built_in">df</span>[<span class="string">'工龄'</span>], <span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/001.png" alt="photo"></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(10, 4))</span><br><span class="line">plt.subplot(1,2,1)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'薪水'</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">plt.boxplot(<span class="built_in">df</span>[<span class="string">'工龄'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/18/002.png" alt="photo"><br>发现数据无异常值和缺失值，接下来我们直接使用各种模型进行应用</p>
<h2 id="拆分数据"><a href="#拆分数据" class="headerlink" title="拆分数据"></a>拆分数据</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(<span class="built_in">df</span>[[<span class="string">'工龄'</span>]], <span class="built_in">df</span>[<span class="string">'薪水'</span>], test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line">y_pred = lr.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 1111088.6497048205<br>r2: 0.785598944374047</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestRegressor()</span><br><span class="line">rm.fit(x_train, y_train)</span><br><span class="line">y_pred = rm.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 1133556.3043982873<br>r2: 0.7812634767360701</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor(random_state=42)</span><br><span class="line">xgb.fit(x_train, y_train)</span><br><span class="line">y_pred_xgb = xgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_xgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_xgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 1413782.32388587<br>r2: 0.7271897046676055</p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line"></span><br><span class="line">lgb = LGBMRegressor(random_state=42)</span><br><span class="line">lgb.fit(x_train, y_train)</span><br><span class="line">y_pred_lgb = lgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred_lgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred_lgb))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 901347.2993528245<br>r2: 0.8260716527720919</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.svm import SVR</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line">svr_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">'svr'</span>, SVR(kernel=<span class="string">'rbf'</span>, C=100, gamma=<span class="string">'scale'</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">svr_pipeline.fit(x_train, y_train)</span><br><span class="line">y_pred = svr_pipeline.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 1812311.167151214<br>r2: 0.6502876458479246<br>发现其效果并不好 SVM需要进行调参 使用网格优化</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = {</span><br><span class="line">    <span class="string">'svr__C'</span>: [0.1, 1, 10, 100, 1000],</span><br><span class="line">    <span class="string">'svr__gamma'</span>: [<span class="string">'scale'</span>, <span class="string">'auto'</span>, 0.001, 0.01, 0.1, 1],</span><br><span class="line">    <span class="string">'svr__kernel'</span>: [<span class="string">'rbf'</span>, <span class="string">'poly'</span>, <span class="string">'linear'</span>]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">grid = GridSearchCV(svr_pipeline, param_grid, cv=5, scoring=<span class="string">'r2'</span>, n_jobs=-1)</span><br><span class="line">grid.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳参数:"</span>, grid.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳交叉验证r2:"</span>, grid.best_score_)</span><br><span class="line"></span><br><span class="line">y_pred = grid.predict(x_test)</span><br></pre></td></tr></table></figure></div>
<p>最佳参数: {‘svr__C’: 1000, ‘svr__gamma’: ‘scale’, ‘svr__kernel’: ‘rbf’}<br>最佳交叉验证r2: 0.8459784410080479</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--客户价值数据表</title>
    <url>/zhihaojiang.github.io/2025/09/19/20250919%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E6%95%B0%E6%8D%AE%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><p>我们首先查看数据</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'客户价值数据表.xlsx'</span>)</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th></th>
<th>客户价值</th>
<th align="left">历史贷款金额</th>
<th align="left">贷款次数</th>
<th align="left">学历</th>
<th align="left">月收入</th>
<th align="left">性别</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1150</td>
<td align="left">6488</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">9567</td>
<td align="left">1</td>
</tr>
<tr>
<td>1</td>
<td>1157</td>
<td align="left">5194</td>
<td align="left">4</td>
<td align="left">2</td>
<td align="left">10767</td>
<td align="left">0</td>
</tr>
<tr>
<td>2</td>
<td>1163</td>
<td align="left">7066</td>
<td align="left">3</td>
<td align="left">2</td>
<td align="left">9317</td>
<td align="left">0</td>
</tr>
<tr>
<td>3</td>
<td>983</td>
<td align="left">3550</td>
<td align="left">3</td>
<td align="left">2</td>
<td align="left">10517</td>
<td align="left">0</td>
</tr>
<tr>
<td>4</td>
<td>1205</td>
<td align="left">7847</td>
<td align="left">3</td>
<td align="left">3</td>
<td align="left">11267</td>
<td align="left">1</td>
</tr>
</tbody></table>
<p>在这个数据中 客户价值是我们要预测的目标</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>客户价值</th>
<th>0</th>
</tr>
</thead>
<tbody><tr>
<td>历史贷款金额</td>
<td>0</td>
</tr>
<tr>
<td>贷款次数</td>
<td>0</td>
</tr>
<tr>
<td>学历</td>
<td>0</td>
</tr>
<tr>
<td>月收入</td>
<td>0</td>
</tr>
<tr>
<td>性别</td>
<td>0</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[column])</span><br><span class="line">    plt.title(column)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/001.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/002.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/003.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/004.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/005.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/006.png" alt="photo"></p>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=[<span class="string">'客户价值'</span>])</span><br><span class="line">Y = <span class="built_in">df</span>[<span class="string">'客户价值'</span>]</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line">y_pred = lr.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 24535.02941821733<br>r2: 0.5802551330031818</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">lr.coef_</span><br></pre></td></tr></table></figure></div>
<p>array([5.99175873e-02, 1.01030266e+02, 1.19661451e+02, 5.92067892e-02,1.41533251e+01])</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import statsmodels.api as sm</span><br><span class="line"></span><br><span class="line">X2 = sm.add_constant(X)</span><br><span class="line">est = sm.OLS(Y, X2).fit()</span><br><span class="line">est.summary()</span><br></pre></td></tr></table></figure></div>

<h2 id="OLS-Regression-Results"><a href="#OLS-Regression-Results" class="headerlink" title="OLS Regression Results"></a>OLS Regression Results</h2><table>
<thead>
<tr>
<th>指标</th>
<th>值</th>
</tr>
</thead>
<tbody><tr>
<td>Dep. Variable</td>
<td>客户价值</td>
</tr>
<tr>
<td>R-squared</td>
<td>0.571</td>
</tr>
<tr>
<td>Adj. R-squared</td>
<td>0.553</td>
</tr>
<tr>
<td>Model</td>
<td>OLS</td>
</tr>
<tr>
<td>Method</td>
<td>Least Squares</td>
</tr>
<tr>
<td>F-statistic</td>
<td>32.44</td>
</tr>
<tr>
<td>Prob (F-statistic)</td>
<td>6.41e-21</td>
</tr>
<tr>
<td>Log-Likelihood</td>
<td>-843.50</td>
</tr>
<tr>
<td>No. Observations</td>
<td>128</td>
</tr>
<tr>
<td>Df Residuals</td>
<td>122</td>
</tr>
<tr>
<td>Df Model</td>
<td>5</td>
</tr>
<tr>
<td>Covariance Type</td>
<td>nonrobust</td>
</tr>
<tr>
<td>AIC</td>
<td>1699</td>
</tr>
<tr>
<td>BIC</td>
<td>1716</td>
</tr>
<tr>
<td>Date</td>
<td>Fri, 19 Sep 2025</td>
</tr>
<tr>
<td>Time</td>
<td>09:57:49</td>
</tr>
</tbody></table>
<hr>
<h2 id="回归系数"><a href="#回归系数" class="headerlink" title="回归系数"></a>回归系数</h2><p>| 变量 | coef | std err | t | P&gt;|t| | [0.025 | 0.975] |<br>|——|——-|———|——|——|——–|——–|<br>| const | -208.4200 | 163.810 | -1.272 | 0.206 | -532.699 | 115.859 |<br>| 历史贷款金额 | 0.0571 | 0.010 | 5.945 | 0.000 | 0.038 | 0.076 |<br>| 贷款次数 | 96.1723 | 25.962 | 3.704 | 0.000 | 44.778 | 147.567 |<br>| 学历 | 113.4520 | 37.909 | 2.993 | 0.003 | 38.406 | 188.498 |<br>| 月收入 | 0.0561 | 0.019 | 2.941 | 0.004 | 0.018 | 0.094 |<br>| 性别 | 1.9787 | 32.286 | 0.061 | 0.951 | -61.934 | 65.891 |</p>
<hr>
<h2 id="诊断统计量"><a href="#诊断统计量" class="headerlink" title="诊断统计量"></a>诊断统计量</h2><table>
<thead>
<tr>
<th>指标</th>
<th>值</th>
</tr>
</thead>
<tbody><tr>
<td>Omnibus</td>
<td>1.597</td>
</tr>
<tr>
<td>Prob(Omnibus)</td>
<td>0.450</td>
</tr>
<tr>
<td>Jarque-Bera (JB)</td>
<td>1.538</td>
</tr>
<tr>
<td>Prob(JB)</td>
<td>0.464</td>
</tr>
<tr>
<td>Skew</td>
<td>0.264</td>
</tr>
<tr>
<td>Kurtosis</td>
<td>2.900</td>
</tr>
<tr>
<td>Durbin-Watson</td>
<td>2.155</td>
</tr>
<tr>
<td>Cond. No.</td>
<td>1.28e+05</td>
</tr>
</tbody></table>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestRegressor()</span><br><span class="line">rm.fit(x_train, y_train)</span><br><span class="line">y_pred = rm.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'mse:'</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'r2:'</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>mse: 18652.006080769228<br>r2: 0.6809017964419799</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">feature_importance = pd.DataFrame({</span><br><span class="line">    <span class="string">"feature"</span>: x_train.columns,</span><br><span class="line">    <span class="string">"importance"</span>: rm.feature_importances_</span><br><span class="line">}).sort_values(by=<span class="string">"importance"</span>, ascending=False)</span><br><span class="line"><span class="built_in">print</span>(feature_importance)</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>feature</th>
<th>importance</th>
</tr>
</thead>
<tbody><tr>
<td>历史贷款金额</td>
<td>0.404590</td>
</tr>
<tr>
<td>月收入</td>
<td>0.362695</td>
</tr>
<tr>
<td>贷款次数</td>
<td>0.130046</td>
</tr>
<tr>
<td>学历</td>
<td>0.073263</td>
</tr>
<tr>
<td>性别</td>
<td>0.029405</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import shap</span><br><span class="line"></span><br><span class="line">explainer = shap.TreeExplainer(<span class="built_in">rm</span>)</span><br><span class="line">shap_values = explainer.shap_values(x_test)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, x_test)</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/007.png" alt="photo"></p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor(random_state=42)</span><br><span class="line">xgb.fit(x_train, y_train)</span><br><span class="line">y_pred = xgb.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 32402.514511845002<br>r2: 0.4456583315103658</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import shap</span><br><span class="line"></span><br><span class="line">explainer = shap.TreeExplainer(xgb)</span><br><span class="line">shap_values = explainer.shap_values(x_test)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, x_test)</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/008.png" alt="photo"></p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=8)</span><br><span class="line">knn.fit(x_train, y_train)</span><br><span class="line">y_pred = knn.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 20527.141826923078<br>r2: 0.6488220059125291</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import shap</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测函数</span></span><br><span class="line">f = lambda X: knn.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选取一部分训练数据作为背景数据</span></span><br><span class="line">background = x_train.sample(50, random_state=42)</span><br><span class="line"></span><br><span class="line">explainer = shap.KernelExplainer(f, background)</span><br><span class="line"></span><br><span class="line">shap_values = explainer.shap_values(x_test[:50])  </span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, x_test[:50])</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/009.png" alt="photo"></p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.svm import SVR</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line">svr_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">'svr'</span>, SVR(kernel=<span class="string">'rbf'</span>, C=100, gamma=<span class="string">'scale'</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">svr_pipeline.fit(x_train, y_train)</span><br><span class="line">y_pred = svr_pipeline.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"MSE:"</span>, mean_squared_error(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"r2:"</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>MSE: 26681.700620075168<br>r2: 0.5435299185047356</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import shap</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测函数</span></span><br><span class="line">f = lambda X: svr_pipeline.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选取一部分训练数据作为背景数据</span></span><br><span class="line">background = x_train.sample(50, random_state=42)</span><br><span class="line"></span><br><span class="line">explainer = shap.KernelExplainer(f, background)</span><br><span class="line"></span><br><span class="line">shap_values = explainer.shap_values(x_test[:50])  </span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, x_test[:50])</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/19/010.png" alt="photo"></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop部署踩过的坑</title>
    <url>/zhihaojiang.github.io/2025/09/21/20250921Hadoop%E9%83%A8%E7%BD%B2%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><p>拥有了3台虚拟机 每台虚拟机都安装好了jdk和Hadoop</p>
<h1 id="Hadoop-集群搭建踩坑总结"><a href="#Hadoop-集群搭建踩坑总结" class="headerlink" title="Hadoop 集群搭建踩坑总结"></a>Hadoop 集群搭建踩坑总结</h1><h2 id="网络与-IP-配置问题"><a href="#网络与-IP-配置问题" class="headerlink" title="网络与 IP 配置问题"></a>网络与 IP 配置问题</h2><ul>
<li>在运行<strong>start-dfs.sh</strong>后 通过<strong>jps</strong>验证时发现节点不存在<strong>DataNode</strong></li>
<li><code>hdfs dfsadmin -report</code> 报错 <code>Connection refused</code></li>
<li>日志显示：</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">Address change detected. Old: 172.16.79.129 New: 127.0.1.1</span><br></pre></td></tr></table></figure></div>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ul>
<li>/etc/hosts 文件配置不当，主机名解析到 127.0.1.1 或 localhost</li>
<li>虚拟机使用 NAT 或错误的网络模式</li>
</ul>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>进入/etc/hosts文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/hosts</span><br></pre></td></tr></table></figure></div>
<p>打开应该是显示为</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1 localhost</span><br><span class="line">127.0.0.1 &lt;你设置的主机名&gt;</span><br></pre></td></tr></table></figure></div>
<p>将其改成</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1 localhost</span><br><span class="line">XXX.XXX.XXX.XXX &lt;你设置的主机名&gt;</span><br></pre></td></tr></table></figure></div>
<p>XXX.XXX.XXX.XXXz这个是你主机的IP</p>
<p>虚拟机推荐使用桥接模式 NAT也不是不可以 不过要进行端口转发</p>
<h2 id="DataNode-启动失败"><a href="#DataNode-启动失败" class="headerlink" title="DataNode 启动失败"></a>DataNode 启动失败</h2><ul>
<li>DataNode 启动后很快退出，jps 不显示 DataNode</li>
<li><ul>
<li>日志显示：</li>
</ul>
</li>
</ul>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">Address change detected. Old: 172.16.79.129 New: 127.0.1.1</span><br></pre></td></tr></table></figure></div>
<h3 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h3><ul>
<li>DataNode 尝试连接 NameNode，但 NameNode 地址解析错误</li>
<li>遗留的 PID 文件阻止进程正常启动</li>
</ul>
<h3 id="解决-1"><a href="#解决-1" class="headerlink" title="解决"></a>解决</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -f /tmp/hadoop-用户名-*.pid</span><br></pre></td></tr></table></figure></div>
<ul>
<li>确保 hdfs-site.xml 中 dfs.datanode.data.dir 指向存在且可写的目录</li>
<li>NameNode 运行正常后再启动 DataNode</li>
</ul>
<h2 id="重复启动-PID-文件残留"><a href="#重复启动-PID-文件残留" class="headerlink" title="重复启动 / PID 文件残留"></a>重复启动 / PID 文件残留</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">namenode is running as process XXX. Stop it first...</span><br></pre></td></tr></table></figure></div>

<h3 id="原因-2"><a href="#原因-2" class="headerlink" title="原因"></a>原因</h3><ul>
<li>上次进程没有完全停止，PID 文件残留</li>
</ul>
<h3 id="解决-2"><a href="#解决-2" class="headerlink" title="解决"></a>解决</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -f /tmp/hadoop-用户名-*.pid</span><br></pre></td></tr></table></figure></div>
<p>再启动集群</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></div>

<h2 id="配置文件错误或不统一"><a href="#配置文件错误或不统一" class="headerlink" title="配置文件错误或不统一"></a>配置文件错误或不统一</h2><ul>
<li>DataNode 与 NameNode 地址不匹配</li>
<li>YARN NodeManager 启动后没有正常注册</li>
</ul>
<h3 id="原因-3"><a href="#原因-3" class="headerlink" title="原因"></a>原因</h3><ul>
<li>core-site.xml 或 yarn-site.xml 中使用了 localhost 或旧 IP</li>
<li>各节点 Hadoop 配置文件不一致</li>
</ul>
<h3 id="解决-3"><a href="#解决-3" class="headerlink" title="解决"></a>解决</h3><p>cd到你的Hadoop文件夹中</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/hadoop</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span></span><br></pre></td></tr></table></figure></div>
<p>会存在下列4个文件</p>
<blockquote>
<p>core-site.xml<br>hdfs-site.xml<br>yarn-site.xml<br>mapred-site.xml</p>
</blockquote>
<p><strong>core-site.xml</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://主节点IP:9000&lt;/value&gt;  &lt;!-- NameNode IP --&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>
<p>fs.defaultFS 指向 NameNode 的 IP:端口，所以所有节点都要写成 主节点的 IP，不能写 localhost</p>
<p><strong>hdfs-site.xml</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;file:///home/用户名/hadoop/dfs/datanode&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>
<p>然后创建个目录 确保目录存在并且 Hadoop 用户有权限读写</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/zhihaojiang/hadoop/dfs/datanode</span><br><span class="line"><span class="built_in">chown</span> -R zhihaojiang: /home/zhihaojiang/hadoop/dfs</span><br><span class="line"><span class="built_in">chmod</span> -R 755 /home/zhihaojiang/hadoop/dfs</span><br></pre></td></tr></table></figure></div>

<p><strong>yarn-site.xml</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;主节点IP&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>

<p><strong>mapred-site.xml</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>
<p>所有节点都需要配置一致，表示 MapReduce 使用 YARN 作为资源管理</p>
<h2 id="虚拟机克隆和静态-IP"><a href="#虚拟机克隆和静态-IP" class="headerlink" title="虚拟机克隆和静态 IP"></a>虚拟机克隆和静态 IP</h2><ul>
<li>克隆虚拟机如果直接启动，IP 会冲突，导致 DataNode 无法注册</li>
<li>/etc/hosts 中重复或错误映射旧节点</li>
</ul>
<h3 id="解决-4"><a href="#解决-4" class="headerlink" title="解决"></a>解决</h3><ul>
<li>克隆虚拟机后修改静态 IP</li>
<li>更新 NameNode 上的 workers 文件</li>
<li>更新所有节点 /etc/hosts</li>
</ul>
<p>在Hadoop文件夹中ls找到workers</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano workers</span><br></pre></td></tr></table></figure></div>
<p>里面的文件改成</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">IP 节点1主机名称</span><br><span class="line">IP 节点2主机名称</span><br><span class="line">IP 节点3主机名称</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--员工离职预测模型</title>
    <url>/zhihaojiang.github.io/2025/09/23/20250923%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E5%91%98%E5%B7%A5%E7%A6%BB%E8%81%8C%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> =pd.read_excel(<span class="string">'员工离职预测模型.xlsx'</span>)</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>工资</th>
<th>满意度</th>
<th>考核得分</th>
<th>工程数量</th>
<th>月工时</th>
<th>工龄</th>
<th>离职</th>
</tr>
</thead>
<tbody><tr>
<td>低</td>
<td>3.8</td>
<td>0.53</td>
<td>2</td>
<td>157</td>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>中</td>
<td>8.0</td>
<td>0.86</td>
<td>5</td>
<td>262</td>
<td>6</td>
<td>1</td>
</tr>
<tr>
<td>中</td>
<td>1.1</td>
<td>0.88</td>
<td>7</td>
<td>272</td>
<td>4</td>
<td>1</td>
</tr>
<tr>
<td>低</td>
<td>7.2</td>
<td>0.87</td>
<td>5</td>
<td>223</td>
<td>5</td>
<td>1</td>
</tr>
<tr>
<td>低</td>
<td>3.7</td>
<td>0.52</td>
<td>2</td>
<td>159</td>
<td>3</td>
<td>1</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段</th>
<th>缺失值数量</th>
</tr>
</thead>
<tbody><tr>
<td>工资</td>
<td>0</td>
</tr>
<tr>
<td>满意度</td>
<td>0</td>
</tr>
<tr>
<td>考核得分</td>
<td>0</td>
</tr>
<tr>
<td>工程数量</td>
<td>0</td>
</tr>
<tr>
<td>月工时</td>
<td>0</td>
</tr>
<tr>
<td>工龄</td>
<td>0</td>
</tr>
<tr>
<td>离职</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.select_dtypes(include=[<span class="string">'number'</span>]).columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/009.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/010.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/011.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/012.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/013.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/014.png" alt="photo"></p>
<p>通过上述图表我们发现<br><strong>离职（目标变量）存在异常值</strong><br>从上面分析中我们知道离职是0-1变量 这说明离职的样本中 不离职的样本非常多 离职的样本非常少 这导致其把离职的当成了异常值</p>
<p><strong>工龄存在异常值</strong><br>我们发现大部份人的工龄在2-5年之间 那些被认为是异常值的都是工龄较长的由于我们是要做员工离职预测模型 我认为那些离职的员工有可能是那些工龄年限长的员工 因此我们不能把这个异常值给删除或归一化处理 因此我们将这个异常值给突出保留下来</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">col = <span class="string">'工龄'</span></span><br><span class="line"></span><br><span class="line">Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[f<span class="string">'{col}_is_outlier'</span>] = ((df[col] &lt; lower_bound) | (df[col] &gt; upper_bound)).astype(int)</span><br></pre></td></tr></table></figure></div>
<h1 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h1><p>可以看到 工资特征不是数值型 我们需要对其进行处理</p>
<p>因为初始工资是按照低中高分类的 因此我们直接使用映射将低中高映射为0、1、2 这样还能保留低中高的顺序关系<br><strong>注意</strong> 这里不推荐使用独热编码 因为其会丢失低中高的顺序关系</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">'工资'</span>] = <span class="built_in">df</span>[<span class="string">'工资'</span>].map({<span class="string">'低'</span>: 0, <span class="string">'中'</span>: 1, <span class="string">'高'</span>: 2})</span><br></pre></td></tr></table></figure></div>

<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=[<span class="string">'离职'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'离职'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">dtc = DecisionTreeClassifier(random_state=42)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>900</td>
<td>136</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>150</td>
<td>223</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.86</td>
<td>0.87</td>
<td>0.86</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td>0.62</td>
<td>0.60</td>
<td>0.61</td>
<td>373</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.80</strong></td>
<td>1409</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.74</td>
<td>0.73</td>
<td>0.74</td>
<td>1409</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.80</td>
<td>0.80</td>
<td>0.80</td>
<td>1409</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(dtc, X_train, y_train, cv=5, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各折准确率："</span>, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"平均准确率：%.4f (+/- %.4f)"</span> % (scores.mean(), scores.std() * 2))</span><br></pre></td></tr></table></figure></div>
<p>各折准确率： [0.97625    0.97833333 0.96958333 0.97541667 0.98      ]<br>平均准确率：0.9759 (+/- 0.0071)</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">param_grid = {</span><br><span class="line">    <span class="string">'max_depth'</span>: [3, 5, 7, 10, None],</span><br><span class="line">    <span class="string">'min_samples_split'</span>: [2, 5, 10],</span><br><span class="line">    <span class="string">'min_samples_leaf'</span>: [1, 2, 4],</span><br><span class="line">    <span class="string">'criterion'</span>: [<span class="string">'gini'</span>, <span class="string">'entropy'</span>]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">dtc = DecisionTreeClassifier(random_state=42)</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(</span><br><span class="line">    estimator=dtc,</span><br><span class="line">    param_grid=param_grid,</span><br><span class="line">    cv=5,</span><br><span class="line">    scoring=<span class="string">'f1'</span>,</span><br><span class="line">    n_jobs=-1,           <span class="comment"># 使用所有 CPU 核心加速</span></span><br><span class="line">    verbose=1            <span class="comment"># 显示过程</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳参数："</span>, grid_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"最佳交叉验证得分：%.4f"</span> % grid_search.best_score_)</span><br><span class="line"></span><br><span class="line">best_dtc = grid_search.best_estimator_</span><br><span class="line">y_pred = best_dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n=== 测试集结果 ==="</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"混淆矩阵："</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n分类报告："</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<p><strong>最佳参数：</strong><br><code>{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}</code></p>
<p><strong>最佳交叉验证得分：</strong> 0.9564<br><strong>混淆矩阵：</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2236</td>
<td>38</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>21</td>
<td>705</td>
</tr>
</tbody></table>
<p><strong>分类报告：</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.99</td>
<td>0.98</td>
<td>0.99</td>
<td>2274</td>
</tr>
<tr>
<td>1</td>
<td>0.95</td>
<td>0.97</td>
<td>0.96</td>
<td>726</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.98</strong></td>
<td>3000</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.97</td>
<td>0.98</td>
<td>0.97</td>
<td>3000</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.98</td>
<td>0.98</td>
<td>0.98</td>
<td>3000</td>
</tr>
</tbody></table>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_pred = rm.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2268</td>
<td>6</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>20</td>
<td>706</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.99</td>
<td>1.00</td>
<td>0.99</td>
<td>2274</td>
</tr>
<tr>
<td>1</td>
<td>0.99</td>
<td>0.97</td>
<td>0.98</td>
<td>726</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.99</strong></td>
<td>3000</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.99</td>
<td>0.98</td>
<td>0.99</td>
<td>3000</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.99</td>
<td>0.99</td>
<td>0.99</td>
<td>3000</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">scores = cross_val_score(<span class="built_in">rm</span>, X_train, y_train, cv=5, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各折准确率："</span>, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"平均准确率：%.4f (+/- %.4f)"</span> % (scores.mean(), scores.std() * 2))</span><br></pre></td></tr></table></figure></div>
<p>各折准确率： [0.99041667 0.99041667 0.98833333 0.99083333 0.99208333]<br>平均准确率：0.9904 (+/- 0.0024)</p>
<h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line">GBDT = GradientBoostingClassifier(random_state=42)</span><br><span class="line">GBDT.fit(X_train, y_train)</span><br><span class="line">y_pred = GBDT.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2249</td>
<td>25</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>53</td>
<td>673</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.98</td>
<td>0.99</td>
<td>0.98</td>
<td>2274</td>
</tr>
<tr>
<td>1</td>
<td>0.96</td>
<td>0.93</td>
<td>0.95</td>
<td>726</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.97</strong></td>
<td>3000</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.97</td>
<td>0.96</td>
<td>0.96</td>
<td>3000</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.97</td>
<td>0.97</td>
<td>0.97</td>
<td>3000</td>
</tr>
</tbody></table>
<p>各折准确率： [0.97333333 0.97625    0.97708333 0.97708333 0.97458333]<br>平均准确率：0.9757 (+/- 0.0030)</p>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"></span><br><span class="line">nb = GaussianNB()</span><br><span class="line">nb.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred_nb = nb.predict(X_test)</span><br><span class="line">y_pred_proba = nb.predict_proba(X_test)[:, 1]  <span class="comment"># 离职概率（正类概率）</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"混淆矩阵："</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_nb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n分类报告："</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_nb))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n前5个样本的离职概率："</span>, y_pred_proba[:5])</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2071</td>
<td>203</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>293</td>
<td>433</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.88</td>
<td>0.91</td>
<td>0.89</td>
<td>2274</td>
</tr>
<tr>
<td>1</td>
<td>0.68</td>
<td>0.60</td>
<td>0.64</td>
<td>726</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.83</strong></td>
<td>3000</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.78</td>
<td>0.75</td>
<td>0.76</td>
<td>3000</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.83</td>
<td>0.83</td>
<td>3000</td>
</tr>
</tbody></table>
<p>前5个样本的离职概率：<br><code>[0.0299, 0.0785, 0.0041, 0.6395, 0.1225]</code></p>
<h1 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.discriminant_analysis import LinearDiscriminantAnalysis</span><br><span class="line"></span><br><span class="line">LDA = LinearDiscriminantAnalysis()</span><br><span class="line">LDA.fit(X_train, y_train)</span><br><span class="line">y_pred_lda = LDA.predict(X_test)</span><br><span class="line">y_pred_proba_lda = LDA.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"混淆矩阵："</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_lda))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n分类报告："</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_lda))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2096</td>
<td>178</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>523</td>
<td>203</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.80</td>
<td>0.92</td>
<td>0.86</td>
<td>2274</td>
</tr>
<tr>
<td>1</td>
<td>0.53</td>
<td>0.28</td>
<td>0.37</td>
<td>726</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.77</strong></td>
<td>3000</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.67</td>
<td>0.60</td>
<td>0.61</td>
<td>3000</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.74</td>
<td>0.77</td>
<td>0.74</td>
<td>3000</td>
</tr>
</tbody></table>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb = XGBClassifier()</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred_xgb = xgb.predict(X_test)</span><br><span class="line">y_pred_proba_xgb = xgb.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"混淆矩阵："</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_xgb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n分类报告："</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_xgb))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2260</td>
<td>14</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>29</td>
<td>697</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.99</td>
<td>0.99</td>
<td>0.99</td>
<td>2274</td>
</tr>
<tr>
<td>1</td>
<td>0.98</td>
<td>0.96</td>
<td>0.97</td>
<td>726</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.99</strong></td>
<td>3000</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.98</td>
<td>0.98</td>
<td>0.98</td>
<td>3000</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.99</td>
<td>0.99</td>
<td>0.99</td>
<td>3000</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--手写字体识别</title>
    <url>/zhihaojiang.github.io/2025/09/23/20250923%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E6%89%8B%E5%86%99%E5%AD%97%E4%BD%93%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'手写字体识别.xlsx'</span></span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>对应数字</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>…</th>
<th>1014</th>
<th>1015</th>
<th>1016</th>
<th>1017</th>
<th>1018</th>
<th>1019</th>
<th>1020</th>
<th>1021</th>
<th>1022</th>
<th>1023</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop(columns=<span class="string">'对应数字'</span>)</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'对应数字'</span>]</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=5)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Accuracy:"</span>, accuracy)</span><br></pre></td></tr></table></figure></div>
<p>Accuracy: 0.9534883720930233</p>
<p><strong>测试</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">img = Image.open(<span class="string">'数字4.png'</span>)</span><br><span class="line">img = img.resize((<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">img = img.convert(<span class="string">'L'</span>)</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">img_new = img.point(lambda x: 0 <span class="keyword">if</span> x &gt; 128 <span class="keyword">else</span> 1)</span><br><span class="line">arr = np.array(img_new)</span><br><span class="line">arr_new = arr.reshape(1, -1)</span><br><span class="line"></span><br><span class="line">answer = knn.predict(arr_new) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">'图片中的数字为：'</span> + str(answer[0]))</span><br></pre></td></tr></table></figure></div>
<p>图片中的数字为：4</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.svm import SVC</span><br><span class="line">svm = SVC(kernel=<span class="string">'rbf'</span>)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line">score = svm.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'SVM模型的准确率为：'</span> + str(score))</span><br></pre></td></tr></table></figure></div>
<p>SVM模型的准确率为：0.9715762273901809<br><strong>测试</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">answer = rf.predict(arr_new) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">'图片中的数字为：'</span> + str(answer[0]))</span><br></pre></td></tr></table></figure></div>
<p>图片中的数字为：4</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">rf = RandomForestClassifier(n_estimators=100)</span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">score = rf.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'随机森林模型的准确率为：'</span> + str(score))</span><br></pre></td></tr></table></figure></div>
<p>随机森林模型的准确率为：0.9689922480620154</p>
<p><strong>测试</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">answer = rf.predict(arr_new) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">'图片中的数字为：'</span> + str(answer[0]))</span><br></pre></td></tr></table></figure></div>
<p>图片中的数字为：4</p>
<h1 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neural_network import MLPClassifier</span><br><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)</span><br><span class="line">mlp.fit(X_train, y_train)</span><br><span class="line">score = mlp.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'神经网络模型的准确率为：'</span> + str(score))</span><br></pre></td></tr></table></figure></div>
<p>神经网络模型的准确率为：0.958656330749354</p>
<p><strong>测试</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">answer = rf.predict(arr_new) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">'图片中的数字为：'</span> + str(answer[0]))</span><br></pre></td></tr></table></figure></div>
<p>图片中的数字为：4</p>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'手写字体识别.xlsx'</span>)</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=<span class="string">'对应数字'</span>)</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'对应数字'</span>]</span><br><span class="line"></span><br><span class="line">X = X.to_numpy().reshape(-1, 32, 32, 1).astype(<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">X = X / 255.0</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">model = models.Sequential([</span><br><span class="line">    layers.Conv2D(32, (3,3), activation=<span class="string">'relu'</span>, input_shape=(32,32,1)),</span><br><span class="line">    layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)),</span><br><span class="line">    layers.Conv2D(64, (3,3), activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(64, activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.Dense(10, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">history</span> = model.fit(X_train, y_train,</span><br><span class="line">                    epochs=10,</span><br><span class="line">                    batch_size=32,</span><br><span class="line">                    validation_data=(X_test, y_test))</span><br></pre></td></tr></table></figure></div>
<p>Epoch 1/10<br>/opt/anaconda3/envs/tf-metal/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an <code>input_shape</code>/<code>input_dim</code> argument to a layer. When using Sequential models, prefer using an <code>Input(shape)</code> object as the first layer in the model instead.<br>  super().<strong>init</strong>(activity_regularizer=activity_regularizer, **kwargs)<br>2025-09-23 20:17:35.573018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 4s 33ms/step - accuracy: 0.1034 - loss: 2.3043 - val_accuracy: 0.0749 - val_loss: 2.3025<br>Epoch 2/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.1028 - loss: 2.3010 - val_accuracy: 0.1137 - val_loss: 2.2969<br>Epoch 3/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 11ms/step - accuracy: 0.1713 - loss: 2.2660 - val_accuracy: 0.2481 - val_loss: 2.1901<br>Epoch 4/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 11ms/step - accuracy: 0.5184 - loss: 1.9033 - val_accuracy: 0.6382 - val_loss: 1.4705<br>Epoch 5/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7673 - loss: 1.0627 - val_accuracy: 0.8062 - val_loss: 0.7945<br>Epoch 6/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 11ms/step - accuracy: 0.8649 - loss: 0.5883 - val_accuracy: 0.8527 - val_loss: 0.5462<br>Epoch 7/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.8908 - loss: 0.4113 - val_accuracy: 0.8786 - val_loss: 0.4564<br>Epoch 8/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.9089 - loss: 0.3249 - val_accuracy: 0.9044 - val_loss: 0.3793<br>Epoch 9/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 11ms/step - accuracy: 0.9211 - loss: 0.2893 - val_accuracy: 0.9018 - val_loss: 0.3861<br>Epoch 10/10<br>49/49 ━━━━━━━━━━━━━━━━━━━━ 1s 11ms/step - accuracy: 0.9302 - loss: 0.2541 - val_accuracy: 0.9173 - val_loss: 0.3233</p>
<p><strong>测试</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">img = Image.open(<span class="string">'数字4.png'</span>)</span><br><span class="line">img = img.resize((<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">img = img.convert(<span class="string">'L'</span>)</span><br><span class="line">img_new = img.point(lambda x: 0 <span class="keyword">if</span> x &gt; 128 <span class="keyword">else</span> 1)</span><br><span class="line"></span><br><span class="line">arr = np.array(img_new)</span><br><span class="line"></span><br><span class="line">arr_new = arr.reshape(1, 32, 32, 1).astype(<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">answer = model.predict(arr_new)</span><br><span class="line">predicted_digit = np.argmax(answer[0])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'图片中的数字为：'</span> + str(predicted_digit))</span><br></pre></td></tr></table></figure></div>
<p>1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 582ms/step<br>图片中的数字为：4</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--股票客户流失</title>
    <url>/zhihaojiang.github.io/2025/09/23/20250923%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E8%82%A1%E7%A5%A8%E5%AE%A2%E6%88%B7%E6%B5%81%E5%A4%B1/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'股票客户流失.xlsx'</span>)</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>账户资金（元）</th>
<th>最后一次交易距今时间（天）</th>
<th>上月交易佣金（元）</th>
<th>累计交易佣金（元）</th>
<th>本券商使用时长（年）</th>
<th>是否流失</th>
</tr>
</thead>
<tbody><tr>
<td>22686.5</td>
<td>297</td>
<td>149.25</td>
<td>2029.85</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>190055.0</td>
<td>42</td>
<td>284.75</td>
<td>3889.50</td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td>29733.5</td>
<td>233</td>
<td>269.25</td>
<td>2108.15</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>185667.5</td>
<td>44</td>
<td>211.50</td>
<td>3840.75</td>
<td>3</td>
<td>0</td>
</tr>
<tr>
<td>33648.5</td>
<td>213</td>
<td>353.50</td>
<td>2151.65</td>
<td>0</td>
<td>1</td>
</tr>
</tbody></table>
<h1 id="查看缺失值情况"><a href="#查看缺失值情况" class="headerlink" title="查看缺失值情况"></a>查看缺失值情况</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段名</th>
<th>值</th>
</tr>
</thead>
<tbody><tr>
<td>账户资金（元）</td>
<td>0</td>
</tr>
<tr>
<td>最后一次交易距今时间（天）</td>
<td>0</td>
</tr>
<tr>
<td>上月交易佣金（元）</td>
<td>0</td>
</tr>
<tr>
<td>累计交易佣金（元）</td>
<td>0</td>
</tr>
<tr>
<td>本券商使用时长（年）</td>
<td>0</td>
</tr>
<tr>
<td>是否流失</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="查看异常值情况"><a href="#查看异常值情况" class="headerlink" title="查看异常值情况"></a>查看异常值情况</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/001.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/002.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/003.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/004.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/005.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/006.png" alt="photo"></p>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=[<span class="string">'是否流失'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'是否流失'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line"></span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import accuracy_score, confusion_matrix, classification_report</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Accuracy:"</span>, accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Confusion Matrix:\n"</span>, confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Classification Report:\n"</span>, classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p><strong>准确率 (Accuracy):</strong> 0.7949</p>
<p><strong>混淆矩阵 (Confusion Matrix):</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>952</td>
<td>84</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>205</td>
<td>168</td>
</tr>
</tbody></table>
<p><strong>分类报告 (Classification Report):</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.82</td>
<td>0.92</td>
<td>0.87</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td>0.67</td>
<td>0.45</td>
<td>0.54</td>
<td>373</td>
</tr>
<tr>
<td>accuracy</td>
<td></td>
<td></td>
<td>0.79</td>
<td>1409</td>
</tr>
<tr>
<td>macro avg</td>
<td>0.74</td>
<td>0.68</td>
<td>0.70</td>
<td>1409</td>
</tr>
<tr>
<td>weighted avg</td>
<td>0.78</td>
<td>0.79</td>
<td>0.78</td>
<td>1409</td>
</tr>
</tbody></table>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.svm import SVC</span><br><span class="line"></span><br><span class="line">svc = SVC(random_state=42, probability=True)</span><br><span class="line">svc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_svc_pred = svc.predict(X_test)</span><br><span class="line">y_svc_proba = svc.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line">def calculate_ks(y_true, y_proba):</span><br><span class="line">    data = np.column_stack([y_proba, y_true])</span><br><span class="line">    sorted_data = data[data[:, 0].argsort()[::-1]]</span><br><span class="line">    </span><br><span class="line">    total_pos = np.sum(y_true == 1)</span><br><span class="line">    total_neg = np.sum(y_true == 0)</span><br><span class="line">    </span><br><span class="line">    cum_pos = 0</span><br><span class="line">    cum_neg = 0</span><br><span class="line">    max_ks = 0</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> prob, label <span class="keyword">in</span> sorted_data:</span><br><span class="line">        <span class="keyword">if</span> label == 1:</span><br><span class="line">            cum_pos += 1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cum_neg += 1</span><br><span class="line">        tpr = cum_pos / total_pos</span><br><span class="line">        fpr = cum_neg / total_neg</span><br><span class="line">        ks = abs(tpr - fpr)</span><br><span class="line">        <span class="keyword">if</span> ks &gt; max_ks:</span><br><span class="line">            max_ks = ks</span><br><span class="line">    <span class="built_in">return</span> max_ks</span><br><span class="line"></span><br><span class="line">ks_score = calculate_ks(y_test, y_svc_proba)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"SVC Accuracy:"</span>, accuracy_score(y_test, y_svc_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KS Score:"</span>, ks_score)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Confusion Matrix:\n"</span>, confusion_matrix(y_test, y_svc_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Classification Report:\n"</span>, classification_report(y_test, y_svc_pred))</span><br></pre></td></tr></table></figure></div>
<p><strong>准确率 (Accuracy):</strong> 0.7353<br><strong>KS Score:</strong> 0.3043</p>
<p><strong>混淆矩阵 (Confusion Matrix):</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>1036</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>373</td>
<td>0</td>
</tr>
</tbody></table>
<p><strong>分类报告 (Classification Report):</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.74</td>
<td>1.00</td>
<td>0.85</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>373</td>
</tr>
<tr>
<td>accuracy</td>
<td></td>
<td></td>
<td>0.74</td>
<td>1409</td>
</tr>
<tr>
<td>macro avg</td>
<td>0.37</td>
<td>0.50</td>
<td>0.42</td>
<td>1409</td>
</tr>
<tr>
<td>weighted avg</td>
<td>0.54</td>
<td>0.74</td>
<td>0.62</td>
<td>1409</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">def plot_ks_curve(y_true, y_proba):</span><br><span class="line">    data = np.column_stack([y_proba, y_true])</span><br><span class="line">    sorted_data = data[data[:, 0].argsort()[::-1]]</span><br><span class="line">    </span><br><span class="line">    total_pos = np.sum(y_true == 1)</span><br><span class="line">    total_neg = np.sum(y_true == 0)</span><br><span class="line">    </span><br><span class="line">    cum_pos = 0</span><br><span class="line">    cum_neg = 0</span><br><span class="line">    tpr_list = []</span><br><span class="line">    fpr_list = []</span><br><span class="line">    thresholds = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> prob, label <span class="keyword">in</span> sorted_data:</span><br><span class="line">        <span class="keyword">if</span> label == 1:</span><br><span class="line">            cum_pos += 1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cum_neg += 1</span><br><span class="line">        tpr_list.append(cum_pos / total_pos)</span><br><span class="line">        fpr_list.append(cum_neg / total_neg)</span><br><span class="line">        thresholds.append(prob)</span><br><span class="line">    </span><br><span class="line">    ks_list = np.abs(np.array(tpr_list) - np.array(fpr_list))</span><br><span class="line">    max_ks_idx = np.argmax(ks_list)</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(8, 6))</span><br><span class="line">    plt.plot(thresholds, tpr_list, label=<span class="string">'TPR'</span>, color=<span class="string">'blue'</span>)</span><br><span class="line">    plt.plot(thresholds, fpr_list, label=<span class="string">'FPR'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">    plt.plot(thresholds, ks_list, label=<span class="string">'KS'</span>, color=<span class="string">'green'</span>, linestyle=<span class="string">'--'</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    plt.axvline(x=thresholds[max_ks_idx], color=<span class="string">'gray'</span>, linestyle=<span class="string">':'</span>, label=f<span class="string">'Max KS'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'预测概率阈值'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'比率'</span>)</span><br><span class="line">    plt.title(<span class="string">'KS 曲线'</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid(True)</span><br><span class="line">    plt.gca().invert_xaxis()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_ks_curve(y_test, y_svc_proba)</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/007.png" alt="photo"></p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=5)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_knn_pred = knn.predict(X_test)</span><br><span class="line">y_knn_proba = knn.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line">ks_score_knn = calculate_ks(y_test, y_knn_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KNN Accuracy:"</span>, accuracy_score(y_test, y_knn_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KNN KS Score:"</span>, ks_score_knn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KNN Confusion Matrix:\n"</span>, confusion_matrix(y_test, y_knn_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KNN Classification Report:\n"</span>, classification_report(y_test, y_knn_pred))</span><br></pre></td></tr></table></figure></div>
<p><strong>准确率 (Accuracy):</strong> 0.7580<br><strong>KS Score:</strong> 0.3060</p>
<p><strong>混淆矩阵 (Confusion Matrix):</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>940</td>
<td>96</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>245</td>
<td>128</td>
</tr>
</tbody></table>
<p><strong>分类报告 (Classification Report):</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.79</td>
<td>0.91</td>
<td>0.85</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td>0.57</td>
<td>0.34</td>
<td>0.43</td>
<td>373</td>
</tr>
<tr>
<td>accuracy</td>
<td></td>
<td></td>
<td>0.76</td>
<td>1409</td>
</tr>
<tr>
<td>macro avg</td>
<td>0.68</td>
<td>0.63</td>
<td>0.64</td>
<td>1409</td>
</tr>
<tr>
<td>weighted avg</td>
<td>0.73</td>
<td>0.76</td>
<td>0.74</td>
<td>1409</td>
</tr>
</tbody></table>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(n_estimators=100, random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_rm_pred = rm.predict(X_test)</span><br><span class="line">y_rm_proba = rm.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line">ks_score_rm = calculate_ks(y_test, y_rm_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Random Forest Accuracy:"</span>, accuracy_score(y_test, y_rm_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Random Forest KS Score:"</span>, ks_score_rm)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Random Forest Confusion Matrix:\n"</span>, confusion_matrix(y_test, y_rm_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Random Forest Classification Report:\n"</span>, classification_report(y_test, y_rm_pred))</span><br></pre></td></tr></table></figure></div>
<p><strong>准确率 (Accuracy):</strong> 0.7686<br><strong>KS Score:</strong> 0.4445<br><strong>混淆矩阵 (Confusion Matrix):</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>909</td>
<td>127</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>199</td>
<td>174</td>
</tr>
</tbody></table>
<p><strong>分类报告 (Classification Report):</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.82</td>
<td>0.88</td>
<td>0.85</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td>0.58</td>
<td>0.47</td>
<td>0.52</td>
<td>373</td>
</tr>
<tr>
<td>accuracy</td>
<td></td>
<td></td>
<td>0.77</td>
<td>1409</td>
</tr>
<tr>
<td>macro avg</td>
<td>0.70</td>
<td>0.67</td>
<td>0.68</td>
<td>1409</td>
</tr>
<tr>
<td>weighted avg</td>
<td>0.76</td>
<td>0.77</td>
<td>0.76</td>
<td>1409</td>
</tr>
</tbody></table>
<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    Dense(32, activation=<span class="string">'relu'</span>, input_shape=(5,)),  <span class="comment"># 第一层，32个神经元</span></span><br><span class="line">    Dropout(0.3),                                   <span class="comment"># 防止过拟合</span></span><br><span class="line">    Dense(16, activation=<span class="string">'relu'</span>),                   <span class="comment"># 第二层，16个神经元</span></span><br><span class="line">    Dropout(0.3),</span><br><span class="line">    Dense(1, activation=<span class="string">'sigmoid'</span>)                  <span class="comment"># 输出层，sigmoid用于二分类</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=Adam(learning_rate=0.001),</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>,   <span class="comment"># 二分类损失函数</span></span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">early_stop = EarlyStopping(</span><br><span class="line">    monitor=<span class="string">'val_loss'</span>,</span><br><span class="line">    patience=10,           <span class="comment"># 如果验证损失10轮不下降就停止</span></span><br><span class="line">    restore_best_weights=True  <span class="comment"># 恢复最佳权重</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">history</span> = model.fit(</span><br><span class="line">    X_train_scaled, y_train,</span><br><span class="line">    validation_data=(X_test_scaled, y_test),</span><br><span class="line">    epochs=100,            <span class="comment"># 最多训练100轮</span></span><br><span class="line">    batch_size=32,</span><br><span class="line">    callbacks=[early_stop],</span><br><span class="line">    verbose=1</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">y_pred_proba = model.predict(X_test_scaled).flatten()  <span class="comment"># 预测概率</span></span><br><span class="line">y_pred = (y_pred_proba &gt; 0.5).astype(int)              <span class="comment"># 转为0/1标签</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"=== 神经网络评估结果 ==="</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Accuracy:"</span>, accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"AUC:"</span>, roc_auc_score(y_test, y_pred_proba))</span><br><span class="line"></span><br><span class="line">def calculate_ks(y_true, y_proba):</span><br><span class="line">    data = np.column_stack([y_proba, y_true])</span><br><span class="line">    sorted_data = data[data[:, 0].argsort()[::-1]]</span><br><span class="line">    total_pos = np.sum(y_true == 1)</span><br><span class="line">    total_neg = np.sum(y_true == 0)</span><br><span class="line">    cum_pos = 0</span><br><span class="line">    cum_neg = 0</span><br><span class="line">    max_ks = 0</span><br><span class="line">    <span class="keyword">for</span> prob, label <span class="keyword">in</span> sorted_data:</span><br><span class="line">        <span class="keyword">if</span> label == 1:</span><br><span class="line">            cum_pos += 1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cum_neg += 1</span><br><span class="line">        tpr = cum_pos / total_pos</span><br><span class="line">        fpr = cum_neg / total_neg</span><br><span class="line">        ks = abs(tpr - fpr)</span><br><span class="line">        <span class="keyword">if</span> ks &gt; max_ks:</span><br><span class="line">            max_ks = ks</span><br><span class="line">    <span class="built_in">return</span> max_ks</span><br><span class="line"></span><br><span class="line">ks_score = calculate_ks(y_test, y_pred_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KS Score:"</span>, ks_score)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\nConfusion Matrix:\n"</span>, confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\nClassification Report:\n"</span>, classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(12, 4))</span><br><span class="line"></span><br><span class="line">plt.subplot(1, 2, 1)</span><br><span class="line">plt.plot(history.history[<span class="string">'loss'</span>], label=<span class="string">'Training Loss'</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'val_loss'</span>], label=<span class="string">'Validation Loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Model Loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(1, 2, 2)</span><br><span class="line">plt.plot(history.history[<span class="string">'accuracy'</span>], label=<span class="string">'Training Accuracy'</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'val_accuracy'</span>], label=<span class="string">'Validation Accuracy'</span>)</span><br><span class="line">plt.title(<span class="string">'Model Accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><strong>准确率 (Accuracy):</strong> 0.7984<br><strong>AUC:</strong> 0.8338<br><strong>KS Score:</strong> 0.5174</p>
<hr>
<p><strong>混淆矩阵 (Confusion Matrix):</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>959</td>
<td>77</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>207</td>
<td>166</td>
</tr>
</tbody></table>
<hr>
<p><strong>分类报告 (Classification Report):</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.82</td>
<td>0.93</td>
<td>0.87</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td>0.68</td>
<td>0.45</td>
<td>0.54</td>
<td>373</td>
</tr>
<tr>
<td>accuracy</td>
<td></td>
<td></td>
<td>0.80</td>
<td>1409</td>
</tr>
<tr>
<td>macro avg</td>
<td>0.75</td>
<td>0.69</td>
<td>0.70</td>
<td>1409</td>
</tr>
<tr>
<td>weighted avg</td>
<td>0.79</td>
<td>0.80</td>
<td>0.78</td>
<td>1409</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/008.png" alt="photo"></p>
<h1 id="横向对比"><a href="#横向对比" class="headerlink" title="横向对比"></a>横向对比</h1><table>
<thead>
<tr>
<th>指标</th>
<th>SVC</th>
<th>KNN</th>
<th>Random Forest</th>
<th><strong>Neural Network</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Accuracy</strong></td>
<td>0.735</td>
<td>0.758</td>
<td>0.769</td>
<td><strong>0.798</strong></td>
</tr>
<tr>
<td><strong>AUC</strong></td>
<td>-</td>
<td>-</td>
<td>-</td>
<td><strong>0.834</strong></td>
</tr>
<tr>
<td><strong>KS Score</strong></td>
<td>0.304</td>
<td>0.306</td>
<td>0.444</td>
<td><strong>0.517</strong></td>
</tr>
<tr>
<td>Class 1 Recall</td>
<td>0.00</td>
<td>0.34</td>
<td>0.47</td>
<td><strong>0.45</strong></td>
</tr>
<tr>
<td>Class 1 F1</td>
<td>0.00</td>
<td>0.43</td>
<td>0.52</td>
<td><strong>0.54</strong></td>
</tr>
</tbody></table>
<p>看起来准确率都还行 但是可以看到召回率最高只有0.47 由于我们是要分析预测股票客户流失 因此 我们得着重提高召回率</p>
<p>以神经网络为例 使用<strong>class_weight</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算类别权重</span></span><br><span class="line">classes = np.unique(y_train)</span><br><span class="line">class_weights = compute_class_weight(<span class="string">'balanced'</span>, classes=classes, y=y_train)</span><br><span class="line">class_weight_dict = dict(zip(classes, class_weights))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Class weights:"</span>, class_weight_dict)</span><br><span class="line"><span class="built_in">history</span> = model.fit(</span><br><span class="line">    X_train_scaled, y_train,</span><br><span class="line">    validation_data=(X_test_scaled, y_test),</span><br><span class="line">    epochs=100,            <span class="comment"># 最多训练100轮</span></span><br><span class="line">    batch_size=32,</span><br><span class="line">    callbacks=[early_stop],</span><br><span class="line">    class_weight=class_weight_dict,  <span class="comment"># 使用类别权重</span></span><br><span class="line">    verbose=1</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>
<p><strong>准确率 (Accuracy):</strong> 0.7459<br><strong>AUC:</strong> 0.8336<strong>KS Score:</strong> 0.5153<br><strong>混淆矩阵 (Confusion Matrix):</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>778</td>
<td>258</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>100</td>
<td>273</td>
</tr>
</tbody></table>
<hr>
<p><strong>分类报告 (Classification Report):</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.89</td>
<td>0.75</td>
<td>0.81</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td><strong>0.51</strong></td>
<td><strong>0.73</strong></td>
<td><strong>0.60</strong></td>
<td>373</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.75</strong></td>
<td>1409</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.70</td>
<td><strong>0.74</strong></td>
<td>0.71</td>
<td>1409</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.79</td>
<td>0.75</td>
<td>0.76</td>
<td>1409</td>
</tr>
</tbody></table>
<p>可以看到 尽管准确率有所降低 但是召回率大幅提高到了0.73 说明模型对真实流失客户的预测准确率提高了</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><p>对于不平衡的样本 我们还可以使用像XGBoost或者lightGBM</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb = XGBClassifier(use_label_encoder=False, eval_metric=<span class="string">'logloss'</span>, random_state=42)</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_xgb_pred = xgb.predict(X_test)</span><br><span class="line">y_xgb_proba = xgb.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line">ks_score_xgb = calculate_ks(y_test, y_xgb_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGB Accuracy:"</span>, accuracy_score(y_test, y_xgb_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGB KS Score:"</span>, ks_score_xgb)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGB Confusion Matrix:\n"</span>, confusion_matrix(y_test, y_xgb_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGB Classification Report:\n"</span>, classification_report(y_test, y_xgb_pred))</span><br></pre></td></tr></table></figure></div>

<p><strong>准确率 (Accuracy):</strong> 0.812<br><strong>KS Score:</strong> 0.538<br><strong>混淆矩阵 (Confusion Matrix):</strong></p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>【如 920】</td>
<td>【如 116】</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>【如 150】</td>
<td>【如 223】</td>
</tr>
</tbody></table>
<p><strong>分类报告 (Classification Report):</strong></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>【如 0.86】</td>
<td>【如 0.89】</td>
<td>【如 0.87】</td>
<td>1036</td>
</tr>
<tr>
<td>1</td>
<td>【如 0.66】</td>
<td>【如 0.60】</td>
<td>【如 0.63】</td>
<td>373</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>【如 0.81】</strong></td>
<td>1409</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>【如 0.76】</td>
<td>【如 0.74】</td>
<td>【如 0.75】</td>
<td>1409</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>【如 0.80】</td>
<td>【如 0.81】</td>
<td>【如 0.80】</td>
<td>1409</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--肿瘤数据</title>
    <url>/zhihaojiang.github.io/2025/09/23/20250923%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E8%82%BF%E7%98%A4%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'肿瘤数据.xlsx'</span>)</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>最大周长</th>
<th>最大凹陷度</th>
<th>平均凹陷度</th>
<th>最大面积</th>
<th>最大半径</th>
<th>平均灰度值</th>
<th>肿瘤性质</th>
</tr>
</thead>
<tbody><tr>
<td>184.60</td>
<td>0.2654</td>
<td>0.14710</td>
<td>2019.0</td>
<td>25.38</td>
<td>17.33</td>
<td>0</td>
</tr>
<tr>
<td>158.80</td>
<td>0.1860</td>
<td>0.07017</td>
<td>1956.0</td>
<td>24.99</td>
<td>23.41</td>
<td>0</td>
</tr>
<tr>
<td>152.50</td>
<td>0.2430</td>
<td>0.12790</td>
<td>1709.0</td>
<td>23.57</td>
<td>25.53</td>
<td>1</td>
</tr>
<tr>
<td>98.87</td>
<td>0.2575</td>
<td>0.10520</td>
<td>567.7</td>
<td>14.91</td>
<td>26.50</td>
<td>0</td>
</tr>
<tr>
<td>152.20</td>
<td>0.1625</td>
<td>0.10430</td>
<td>1575.0</td>
<td>22.54</td>
<td>16.67</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段</th>
<th>缺失值数量</th>
</tr>
</thead>
<tbody><tr>
<td>最大周长</td>
<td>0</td>
</tr>
<tr>
<td>最大凹陷度</td>
<td>0</td>
</tr>
<tr>
<td>平均凹陷度</td>
<td>0</td>
</tr>
<tr>
<td>最大面积</td>
<td>0</td>
</tr>
<tr>
<td>最大半径</td>
<td>0</td>
</tr>
<tr>
<td>平均灰度值</td>
<td>0</td>
</tr>
<tr>
<td>肿瘤性质</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/015.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/016.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/017.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/018.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/019.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/020.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/021.png" alt="photo"></p>
<p>发现用四分位数发现存在一些异常值 朴素贝叶斯是对异常值敏感的 我们可视化数据的分布情况</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">cols = [<span class="string">'最大周长'</span>, <span class="string">'平均凹陷度'</span>, <span class="string">'最大面积'</span>, <span class="string">'最大半径'</span>, <span class="string">'平均灰度值'</span>]</span><br><span class="line">target_col = <span class="string">'肿瘤性质'</span></span><br><span class="line"></span><br><span class="line">n_cols = len(cols)</span><br><span class="line">fig, axes = plt.subplots(n_cols, 2, figsize=(14, n_cols * 4))</span><br><span class="line">fig.suptitle(<span class="string">'特征分布与目标变量关系'</span>, fontsize=16, fontweight=<span class="string">'bold'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, col <span class="keyword">in</span> enumerate(cols):</span><br><span class="line">    ax1 = axes[i, 0]</span><br><span class="line">    ax2 = axes[i, 1]</span><br><span class="line"></span><br><span class="line">    sns.histplot(</span><br><span class="line">        data=<span class="built_in">df</span>,</span><br><span class="line">        x=col,</span><br><span class="line">        hue=target_col,</span><br><span class="line">        kde=True,</span><br><span class="line">        ax=ax1,</span><br><span class="line">        bins=30,</span><br><span class="line">        alpha=0.7,</span><br><span class="line">        palette=<span class="string">'Set2'</span></span><br><span class="line">    )</span><br><span class="line">    ax1.set_title(f<span class="string">'{col} - 分布直方图 &amp; KDE'</span>, fontsize=14)</span><br><span class="line">    ax1.grid(True, linestyle=<span class="string">'--'</span>, alpha=0.6)</span><br><span class="line"></span><br><span class="line">    sns.boxplot(</span><br><span class="line">        data=<span class="built_in">df</span>,</span><br><span class="line">        x=target_col,</span><br><span class="line">        y=col,</span><br><span class="line">        ax=ax2,</span><br><span class="line">        palette=<span class="string">'Set2'</span></span><br><span class="line">    )</span><br><span class="line">    ax2.set_title(f<span class="string">'{col} - 箱线图'</span>, fontsize=14)</span><br><span class="line">    ax2.grid(True, linestyle=<span class="string">'--'</span>, alpha=0.6)</span><br><span class="line">    ax2.set_xlabel(<span class="string">'目标类别'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout(rect=[0, 0, 1, 0.97])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/23/022.png" alt="photo"></p>
<p>可以发现 数据呈现右偏 应该是使用对数变换处理 不过为了更具体我们测试各类预处理方案</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">from sklearn.preprocessing import StandardScaler, RobustScaler</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">score_raw = cross_val_score(GaussianNB(), X, y, cv=5, scoring=<span class="string">'f1'</span>).mean()</span><br><span class="line"></span><br><span class="line">X_scaled = StandardScaler().fit_transform(X)</span><br><span class="line">score_scaled = cross_val_score(GaussianNB(), X_scaled, y, cv=5, scoring=<span class="string">'f1'</span>).mean()</span><br><span class="line"></span><br><span class="line">X_robust = RobustScaler().fit_transform(X)</span><br><span class="line">score_robust = cross_val_score(GaussianNB(), X_robust, y, cv=5, scoring=<span class="string">'f1'</span>).mean()</span><br><span class="line"></span><br><span class="line">X_log = np.log(X + 1)</span><br><span class="line">score_log = cross_val_score(GaussianNB(), X_log, y, cv=5, scoring=<span class="string">'f1'</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"原始: {score_raw:.4f}"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"标准化: {score_scaled:.4f}"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"鲁棒缩放: {score_robust:.4f}"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"对数变换: {score_log:.4f}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>原始: 0.9711<br>标准化: 0.9651<br>鲁棒缩放: 0.9651<br>对数变换: 0.9692<br>发现不进行预处理反而会更好</p>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"></span><br><span class="line">nb = GaussianNB()</span><br><span class="line">nb.fit(X_train, y_train)</span><br><span class="line">y_pred = nb.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>准确率：0.9649</p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>39</td>
<td>3</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>1</td>
<td>71</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.97</td>
<td>0.93</td>
<td>0.95</td>
<td>42</td>
</tr>
<tr>
<td>1</td>
<td>0.96</td>
<td>0.99</td>
<td>0.97</td>
<td>72</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.96</strong></td>
<td>114</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.97</td>
<td>0.96</td>
<td>0.96</td>
<td>114</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.97</td>
<td>0.96</td>
<td>0.96</td>
<td>114</td>
</tr>
</tbody></table>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>其他的数据我们添加异常值的</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'肿瘤数据.xlsx'</span>)</span><br><span class="line"></span><br><span class="line">cols = [<span class="string">'最大周长'</span>, <span class="string">'平均凹陷度'</span>, <span class="string">'最大面积'</span>, <span class="string">'最大半径'</span>, <span class="string">'平均灰度值'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">    Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">    Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">    lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">    upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line">    <span class="built_in">df</span>[f<span class="string">'{col}_is_outlier'</span>] = ((df[col] &lt; lower_bound) | (df[col] &gt; upper_bound)).astype(int)</span><br><span class="line"></span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=[<span class="string">'肿瘤性质'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'肿瘤性质'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line">y_pred = lr.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>准确率：0.9561</p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>39</td>
<td>3</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>2</td>
<td>70</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.95</td>
<td>0.93</td>
<td>0.94</td>
<td>42</td>
</tr>
<tr>
<td>1</td>
<td>0.96</td>
<td>0.97</td>
<td>0.97</td>
<td>72</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.96</strong></td>
<td>114</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.96</td>
<td>0.95</td>
<td>0.95</td>
<td>114</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.96</td>
<td>0.96</td>
<td>0.96</td>
<td>114</td>
</tr>
</tbody></table>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">dtc = DecisionTreeClassifier(random_state=42)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>准确率：0.9211</p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>37</td>
<td>5</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>4</td>
<td>68</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.90</td>
<td>0.88</td>
<td>0.89</td>
<td>42</td>
</tr>
<tr>
<td>1</td>
<td>0.93</td>
<td>0.94</td>
<td>0.94</td>
<td>72</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.92</strong></td>
<td>114</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.92</td>
<td>0.91</td>
<td>0.91</td>
<td>114</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.92</td>
<td>0.92</td>
<td>0.92</td>
<td>114</td>
</tr>
</tbody></table>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb = XGBClassifier(use_label_encoder=False, eval_metric=<span class="string">'logloss'</span>, random_state=42)</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_xgb_pred = xgb.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGB Accuracy:"</span>, accuracy_score(y_test, y_xgb_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGB Confusion Matrix:\n"</span>, confusion_matrix(y_test, y_xgb_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGB Classification Report:\n"</span>, classification_report(y_test, y_xgb_pred))</span><br></pre></td></tr></table></figure></div>
<p><strong>XGB Accuracy:</strong> 0.9561</p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>39</td>
<td>3</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>2</td>
<td>70</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.95</td>
<td>0.93</td>
<td>0.94</td>
<td>42</td>
</tr>
<tr>
<td>1</td>
<td>0.96</td>
<td>0.97</td>
<td>0.97</td>
<td>72</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.96</strong></td>
<td>114</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.96</td>
<td>0.95</td>
<td>0.95</td>
<td>114</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.96</td>
<td>0.96</td>
<td>0.96</td>
<td>114</td>
</tr>
</tbody></table>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(n_estimators=100, random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_rm_pred = rm.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Random Forest Accuracy:"</span>, accuracy_score(y_test, y_rm_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Random Forest Confusion Matrix:\n"</span>, confusion_matrix(y_test, y_rm_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Random Forest Classification Report:\n"</span>, classification_report(y_test, y_rm_pred))</span><br></pre></td></tr></table></figure></div>

<p><strong>Random Forest Accuracy:</strong> 0.9561</p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>39</td>
<td>3</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>2</td>
<td>70</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.95</td>
<td>0.93</td>
<td>0.94</td>
<td>42</td>
</tr>
<tr>
<td>1</td>
<td>0.96</td>
<td>0.97</td>
<td>0.97</td>
<td>72</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.96</strong></td>
<td>114</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.96</td>
<td>0.95</td>
<td>0.95</td>
<td>114</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.96</td>
<td>0.96</td>
<td>0.96</td>
<td>114</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>linux常用命令</title>
    <url>/zhihaojiang.github.io/2025/09/22/20250924linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="远程连接-ssh"><a href="#远程连接-ssh" class="headerlink" title="远程连接 ssh"></a>远程连接 ssh</h1><p>Linux上不能复制粘贴 并且大部份时候其实Linux是运行在服务器上的 个人不会直接在服务器上使用 大多数时候是管理人员给你一个IP地址和用户名 通过远程连接 因此我们使用ssh远程连接 现在的电脑都自带openssh 打开终端（window上叫cmd）<br>运行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ssh 用户名@IP地址</span><br></pre></td></tr></table></figure></div>
<p>用户名在Linux中运行<strong>whoami</strong>即可查看<br>IP地址运行<strong>ip a</strong>即可查看</p>
<p>运行后按回车 第一次会让你确认是否连接 输入<strong>yes</strong></p>
<h1 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h1><h2 id="查看虚拟机的IP"><a href="#查看虚拟机的IP" class="headerlink" title="查看虚拟机的IP"></a>查看虚拟机的IP</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ip a</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">ip addr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">ifconfig</span><br></pre></td></tr></table></figure></div>
<p>查看网络接口信息 例如我运行ip a时显示</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~$ ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:73:b0:46 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    altname enp2s0</span><br><span class="line">    inet 172.16.79.129/24 brd 172.16.79.255 scope global ens160</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe73:b046/64 scope link proto kernel_ll </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></div>
<p>可以看到<strong>172.16.79.129</strong>就是这台Linux的IP</p>
<h2 id="修改静态IP"><a href="#修改静态IP" class="headerlink" title="修改静态IP"></a>修改静态IP</h2><p>在Ubuntu中</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/netplan/00-installer-config.yaml</span><br></pre></td></tr></table></figure></div>
<p>将文件中的改为</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    ens33:</span><br><span class="line">      dhcp4: no</span><br><span class="line">      addresses: [192.168.1.102/24]   # 改成新IP</span><br><span class="line">      gateway4: 192.168.1.1</span><br><span class="line">      nameservers:</span><br><span class="line">        addresses: [8.8.8.8, 1.1.1.1]</span><br></pre></td></tr></table></figure></div>
<p>保存后执行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> netplan apply</span><br></pre></td></tr></table></figure></div>

<h2 id="ping"><a href="#ping" class="headerlink" title="ping"></a>ping</h2><p>运行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ping ip</span><br></pre></td></tr></table></figure></div>
<p>可以查看当前虚拟机网络是否畅通<br>若畅通 则其会显示(以ping baidu.com为例)</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">└─(21:46:47 on main ✖ ✭)──&gt; ping baidu.com                                  ──(一, 922)─┘</span><br><span class="line">PING baidu.com (39.156.70.37): 56 data bytes</span><br><span class="line">64 bytes from 39.156.70.37: icmp_seq=0 ttl=52 time=29.018 ms</span><br><span class="line">64 bytes from 39.156.70.37: icmp_seq=1 ttl=52 time=29.395 ms</span><br><span class="line">64 bytes from 39.156.70.37: icmp_seq=2 ttl=52 time=29.145 ms</span><br><span class="line">64 bytes from 39.156.70.37: icmp_seq=3 ttl=52 time=29.567 ms</span><br><span class="line">^C</span><br></pre></td></tr></table></figure></div>

<h2 id="curl"><a href="#curl" class="headerlink" title="curl"></a>curl</h2><p>下载或访问网页</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">curl -O http://xxx/file.zip</span><br></pre></td></tr></table></figure></div>

<h2 id="wegt"><a href="#wegt" class="headerlink" title="wegt"></a>wegt</h2><p>下载文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">wget http://xxx/file.tar.gz</span><br></pre></td></tr></table></figure></div>

<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><h2 id="pwd"><a href="#pwd" class="headerlink" title="pwd"></a>pwd</h2><p>显示当前路径</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">└─(21:57:08 on main ✖ ✭)──&gt; <span class="built_in">pwd</span>                                             ──(一, 922)─┘</span><br><span class="line">/Users/jiangzhihao</span><br></pre></td></tr></table></figure></div>

<p>运行后显示我当前在 <em>/Users/jiangzhihao</em>中</p>
<h2 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h2><p>列出目录内容</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">└─(21:57:10 on main ✖ ✭)──&gt; <span class="built_in">ls</span>                                              ──(一, 922)─┘</span><br><span class="line">Adlm</span><br><span class="line">Applications</span><br><span class="line">CodeGeeXProjects</span><br><span class="line">Creative Cloud Files  zhihaojiangzhj@126.com C9F41D6A65B065A70A495C64@AdobeID</span><br><span class="line">Desktop</span><br><span class="line">Documents</span><br><span class="line">Downloads</span><br><span class="line">Library</span><br><span class="line">Movies</span><br><span class="line">Music</span><br><span class="line">Pictures</span><br><span class="line">Public</span><br><span class="line">Sunlogin</span><br><span class="line">Sunlogin Files</span><br><span class="line">Virtual Machines.localized</span><br><span class="line">dify</span><br><span class="line">exo</span><br><span class="line">jupyter_notbook_saved_code</span><br><span class="line">protocol_config.conf</span><br><span class="line">scikit_learn_data</span><br><span class="line">yolov5s.pt</span><br><span class="line">yolov8n.pt</span><br></pre></td></tr></table></figure></div>
<p>运行后会列出我当前目录中的文件名称</p>
<h2 id="cd"><a href="#cd" class="headerlink" title="cd"></a>cd</h2><p>切换目录<br><strong>回家</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换到hadoop/etc/hadoop</span></span><br><span class="line"><span class="built_in">cd</span> hadoop/etc/hadoop</span><br></pre></td></tr></table></figure></div>
<h2 id="mkdir"><a href="#mkdir" class="headerlink" title="mkdir"></a>mkdir</h2><p>创建目录</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在当前目录下创建了一个叫fold的目录</span></span><br><span class="line"><span class="built_in">mkdir</span> <span class="built_in">fold</span></span><br></pre></td></tr></table></figure></div>
<h2 id="rmdir"><a href="#rmdir" class="headerlink" title="rmdir"></a>rmdir</h2><p>删除空目录</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除叫fold的目录（注：目录中一定是空的 否则无法删除）</span></span><br><span class="line"><span class="built_in">rmdir</span> <span class="built_in">fold</span></span><br></pre></td></tr></table></figure></div>

<h2 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h2><p>删除文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除一个叫file.txt的文件</span></span><br><span class="line"><span class="built_in">rm</span> file.txt</span><br></pre></td></tr></table></figure></div>

<h2 id="cp"><a href="#cp" class="headerlink" title="cp"></a>cp</h2><p>复制文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 复制file1.txt并叫file2.txt</span></span><br><span class="line"><span class="built_in">cp</span> file1.txt file2.txt</span><br></pre></td></tr></table></figure></div>
<h2 id="mv"><a href="#mv" class="headerlink" title="mv"></a>mv</h2><p>重命名或移动文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把old.txt改成new.txt</span></span><br><span class="line"><span class="built_in">mv</span> old.txt new.txt</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把file.txt移动到/home/</span></span><br><span class="line"><span class="built_in">mv</span> file.txt /home/</span><br></pre></td></tr></table></figure></div>

<h2 id="touch"><a href="#touch" class="headerlink" title="touch"></a>touch</h2><p>创建空文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个叫newfile.txt的空文件</span></span><br><span class="line"><span class="built_in">touch</span> newfile.txt</span><br></pre></td></tr></table></figure></div>
<h2 id="cat"><a href="#cat" class="headerlink" title="cat"></a>cat</h2><p>查看文件内容</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看file.txt中的内容</span></span><br><span class="line"><span class="built_in">cat</span> file.txt</span><br></pre></td></tr></table></figure></div>

<h1 id="文本编辑-查看"><a href="#文本编辑-查看" class="headerlink" title="文本编辑 查看"></a>文本编辑 查看</h1><h2 id="nano"><a href="#nano" class="headerlink" title="nano"></a>nano</h2><p>一个十分简单的编辑器 相当于你右键新建一个txt文本后打开进行编辑<br>各种操作都在下面会标注出来<br>例如 ctrl+o是保存 ctrl+x是关闭</p>
<h2 id="vim-vi"><a href="#vim-vi" class="headerlink" title="vim vi"></a>vim vi</h2><p>这是世界上最强大的编辑器 任何语言都可以用它来进行编写 其精髓在于快捷键 学习曲线非常陡峭 不过用得好的人可以用的飞起</p>
<h2 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h2><p>文本搜索神器</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在logfile.txt中搜索error</span></span><br><span class="line">grep <span class="string">"error"</span> logfile.txt</span><br></pre></td></tr></table></figure></div>

<h2 id="wc"><a href="#wc" class="headerlink" title="wc"></a>wc</h2><p>统计行/词/字符</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计行数</span></span><br><span class="line"><span class="built_in">wc</span> -l file.txt</span><br></pre></td></tr></table></figure></div>

<h2 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h2><p>排序</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对文件内的内容进行排序</span></span><br><span class="line"><span class="built_in">sort</span> file.txt</span><br></pre></td></tr></table></figure></div>

<h1 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h1><h2 id="uname-a"><a href="#uname-a" class="headerlink" title="uname -a"></a>uname -a</h2><p>查看系统内核信息</p>
<h2 id="hostname"><a href="#hostname" class="headerlink" title="hostname"></a>hostname</h2><p>查看主机名</p>
<h2 id="df-h"><a href="#df-h" class="headerlink" title="df -h"></a>df -h</h2><p>查看磁盘空间</p>
<h2 id="free-h"><a href="#free-h" class="headerlink" title="free -h"></a>free -h</h2><p>查看内存使用</p>
<h2 id="top-htop"><a href="#top-htop" class="headerlink" title="top /htop"></a>top /htop</h2><p>实时查看进程和资源占用</p>
<h2 id="ps-aux"><a href="#ps-aux" class="headerlink" title="ps aux"></a>ps aux</h2><p>查看所有进程</p>
<h2 id="kill-PID"><a href="#kill-PID" class="headerlink" title="kill [PID]"></a>kill [PID]</h2><p>杀死进程</p>
<h2 id="kill-9-PID"><a href="#kill-9-PID" class="headerlink" title="kill -9 [PID]"></a>kill -9 [PID]</h2><p>强制杀死进程</p>
<h2 id="whoami"><a href="#whoami" class="headerlink" title="whoami"></a>whoami</h2><p>查看当前用户</p>
<h2 id="who"><a href="#who" class="headerlink" title="who"></a>who</h2><p>查看谁登录了系统</p>
<h2 id="uptime"><a href="#uptime" class="headerlink" title="uptime"></a>uptime</h2><p>查看系统运行时间</p>
<h2 id="history"><a href="#history" class="headerlink" title="history"></a>history</h2><p>查看命令历史</p>
<h2 id="fastfetch"><a href="#fastfetch" class="headerlink" title="fastfetch"></a>fastfetch</h2><p>一个非常好看的查看系统信息的工具</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 需要安装</span></span><br><span class="line">apt install fastfetch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装好后运行</span></span><br><span class="line">fastfetch</span><br></pre></td></tr></table></figure></div>

<h1 id="权限-用户管理"><a href="#权限-用户管理" class="headerlink" title="权限 用户管理"></a>权限 用户管理</h1><h2 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h2><p>修改文件权限</p>
<h2 id="sudo"><a href="#sudo" class="headerlink" title="sudo"></a>sudo</h2><p>以管理员身份执行</p>
<h2 id="su"><a href="#su" class="headerlink" title="su"></a>su</h2><p>切换用户</p>
<h2 id="passwd"><a href="#passwd" class="headerlink" title="passwd"></a>passwd</h2><p>修改密码</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop部署--验证分布式是否成功</title>
    <url>/zhihaojiang.github.io/2025/09/24/20250924Hadoop%E9%83%A8%E7%BD%B2--%E9%AA%8C%E8%AF%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F/</url>
    <content><![CDATA[<p><strong>我遇到的所有问题都能在网上找到</strong></p>
<h1 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h1><ul>
<li>你已经创建了3台虚拟机</li>
<li>每台虚拟机都安装了jdk和Hadoop</li>
</ul>
<h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><p>将3台虚拟机都打开 在主节点运行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></div>
<p>虚拟机会输出</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~$ start-dfs.sh</span><br><span class="line">Starting namenodes on [linux-24-10]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [linux-24-10]</span><br><span class="line">2025-09-24 05:27:13,484 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line"></span><br><span class="line">zhihaojiang@linux-24-10:~$ start-yarn.sh</span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>不用管warning</p>
</blockquote>
<p>然后输入jps<br>主节点的虚拟机会输出</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~$ jps</span><br><span class="line">8245 DataNode</span><br><span class="line">8071 NameNode</span><br><span class="line">8969 NodeManager</span><br><span class="line">8633 ResourceManager</span><br><span class="line">8445 SecondaryNameNode</span><br><span class="line">9134 Jps</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>主要是看是否有这五个东西</p>
</blockquote>
<p>从节点的虚拟机会输出</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10-node4:~$ jps</span><br><span class="line">3675 NodeManager</span><br><span class="line">3516 DataNode</span><br><span class="line">3806 Jps</span><br></pre></td></tr></table></figure></div>
<p>看到这些都存在 那么你的Hadoop基本上是启动成功了</p>
<h1 id="检查部署是否正常"><a href="#检查部署是否正常" class="headerlink" title="检查部署是否正常"></a>检查部署是否正常</h1><p>在主节点输入</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hdfs dfsadmin -report</span><br></pre></td></tr></table></figure></div>

<p>其会输出</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~$ hdfs dfsadmin -report</span><br><span class="line">2025-09-24 05:31:46,974 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Configured Capacity: 31392067584 (29.24 GB)</span><br><span class="line">Present Capacity: 7492927488 (6.98 GB)</span><br><span class="line">DFS Remaining: 7492829184 (6.98 GB)</span><br><span class="line">DFS Used: 98304 (96 KB)</span><br><span class="line">DFS Used%: 0.00%</span><br><span class="line">Replicated Blocks:</span><br><span class="line">	Under replicated blocks: 0</span><br><span class="line">	Blocks with corrupt replicas: 0</span><br><span class="line">	Missing blocks: 0</span><br><span class="line">	Missing blocks (with replication factor 1): 0</span><br><span class="line">	Low redundancy blocks with highest priority to recover: 0</span><br><span class="line">	Pending deletion blocks: 0</span><br><span class="line">Erasure Coded Block Groups: </span><br><span class="line">	Low redundancy block groups: 0</span><br><span class="line">	Block groups with corrupt internal blocks: 0</span><br><span class="line">	Missing block groups: 0</span><br><span class="line">	Low redundancy blocks with highest priority to recover: 0</span><br><span class="line">	Pending deletion blocks: 0</span><br><span class="line"></span><br><span class="line">-------------------------------------------------</span><br><span class="line">Live datanodes (3):</span><br><span class="line"></span><br><span class="line">Name: 172.16.79.100:9866 (linux-24-10-node2)</span><br><span class="line">Hostname: linux-24-10-node2</span><br><span class="line">Decommission Status : Normal</span><br><span class="line">Configured Capacity: 10464022528 (9.75 GB)</span><br><span class="line">DFS Used: 32768 (32 KB)</span><br><span class="line">Non DFS Used: 7416832000 (6.91 GB)</span><br><span class="line">DFS Remaining: 2493509632 (2.32 GB)</span><br><span class="line">DFS Used%: 0.00%</span><br><span class="line">DFS Remaining%: 23.83%</span><br><span class="line">Configured Cache Capacity: 0 (0 B)</span><br><span class="line">Cache Used: 0 (0 B)</span><br><span class="line">Cache Remaining: 0 (0 B)</span><br><span class="line">Cache Used%: 100.00%</span><br><span class="line">Cache Remaining%: 0.00%</span><br><span class="line">Xceivers: 0</span><br><span class="line">Last contact: Wed Sep 24 05:31:45 UTC 2025</span><br><span class="line">Last Block Report: Wed Sep 24 05:27:09 UTC 2025</span><br><span class="line">Num of Blocks: 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Name: 172.16.79.120:9866 (linux-24-10-node4)</span><br><span class="line">Hostname: linux-24-10-node4</span><br><span class="line">Decommission Status : Normal</span><br><span class="line">Configured Capacity: 10464022528 (9.75 GB)</span><br><span class="line">DFS Used: 32768 (32 KB)</span><br><span class="line">Non DFS Used: 7425851392 (6.92 GB)</span><br><span class="line">DFS Remaining: 2484490240 (2.31 GB)</span><br><span class="line">DFS Used%: 0.00%</span><br><span class="line">DFS Remaining%: 23.74%</span><br><span class="line">Configured Cache Capacity: 0 (0 B)</span><br><span class="line">Cache Used: 0 (0 B)</span><br><span class="line">Cache Remaining: 0 (0 B)</span><br><span class="line">Cache Used%: 100.00%</span><br><span class="line">Cache Remaining%: 0.00%</span><br><span class="line">Xceivers: 0</span><br><span class="line">Last contact: Wed Sep 24 05:31:45 UTC 2025</span><br><span class="line">Last Block Report: Wed Sep 24 05:27:09 UTC 2025</span><br><span class="line">Num of Blocks: 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Name: 172.16.79.129:9866 (linux-24-10)</span><br><span class="line">Hostname: linux-24-10</span><br><span class="line">Decommission Status : Normal</span><br><span class="line">Configured Capacity: 10464022528 (9.75 GB)</span><br><span class="line">DFS Used: 32768 (32 KB)</span><br><span class="line">Non DFS Used: 7395512320 (6.89 GB)</span><br><span class="line">DFS Remaining: 2514829312 (2.34 GB)</span><br><span class="line">DFS Used%: 0.00%</span><br><span class="line">DFS Remaining%: 24.03%</span><br><span class="line">Configured Cache Capacity: 0 (0 B)</span><br><span class="line">Cache Used: 0 (0 B)</span><br><span class="line">Cache Remaining: 0 (0 B)</span><br><span class="line">Cache Used%: 100.00%</span><br><span class="line">Cache Remaining%: 0.00%</span><br><span class="line">Xceivers: 0</span><br><span class="line">Last contact: Wed Sep 24 05:31:45 UTC 2025</span><br><span class="line">Last Block Report: Wed Sep 24 05:27:09 UTC 2025</span><br><span class="line">Num of Blocks: 0</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>Live datanodes (3):</p>
</blockquote>
<p>说明你有三台机器都存活<br>或者在浏览器输入</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">虚拟机IP:8088</span><br><span class="line">虚拟机IP:9870</span><br></pre></td></tr></table></figure></div>
<p>可以看到两个界面</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/24/001.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/24/002.png" alt="photo"></p>
<p>在9870端口的界面中Overview右边有你虚拟机的名称和一个(active)<br>若有(✅active)说明成功启动的</p>
<h1 id="检查运行是否正常"><a href="#检查运行是否正常" class="headerlink" title="检查运行是否正常"></a>检查运行是否正常</h1><p>我们创建一个文件</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~$ nano input.txt</span><br><span class="line"><span class="comment"># 使用vim也行 我喜欢用nano</span></span><br></pre></td></tr></table></figure></div>

<p>随便在文件中写些什么东西 例如</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">This is a dfs <span class="built_in">test</span>.</span><br><span class="line">Another line with dfs.</span><br><span class="line">No match here.</span><br><span class="line">dfs appears again.</span><br></pre></td></tr></table></figure></div>

<p>之后推送到Hadoop上</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 路径换成自己的路径</span></span><br><span class="line">zhihaojiang@linux-24-10:~$ hdfs dfs -<span class="built_in">mkdir</span> -p /user/zhihaojiang/grep/input</span><br></pre></td></tr></table></figure></div>


  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>解释上述命令</p>

    </div>
    <div class="notel-content">
      <p>我解释下上述命令<br><strong>hdfs dfs</strong><br>调用 Hadoop 的HDFS 文件系统客户端工具 用于操作 HDFS</p>
<p><strong>-mkdir</strong><br>HDFS 的创建目录命令 对应 Linux 的mkdir</p>
<p><strong>-p</strong><br>递归创建父目录</p>
<p><strong>/user/zhihaojiang/grep/input</strong><br>你自己想要在 HDFS 上创建的完整目录路径 记得路径换成自己的路径</p>

    </div>
  </div>

<p>运行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 路径换成自己的路径</span></span><br><span class="line">hdfs dfs -put input.txt /user/zhihaojiang/grep/input/</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 路径换成自己的路径</span></span><br><span class="line">hdfs dfs -<span class="built_in">ls</span> /user/zhihaojiang/grep/input</span><br></pre></td></tr></table></figure></div>
<p>显示</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~$ hdfs dfs -put input.txt /user/zhihaojiang/grep/input/</span><br><span class="line">2025-09-24 05:56:03,010 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">zhihaojiang@linux-24-10:~$ hdfs dfs -ls /user/zhihaojiang/grep/input</span><br><span class="line">2025-09-24 05:56:10,664 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 zhihaojiang supergroup         77 2025-09-24 05:56 /user/zhihaojiang/grep/input/input.txt</span><br></pre></td></tr></table></figure></div>
<p>重点看</p>
<blockquote>
<p>-rw-r–r–   3 zhihaojiang supergroup         77 2025-09-24 05:56 /user/zhihaojiang/grep/input/input.txt</p>
</blockquote>
<p>这说明 已经确认文件已存在 副本数 = 3</p>
<p>接下来我们测试官方的Grep示例</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 路径换成自己的路径</span></span><br><span class="line">hadoop jar ~/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep \</span><br><span class="line">  /user/zhihaojiang/grep/input \</span><br><span class="line">  /user/zhihaojiang/grep/output \</span><br><span class="line">  <span class="string">'dfs[a-z.]*'</span></span><br></pre></td></tr></table></figure></div>

<p>他会输出很多东西 但你只需要看到</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">2025-09-24 06:24:24,842 INFO mapreduce.Job: Job job_1758694801292_0002 completed successfully</span><br></pre></td></tr></table></figure></div>



<p>你还可以运行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~/hadoop/etc/hadoop$ hdfs dfs -<span class="built_in">cat</span> /user/zhihaojiang/grep/output/part-r-00000</span><br></pre></td></tr></table></figure></div>
<p>出现<strong>completed successfully</strong>说明运行成功 你也可以在浏览器上刷新8088端口 出现下述黄色框中的就成功运行了</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/24/003.png" alt="photo"></p>
<p><strong>但是</strong> 在进行</p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>测试</p>

    </div>
    <div class="notel-content">
      <p>接下来我们测试官方的Grep示例</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 路径换成自己的路径</span></span><br><span class="line">hadoop jar ~/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep \</span><br><span class="line">  /user/zhihaojiang/grep/input \</span><br><span class="line">  /user/zhihaojiang/grep/output \</span><br><span class="line">  <span class="string">'dfs[a-z.]*'</span></span><br></pre></td></tr></table></figure></div>
    </div>
  </div>

<p>会存在一些问题 </p>
<h2 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h2><p>例如 运行后显示</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~$ hadoop jar ~/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep \</span><br><span class="line">  /user/zhihaojiang/grep/input \</span><br><span class="line">  /user/zhihaojiang/grep/output \</span><br><span class="line">  <span class="string">'dfs[a-z.]*'</span></span><br><span class="line">2025-09-24 06:11:23,729 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">2025-09-24 06:11:24,049 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /172.16.79.129:8032</span><br><span class="line">2025-09-24 06:11:24,396 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding <span class="keyword">for</span> path: /tmp/hadoop-yarn/staging/zhihaojiang/.staging/job_1758691653973_0001</span><br><span class="line">2025-09-24 06:11:24,669 INFO input.FileInputFormat: Total input files to process : 1</span><br><span class="line">2025-09-24 06:11:24,723 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">2025-09-24 06:11:24,829 INFO mapreduce.JobSubmitter: Submitting tokens <span class="keyword">for</span> job: job_1758691653973_0001</span><br><span class="line">2025-09-24 06:11:24,829 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2025-09-24 06:11:24,934 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2025-09-24 06:11:24,934 INFO resource.ResourceUtils: Unable to find <span class="string">'resource-types.xml'</span>.</span><br><span class="line">2025-09-24 06:11:25,462 INFO impl.YarnClientImpl: Submitted application application_1758691653973_0001</span><br><span class="line">2025-09-24 06:11:25,499 INFO mapreduce.Job: The url to track the job: http://linux-24-10:8088/proxy/application_1758691653973_0001/</span><br><span class="line">2025-09-24 06:11:25,499 INFO mapreduce.Job: Running job: job_1758691653973_0001</span><br><span class="line">2025-09-24 06:11:30,609 INFO mapreduce.Job: Job job_1758691653973_0001 running <span class="keyword">in</span> uber mode : <span class="literal">false</span></span><br><span class="line">2025-09-24 06:11:30,612 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2025-09-24 06:11:30,648 INFO mapreduce.Job: Job job_1758691653973_0001 failed with state FAILED due to: Application application_1758691653973_0001 failed 2 <span class="built_in">times</span> due to AM Container <span class="keyword">for</span> appattempt_1758691653973_0001_000002 exited with  exitCode: 1</span><br><span class="line">Failing this attempt.Diagnostics: [2025-09-24 06:11:29.653]Exception from container-launch.</span><br><span class="line">Container <span class="built_in">id</span>: container_1758691653973_0001_02_000001</span><br><span class="line">Exit code: 1</span><br><span class="line"></span><br><span class="line">[2025-09-24 06:11:29.674]Container exited with a non-zero <span class="built_in">exit</span> code 1. Error file: prelaunch.err.</span><br><span class="line">Last 4096 bytes of prelaunch.err :</span><br><span class="line">Last 4096 bytes of stderr :</span><br><span class="line">Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster</span><br><span class="line"></span><br><span class="line">Please check whether your &lt;HADOOP_HOME&gt;/etc/hadoop/mapred-site.xml contains the below configuration:</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">${full path of your hadoop distribution directory}</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">${full path of your hadoop distribution directory}</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">${full path of your hadoop distribution directory}</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">[2025-09-24 06:11:29.675]Container exited with a non-zero <span class="built_in">exit</span> code 1. Error file: prelaunch.err.</span><br><span class="line">Last 4096 bytes of prelaunch.err :</span><br><span class="line">Last 4096 bytes of stderr :</span><br><span class="line">Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster</span><br><span class="line"></span><br><span class="line">Please check whether your &lt;HADOOP_HOME&gt;/etc/hadoop/mapred-site.xml contains the below configuration:</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">${full path of your hadoop distribution directory}</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">${full path of your hadoop distribution directory}</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">${full path of your hadoop distribution directory}</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">For more detailed output, check the application tracking page: http://linux-24-10:8088/cluster/app/application_1758691653973_0001 Then click on links to logs of each attempt.</span><br><span class="line">. Failing the application.</span><br><span class="line">2025-09-24 06:11:30,675 INFO mapreduce.Job: Counters: 0</span><br><span class="line">2025-09-24 06:11:30,707 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /172.16.79.129:8032</span><br><span class="line">2025-09-24 06:11:30,731 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding <span class="keyword">for</span> path: /tmp/hadoop-yarn/staging/zhihaojiang/.staging/job_1758691653973_0002</span><br><span class="line">2025-09-24 06:11:30,836 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/zhihaojiang/.staging/job_1758691653973_0002</span><br><span class="line">org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://172.16.79.129:9000/user/zhihaojiang/grep-temp-212921694</span><br><span class="line">	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:340)</span><br><span class="line">	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:279)</span><br><span class="line">	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)</span><br><span class="line">	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:404)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job<span class="variable">$11</span>.run(Job.java:1678)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job<span class="variable">$11</span>.run(Job.java:1675)</span><br><span class="line">	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">	at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1675)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1696)</span><br><span class="line">	at org.apache.hadoop.examples.Grep.run(Grep.java:94)</span><br><span class="line">	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82)</span><br><span class="line">	at org.apache.hadoop.examples.Grep.main(Grep.java:103)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">	at org.apache.hadoop.util.ProgramDriver<span class="variable">$ProgramDescription</span>.invoke(ProgramDriver.java:71)</span><br><span class="line">	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)</span><br><span class="line">	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.run(RunJar.java:328)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.main(RunJar.java:241)</span><br><span class="line">Caused by: java.io.IOException: Input path does not exist: hdfs://172.16.79.129:9000/user/zhihaojiang/grep-temp-212921694</span><br><span class="line">	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:313)</span><br><span class="line">	... 29 more</span><br></pre></td></tr></table></figure></div>
<p>这是因为Hadoop MapReduce 作业无法启动 ApplicationMaster 根本原因是 环境变量 HADOOP_MAPRED_HOME 未正确配置<br><strong>错误信息</strong></p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster</span><br></pre></td></tr></table></figure></div>
<p><strong>解决方法</strong></p>
<ol>
<li>进入 Hadoop 配置目录</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure></div>
<p>查看是否已有 mapred-site.xml</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> mapred-site.xml</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>编辑文件</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">nano mapred-site.xml</span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li>添加关键配置<br>在 <configuration> 标签内 添加以下 3 个属性：</configuration></li>
</ol>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- 其他已有配置... --&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME=/home/zhihaojiang/hadoop&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME=/home/zhihaojiang/hadoop&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME=/home/zhihaojiang/hadoop&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></div>
<p><strong>注意 路径一定是绝对路径</strong></p>
<ol start="4">
<li>同步配置到所有节点</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 我的从节点主机名是 linux-24-10-node2 和 linux-24-10-node4</span></span><br><span class="line">scp ~/hadoop/etc/hadoop/mapred-site.xml linux-24-10-node2:~/hadoop/etc/hadoop/</span><br><span class="line">scp ~/hadoop/etc/hadoop/mapred-site.xml linux-24-10-node4:~/hadoop/etc/hadoop/</span><br></pre></td></tr></table></figure></div>

<ol start="5">
<li>重启 YARN</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在主节点执行</span></span><br><span class="line">stop-yarn.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></div>

<ol start="6">
<li>重新运行 Grep 示例</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先删除旧的输出目录（如果存在）</span></span><br><span class="line">hdfs dfs -<span class="built_in">rm</span> -r /user/zhihaojiang/grep/output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新运行</span></span><br><span class="line">hadoop jar ~/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep \</span><br><span class="line">  /user/zhihaojiang/grep/input \</span><br><span class="line">  /user/zhihaojiang/grep/output \</span><br><span class="line">  <span class="string">'dfs[a-z.]*'</span></span><br></pre></td></tr></table></figure></div>

<h2 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h2><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10:~/hadoop/etc/hadoop$ hadoop jar ~/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep \</span><br><span class="line">  /user/zhihaojiang/grep/input \</span><br><span class="line">  /user/zhihaojiang/grep/output \</span><br><span class="line">  'dfs[a-z.]*'</span><br><span class="line">2025-09-24 06:15:54,235 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2025-09-24 06:15:54,535 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /172.16.79.129:8032</span><br><span class="line">2025-09-24 06:15:54,836 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/zhihaojiang/.staging/job_1758694526692_0001</span><br><span class="line">2025-09-24 06:15:55,078 INFO input.FileInputFormat: Total input files to process : 1</span><br><span class="line">2025-09-24 06:15:55,133 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">2025-09-24 06:15:55,215 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1758694526692_0001</span><br><span class="line">2025-09-24 06:15:55,215 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2025-09-24 06:15:55,339 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2025-09-24 06:15:55,339 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.</span><br><span class="line">2025-09-24 06:15:55,726 INFO impl.YarnClientImpl: Submitted application application_1758694526692_0001</span><br><span class="line">2025-09-24 06:15:55,768 INFO mapreduce.Job: The url to track the job: http://linux-24-10:8088/proxy/application_1758694526692_0001/</span><br><span class="line">2025-09-24 06:15:55,768 INFO mapreduce.Job: Running job: job_1758694526692_0001</span><br><span class="line">2025-09-24 06:16:00,853 INFO mapreduce.Job: Job job_1758694526692_0001 running in uber mode : false</span><br><span class="line">2025-09-24 06:16:00,857 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2025-09-24 06:16:01,920 INFO mapreduce.Job: Task Id : attempt_1758694526692_0001_m_000000_0, Status : FAILED</span><br><span class="line">Container launch failed for container_1758694526692_0001_01_000002 : org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:mapreduce_shuffle does not exist</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:750)</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:03,974 INFO mapreduce.Job: Task Id : attempt_1758694526692_0001_m_000000_1, Status : FAILED</span><br><span class="line">Container launch failed for container_1758694526692_0001_01_000003 : org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:mapreduce_shuffle does not exist</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:750)</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:06,012 INFO mapreduce.Job: Task Id : attempt_1758694526692_0001_m_000000_2, Status : FAILED</span><br><span class="line">Container launch failed for container_1758694526692_0001_01_000004 : org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:mapreduce_shuffle does not exist</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:750)</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:09,053 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">2025-09-24 06:16:10,090 INFO mapreduce.Job: Job job_1758694526692_0001 failed with state FAILED due to: Task failed task_1758694526692_0001_m_000000</span><br><span class="line">Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:10,179 INFO mapreduce.Job: Counters: 10</span><br><span class="line">	Job Counters </span><br><span class="line">		Failed map tasks=4</span><br><span class="line">		Killed reduce tasks=1</span><br><span class="line">		Launched map tasks=4</span><br><span class="line">		Other local map tasks=3</span><br><span class="line">		Data-local map tasks=1</span><br><span class="line">		Total time spent by all maps in occupied slots (ms)=2</span><br><span class="line">		Total time spent by all reduces in occupied slots (ms)=0</span><br><span class="line">		Total time spent by all map tasks (ms)=2</span><br><span class="line">		Total vcore-milliseconds taken by all map tasks=2</span><br><span class="line">		Total megabyte-milliseconds taken by all map tasks=2048</span><br><span class="line">2025-09-24 06:16:10,203 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /172.16.79.129:8032</span><br><span class="line">2025-09-24 06:16:10,251 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/zhihaojiang/.staging/job_1758694526692_0002</span><br><span class="line">2025-09-24 06:16:10,287 INFO input.FileInputFormat: Total input files to process : 0</span><br><span class="line">2025-09-24 06:16:10,723 INFO mapreduce.JobSubmitter: number of splits:0</span><br><span class="line">2025-09-24 06:16:10,793 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1758694526692_0002</span><br><span class="line">2025-09-24 06:16:10,793 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2025-09-24 06:16:11,021 INFO impl.YarnClientImpl: Submitted application application_1758694526692_0002</span><br><span class="line">2025-09-24 06:16:11,029 INFO mapreduce.Job: The url to track the job: http://linux-24-10:8088/proxy/application_1758694526692_0002/</span><br><span class="line">2025-09-24 06:16:11,029 INFO mapreduce.Job: Running job: job_1758694526692_0002</span><br><span class="line">2025-09-24 06:16:19,174 INFO mapreduce.Job: Job job_1758694526692_0002 running in uber mode : false</span><br><span class="line">2025-09-24 06:16:19,182 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2025-09-24 06:16:22,264 INFO mapreduce.Job: Task Id : attempt_1758694526692_0002_r_000000_0, Status : FAILED</span><br><span class="line">Container launch failed for container_1758694526692_0002_01_000002 : org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:mapreduce_shuffle does not exist</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:750)</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:24,312 INFO mapreduce.Job: Task Id : attempt_1758694526692_0002_r_000000_1, Status : FAILED</span><br><span class="line">Container launch failed for container_1758694526692_0002_01_000003 : org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:mapreduce_shuffle does not exist</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:750)</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:27,344 INFO mapreduce.Job: Task Id : attempt_1758694526692_0002_r_000000_2, Status : FAILED</span><br><span class="line">Container launch failed for container_1758694526692_0002_01_000004 : org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:mapreduce_shuffle does not exist</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)</span><br><span class="line">	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)</span><br><span class="line">	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:750)</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:31,375 INFO mapreduce.Job:  map 0% reduce 100%</span><br><span class="line">2025-09-24 06:16:32,399 INFO mapreduce.Job: Job job_1758694526692_0002 failed with state FAILED due to: Task failed task_1758694526692_0002_r_000000</span><br><span class="line">Job failed as tasks failed. failedMaps:0 failedReduces:1 killedMaps:0 killedReduces: 0</span><br><span class="line"></span><br><span class="line">2025-09-24 06:16:32,439 INFO mapreduce.Job: Counters: 7</span><br><span class="line">	Job Counters </span><br><span class="line">		Failed reduce tasks=4</span><br><span class="line">		Launched reduce tasks=4</span><br><span class="line">		Total time spent by all maps in occupied slots (ms)=0</span><br><span class="line">		Total time spent by all reduces in occupied slots (ms)=2</span><br><span class="line">		Total time spent by all reduce tasks (ms)=2</span><br><span class="line">		Total vcore-milliseconds taken by all reduce tasks=2</span><br><span class="line">		Total megabyte-milliseconds taken by all reduce tasks=2048</span><br></pre></td></tr></table></figure></div>

<p><strong>错误信息</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException: The auxService:mapreduce_shuffle does not exist</span><br></pre></td></tr></table></figure></div>
<p>这是YARN未正确配置MapReduce Shuffle服务导致的<br>YARN 需要知道如何为MapReduce任务提供Shuffle服务 用于 Map → Reduce 的数据传输<br>这个服务叫 mapreduce_shuffle 必须在 所有 NodeManager 节点 的 yarn-site.xml 中显式启用<br>我们需要配置yarn-site.xml</p>
<ol>
<li>编辑主节点的 yarn-site.xml</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/hadoop/etc/hadoop</span><br><span class="line">nano yarn-site.xml</span><br></pre></td></tr></table></figure></div>
<p>在 <configuration> 标签内 添加以下属性</configuration></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>将配置同步到所有从节点</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 复制到两个从节点 用你的实际主机名或 IP）</span></span><br><span class="line">scp yarn-site.xml linux-24-10-node2:~/hadoop/etc/hadoop/</span><br><span class="line">scp yarn-site.xml linux-24-10-node4:~/hadoop/etc/hadoop/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者使用IP</span></span><br><span class="line"><span class="comment"># scp yarn-site.xml zhihaojiang@172.16.79.100:~/hadoop/etc/hadoop/</span></span><br><span class="line"><span class="comment"># scp yarn-site.xml zhihaojiang@172.16.79.120:~/hadoop/etc/hadoop/</span></span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li>重启 YARN 服务</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在主节点执行</span></span><br><span class="line">stop-yarn.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></div>

<ol start="4">
<li>验证 NodeManager 是否加载了 shuffle 服务</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看最新 NodeManager 日志</span></span><br><span class="line"><span class="built_in">ls</span> -lt ~/hadoop/logs/ | grep nodemanager</span><br><span class="line"><span class="built_in">cat</span> ~/hadoop/logs/hadoop-zhihaojiang-nodemanager-*.<span class="built_in">log</span> | grep -i shuffle</span><br></pre></td></tr></table></figure></div>

<p>这会输出很多东西 只要看到有</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Registered auxiliary service mapreduce_shuffle, service class org.apache.hadoop.mapred.ShuffleHandler</span><br></pre></td></tr></table></figure></div>
<p>就说明加载了 shuffle 服务</p>
<ol start="5">
<li>重新运行 Grep 示例</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先删除旧的输出目录（如果存在）</span></span><br><span class="line">hdfs dfs -<span class="built_in">rm</span> -r /user/zhihaojiang/grep/output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新运行</span></span><br><span class="line">hadoop jar ~/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep \</span><br><span class="line">  /user/zhihaojiang/grep/input \</span><br><span class="line">  /user/zhihaojiang/grep/output \</span><br><span class="line">  <span class="string">'dfs[a-z.]*'</span></span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析与算法设计--实验报告1</title>
    <url>/zhihaojiang.github.io/2025/09/24/20250924%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E4%B8%8E%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1--%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A1/</url>
    <content><![CDATA[<h1 id="一、实验名称"><a href="#一、实验名称" class="headerlink" title="一、实验名称"></a>一、实验名称</h1><p>了解计算方法思想</p>
<h1 id="二-实验目的"><a href="#二-实验目的" class="headerlink" title="二 实验目的"></a>二 实验目的</h1><ol>
<li>了解误差分析的重要性;</li>
<li>考察误差在数值计算中的传播情况, 掌握算法稳定性的重要性;</li>
<li>学会在数值计算中避免误差伤害, 了解设计算法时应遵循的原则.</li>
</ol>
<h1 id="三、实验题目"><a href="#三、实验题目" class="headerlink" title="三、实验题目"></a>三、实验题目</h1><h2 id="3-1-题目1"><a href="#3-1-题目1" class="headerlink" title="3.1 题目1"></a>3.1 题目1</h2><p>分别利用正向递推与反向递推计算</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.063ex;" xmlns="http://www.w3.org/2000/svg" width="37.263ex" height="5.59ex" role="img" focusable="false" viewBox="0 -1559 16470.4 2470.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mi" transform="translate(473,-150) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1225,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(2280.8,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msubsup" transform="translate(3900.2,0)"><g data-mml-node="mo" transform="translate(0 1)"><path data-c="222B" d="M114 -798Q132 -824 165 -824H167Q195 -824 223 -764T275 -600T320 -391T362 -164Q365 -143 367 -133Q439 292 523 655T645 1127Q651 1145 655 1157T672 1201T699 1257T733 1306T777 1346T828 1360Q884 1360 912 1325T944 1245Q944 1220 932 1205T909 1186T887 1183Q866 1183 849 1198T832 1239Q832 1287 885 1296L882 1300Q879 1303 874 1307T866 1313Q851 1323 833 1323Q819 1323 807 1311T775 1255T736 1139T689 936T633 628Q574 293 510 -5T410 -437T355 -629Q278 -862 165 -862Q125 -862 92 -831T55 -746Q55 -711 74 -698T112 -685Q133 -685 150 -700T167 -741Q167 -789 114 -798Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1046.4,1088.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(589,-896.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><g data-mml-node="msup" transform="translate(5516.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,413) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msup" transform="translate(6596.1,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(499,413) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(7549.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7994.2,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(8514.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(9086.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(9364.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(10530.9,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(11408.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(12464.4,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(12964.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(13409.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(13909.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(14353.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(14853.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(15298.4,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g></g></g></svg></mjx-container></p>
<p>给出python语言程序 并比较计算得到的数值结果（保留4位小数）</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">e_inv = 1 / np.exp(1)</span><br><span class="line"></span><br><span class="line">I0_forward = 0.6321 <span class="comment"># 选用1 - 1/e效果会好点</span></span><br><span class="line">I9_backward = (e_inv + 1) / 20</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正向递推</span></span><br><span class="line">I_forward = [0.0] * 11</span><br><span class="line">I_forward[0] = I0_forward</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(1, 11):</span><br><span class="line">    I_forward[n] = 1 - n * I_forward[n-1]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向递推</span></span><br><span class="line">I_backward = [0.0] * 11</span><br><span class="line">I_backward[9] = I9_backward</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(9, 0, -1):</span><br><span class="line">    I_backward[n-1] = (1 - I_backward[n]) / n</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(1, 11):</span><br><span class="line">    I_backward[n] = 1 - n * I_backward[n-1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"n\t正向递推 I_n\t反向递推 I_n"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"-"</span> * 35)</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(11):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{n}\t{I_forward[n]:.4f}\t{I_backward[n]:.4f}"</span>)</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>n</th>
<th>正向递推</th>
<th>反向递推</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.6321</td>
<td>0.6321</td>
</tr>
<tr>
<td>1</td>
<td>0.3679</td>
<td>0.3679</td>
</tr>
<tr>
<td>2</td>
<td>0.2642</td>
<td>0.2642</td>
</tr>
<tr>
<td>3</td>
<td>0.2074</td>
<td>0.2073</td>
</tr>
<tr>
<td>4</td>
<td>0.1704</td>
<td>0.1709</td>
</tr>
<tr>
<td>5</td>
<td>0.1480</td>
<td>0.1455</td>
</tr>
<tr>
<td>6</td>
<td>0.1120</td>
<td>0.1268</td>
</tr>
<tr>
<td>7</td>
<td>0.2160</td>
<td>0.1121</td>
</tr>
<tr>
<td>8</td>
<td>-0.7280</td>
<td>0.1035</td>
</tr>
<tr>
<td>9</td>
<td>7.5520</td>
<td>0.0684</td>
</tr>
<tr>
<td>10</td>
<td>-74.5200</td>
<td>0.3161</td>
</tr>
</tbody></table>
<p>发现 正向递推的时候 当n=8时 其结果非常奇怪 说明误差对结果产生了很大的影响 逆向递推的时候 其结果看起来比较稳定</p>
<h2 id="3-2-题目2"><a href="#3-2-题目2" class="headerlink" title="3.2 题目2"></a>3.2 题目2</h2><p>已知函数</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.654ex;" xmlns="http://www.w3.org/2000/svg" width="18.29ex" height="4.957ex" role="img" focusable="false" viewBox="0 -1460 8084 2190.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1511,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2177.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3233.6,0)"><g data-mml-node="mrow" transform="translate(220,710)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(1722.4,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(3060.4,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(3060.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3449.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(4021.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="msup" transform="translate(1920.9,-719.9)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><rect width="4610.4" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>取</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="65.522ex" height="2.455ex" role="img" focusable="false" viewBox="0 -891 28960.5 1085"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1905.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(2627.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(3628,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5614.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(6059.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(6504,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(7226.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(8226.5,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10213.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(10657.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(11102.5,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(11824.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(12824.9,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g></g></g><g data-mml-node="mo" transform="translate(14811.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(15256.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(15700.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(16423.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(17423.4,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></g></g></g><g data-mml-node="mo" transform="translate(19410.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(19854.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(20299.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(21021.6,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(22021.8,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path></g></g></g><g data-mml-node="mo" transform="translate(24008.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(24453.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(24897.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(25620.1,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(26620.3,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></p>
<p>进行计算，结果保留4位小数</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line"></span><br><span class="line">def f(x):</span><br><span class="line">    <span class="built_in">return</span> (1 - math.cos(x)) / (x ** 2)</span><br><span class="line"></span><br><span class="line">x_values = [1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"x\t\t\tf(x)"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"-"</span> * 30)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_values:</span><br><span class="line">    result = f(x)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{x:.1e}\t{result:.4f}"</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>x</th>
<th>f(x)</th>
</tr>
</thead>
<tbody><tr>
<td>1.0e-05</td>
<td>0.5000</td>
</tr>
<tr>
<td>1.0e-06</td>
<td>0.5000</td>
</tr>
<tr>
<td>1.0e-07</td>
<td>0.4996</td>
</tr>
<tr>
<td>1.0e-08</td>
<td>0.0000</td>
</tr>
<tr>
<td>1.0e-09</td>
<td>0.0000</td>
</tr>
<tr>
<td>1.0e-10</td>
<td>0.0000</td>
</tr>
</tbody></table>
<p>发现 当x值在1e-8之后 结果都为0 这是因为尽管0.000000000001和0.000000000000001对人类来说是一个约等于的关系 但是对于计算机来说 其保存的浮点数精度是有限的 在他看来这两个数是相等的<br>在x很小的时候 cos（x）对于计算机来说就是1 1- cos（x）对于计算机就是0了 因此计算结果就变成0了<br>我们可以对这个函数进行变换 由倍角公式得</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="24.262ex" height="4.153ex" role="img" focusable="false" viewBox="0 -1149.5 10723.9 1835.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(1722.4,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(3060.4,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(3060.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3449.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(4021.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4688.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5744,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msup" transform="translate(6410.7,0)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mn" transform="translate(1261,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(8075.2,0)"><path data-c="21" d="M78 661Q78 682 96 699T138 716T180 700T199 661Q199 654 179 432T158 206Q156 198 139 198Q121 198 119 206Q118 209 98 431T78 661ZM79 61Q79 89 97 105T141 121Q164 119 181 104T198 61Q198 31 181 16T139 1Q114 1 97 16T79 61Z"></path></g><g data-mml-node="mrow" transform="translate(8519.9,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="mfrac" transform="translate(597,0)"><g data-mml-node="mi" transform="translate(220,676)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mn" transform="translate(255,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="770" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1607,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g></g></g></svg></mjx-container></p>
<p>得到</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.827ex;" xmlns="http://www.w3.org/2000/svg" width="22.148ex" height="7.233ex" role="img" focusable="false" viewBox="0 -1947.5 9789.2 3197"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1511,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2177.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3233.6,0)"><g data-mml-node="mn" transform="translate(220,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mn" transform="translate(220,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="700" height="60" x="120" y="220"></rect></g><g data-mml-node="msup" transform="translate(4173.6,0)"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M758 -1237T758 -1240T752 -1249H736Q718 -1249 717 -1248Q711 -1245 672 -1199Q237 -706 237 251T672 1700Q697 1730 716 1749Q718 1750 735 1750H752Q758 1744 758 1741Q758 1737 740 1713T689 1644T619 1537T540 1380T463 1176Q348 802 348 251Q348 -242 441 -599T744 -1218Q758 -1237 758 -1240Z"></path></g><g data-mml-node="mfrac" transform="translate(792,0)"><g data-mml-node="mrow" transform="translate(220,809.5)"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(1228,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(1394.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path></g><g data-mml-node="mfrac" transform="translate(458,0)"><g data-mml-node="mi" transform="translate(220,394) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(245.5,-345) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="604.5" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(1302.5,0) translate(0 -0.5)"><path data-c="29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path></g></g></g><g data-mml-node="mfrac" transform="translate(1375.3,-686)"><g data-mml-node="mi" transform="translate(220,394) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(245.5,-345) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="604.5" height="60" x="120" y="220"></rect></g><rect width="3355.1" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(4387.1,0) translate(0 -0.5)"><path data-c="29" d="M33 1741Q33 1750 51 1750H60H65Q73 1750 81 1743T119 1700Q554 1207 554 251Q554 -707 119 -1199Q76 -1250 66 -1250Q65 -1250 62 -1250T56 -1249Q55 -1249 53 -1249T49 -1250Q33 -1250 33 -1239Q33 -1236 50 -1214T98 -1150T163 -1052T238 -910T311 -727Q443 -335 443 251Q443 402 436 532T405 831T339 1142T224 1438T50 1716Q33 1737 33 1741Z"></path></g></g><g data-mml-node="mn" transform="translate(5212.1,1476.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
<p>我们使用此函数进行计算</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def f_new(x):</span><br><span class="line">    y = x / 2</span><br><span class="line">    <span class="built_in">return</span> 0.5 * (math.sin(y) / y)**2</span><br></pre></td></tr></table></figure></div>
<p>解得</p>
<table>
<thead>
<tr>
<th>x</th>
<th>f(x)</th>
</tr>
</thead>
<tbody><tr>
<td>1.0e-05</td>
<td>0.5000</td>
</tr>
<tr>
<td>1.0e-06</td>
<td>0.5000</td>
</tr>
<tr>
<td>1.0e-07</td>
<td>0.5000</td>
</tr>
<tr>
<td>1.0e-08</td>
<td>0.5000</td>
</tr>
<tr>
<td>1.0e-09</td>
<td>0.5000</td>
</tr>
<tr>
<td>1.0e-10</td>
<td>0.5000</td>
</tr>
</tbody></table>
<h2 id="3-3题目3"><a href="#3-3题目3" class="headerlink" title="3.3题目3"></a>3.3题目3</h2><p>已知函数</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="27.292ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 12063.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1511,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2177.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3233.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mrow" transform="translate(3972.2,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(1223,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(1223,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1612,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2406.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(3406.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3906.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4517.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(5517.9,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(6351.9,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(6351.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6740.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7312.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7701.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container></p>
<p>取</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="72.012ex" height="2.456ex" role="img" focusable="false" viewBox="0 -891.7 31829.4 1085.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1905.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(2627.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(3628,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(5418.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(5862.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(6307.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(7029.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(8029.9,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(9820,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(10264.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(10709.3,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(11431.5,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(12431.8,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(14221.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(14666.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(15111.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(15833.4,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(16833.7,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(18623.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(19068.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(19513.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(20235.3,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(21235.5,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(23025.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(23470.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(23915,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(24637.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(25637.4,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(27427.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(27872.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(28316.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(29039.1,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(30039.3,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></p>
<p>进行计算，结果保留4位小数</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line"></span><br><span class="line">def f(x):</span><br><span class="line">    <span class="built_in">return</span> x * (math.log(x + 1) - math.log(x))</span><br><span class="line"></span><br><span class="line">x_values = [1e10, 1e11, 1e12, 1e13, 1e14, 1e15, 1e16]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"x\t\t\tf(x)"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"-"</span> * 30)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_values:</span><br><span class="line">    result = f_new(x)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"{x:.1e}\t{result:.4f}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>解得</p>
<table>
<thead>
<tr>
<th>x</th>
<th>f(x)</th>
</tr>
</thead>
<tbody><tr>
<td>1.0e+10</td>
<td>1.0000</td>
</tr>
<tr>
<td>1.0e+11</td>
<td>0.9997</td>
</tr>
<tr>
<td>1.0e+12</td>
<td>1.0019</td>
</tr>
<tr>
<td>1.0e+13</td>
<td>0.9948</td>
</tr>
<tr>
<td>1.0e+14</td>
<td>0.7105</td>
</tr>
<tr>
<td>1.0e+15</td>
<td>0.0000</td>
</tr>
<tr>
<td>1.0e+16</td>
<td>0.0000</td>
</tr>
</tbody></table>
<p>在算到1.0e+15后 结果是0了<br>当x的值非常大的时候，ln(x+1)-ln(x)的值非常小，计算机无法保存如此大的精度 因此ln(x+1)-ln(x)=0<br>我们需要对等式进行变形 由对数运算的性质得</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.148ex;" xmlns="http://www.w3.org/2000/svg" width="46.141ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 20394.2 2399"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(834,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(834,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1223,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2017.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(3017.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3517.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4128.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(5128.9,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(5962.9,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(5962.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6351.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6923.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7590.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(8646.4,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(9480.4,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(9647.1,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(794.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1794.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1081.2,-686)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><rect width="2494.4" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3470.4,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g><g data-mml-node="mo" transform="translate(14131.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(15187.1,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(16021.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(16187.8,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mn" transform="translate(736,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1458.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mfrac" transform="translate(2458.4,0)"><g data-mml-node="mn" transform="translate(256,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(220,-686)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><rect width="772" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3470.4,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g></g></g></svg></mjx-container></p>
<p>因此</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.148ex;" xmlns="http://www.w3.org/2000/svg" width="20.768ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 9179.3 2399"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1511,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2177.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3233.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(3972.2,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(4806.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(4972.9,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mn" transform="translate(736,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1458.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mfrac" transform="translate(2458.4,0)"><g data-mml-node="mn" transform="translate(256,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(220,-686)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><rect width="772" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3470.4,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g></g></g></svg></mjx-container></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def f_new(x):</span><br><span class="line">    <span class="built_in">return</span> x * math.log1p(1 / x)</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>x</th>
<th>f(x)</th>
</tr>
</thead>
<tbody><tr>
<td>1.0e+10</td>
<td>1.0000</td>
</tr>
<tr>
<td>1.0e+11</td>
<td>1.0000</td>
</tr>
<tr>
<td>1.0e+12</td>
<td>1.0000</td>
</tr>
<tr>
<td>1.0e+13</td>
<td>1.0000</td>
</tr>
<tr>
<td>1.0e+14</td>
<td>1.0000</td>
</tr>
<tr>
<td>1.0e+15</td>
<td>1.0000</td>
</tr>
<tr>
<td>1.0e+16</td>
<td>1.0000</td>
</tr>
</tbody></table>
<h1 id="五、实验总结"><a href="#五、实验总结" class="headerlink" title="五、实验总结"></a>五、实验总结</h1><p>本次实验让我了解到了尽管在数学中看似合理的公式放到计算机上运行时还要考虑到截断误差 看似非常小的误差在经过n次计算后误差可能会放大好几万倍 计算机由于储存有限 无法保存准确值 只能保存精确值 因此我们必须避免那些无穷小减无穷小、大数减小数 可以通过对公式进行一定的变换来避免这些误差</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>算法设计</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--产品定价模型</title>
    <url>/zhihaojiang.github.io/2025/09/25/20250925%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%BA%A7%E5%93%81%E5%AE%9A%E4%BB%B7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'产品定价模型.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>页数</th>
<th>类别</th>
<th>彩印</th>
<th>纸张</th>
<th>价格</th>
</tr>
</thead>
<tbody><tr>
<td>207</td>
<td>技术类</td>
<td>0</td>
<td>双胶纸</td>
<td>60</td>
</tr>
<tr>
<td>210</td>
<td>技术类</td>
<td>0</td>
<td>双胶纸</td>
<td>62</td>
</tr>
<tr>
<td>206</td>
<td>技术类</td>
<td>0</td>
<td>双胶纸</td>
<td>62</td>
</tr>
<tr>
<td>218</td>
<td>技术类</td>
<td>0</td>
<td>双胶纸</td>
<td>64</td>
</tr>
<tr>
<td>209</td>
<td>技术类</td>
<td>0</td>
<td>双胶纸</td>
<td>60</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段</th>
<th>缺失值数量</th>
</tr>
</thead>
<tbody><tr>
<td>页数</td>
<td>0</td>
</tr>
<tr>
<td>类别</td>
<td>0</td>
</tr>
<tr>
<td>彩印</td>
<td>0</td>
</tr>
<tr>
<td>纸张</td>
<td>0</td>
</tr>
<tr>
<td>价格</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">df</span>[col].dtype <span class="keyword">in</span> [<span class="string">'int64'</span>, <span class="string">'float64'</span>]:</span><br><span class="line">        plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">        plt.title(col)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">df</span>[col].value_counts().plot(kind=<span class="string">'bar'</span>)</span><br><span class="line">        plt.title(col)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/003.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/004.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/005.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/006.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/007.png" alt="photo"></p>
<p>发现页数存在异常值 将页数进行胜率变换</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy.stats import mstats</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'页数'</span>] = mstats.winsorize(<span class="built_in">df</span>[<span class="string">'页数'</span>], limits=[0.01, 0.01])</span><br></pre></td></tr></table></figure></div>
<h1 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">'类别'</span>].describe()</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'纸张'</span>].describe()</span><br><span class="line"></span><br><span class="line">from sklearn.preprocessing import LabelEncoder</span><br><span class="line">le = LabelEncoder()</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'类别'</span>] = le.fit_transform(<span class="built_in">df</span>[<span class="string">'类别'</span>])</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'纸张'</span>] = le.fit_transform(<span class="built_in">df</span>[<span class="string">'纸张'</span>])</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>统计量</th>
<th>值</th>
</tr>
</thead>
<tbody><tr>
<td>count</td>
<td>1000</td>
</tr>
<tr>
<td>unique</td>
<td>3</td>
</tr>
<tr>
<td>top</td>
<td>技术类</td>
</tr>
<tr>
<td>freq</td>
<td>336</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>统计量</th>
<th>值</th>
</tr>
</thead>
<tbody><tr>
<td>count</td>
<td>1000</td>
</tr>
<tr>
<td>unique</td>
<td>3</td>
</tr>
<tr>
<td>top</td>
<td>双胶纸</td>
</tr>
<tr>
<td>freq</td>
<td>615</td>
</tr>
</tbody></table>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X = df.drop([<span class="string">'价格'</span>], axis=1)</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'价格'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import GradientBoostingRegressor</span><br><span class="line"></span><br><span class="line">GBDT = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)</span><br><span class="line">GBDT.fit(X_train, y_train)</span><br><span class="line">y_pred = GBDT.predict(X_test)</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line"></span><br><span class="line">rmse = mean_squared_error(y_test, y_pred, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Root Mean Squared Error:"</span>, rmse)</span><br><span class="line">from sklearn.metrics import r2_score</span><br><span class="line">r2 = r2_score(y_test, GBDT.predict(X_test))</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br><span class="line">from sklearn.metrics import mean_squared_log_error</span><br><span class="line">rmsle = mean_squared_log_error(y_test, y_pred, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"GBDT RMSLE:"</span>, rmsle)</span><br></pre></td></tr></table></figure></div>
<p>Root Mean Squared Error: 8.252320312081766<br>0.8465042353222849<br>GBDT RMSLE: 0.14476982287151097</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred_xgb = xgb.predict(X_test)</span><br><span class="line">rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGBoost Root Mean Squared Error:"</span>, rmse_xgb)</span><br><span class="line">r2_xgb = r2_score(y_test, y_pred_xgb)</span><br><span class="line"><span class="built_in">print</span>(r2_xgb)</span><br><span class="line">rmsle_xgb = mean_squared_log_error(y_test, y_pred_xgb, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"XGBoost RMSLE:"</span>, rmsle_xgb)</span><br></pre></td></tr></table></figure></div>
<p>XGBoost Root Mean Squared Error: 8.176196042228552<br>0.8493230448316168<br>Root Mean Squared Log Error: 8.252320312081766<br>XGBoost RMSLE: 0.14297996456087966</p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line"></span><br><span class="line">lgbm = LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)</span><br><span class="line">lgbm.fit(X_train, y_train)</span><br><span class="line">y_pred_lgbm = lgbm.predict(X_test)</span><br><span class="line">rmse_lgbm = mean_squared_error(y_test, y_pred_lgbm, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"LightGBM RMSE:"</span>, rmse_lgbm)</span><br><span class="line">r2_lgbm = r2_score(y_test, y_pred_lgbm)</span><br><span class="line"><span class="built_in">print</span>(r2_lgbm)</span><br><span class="line">rmsle_lgbm = mean_squared_log_error(y_test, y_pred_lgbm, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"LightGBM RMSLE:"</span>, rmsle_lgbm)</span><br></pre></td></tr></table></figure></div>
<p>LightGBM RMSE: 8.222406796622195<br>0.847615020120697<br>LightGBM RMSLE: 0.1428256145540605</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.svm import SVR</span><br><span class="line"></span><br><span class="line">svr = SVR(kernel=<span class="string">'linear'</span>, C=1.0, epsilon=0.1)</span><br><span class="line">svr.fit(X_train, y_train)</span><br><span class="line">y_pred_svr = svr.predict(X_test)</span><br><span class="line">rmse_svr = mean_squared_error(y_test, y_pred_svr, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"SVR RMSE:"</span>, rmse_svr)</span><br><span class="line">r2_svr = r2_score(y_test, y_pred_svr)</span><br><span class="line"><span class="built_in">print</span>(r2_svr)</span><br><span class="line">rmsle_svr = mean_squared_log_error(y_test, y_pred_svr, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"SVR RMSLE:"</span>, rmsle_svr)</span><br></pre></td></tr></table></figure></div>
<p>SVR RMSE: 15.248610756339428<br>0.47591129445611624<br>SVR RMSLE: 0.2390376383177629</p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=5)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred_knn = knn.predict(X_test)</span><br><span class="line">rmse_knn = mean_squared_error(y_test, y_pred_knn, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KNN RMSE:"</span>, rmse_knn)</span><br><span class="line">r2_knn = r2_score(y_test, y_pred_knn)</span><br><span class="line"><span class="built_in">print</span>(r2_knn)</span><br><span class="line">rmsle_knn = mean_squared_log_error(y_test, y_pred_knn, squared=False)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"KNN RMSLE:"</span>, rmsle_knn)</span><br></pre></td></tr></table></figure></div>
<p>KNN RMSE: 14.38134207923586<br>0.5338313360332646<br>KNN RMSLE: 0.2380403734142886</p>
<h1 id="产品定价模型回归结果"><a href="#产品定价模型回归结果" class="headerlink" title="产品定价模型回归结果"></a>产品定价模型回归结果</h1><h2 id="模型评估结果对比"><a href="#模型评估结果对比" class="headerlink" title="模型评估结果对比"></a>模型评估结果对比</h2><table>
<thead>
<tr>
<th>模型</th>
<th>RMSE</th>
<th>R²</th>
<th>RMSLE</th>
</tr>
</thead>
<tbody><tr>
<td>GBDT</td>
<td>8.252</td>
<td>0.847</td>
<td>0.145</td>
</tr>
<tr>
<td>XGBoost</td>
<td>8.176</td>
<td>0.849</td>
<td>0.143</td>
</tr>
<tr>
<td>LightGBM</td>
<td>8.222</td>
<td>0.848</td>
<td>0.143</td>
</tr>
<tr>
<td>SVR</td>
<td>15.249</td>
<td>0.476</td>
<td>0.239</td>
</tr>
<tr>
<td>KNN</td>
<td>14.381</td>
<td>0.534</td>
<td>0.238</td>
</tr>
</tbody></table>
<h2 id="结果解读"><a href="#结果解读" class="headerlink" title="结果解读"></a>结果解读</h2><h3 id="集成树模型（GBDT-XGBoost-LightGBM）"><a href="#集成树模型（GBDT-XGBoost-LightGBM）" class="headerlink" title="集成树模型（GBDT / XGBoost / LightGBM）"></a>集成树模型（GBDT / XGBoost / LightGBM）</h3><ul>
<li><strong>特点：</strong><ul>
<li>能捕捉非线性关系和特征交互。</li>
<li>不依赖特征标准化，对异常值不敏感。</li>
<li>Boosting 框架逐步优化残差。</li>
</ul>
</li>
<li><strong>结果：</strong><ul>
<li>RMSE ~8、R² ~0.85、RMSLE ~0.14 → 效果最佳。</li>
<li>XGBoost/LightGBM 在优化与并行上更先进，略优于传统 GBDT。</li>
</ul>
</li>
</ul>
<h3 id="SVR（支持向量回归）"><a href="#SVR（支持向量回归）" class="headerlink" title="SVR（支持向量回归）"></a>SVR（支持向量回归）</h3><ul>
<li><strong>特点：</strong><ul>
<li>基于核函数映射，高维空间里拟合线性。</li>
<li>更适合连续、平滑的函数关系。</li>
<li>对高维离散特征敏感，需要标准化与合适核函数。</li>
</ul>
</li>
<li><strong>结果：</strong><ul>
<li>RMSE ~15、R² ~0.48 → 误差大，拟合不足。</li>
<li>难以捕捉“跳跃式”的定价规律。</li>
</ul>
</li>
</ul>
<h3 id="KNN（K近邻回归）"><a href="#KNN（K近邻回归）" class="headerlink" title="KNN（K近邻回归）"></a>KNN（K近邻回归）</h3><ul>
<li><strong>特点：</strong><ul>
<li>基于“相似样本价格相似”的假设。</li>
<li>局部模型，对高维数据容易受“维度灾难”影响。</li>
</ul>
</li>
<li><strong>结果：</strong><ul>
<li>RMSE ~14、R² ~0.53 → 效果一般。</li>
<li>最近邻不一定能找到真正相似的样本。</li>
</ul>
</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li><strong>最佳模型：</strong> XGBoost / LightGBM 稳定且泛化最好</li>
<li><strong>可选模型：</strong> GBDT 性能稍逊</li>
<li><strong>不适合：</strong> SVR、KNN 误差大，拟合不足</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--信用卡精准营销模型</title>
    <url>/zhihaojiang.github.io/2025/09/25/20250925%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%BF%A1%E7%94%A8%E5%8D%A1%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> =pd.read_excel(<span class="string">'信用卡精准营销模型.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>年龄</th>
<th>月收入（元）</th>
<th>月消费（元）</th>
<th>性别</th>
<th>月消费/月收入</th>
<th>响应</th>
</tr>
</thead>
<tbody><tr>
<td>30</td>
<td>7275</td>
<td>6062</td>
<td>0</td>
<td>0.833265</td>
<td>1</td>
</tr>
<tr>
<td>25</td>
<td>17739</td>
<td>13648</td>
<td>0</td>
<td>0.769378</td>
<td>1</td>
</tr>
<tr>
<td>29</td>
<td>25736</td>
<td>14311</td>
<td>0</td>
<td>0.556069</td>
<td>1</td>
</tr>
<tr>
<td>23</td>
<td>14162</td>
<td>7596</td>
<td>0</td>
<td>0.536365</td>
<td>1</td>
</tr>
<tr>
<td>27</td>
<td>15563</td>
<td>12849</td>
<td>0</td>
<td>0.825612</td>
<td>1</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段</th>
<th>缺失值数量</th>
</tr>
</thead>
<tbody><tr>
<td>年龄</td>
<td>0</td>
</tr>
<tr>
<td>月收入（元）</td>
<td>0</td>
</tr>
<tr>
<td>月消费（元）</td>
<td>0</td>
</tr>
<tr>
<td>性别</td>
<td>0</td>
</tr>
<tr>
<td>月消费/月收入</td>
<td>0</td>
</tr>
<tr>
<td>响应</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">df</span>[col].dtype <span class="keyword">in</span> [<span class="string">'int64'</span>, <span class="string">'float64'</span>]:</span><br><span class="line">        plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">        plt.title(col)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">df</span>[col].value_counts().plot(kind=<span class="string">'bar'</span>)</span><br><span class="line">        plt.title(col)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/008.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/009.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/010.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/011.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/012.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/013.png" alt="photo"></p>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X = df.drop([<span class="string">'响应'</span>], axis=1)</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'响应'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import AdaBoostClassifier</span><br><span class="line">adab = AdaBoostClassifier(random_state=123)</span><br><span class="line">adab.fit(X_train, y_train)</span><br><span class="line">y_pred = adab.predict(X_test)</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line"></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Accuracy:"</span>, accuracy)</span><br><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line"></span><br><span class="line">cm = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Confusion Matrix:\n"</span>, confusion_matrix)</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line"></span><br><span class="line">y_pred_proba = adab.predict_proba(X_test)</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test.values, y_pred_proba[:,1])</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/014.png" alt="photo"></p>
<p><strong>Accuracy:</strong> 0.83</p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>—</td>
<td>—</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.83</td>
<td>0.89</td>
<td>0.86</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.82</td>
<td>0.74</td>
<td>0.78</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.83</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.83</td>
<td>0.82</td>
<td>0.82</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.83</td>
<td>0.83</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_pred = rm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line">feature_importance = pd.DataFrame({</span><br><span class="line">    <span class="string">"feature"</span>: X_train.columns,</span><br><span class="line">    <span class="string">"importance"</span>: rm.feature_importances_</span><br><span class="line">}).sort_values(by=<span class="string">"importance"</span>, ascending=False)</span><br><span class="line"><span class="built_in">print</span>(feature_importance)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line"></span><br><span class="line">y_pred_proba = rm.predict_proba(X_test)</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test.values, y_pred_proba[:,1])</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/015.png" alt="photo"></p>
<p><strong>Accuracy:</strong> 0.83</p>
<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>109</td>
<td>10</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>23</td>
<td>58</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.83</td>
<td>0.92</td>
<td>0.87</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.85</td>
<td>0.72</td>
<td>0.78</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.83</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.84</td>
<td>0.82</td>
<td>0.82</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.84</td>
<td>0.83</td>
<td>0.83</td>
<td>200</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>feature</th>
<th>importance</th>
</tr>
</thead>
<tbody><tr>
<td>月消费/月收入</td>
<td>0.360143</td>
</tr>
<tr>
<td>月消费（元）</td>
<td>0.264454</td>
</tr>
<tr>
<td>年龄</td>
<td>0.206565</td>
</tr>
<tr>
<td>月收入（元）</td>
<td>0.143241</td>
</tr>
<tr>
<td>性别</td>
<td>0.025597</td>
</tr>
</tbody></table>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb = XGBClassifier()</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred_xgb = xgb.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_xgb))</span><br><span class="line"></span><br><span class="line">feature_importance = pd.DataFrame({</span><br><span class="line">    <span class="string">"feature"</span>: X_train.columns,</span><br><span class="line">    <span class="string">"importance"</span>: xgb.feature_importances_</span><br><span class="line">}).sort_values(by=<span class="string">"importance"</span>, ascending=False)</span><br><span class="line"><span class="built_in">print</span>(feature_importance)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line"></span><br><span class="line">y_pred_proba = xgb.predict_proba(X_test)</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test.values, y_pred_proba[:,1])</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/016.png" alt="photo"></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.85</td>
<td>0.90</td>
<td>0.87</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.84</td>
<td>0.77</td>
<td>0.80</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.84</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.84</td>
<td>0.83</td>
<td>0.84</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.84</td>
<td>0.84</td>
<td>0.84</td>
<td>200</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>feature</th>
<th>importance</th>
</tr>
</thead>
<tbody><tr>
<td>月消费/月收入</td>
<td>0.284714</td>
</tr>
<tr>
<td>年龄</td>
<td>0.270551</td>
</tr>
<tr>
<td>月消费（元）</td>
<td>0.214029</td>
</tr>
<tr>
<td>性别</td>
<td>0.140819</td>
</tr>
<tr>
<td>月收入（元）</td>
<td>0.089888</td>
</tr>
</tbody></table>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.svm import SVC</span><br><span class="line"></span><br><span class="line">svc = SVC(probability=True)</span><br><span class="line">svc.fit(X_train, y_train)</span><br><span class="line">y_pred_svc = svc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_svc))</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line"></span><br><span class="line">y_pred_proba = svc.predict_proba(X_test)</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test.values, y_pred_proba[:,1])</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/017.png" alt="photo"></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.72</td>
<td>0.88</td>
<td>0.80</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.75</td>
<td>0.51</td>
<td>0.60</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.73</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.73</td>
<td>0.69</td>
<td>0.70</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.73</td>
<td>0.73</td>
<td>0.72</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=5)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred_knn = knn.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_knn))</span><br><span class="line"></span><br><span class="line">y_pred_proba = knn.predict_proba(X_test)</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test.values, y_pred_proba[:,1])</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/018.png" alt="photo"></p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.75</td>
<td>0.85</td>
<td>0.80</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.72</td>
<td>0.58</td>
<td>0.64</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.74</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.74</td>
<td>0.71</td>
<td>0.72</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.74</td>
<td>0.74</td>
<td>0.73</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="模型横向比较"><a href="#模型横向比较" class="headerlink" title="模型横向比较"></a>模型横向比较</h1><h2 id="分类报告比较"><a href="#分类报告比较" class="headerlink" title="分类报告比较"></a>分类报告比较</h2><table>
<thead>
<tr>
<th>模型</th>
<th>Accuracy</th>
<th>Precision (正类)</th>
<th>Recall (正类)</th>
<th>F1-Score (正类)</th>
<th>特点/说明</th>
</tr>
</thead>
<tbody><tr>
<td>AdaBoost</td>
<td>0.83</td>
<td>0.82</td>
<td>0.74</td>
<td>0.78</td>
<td>强调难分类样本的迭代加权，适合弱分类器组合；可能对噪声敏感。</td>
</tr>
<tr>
<td>随机森林</td>
<td>0.83</td>
<td>0.85</td>
<td>0.72</td>
<td>0.78</td>
<td>多棵决策树投票，抗过拟合能力强，对特征相关性不敏感；正负类召回存在差异。</td>
</tr>
<tr>
<td>XGBoost</td>
<td>0.84</td>
<td>0.84</td>
<td>0.77</td>
<td>0.80</td>
<td>梯度提升树，学习能力强、对非线性关系拟合优秀；特征重要性分布较合理。</td>
</tr>
<tr>
<td>SVM</td>
<td>0.73</td>
<td>0.75</td>
<td>0.51</td>
<td>0.60</td>
<td>对高维线性可分表现好，非线性需核函数；对不平衡数据敏感，召回率偏低。</td>
</tr>
<tr>
<td>KNN</td>
<td>0.74</td>
<td>0.72</td>
<td>0.58</td>
<td>0.64</td>
<td>基于距离度量，易受噪声和特征尺度影响；正类召回明显低于树模型。</td>
</tr>
</tbody></table>
<h2 id="混淆矩阵对比"><a href="#混淆矩阵对比" class="headerlink" title="混淆矩阵对比"></a>混淆矩阵对比</h2><table>
<thead>
<tr>
<th>模型</th>
<th>TP</th>
<th>FN</th>
<th>FP</th>
<th>TN</th>
</tr>
</thead>
<tbody><tr>
<td>AdaBoost</td>
<td>58</td>
<td>23</td>
<td>10</td>
<td>109</td>
</tr>
<tr>
<td>随机森林</td>
<td>58</td>
<td>23</td>
<td>10</td>
<td>109</td>
</tr>
<tr>
<td>XGBoost</td>
<td>62</td>
<td>19</td>
<td>14</td>
<td>105</td>
</tr>
<tr>
<td>SVM</td>
<td>41</td>
<td>40</td>
<td>18</td>
<td>101</td>
</tr>
<tr>
<td>KNN</td>
<td>47</td>
<td>34</td>
<td>18</td>
<td>101</td>
</tr>
</tbody></table>
<p><strong>说明：</strong>  </p>
<ul>
<li>树模型（AdaBoost、随机森林、XGBoost）对正类和负类的预测都相对均衡，XGBoost略优。  </li>
<li>SVM 和 KNN 正类召回较低，导致 F1-Score 较低。  </li>
<li>XGBoost 正类召回率比随机森林和 AdaBoost 更高，因此 F1-Score 也略高。</li>
</ul>
<h2 id="特征重要性对比"><a href="#特征重要性对比" class="headerlink" title="特征重要性对比"></a>特征重要性对比</h2><table>
<thead>
<tr>
<th>特征</th>
<th>AdaBoost</th>
<th>随机森林</th>
<th>XGBoost</th>
</tr>
</thead>
<tbody><tr>
<td>月消费/月收入</td>
<td>0.36</td>
<td>0.36</td>
<td>0.28</td>
</tr>
<tr>
<td>月消费（元）</td>
<td>0.26</td>
<td>0.26</td>
<td>0.21</td>
</tr>
<tr>
<td>年龄</td>
<td>0.21</td>
<td>0.21</td>
<td>0.27</td>
</tr>
<tr>
<td>月收入（元）</td>
<td>0.14</td>
<td>0.14</td>
<td>0.09</td>
</tr>
<tr>
<td>性别</td>
<td>0.03</td>
<td>0.03</td>
<td>0.14</td>
</tr>
</tbody></table>
<p><strong>说明：</strong>  </p>
<ul>
<li>XGBoost 更看重年龄和性别的作用，而 AdaBoost 和随机森林更侧重消费特征。  </li>
<li>特征权重差异会导致不同模型在正类和负类上的表现略有不同。</li>
</ul>
<h2 id="模型结果差异原因分析"><a href="#模型结果差异原因分析" class="headerlink" title="模型结果差异原因分析"></a>模型结果差异原因分析</h2><ol>
<li><p><strong>算法机制不同：</strong>  </p>
<ul>
<li>树模型（随机森林、XGBoost、AdaBoost）通过划分特征空间拟合非线性关系，对类别不平衡具有一定容错。  </li>
<li>SVM 偏向最大化间隔，对于非线性和不平衡数据，召回率下降。  </li>
<li>KNN 依赖邻近样本，易受噪声和数据分布影响，导致正类召回低。</li>
</ul>
</li>
<li><p><strong>正负类不平衡：</strong>  </p>
<ul>
<li>树模型可通过样本加权（AdaBoost）或集成投票（随机森林、XGBoost）缓解。  </li>
<li>SVM 和 KNN 对不平衡敏感，正类容易被误判。</li>
</ul>
</li>
<li><p><strong>特征处理和重要性：</strong>  </p>
<ul>
<li>不同模型对特征敏感性不同，例如 SVM 对尺度敏感，KNN 对距离敏感，而树模型不敏感。  </li>
<li>特征重要性分布不同会直接影响模型预测偏向，尤其是在正负类分布不均时。</li>
</ul>
</li>
<li><p><strong>模型调参与复杂度：</strong>  </p>
<ul>
<li>XGBoost 提供更多正则化和优化手段，因此整体 F1 更高。  </li>
<li>AdaBoost 使用简单弱分类器叠加，效果略低于 XGBoost。  </li>
<li>KNN、SVM 调参未充分时容易欠拟合或偏向负类。</li>
</ul>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li><strong>XGBoost 综合表现最佳</strong>，F1-Score、Accuracy 较高，正类召回也不错。  </li>
<li><strong>随机森林、AdaBoost 次之</strong>，均衡性良好。  </li>
<li><strong>SVM、KNN 表现较差</strong>，主要受类别不平衡和特征尺度影响，正类召回明显低。  </li>
<li><strong>模型选择需考虑任务需求</strong>：若更关注正类召回，XGBoost 和随机森林更适合；若对整体准确率要求高，AdaBoost 也可考虑。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--信用卡交易数据</title>
    <url>/zhihaojiang.github.io/2025/09/26/20250926%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%BF%A1%E7%94%A8%E5%8D%A1%E4%BA%A4%E6%98%93%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'信用卡交易数据.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>换设备次数</th>
<th>支付失败次数</th>
<th>换IP次数</th>
<th>换IP国次数</th>
<th>交易金额</th>
<th>欺诈标签</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>11</td>
<td>3</td>
<td>5</td>
<td>28836</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>6</td>
<td>1</td>
<td>4</td>
<td>21966</td>
<td>1</td>
</tr>
<tr>
<td>6</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>18199</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>8</td>
<td>2</td>
<td>2</td>
<td>24803</td>
<td>1</td>
</tr>
<tr>
<td>7</td>
<td>10</td>
<td>5</td>
<td>0</td>
<td>26277</td>
<td>1</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段</th>
<th>缺失值数量</th>
</tr>
</thead>
<tbody><tr>
<td>换设备次数</td>
<td>0</td>
</tr>
<tr>
<td>支付失败次数</td>
<td>0</td>
</tr>
<tr>
<td>换IP次数</td>
<td>0</td>
</tr>
<tr>
<td>换IP国次数</td>
<td>0</td>
</tr>
<tr>
<td>交易金额</td>
<td>0</td>
</tr>
<tr>
<td>欺诈标签</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/018.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/019.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/020.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/021.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/022.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/023.png" alt="photo"></p>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X = df.drop(columns=[<span class="string">'欺诈标签'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'欺诈标签'</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb = XGBClassifier(</span><br><span class="line">    n_estimators=100,</span><br><span class="line">    learning_rate=0.1,</span><br><span class="line">    max_depth=5,</span><br><span class="line">    subsample=0.8,</span><br><span class="line">    colsample_bytree=0.8,</span><br><span class="line">    objective=<span class="string">'binary:logistic'</span>,</span><br><span class="line">    eval_metric=<span class="string">'auc'</span>,</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred = xgb.predict(X_test)</span><br><span class="line">y_pred_proba = xgb.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import roc_curve, auc</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)</span><br><span class="line">roc_auc = auc(fpr, tpr)</span><br><span class="line">plt.plot(fpr, tpr, color=<span class="string">'darkorange'</span>, lw=2, label=<span class="string">'ROC curve (area = %0.2f)'</span> % roc_auc)</span><br><span class="line">plt.title(<span class="string">'ROC - XGBoost'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>119</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>18</td>
<td>63</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.87</td>
<td>1.00</td>
<td>0.93</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>1.00</td>
<td>0.78</td>
<td>0.88</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.93</td>
<td>0.89</td>
<td>0.90</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.92</td>
<td>0.91</td>
<td>0.91</td>
<td>200</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/024.png" alt="photo"></p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMClassifier</span><br><span class="line"></span><br><span class="line">lgbm = LGBMClassifier(</span><br><span class="line">    n_estimators=100,</span><br><span class="line">    learning_rate=0.1,</span><br><span class="line">    max_depth=5,</span><br><span class="line">    subsample=0.8,</span><br><span class="line">    colsample_bytree=0.8,</span><br><span class="line">    objective=<span class="string">'binary'</span>,</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line">lgbm.fit(X_train, y_train)</span><br><span class="line">y_pred_lgbm = lgbm.predict(X_test)</span><br><span class="line">y_pred_proba_lgbm = lgbm.predict_proba(X_test)[:,1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_lgbm))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_lgbm))</span><br><span class="line"></span><br><span class="line">fpr_lgbm, tpr_lgbm, thresholds_lgbm = roc_curve(y_test, y_pred_proba_lgbm)</span><br><span class="line">roc_auc_lgbm = auc(fpr_lgbm, tpr_lgbm)</span><br><span class="line">plt.plot(fpr_lgbm, tpr_lgbm, color=<span class="string">'blue'</span>, lw=2, label=<span class="string">'ROC curve (area = %0.2f)'</span> % roc_auc_lgbm)</span><br><span class="line">plt.title(<span class="string">'ROC - LGBM'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>118</td>
<td>1</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>18</td>
<td>63</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.87</td>
<td>0.99</td>
<td>0.93</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.98</td>
<td>0.78</td>
<td>0.87</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.93</td>
<td>0.88</td>
<td>0.90</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.91</td>
<td>0.91</td>
<td>0.90</td>
<td>200</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/025.png" alt="photo"></p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(n_estimators=100, random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_pred_rm = rm.predict(X_test)</span><br><span class="line">y_pred_proba_rm = rm.predict_proba(X_test)[:,1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_rm))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_rm))</span><br><span class="line"></span><br><span class="line">fpr_rm, tpr_rm, thresholds_rm = roc_curve(y_test, y_pred_proba_rm)</span><br><span class="line">roc_auc_rm = auc(fpr_rm, tpr_rm)</span><br><span class="line">plt.plot(fpr_rm, tpr_rm, color=<span class="string">'green'</span>, lw=2, label=<span class="string">'ROC curve (area = %0.2f)'</span> % roc_auc_rm)</span><br><span class="line">plt.title(<span class="string">'ROC - Random Forest'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>118</td>
<td>1</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>17</td>
<td>64</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.87</td>
<td>0.99</td>
<td>0.93</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.98</td>
<td>0.79</td>
<td>0.88</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.93</td>
<td>0.89</td>
<td>0.90</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.92</td>
<td>0.91</td>
<td>0.91</td>
<td>200</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/026.png" alt="photo"></p>
<h1 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"></span><br><span class="line">nb = GaussianNB()</span><br><span class="line">nb.fit(X_train, y_train)</span><br><span class="line">y_pred_nb = nb.predict(X_test)</span><br><span class="line">y_pred_proba_nb = nb.predict_proba(X_test)[:,1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_nb))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_nb))</span><br><span class="line"></span><br><span class="line">fpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, y_pred_proba_nb)</span><br><span class="line">roc_auc_nb = auc(fpr_nb, tpr_nb)</span><br><span class="line">plt.plot(fpr_nb, tpr_nb, color=<span class="string">'red'</span>, lw=2, label=<span class="string">'ROC curve (area = %0.2f)'</span> % roc_auc_nb)</span><br><span class="line">plt.title(<span class="string">'ROC - NB'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>114</td>
<td>5</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>24</td>
<td>57</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.83</td>
<td>0.96</td>
<td>0.89</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.92</td>
<td>0.70</td>
<td>0.80</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.85</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.87</td>
<td>0.83</td>
<td>0.84</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.86</td>
<td>0.85</td>
<td>0.85</td>
<td>200</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/027.png" alt="photo"></p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred_knn = knn.predict(X_test)</span><br><span class="line">y_pred_proba_knn = knn.predict_proba(X_test)[:,1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_knn))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_knn))</span><br><span class="line">fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_pred_proba_knn)</span><br><span class="line">roc_auc_knn = auc(fpr_knn, tpr_knn)</span><br><span class="line">plt.plot(fpr_knn, tpr_knn, color=<span class="string">'purple'</span>, lw=2, label=<span class="string">'ROC curve (area = %0.2f)'</span> % roc_auc_knn)</span><br><span class="line">plt.title(<span class="string">'ROC - KNN'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>86</td>
<td>33</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>57</td>
<td>24</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.60</td>
<td>0.72</td>
<td>0.66</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.42</td>
<td>0.30</td>
<td>0.35</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.55</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.51</td>
<td>0.51</td>
<td>0.50</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.53</td>
<td>0.55</td>
<td>0.53</td>
<td>200</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/028.png" alt="photo"></p>
<h1 id="模型结果汇总对比"><a href="#模型结果汇总对比" class="headerlink" title="模型结果汇总对比"></a>模型结果汇总对比</h1><h2 id="XGBoost-1"><a href="#XGBoost-1" class="headerlink" title="XGBoost"></a>XGBoost</h2><table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>119</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>18</td>
<td>63</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.87</td>
<td>1.00</td>
<td>0.93</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>1.00</td>
<td>0.78</td>
<td>0.88</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.93</td>
<td>0.89</td>
<td>0.90</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.92</td>
<td>0.91</td>
<td>0.91</td>
<td>200</td>
</tr>
</tbody></table>
<h2 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h2><table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>118</td>
<td>1</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>18</td>
<td>63</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.87</td>
<td>0.99</td>
<td>0.93</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.98</td>
<td>0.78</td>
<td>0.87</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.93</td>
<td>0.88</td>
<td>0.90</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.91</td>
<td>0.91</td>
<td>0.90</td>
<td>200</td>
</tr>
</tbody></table>
<h2 id="随机森林-1"><a href="#随机森林-1" class="headerlink" title="随机森林"></a>随机森林</h2><table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>118</td>
<td>1</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>17</td>
<td>64</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.87</td>
<td>0.99</td>
<td>0.93</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.98</td>
<td>0.79</td>
<td>0.88</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.93</td>
<td>0.89</td>
<td>0.90</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.92</td>
<td>0.91</td>
<td>0.91</td>
<td>200</td>
</tr>
</tbody></table>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>114</td>
<td>5</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>24</td>
<td>57</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.83</td>
<td>0.96</td>
<td>0.89</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.92</td>
<td>0.70</td>
<td>0.80</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.85</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.87</td>
<td>0.83</td>
<td>0.84</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.86</td>
<td>0.85</td>
<td>0.85</td>
<td>200</td>
</tr>
</tbody></table>
<h2 id="KNN-1"><a href="#KNN-1" class="headerlink" title="KNN"></a>KNN</h2><table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>86</td>
<td>33</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>57</td>
<td>24</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.60</td>
<td>0.72</td>
<td>0.66</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.42</td>
<td>0.30</td>
<td>0.35</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.55</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.51</td>
<td>0.51</td>
<td>0.50</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.53</td>
<td>0.55</td>
<td>0.53</td>
<td>200</td>
</tr>
</tbody></table>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li><strong>树模型 (XGBoost / LightGBM / 随机森林)</strong> → 表现最好，准确率 0.91，ROC-AUC 高，Precision 接近 1，但 Recall 约 0.78–0.79，有一定漏判风险。  </li>
<li><strong>朴素贝叶斯</strong> → 简单快速，但 Recall 下降到 0.70，漏判更多。  </li>
<li><strong>KNN</strong> → 表现最差，不适合该任务。</li>
</ul>
<blockquote>
<p><strong>结论：</strong> 金融场景推荐使用 <strong>XGBoost / LightGBM / 随机森林</strong>，并可通过 <strong>阈值调整、类别权重、SMOTE</strong> 等方法进一步优化 Recall。</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--股票涨跌预测模型搭建</title>
    <url>/zhihaojiang.github.io/2025/09/25/20250925%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E8%82%A1%E7%A5%A8%E6%B6%A8%E8%B7%8C%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import tushare as ts  <span class="comment"># 股票基本数据相关库</span></span><br><span class="line">import numpy as np  <span class="comment"># 科学计算相关库</span></span><br><span class="line">import pandas as pd  <span class="comment"># 科学计算相关库  </span></span><br><span class="line">import talib  <span class="comment"># 股票衍生变量数据相关库</span></span><br><span class="line">import matplotlib.pyplot as plt  <span class="comment"># 引入绘图相关库，可视化</span></span><br><span class="line">from sklearn.ensemble import RandomForestClassifier  <span class="comment"># 引入分类决策树模型</span></span><br><span class="line">from sklearn.metrics import accuracy_score  <span class="comment"># 引入准确度评分函数</span></span><br><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>) <span class="comment"># 忽略警告信息，警告非报错，不影响代码执行</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.股票基本数据获取</span></span><br><span class="line"><span class="built_in">df</span> = ts.get_k_data(<span class="string">'000002'</span>,start=<span class="string">'2015-01-01'</span>,end=<span class="string">'2019-12-31'</span>)</span><br><span class="line"><span class="built_in">df</span> = df.set_index(<span class="string">'date'</span>)  <span class="comment"># 设置日期为索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.简单衍生变量构造</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'close-open'</span>] = (<span class="built_in">df</span>[<span class="string">'close'</span>] - <span class="built_in">df</span>[<span class="string">'open'</span>])/df[<span class="string">'open'</span>]</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'high-low'</span>] = (<span class="built_in">df</span>[<span class="string">'high'</span>] - <span class="built_in">df</span>[<span class="string">'low'</span>])/df[<span class="string">'low'</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'pre_close'</span>] = <span class="built_in">df</span>[<span class="string">'close'</span>].<span class="built_in">shift</span>(1)  <span class="comment"># 该列所有往下移一行形成昨日收盘价</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'price_change'</span>] = <span class="built_in">df</span>[<span class="string">'close'</span>]-<span class="built_in">df</span>[<span class="string">'pre_close'</span>]</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'p_change'</span>] = (<span class="built_in">df</span>[<span class="string">'close'</span>]-<span class="built_in">df</span>[<span class="string">'pre_close'</span>])/df[<span class="string">'pre_close'</span>]*100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.移动平均线相关数据构造</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'MA5'</span>] = <span class="built_in">df</span>[<span class="string">'close'</span>].rolling(5).mean()</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'MA10'</span>] = <span class="built_in">df</span>[<span class="string">'close'</span>].rolling(10).mean()</span><br><span class="line">df.dropna(inplace=True)  <span class="comment"># 删除空值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.通过Ta_lib库构造衍生变量</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'RSI'</span>] = talib.RSI(<span class="built_in">df</span>[<span class="string">'close'</span>], timeperiod=12)  <span class="comment"># 相对强弱指标</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'MOM'</span>] = talib.MOM(<span class="built_in">df</span>[<span class="string">'close'</span>], timeperiod=5)  <span class="comment"># 动量指标</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'EMA12'</span>] = talib.EMA(<span class="built_in">df</span>[<span class="string">'close'</span>], timeperiod=12)  <span class="comment"># 12日指数移动平均线</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'EMA26'</span>] = talib.EMA(<span class="built_in">df</span>[<span class="string">'close'</span>], timeperiod=26)  <span class="comment"># 26日指数移动平均线</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'MACD'</span>], <span class="built_in">df</span>[<span class="string">'MACDsignal'</span>], <span class="built_in">df</span>[<span class="string">'MACDhist'</span>] = talib.MACD(<span class="built_in">df</span>[<span class="string">'close'</span>], fastperiod=12, slowperiod=26, signalperiod=9)  <span class="comment"># MACD值</span></span><br><span class="line">df.dropna(inplace=True)  <span class="comment"># 删除空值</span></span><br></pre></td></tr></table></figure></div>

<p>库太老了 我使用其他数据获取库<br>用其他更现代的库来获取股票数据</p>
<p>akshare</p>
<p>pip install akshare</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import akshare as ak</span><br><span class="line"><span class="built_in">df</span> = ak.stock_zh_a_hist(symbol=<span class="string">"000002"</span>, period=<span class="string">"daily"</span>, start_date=<span class="string">"20150101"</span>, end_date=<span class="string">"20191231"</span>, adjust=<span class="string">""</span>)</span><br><span class="line"><span class="built_in">df</span> = df.set_index(<span class="string">'日期'</span>)</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>日期</th>
<th>股票代码</th>
<th>开盘</th>
<th>收盘</th>
<th>最高</th>
<th>最低</th>
<th>成交量</th>
<th>成交额</th>
<th>振幅</th>
<th>涨跌幅</th>
<th>涨跌额</th>
<th>换手率</th>
</tr>
</thead>
<tbody><tr>
<td>2015-01-05</td>
<td>000002</td>
<td>14.39</td>
<td>14.91</td>
<td>15.29</td>
<td>14.22</td>
<td>6560836</td>
<td>9.700712e+09</td>
<td>7.70</td>
<td>7.27</td>
<td>1.01</td>
<td>6.76</td>
</tr>
<tr>
<td>2015-01-06</td>
<td>000002</td>
<td>14.60</td>
<td>14.36</td>
<td>14.99</td>
<td>14.05</td>
<td>3346347</td>
<td>4.839616e+09</td>
<td>6.30</td>
<td>-3.69</td>
<td>-0.55</td>
<td>3.45</td>
</tr>
<tr>
<td>2015-01-07</td>
<td>000002</td>
<td>14.26</td>
<td>14.23</td>
<td>14.50</td>
<td>14.00</td>
<td>2642051</td>
<td>3.772151e+09</td>
<td>3.48</td>
<td>-0.91</td>
<td>-0.13</td>
<td>2.72</td>
</tr>
<tr>
<td>2015-01-08</td>
<td>000002</td>
<td>14.32</td>
<td>13.59</td>
<td>14.37</td>
<td>13.46</td>
<td>2639394</td>
<td>3.629554e+09</td>
<td>6.39</td>
<td>-4.50</td>
<td>-0.64</td>
<td>2.72</td>
</tr>
<tr>
<td>2015-01-09</td>
<td>000002</td>
<td>13.54</td>
<td>13.45</td>
<td>14.22</td>
<td>13.29</td>
<td>3294584</td>
<td>4.521978e+09</td>
<td>6.84</td>
<td>-1.03</td>
<td>-0.14</td>
<td>3.39</td>
</tr>
</tbody></table>
<h1 id="画k线图"><a href="#画k线图" class="headerlink" title="画k线图"></a>画k线图</h1><p>针对股票市场 我们肯定要查看其k线图</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import plotly.graph_objects as go</span><br><span class="line"></span><br><span class="line">data = df.loc[<span class="string">"2015-01-01"</span>:<span class="string">"2015-01-31"</span>]</span><br><span class="line"></span><br><span class="line">fig = go.Figure(data=[go.Candlestick(</span><br><span class="line">    x=data.index,</span><br><span class="line">    open=data[<span class="string">"Open"</span>],</span><br><span class="line">    high=data[<span class="string">"High"</span>],</span><br><span class="line">    low=data[<span class="string">"Low"</span>],</span><br><span class="line">    close=data[<span class="string">"Close"</span>],</span><br><span class="line">    increasing_line_color=<span class="string">"red"</span>,</span><br><span class="line">    decreasing_line_color=<span class="string">"green"</span></span><br><span class="line">)])</span><br><span class="line"></span><br><span class="line">fig.update_layout(</span><br><span class="line">    title=<span class="string">"000002 万科A K线图 (2015-01)"</span>,</span><br><span class="line">    xaxis_title=<span class="string">"日期"</span>,</span><br><span class="line">    yaxis_title=<span class="string">"价格"</span>,</span><br><span class="line">    xaxis_rangeslider_visible=False</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/25/001.png" alt="photo"></p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.metrics import classification_report, accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = ak.stock_zh_a_hist(symbol=<span class="string">"000002"</span>, period=<span class="string">"daily"</span>, start_date=<span class="string">"20150101"</span>, end_date=<span class="string">"20150131"</span>, adjust=<span class="string">"qfq"</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">"label"</span>] = (<span class="built_in">df</span>[<span class="string">"收盘"</span>].<span class="built_in">shift</span>(-1) &gt; <span class="built_in">df</span>[<span class="string">"收盘"</span>]).astype(int)  <span class="comment"># 次日涨=1，跌=0</span></span><br><span class="line"></span><br><span class="line">X = <span class="built_in">df</span>[[<span class="string">"开盘"</span>, <span class="string">"最高"</span>, <span class="string">"最低"</span>, <span class="string">"收盘"</span>, <span class="string">"成交量"</span>, <span class="string">"成交额"</span>, <span class="string">"振幅"</span>, <span class="string">"涨跌幅"</span>, <span class="string">"换手率"</span>]]</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">"label"</span>]</span><br><span class="line"></span><br><span class="line">X = X[:-1]</span><br><span class="line">y = y[:-1]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)</span><br><span class="line"></span><br><span class="line">rf = RandomForestClassifier(n_estimators=200, random_state=42)</span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"准确率:"</span>, accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>准确率: 1.0</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>2</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>1.00</strong></td>
<td>4</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>4</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>4</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">feature_importances = pd.Series(rf.feature_importances_, index=X.columns)</span><br><span class="line">feature_importances = feature_importances.sort_values(ascending=False)</span><br><span class="line"><span class="built_in">print</span>(feature_importances)</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>特征</th>
<th>重要性</th>
</tr>
</thead>
<tbody><tr>
<td>开盘</td>
<td>0.3772</td>
</tr>
<tr>
<td>最高</td>
<td>0.2516</td>
</tr>
<tr>
<td>最低</td>
<td>0.1511</td>
</tr>
<tr>
<td>收盘</td>
<td>0.1213</td>
</tr>
<tr>
<td>涨跌幅</td>
<td>0.0444</td>
</tr>
<tr>
<td>振幅</td>
<td>0.0196</td>
</tr>
<tr>
<td>成交量</td>
<td>0.0173</td>
</tr>
<tr>
<td>换手率</td>
<td>0.0095</td>
</tr>
<tr>
<td>成交额</td>
<td>0.0081</td>
</tr>
</tbody></table>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">dtc = DecisionTreeClassifier(random_state=42)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.67</td>
<td>1.00</td>
<td>0.80</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>1.00</td>
<td>0.50</td>
<td>0.67</td>
<td>2</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.75</strong></td>
<td>4</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.83</td>
<td>0.75</td>
<td>0.73</td>
<td>4</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.75</td>
<td>0.73</td>
<td>4</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(dtc, X_train, y_train, cv=5, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各折准确率："</span>, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"平均准确率：%.4f (+/- %.4f)"</span> % (scores.mean(), scores.std() * 2))</span><br></pre></td></tr></table></figure></div>
<p>各折准确率： [1.         1.         0.66666667 0.66666667 1.        ]<br>平均准确率：0.8667 (+/- 0.3266)</p>
<h2 id="决策树结果分析"><a href="#决策树结果分析" class="headerlink" title="决策树结果分析"></a>决策树结果分析</h2><p>发现决策树效果并没有随机森林那么好 这是因为随机森林是一种集成算法 是由多个决策树集成的 其结果是由多个决策树共同打分的 因此随机森林在处高维数据时会比决策树要好</p>
<h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line">GBDT = GradientBoostingClassifier(random_state=42)</span><br><span class="line">GBDT.fit(X_train, y_train)</span><br><span class="line">y_pred = GBDT.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.67</td>
<td>1.00</td>
<td>0.80</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>1.00</td>
<td>0.50</td>
<td>0.67</td>
<td>2</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.75</strong></td>
<td>4</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.83</td>
<td>0.75</td>
<td>0.73</td>
<td>4</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.75</td>
<td>0.73</td>
<td>4</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(GBDT, X_train, y_train, cv=5, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各折准确率："</span>, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"平均准确率：%.4f (+/- %.4f)"</span> % (scores.mean(), scores.std() * 2))</span><br></pre></td></tr></table></figure></div>
<p>各折准确率： [1.         1.         0.66666667 0.66666667 1.        ]<br>平均准确率：0.8667 (+/- 0.3266)</p>
<h2 id="GBDT结果分析"><a href="#GBDT结果分析" class="headerlink" title="GBDT结果分析"></a>GBDT结果分析</h2><p>发现GBDT的结果没随机森林要好 这是因为GBDT对参数敏感 需要进行调参 使用网格优化</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = {</span><br><span class="line">    <span class="string">'n_estimators'</span>: [100, 200, 500],</span><br><span class="line">    <span class="string">'learning_rate'</span>: [0.1, 0.05, 0.01],</span><br><span class="line">    <span class="string">'max_depth'</span>: [3, 5, 7],</span><br><span class="line">    <span class="string">'min_samples_split'</span>: [2, 5, 10],</span><br><span class="line">    <span class="string">'min_samples_leaf'</span>: [1, 2, 4]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">grid = GridSearchCV(</span><br><span class="line">    GradientBoostingClassifier(random_state=42),</span><br><span class="line">    param_grid,</span><br><span class="line">    cv=5,</span><br><span class="line">    scoring=<span class="string">'f1_macro'</span>,  <span class="comment"># 也可以换成 'accuracy', 'roc_auc'</span></span><br><span class="line">    n_jobs=-1</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Best Params:"</span>, grid.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Best Score:"</span>, grid.best_score_)</span><br></pre></td></tr></table></figure></div>
<p>Best Params: {‘learning_rate’: 0.1, ‘max_depth’: 3, ‘min_samples_leaf’: 1, ‘min_samples_split’: 2, ‘n_estimators’: 100}<br>Best Score: 0.8666666666666666<br>其结果要比之前的好了一些</p>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"></span><br><span class="line">nb = GaussianNB()</span><br><span class="line">nb.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred_nb = nb.predict(X_test)</span><br><span class="line">y_pred_proba = nb.predict_proba(X_test)[:, 1]  <span class="comment"># 离职概率（正类概率）</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"混淆矩阵："</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_nb))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n分类报告："</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_nb))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n前5个样本的离职概率："</span>, y_pred_proba[:5])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(nb, X_train, y_train, cv=5, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各折准确率："</span>, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"平均准确率：%.4f (+/- %.4f)"</span> % (scores.mean(), scores.std() * 2))</span><br></pre></td></tr></table></figure></div>

<h2 id="贝叶斯结果分析"><a href="#贝叶斯结果分析" class="headerlink" title="贝叶斯结果分析"></a>贝叶斯结果分析</h2><p>可以看到 贝叶斯的结果非常不好 这是因为 贝叶斯模型是假设特征之间是相互独立的 而在股票市场中 特征之间往往是存在相关性的 因此贝叶斯模型的效果是要比其他模型差的</p>
<p>我们还可以画出特征之间的热力图</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">correlation_matrix = pd.concat([X_train, y_train], axis=1).corr()</span><br><span class="line"></span><br><span class="line">sns.heatmap(correlation_matrix, annot=True, cmap=<span class="string">'coolwarm'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<p>可以看到 像开盘与最高 开盘与最低等之间呈现高相关性</p>
<h1 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.discriminant_analysis import LinearDiscriminantAnalysis</span><br><span class="line"></span><br><span class="line">LDA = LinearDiscriminantAnalysis()</span><br><span class="line">LDA.fit(X_train, y_train)</span><br><span class="line">y_pred_lda = LDA.predict(X_test)</span><br><span class="line">y_pred_proba_lda = LDA.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"混淆矩阵："</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred_lda))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n分类报告："</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_lda))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>0</td>
<td>2</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>2</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>1.00</strong></td>
<td>4</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>4</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>4</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(LDA, X_train, y_train, cv=5, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各折准确率："</span>, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"平均准确率：%.4f (+/- %.4f)"</span> % (scores.mean(), scores.std() * 2))</span><br></pre></td></tr></table></figure></div>
<p>各折准确率： [0.66666667 0.66666667 0.66666667 0.66666667 0.33333333]<br>平均准确率：0.6000 (+/- 0.2667)</p>
<h2 id="LDA结果分析"><a href="#LDA结果分析" class="headerlink" title="LDA结果分析"></a>LDA结果分析</h2><p>我们看到 LDA的分类报告非常好 但是进行k折交叉验证的时候没那么好<br>这是因为我的数据样本少 分类报告恰好分类得很好 但是在交叉验证的时候发现了此问题 此外 对于股票行情 不推荐使用k折交叉验证 因为交叉验证是随机划分的 有可能会泄漏未来的信息 推荐使用时序交叉验证</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import TimeSeriesSplit, cross_val_score</span><br><span class="line"></span><br><span class="line">tscv = TimeSeriesSplit(n_splits=5)</span><br><span class="line">scores = cross_val_score(LDA, X_train, y_train, cv=tscv, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"各折准确率："</span>, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"平均准确率：%.4f (+/- %.4f)"</span> % (scores.mean(), scores.std() * 2))</span><br></pre></td></tr></table></figure></div>
<p>各折准确率： [0.5 0.5 0.5 0.5 0.5]<br>平均准确率：0.5000 (+/- 0.0000)</p>
<p>LDA 假设特征服从高斯分布 且协方差矩阵相同 但股票特征往往不满足</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--客户信息及违约表现</title>
    <url>/zhihaojiang.github.io/2025/09/26/20250926%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E5%AE%A2%E6%88%B7%E4%BF%A1%E6%81%AF%E5%8F%8A%E8%BF%9D%E7%BA%A6%E8%A1%A8%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'客户信息及违约表现.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>收入</th>
<th>年龄</th>
<th>性别</th>
<th>历史授信额度</th>
<th>历史违约次数</th>
<th>是否违约</th>
</tr>
</thead>
<tbody><tr>
<td>462087</td>
<td>26</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>362324</td>
<td>32</td>
<td>0</td>
<td>13583</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>332011</td>
<td>52</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>252895</td>
<td>39</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>352355</td>
<td>50</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/010.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/011.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/012.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/013.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/014.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/015.png" alt="photo"></p>
<p>发现两个特征存在异常值 使用热力图查看特征之间的关系</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line">sns.heatmap(df.corr(), annot=True, cmap=<span class="string">'coolwarm'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/016.png" alt="photo"></p>
<p>看到 历史违约次数和是否违约相关性很大 并且历史违约次数存在异常值 因此新增此特征的异常值特征列</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">col = <span class="string">'历史违约次数'</span></span><br><span class="line"></span><br><span class="line">Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[f<span class="string">'{col}_is_outlier'</span>] = ((df[col] &lt; lower_bound) | (df[col] &gt; upper_bound)).astype(int)</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = df.drop(columns=[<span class="string">'历史授信额度'</span>])</span><br></pre></td></tr></table></figure></div>

<p>继续查看另一个异常值的特征分布</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.hist(<span class="built_in">df</span>[<span class="string">'历史授信额度'</span>], bins=30, color=<span class="string">'skyblue'</span>, edgecolor=<span class="string">'black'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/017.png" alt="photo"></p>
<p>可以看到 数据是右偏的 并且是长尾分布 对于此数据 使用对数变换</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">col = <span class="string">'历史授信额度'</span></span><br><span class="line"><span class="built_in">df</span>[f<span class="string">'{col}_log'</span>] = np.log1p(<span class="built_in">df</span>[col])</span><br></pre></td></tr></table></figure></div>

<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = df.drop(columns=[<span class="string">'是否违约'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'是否违约'</span>]</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb = XGBClassifier(</span><br><span class="line">    n_estimators=100,</span><br><span class="line">    learning_rate=0.1,</span><br><span class="line">    max_depth=5,</span><br><span class="line">    subsample=0.8,</span><br><span class="line">    colsample_bytree=0.8,</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred = xgb.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>110</td>
<td>9</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>29</td>
<td>52</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.79</td>
<td>0.92</td>
<td>0.85</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.85</td>
<td>0.64</td>
<td>0.73</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.81</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.82</td>
<td>0.78</td>
<td>0.79</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.82</td>
<td>0.81</td>
<td>0.80</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMClassifier</span><br><span class="line"></span><br><span class="line">lgbm = LGBMClassifier(</span><br><span class="line">    n_estimators=100,</span><br><span class="line">    learning_rate=0.1,</span><br><span class="line">    max_depth=5,</span><br><span class="line">    subsample=0.8,</span><br><span class="line">    colsample_bytree=0.8,</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line">lgbm.fit(X_train, y_train)</span><br><span class="line">y_pred = lgbm.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>113</td>
<td>6</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>29</td>
<td>52</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.80</td>
<td>0.95</td>
<td>0.87</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.90</td>
<td>0.64</td>
<td>0.75</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.82</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.85</td>
<td>0.80</td>
<td>0.81</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.84</td>
<td>0.82</td>
<td>0.82</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(</span><br><span class="line">    n_estimators=100,</span><br><span class="line">    max_depth=5,</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_pred = rm.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>117</td>
<td>2</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>29</td>
<td>52</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.80</td>
<td>0.98</td>
<td>0.88</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.96</td>
<td>0.64</td>
<td>0.77</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.84</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.88</td>
<td>0.81</td>
<td>0.83</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.87</td>
<td>0.84</td>
<td>0.84</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"></span><br><span class="line">nb = GaussianNB()</span><br><span class="line">nb.fit(X_train, y_train)</span><br><span class="line">y_pred = nb.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>111</td>
<td>8</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>43</td>
<td>38</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.72</td>
<td>0.93</td>
<td>0.81</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.83</td>
<td>0.47</td>
<td>0.60</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.74</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.77</td>
<td>0.70</td>
<td>0.71</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.76</td>
<td>0.74</td>
<td>0.73</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line">y_pred = lr.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>88</td>
<td>31</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>60</td>
<td>21</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.59</td>
<td>0.74</td>
<td>0.66</td>
<td>119</td>
</tr>
<tr>
<td>1</td>
<td>0.40</td>
<td>0.26</td>
<td>0.32</td>
<td>81</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.55</strong></td>
<td>200</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.50</td>
<td>0.50</td>
<td>0.49</td>
<td>200</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.52</td>
<td>0.55</td>
<td>0.52</td>
<td>200</td>
</tr>
</tbody></table>
<h1 id="模型横向对比"><a href="#模型横向对比" class="headerlink" title="模型横向对比"></a>模型横向对比</h1><h2 id="XGBoost-1"><a href="#XGBoost-1" class="headerlink" title="XGBoost"></a>XGBoost</h2><ul>
<li><strong>整体表现：</strong> Accuracy = 0.81</li>
<li><strong>优点：</strong><ul>
<li>Precision 对 1 类 较高 (0.85)，但 Recall 偏低 (0.64)</li>
<li>说明它比较谨慎 预测为违约时大多是真的（低假阳性）但漏掉了不少实际违约（高假阴性）</li>
<li>适合在误判正常人为违约成本高的场景</li>
</ul>
</li>
</ul>
<h2 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h2><ul>
<li><strong>整体表现：</strong> Accuracy = 0.82（略高于 XGB）  </li>
<li><strong>优点：</strong><ul>
<li>对类别 1 的 Precision 更高 (0.90) Recall 同样偏低 (0.64)</li>
<li>预测结果更保守 对 1 的识别严格 但仍漏掉一部分违约客户</li>
<li>对比 XGBoost：性能非常接近，但 LightGBM 对类别 0 的 Recall 更高 对正常客户的识别更稳</li>
</ul>
</li>
</ul>
<h2 id="随机森林-1"><a href="#随机森林-1" class="headerlink" title="随机森林"></a>随机森林</h2><ul>
<li><strong>整体表现：</strong> Accuracy = 0.84</li>
<li><strong>优点：</strong><ul>
<li>类别 0 的 Recall 极高 几乎不会把正常客户错判为违约</li>
<li>类别 1 的 Precision 很高 (0.96)，但 Recall 仍然只有 0.64 但还是漏掉部分</li>
</ul>
</li>
<li><strong>特点：</strong><ul>
<li>Bagging 思路让它在这类低维表格数据上表现最稳健。</li>
<li>如果更在意总体准确率和稳健性，随机森林是首选。</li>
</ul>
</li>
</ul>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><ul>
<li><strong>整体表现：</strong> Accuracy = 0.74  </li>
<li><strong>优点：</strong> 对类别 0 Recall 较高</li>
<li><strong>缺点：</strong> 类别 1 Recall 低 几乎一半违约客户都漏掉。  </li>
<li><strong>原因：</strong><ul>
<li>假设特征独立，这在客户数据里往往不成立 会导致性能下降</li>
</ul>
</li>
</ul>
<h2 id="逻辑回归-1"><a href="#逻辑回归-1" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><ul>
<li><strong>整体表现：</strong> Accuracy = 0.55</li>
<li><strong>缺点：</strong><ul>
<li>类别 1 的 Recall 极低 大部分违约客户被判成了正常</li>
<li>说明数据中的关系并不是线性可分的 逻辑回归模型过于简单</li>
</ul>
</li>
<li><strong>适用场景：</strong><ul>
<li>在数据高度线性且变量少时可用 但在这个复杂数据集上严重欠拟合</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table>
<thead>
<tr>
<th>模型</th>
<th>Accuracy</th>
<th>类别 1 (违约) Recall</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>随机森林</td>
<td>0.84</td>
<td>0.64</td>
<td>最优表现，稳健，几乎不误判正常客户</td>
</tr>
<tr>
<td>LightGBM</td>
<td>0.82</td>
<td>0.64</td>
<td>高效，Precision 高，Recall 偏低</td>
</tr>
<tr>
<td>XGBoost</td>
<td>0.81</td>
<td>0.64</td>
<td>与 LGBM 接近，偏保守</td>
</tr>
<tr>
<td>朴素贝叶斯</td>
<td>0.74</td>
<td>0.47</td>
<td>偏弱，假设不符合实际</td>
</tr>
<tr>
<td>逻辑回归</td>
<td>0.55</td>
<td>0.26</td>
<td>严重欠拟合，不适合此任务</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>结论：</strong>  </p>
<ul>
<li>整体上 <strong>树模型（RF、XGB、LGBM）表现远优于线性模型（LR）和简单概率模型（NB）</strong> </li>
<li><strong>随机森林在这里是最佳选择</strong>，因为它在准确率和稳定性上均优 并且对违约的准确率特别高</li>
<li>但三种树模型都有一个共性：<strong>违约 Recall 偏低（都在 0.64 左右）</strong> 意味着有不少违约客户没被识别出来</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--广告收益数据</title>
    <url>/zhihaojiang.github.io/2025/09/26/20250926%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E5%B9%BF%E5%91%8A%E6%94%B6%E7%9B%8A%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'广告收益数据.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>电视</th>
<th>广播</th>
<th>报纸</th>
<th>收益</th>
</tr>
</thead>
<tbody><tr>
<td>230.1</td>
<td>37.8</td>
<td>69.2</td>
<td>331.5</td>
</tr>
<tr>
<td>44.5</td>
<td>39.3</td>
<td>45.1</td>
<td>156.0</td>
</tr>
<tr>
<td>17.2</td>
<td>45.9</td>
<td>69.3</td>
<td>139.5</td>
</tr>
<tr>
<td>151.5</td>
<td>41.3</td>
<td>58.5</td>
<td>277.5</td>
</tr>
<tr>
<td>180.8</td>
<td>10.8</td>
<td>58.4</td>
<td>193.5</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段</th>
<th>缺失值数量</th>
</tr>
</thead>
<tbody><tr>
<td>电视</td>
<td>0</td>
</tr>
<tr>
<td>广播</td>
<td>0</td>
</tr>
<tr>
<td>报纸</td>
<td>0</td>
</tr>
<tr>
<td>收益</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/001.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/002.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/003.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/004.png" alt="photo"></p>
<p>发现报纸存在异常值 画出热力图查看其相关性<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/005.png" alt="photo"></p>
<p>发现报纸与收益的相关性系数为0.22 虽然是一个比较小的数 但是考虑到数据只有3个特征 我们添加一列用于保留异常值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">col = <span class="string">'报纸'</span></span><br><span class="line"></span><br><span class="line">Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line">lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[f<span class="string">'{col}_is_outlier'</span>] = ((df[col] &lt; lower_bound) | (df[col] &gt; upper_bound)).astype(int)</span><br></pre></td></tr></table></figure></div>

<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=[<span class="string">'收益'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'收益'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor()</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred = xgb.predict(X_test)</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'MSE: {mse}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'R2: {r2}'</span>)</span><br><span class="line"></span><br><span class="line">feature_importance = pd.DataFrame({</span><br><span class="line">    <span class="string">"feature"</span>: X_train.columns,</span><br><span class="line">    <span class="string">"importance"</span>: xgb.feature_importances_</span><br><span class="line">}).sort_values(by=<span class="string">"importance"</span>, ascending=False)</span><br><span class="line"><span class="built_in">print</span>(feature_importance)</span><br><span class="line"></span><br><span class="line">import shap</span><br><span class="line"></span><br><span class="line">explainer = shap.TreeExplainer(xgb)</span><br><span class="line">shap_values = explainer.shap_values(X_test)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, X_test)</span><br></pre></td></tr></table></figure></div>
<p><strong>XGBoost 模型性能</strong>  </p>
<ul>
<li><strong>MSE:</strong> 297.333</li>
<li><strong>R²:</strong> 0.9586</li>
</ul>
<table>
<thead>
<tr>
<th>feature</th>
<th>importance</th>
</tr>
</thead>
<tbody><tr>
<td>电视</td>
<td>0.561881</td>
</tr>
<tr>
<td>广播</td>
<td>0.412244</td>
</tr>
<tr>
<td>报纸</td>
<td>0.025875</td>
</tr>
<tr>
<td>报纸_is_outlier</td>
<td>0.000000</td>
</tr>
</tbody></table>
<blockquote>
<p>可以看到 我们新增的特征完全没有用 可以将上述的新增特征的代码删除</p>
</blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/006.png" alt="photo"></p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line"></span><br><span class="line">lgbm = LGBMRegressor()</span><br><span class="line">lgbm.fit(X_train, y_train)</span><br><span class="line">y_pred_lgbm = lgbm.predict(X_test)</span><br><span class="line">mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)</span><br><span class="line">r2_lgbm = r2_score(y_test, y_pred_lgbm)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'LGBM MSE: {mse_lgbm}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'LGBM R2: {r2_lgbm}'</span>)</span><br><span class="line">feature_importance_lgbm = pd.DataFrame({</span><br><span class="line">    <span class="string">"feature"</span>: X_train.columns,</span><br><span class="line">    <span class="string">"importance"</span>: lgbm.feature_importances_</span><br><span class="line">}).sort_values(by=<span class="string">"importance"</span>, ascending=False)</span><br><span class="line"><span class="built_in">print</span>(feature_importance_lgbm)</span><br><span class="line"></span><br><span class="line">explainer = shap.TreeExplainer(lgbm)</span><br><span class="line">shap_values = explainer.shap_values(X_test)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, X_test)</span><br></pre></td></tr></table></figure></div>
<p><strong>LGBM 模型性能</strong>  </p>
<ul>
<li><strong>MSE:</strong> 308.58  </li>
<li><strong>R²:</strong> 0.9570</li>
</ul>
<table>
<thead>
<tr>
<th>feature</th>
<th>importance</th>
</tr>
</thead>
<tbody><tr>
<td>广播</td>
<td>990</td>
</tr>
<tr>
<td>电视</td>
<td>981</td>
</tr>
<tr>
<td>报纸</td>
<td>978</td>
</tr>
<tr>
<td>报纸_is_outlier</td>
<td>0</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/007.png" alt="photo"></p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestRegressor(n_estimators=100, random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_pred_rm = rm.predict(X_test)</span><br><span class="line">mse_rm = mean_squared_error(y_test, y_pred_rm)</span><br><span class="line">r2_rm = r2_score(y_test, y_pred_rm)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Random Forest MSE: {mse_rm}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Random Forest R2: {r2_rm}'</span>)</span><br><span class="line">feature_importance_rm = pd.DataFrame({</span><br><span class="line">    <span class="string">"feature"</span>: X_train.columns,</span><br><span class="line">    <span class="string">"importance"</span>: rm.feature_importances_</span><br><span class="line">}).sort_values(by=<span class="string">"importance"</span>, ascending=False)</span><br><span class="line"><span class="built_in">print</span>(feature_importance_rm)</span><br><span class="line"></span><br><span class="line">explainer = shap.TreeExplainer(<span class="built_in">rm</span>)</span><br><span class="line">shap_values = explainer.shap_values(X_test)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, X_test)</span><br></pre></td></tr></table></figure></div>

<p><strong>Random Forest 模型性能</strong>  </p>
<ul>
<li><strong>MSE:</strong> 277.82  </li>
<li><strong>R²:</strong> 0.9613</li>
</ul>
<table>
<thead>
<tr>
<th>feature</th>
<th>importance</th>
</tr>
</thead>
<tbody><tr>
<td>电视</td>
<td>0.624624</td>
</tr>
<tr>
<td>广播</td>
<td>0.356226</td>
</tr>
<tr>
<td>报纸</td>
<td>0.018884</td>
</tr>
<tr>
<td>报纸_is_outlier</td>
<td>0.000266</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/008.png" alt="photo"></p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.svm import SVR</span><br><span class="line"></span><br><span class="line">svr = SVR()</span><br><span class="line">svr.fit(X_train, y_train)</span><br><span class="line">y_pred_svr = svr.predict(X_test)</span><br><span class="line">mse_svr = mean_squared_error(y_test, y_pred_svr)</span><br><span class="line">r2_svr = r2_score(y_test, y_pred_svr)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'SVR MSE: {mse_svr}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'SVR R2: {r2_svr}'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">explainer = shap.TreeExplainer(<span class="built_in">rm</span>)</span><br><span class="line">shap_values = explainer.shap_values(X_test)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, X_test)</span><br></pre></td></tr></table></figure></div>

<p>SVR MSE: 2942.2258137398626<br>SVR R2: 0.5903858154199828</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/26/009.png" alt="photo"></p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=5)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred_knn = knn.predict(X_test)</span><br><span class="line">mse_knn = mean_squared_error(y_test, y_pred_knn)</span><br><span class="line">r2_knn = r2_score(y_test, y_pred_knn)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'KNN MSE: {mse_knn}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'KNN R2: {r2_knn}'</span>)</span><br></pre></td></tr></table></figure></div>
<p>KNN MSE: 423.61199999999997<br>KNN R2: 0.9410250963240132</p>
<h1 id="模型横向对比"><a href="#模型横向对比" class="headerlink" title="模型横向对比"></a>模型横向对比</h1><h2 id="XGBoost-1"><a href="#XGBoost-1" class="headerlink" title="XGBoost"></a>XGBoost</h2><ul>
<li><strong>性能：</strong> MSE = 297.33，R2 = 0.9586  </li>
<li><strong>特征重要性：</strong> 电视 &gt; 广播 &gt; 报纸  </li>
<li><strong>特点：</strong><ul>
<li>作为 Boosting 模型，它在处理非线性关系和特征交互方面很强 能较好地拟合广告投入与收益的关系</li>
<li>由于数据集相对简单（变量少，关系较直观） XGBoost 表现稳定但没有压倒性优势</li>
<li>新增的“报纸_is_outlier”特征完全无效 说明模型能自动忽略无信息量的特征 避免过拟合</li>
</ul>
</li>
</ul>
<h2 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h2><ul>
<li><strong>性能：</strong> MSE = 308.58，R2 = 0.9570  </li>
<li><strong>特征重要性：</strong> 广播 ≈ 电视 ≈ 报纸（几乎持平）  </li>
<li><strong>特点：</strong><ul>
<li>LightGBM 与 XGBoost 同属 Boosting 系列 但它采用了基于直方图的分裂方式，更适合高维稀疏特征</li>
<li>在这个小数据集上 优势不明显 反而略逊于 XGBoost</li>
<li>特征重要性差别不大 说明 LightGBM 在分裂时对每个特征都较平均地利用 但这可能导致它对真实最关键的“电视”变量抓取力度稍弱</li>
</ul>
</li>
</ul>
<h2 id="随机森林-1"><a href="#随机森林-1" class="headerlink" title="随机森林"></a>随机森林</h2><ul>
<li><strong>性能：</strong> MSE = 277.82，R2 = 0.9613</li>
<li><strong>特征重要性：</strong> 电视 &gt; 广播 &gt; 报纸  </li>
<li><strong>特点：</strong><ul>
<li>Bagging 思路 适合低维小数据 能降低方差、提高稳定性</li>
<li>在广告收益数据集中 投入与收益的关系并不复杂 因此随机森林可以在不需要 Boosting 那种强烈逐步修正的情况下 直接通过平均化结果取得最优表现</li>
<li>树模型捕捉到了 “电视广告” 的关键作用</li>
</ul>
</li>
</ul>
<h2 id="SVM-1"><a href="#SVM-1" class="headerlink" title="SVM"></a>SVM</h2><ul>
<li><strong>性能：</strong> MSE = 2942.23，R2 = 0.5904</li>
<li><strong>特点：</strong><ul>
<li>默认参数的 SVR（核函数 RBF，C=1）不适合这种回归任务。它需要仔细调参（C、γ、ε）才能拟合非线性关系</li>
<li>数据集维度很低（只有 3 个主要特征） 而 SVR 在小样本、复杂边界时更有优势 但这里的关系接近线性 SVR 没有优势。</li>
<li>因此在这个广告收益场景中 SVR 明显欠拟合</li>
</ul>
</li>
</ul>
<h2 id="KNN-1"><a href="#KNN-1" class="headerlink" title="KNN"></a>KNN</h2><ul>
<li><strong>性能：</strong> MSE = 423.61，R2 = 0.9410</li>
<li><strong>特点：</strong><ul>
<li>基于邻居的局部平均方法 效果依赖样本分布和邻居数 k</li>
<li>在数据集较小、关系清晰时 KNN 能捕捉到一定趋势 但预测平滑化严重</li>
<li>所以它的表现比树模型差 但仍然比 SVR 稳定</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>模型</th>
<th>MSE</th>
<th>R2</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>随机森林</td>
<td>277.82</td>
<td>0.9613</td>
<td>Bagging 模型，抗过拟合强，最适合此数据集</td>
</tr>
<tr>
<td>XGBoost</td>
<td>297.33</td>
<td>0.9586</td>
<td>Boosting 思路，拟合能力强，但未明显优于RF</td>
</tr>
<tr>
<td>LightGBM</td>
<td>308.58</td>
<td>0.9570</td>
<td>与XGB接近，小数据集不占优</td>
</tr>
<tr>
<td>KNN</td>
<td>423.61</td>
<td>0.9410</td>
<td>捕捉趋势，但预测过于平滑</td>
</tr>
<tr>
<td>SVR</td>
<td>2942.23</td>
<td>0.5904</td>
<td>默认参数欠拟合，不适合本任务</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>结论：</strong>  </p>
<ul>
<li>广告收益预测是一个低维、非极复杂的回归问题，<strong>随机森林表现最佳</strong>。  </li>
<li><strong>Boosting 系列（XGBoost / LightGBM）</strong> 在特征复杂、数据量大时会更有优势。  </li>
<li><strong>SVR 和 KNN</strong> 更适合特定场景，这里表现不佳。</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>RGB灯光与OLED显示</title>
    <url>/zhihaojiang.github.io/2025/09/28/20250928RGB%E7%81%AF%E5%85%89%E4%B8%8EOLED%E6%98%BE%E7%A4%BA/</url>
    <content><![CDATA[<h2 id="开发板"><a href="#开发板" class="headerlink" title="开发板"></a>开发板</h2><p>Arduino UNO R3</p>
<h2 id="接线"><a href="#接线" class="headerlink" title="接线"></a>接线</h2><p><strong>共阴极RGB灯组</strong></p>
<blockquote>
<p>R → D9<br>G → D10<br>B → D11<br>GND → GND</p>
</blockquote>
<p><strong>OLED (SSD1306 I2C)</strong></p>
<blockquote>
<p>VCC → 3.3V 或 5V<br>GND → GND<br>SCL → A5<br>SDA → A4</p>
</blockquote>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#include &lt;Wire.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;Adafruit_GFX.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;Adafruit_SSD1306.h&gt;</span></span><br><span class="line"></span><br><span class="line">// OLED 屏幕分辨率</span><br><span class="line"><span class="comment">#define SCREEN_WIDTH 128</span></span><br><span class="line"><span class="comment">#define SCREEN_HEIGHT 64</span></span><br><span class="line">Adafruit_SSD1306 display(SCREEN_WIDTH, SCREEN_HEIGHT, &amp;Wire, -1);</span><br><span class="line"></span><br><span class="line">// RGB 引脚</span><br><span class="line">const int redPin = 9;</span><br><span class="line">const int greenPin = 10;</span><br><span class="line">const int bluePin = 11;</span><br><span class="line"></span><br><span class="line">void <span class="function"><span class="title">setup</span></span>() &#123;</span><br><span class="line">  // 初始化 RGB 引脚</span><br><span class="line">  pinMode(redPin, OUTPUT);</span><br><span class="line">  pinMode(greenPin, OUTPUT);</span><br><span class="line">  pinMode(bluePin, OUTPUT);</span><br><span class="line"></span><br><span class="line">  // 初始化 OLED</span><br><span class="line">  <span class="keyword">if</span> (!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) &#123; // 0x3C 是常见地址</span><br><span class="line">    <span class="keyword">for</span> (;;); // 如果初始化失败就卡住</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  display.clearDisplay();</span><br><span class="line">  display.setTextSize(2);      // 字体大小</span><br><span class="line">  display.setTextColor(SSD1306_WHITE);</span><br><span class="line">  display.setCursor(0, 0);</span><br><span class="line">  display.println(<span class="string">&quot;RGB TEST&quot;</span>);</span><br><span class="line">  display.display();</span><br><span class="line">  delay(1000);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void <span class="function"><span class="title">loop</span></span>() &#123;</span><br><span class="line">  // 红色</span><br><span class="line">  setColor(HIGH, LOW, LOW);</span><br><span class="line">  showText(<span class="string">&quot;RED&quot;</span>);</span><br><span class="line">  delay(1000);</span><br><span class="line"></span><br><span class="line">  // 绿色</span><br><span class="line">  setColor(LOW, HIGH, LOW);</span><br><span class="line">  showText(<span class="string">&quot;GREEN&quot;</span>);</span><br><span class="line">  delay(1000);</span><br><span class="line"></span><br><span class="line">  // 蓝色</span><br><span class="line">  setColor(LOW, LOW, HIGH);</span><br><span class="line">  showText(<span class="string">&quot;BLUE&quot;</span>);</span><br><span class="line">  delay(1000);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 控制 RGB 灯亮灭</span><br><span class="line">void setColor(int r, int g, int b) &#123;</span><br><span class="line">  digitalWrite(redPin, r);</span><br><span class="line">  digitalWrite(greenPin, g);</span><br><span class="line">  digitalWrite(bluePin, b);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// OLED 显示文字</span><br><span class="line">void showText(const char *text) &#123;</span><br><span class="line">  display.clearDisplay();</span><br><span class="line">  display.setCursor(0, 20);</span><br><span class="line">  display.println(text);</span><br><span class="line">  display.display();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--信用评分卡模型</title>
    <url>/zhihaojiang.github.io/2025/09/28/20250928%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%BF%A1%E7%94%A8%E8%AF%84%E5%88%86%E5%8D%A1%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'信用评分卡模型.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>月收入</th>
<th>年龄</th>
<th>性别</th>
<th>历史授信额度</th>
<th>历史违约次数</th>
<th>信用评分</th>
</tr>
</thead>
<tbody><tr>
<td>7783</td>
<td>29</td>
<td>0</td>
<td>32274</td>
<td>3</td>
<td>73</td>
</tr>
<tr>
<td>7836</td>
<td>40</td>
<td>1</td>
<td>6681</td>
<td>4</td>
<td>72</td>
</tr>
<tr>
<td>6398</td>
<td>25</td>
<td>0</td>
<td>26038</td>
<td>2</td>
<td>74</td>
</tr>
<tr>
<td>6483</td>
<td>23</td>
<td>1</td>
<td>24584</td>
<td>4</td>
<td>65</td>
</tr>
<tr>
<td>5167</td>
<td>23</td>
<td>1</td>
<td>6710</td>
<td>3</td>
<td>73</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>字段</th>
<th>缺失值数量</th>
</tr>
</thead>
<tbody><tr>
<td>月收入</td>
<td>0</td>
</tr>
<tr>
<td>年龄</td>
<td>0</td>
</tr>
<tr>
<td>性别</td>
<td>0</td>
</tr>
<tr>
<td>历史授信额度</td>
<td>0</td>
</tr>
<tr>
<td>历史违约次数</td>
<td>0</td>
</tr>
<tr>
<td>信用评分</td>
<td>0</td>
</tr>
</tbody></table>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/001.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/002.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/003.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/004.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/005.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/006.png" alt="photo"></p>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X = df.drop(columns=[<span class="string">'信用评分'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'信用评分'</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line"></span><br><span class="line">xgb = XGBRegressor(objective=<span class="string">'reg:squarederror'</span>, random_state=42)</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred = xgb.predict(X_test)</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Mean Squared Error: {mse}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'R^2 Score: {r2}'</span>)</span><br></pre></td></tr></table></figure></div>
<p>Mean Squared Error: 30.737820683092288<br>R^2 Score: 0.5528881678156692</p>
<h2 id="网格优化"><a href="#网格优化" class="headerlink" title="网格优化"></a>网格优化</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV  </span><br><span class="line">parameters = {<span class="string">'max_depth'</span>: [1, 3, 5], <span class="string">'n_estimators'</span>: [50, 100, 150], <span class="string">'learning_rate'</span>: [0.01, 0.05, 0.1, 0.2]}  <span class="comment"># 指定模型中参数的范围</span></span><br><span class="line">xgb_best = XGBRegressor()</span><br><span class="line">grid_search = GridSearchCV(xgb_best, parameters, cv=5, scoring=<span class="string">'neg_mean_squared_error'</span>)  <span class="comment"># 5折交叉验证</span></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Best parameters:"</span>, grid_search.best_params_)</span><br><span class="line"></span><br><span class="line">best_xgb = grid_search.best_estimator_</span><br><span class="line">y_pred_best = best_xgb.predict(X_test)</span><br><span class="line">mse_best = mean_squared_error(y_test, y_pred_best)</span><br><span class="line">r2_best = r2_score(y_test, y_pred_best)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Optimized Mean Squared Error: {mse_best}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Optimized R^2 Score: {r2_best}'</span>)</span><br></pre></td></tr></table></figure></div>
<p>Best parameters: {‘learning_rate’: 0.05, ‘max_depth’: 3, ‘n_estimators’: 50}</p>
<p>Optimized Mean Squared Error: 22.005304773406532<br>Optimized R^2 Score: 0.6799112000668165</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">feature_importances = best_xgb.feature_importances_</span><br><span class="line">features = X.columns</span><br><span class="line">importance_df = pd.DataFrame({<span class="string">'Feature'</span>: features, <span class="string">'Importance'</span>: feature_importances})</span><br><span class="line">importance_df.sort_values(by=<span class="string">'Importance'</span>, ascending=False, inplace=True)</span><br><span class="line">importance_df</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import shap</span><br><span class="line">explainer = shap.Explainer(best_xgb)</span><br><span class="line">shap_values = explainer(X)</span><br><span class="line">shap.summary_plot(shap_values, X)</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/007.png" alt="photo"></p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">lgbm = LGBMRegressor(random_state=42)</span><br><span class="line">lgbm.fit(X_train, y_train)</span><br><span class="line">y_pred_lgbm = lgbm.predict(X_test)</span><br><span class="line">mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)</span><br><span class="line">r2_lgbm = r2_score(y_test, y_pred_lgbm)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'LightGBM Mean Squared Error: {mse_lgbm}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'LightGBM R^2 Score: {r2_lgbm}'</span>)</span><br><span class="line"></span><br><span class="line">feature_importances_lgbm = lgbm.feature_importances_</span><br><span class="line">features = X.columns</span><br><span class="line">importance_df_lgbm = pd.DataFrame({<span class="string">'Feature'</span>: features, <span class="string">'Importance'</span>: feature_importances_lgbm})</span><br><span class="line">importance_df_lgbm.sort_values(by=<span class="string">'Importance'</span>, ascending=False, inplace=True)</span><br><span class="line">importance_df_lgbm</span><br><span class="line"></span><br><span class="line">explainer = shap.Explainer(lgbm)</span><br><span class="line">shap_values = explainer(X)</span><br><span class="line">shap.summary_plot(shap_values, X)</span><br></pre></td></tr></table></figure></div>
<p>LightGBM Mean Squared Error: 25.26260176146583<br>LightGBM R^2 Score: 0.6325306118554737</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/008.png" alt="photo"></p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestRegressor(random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">y_pred_rm = rm.predict(X_test)</span><br><span class="line">mse_rm = mean_squared_error(y_test, y_pred_rm)</span><br><span class="line">r2_rm = r2_score(y_test, y_pred_rm)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Random Forest Mean Squared Error: {mse_rm}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Random Forest R^2 Score: {r2_rm}'</span>)</span><br><span class="line"></span><br><span class="line">feature_importances_rm = rm.feature_importances_</span><br><span class="line">features = X.columns</span><br><span class="line">importance_df_rm = pd.DataFrame({<span class="string">'Feature'</span>: features, <span class="string">'Importance'</span>: feature_importances_rm})</span><br><span class="line">importance_df_rm.sort_values(by=<span class="string">'Importance'</span>, ascending=False, inplace=True)</span><br><span class="line">importance_df_rm</span><br><span class="line"></span><br><span class="line">explainer = shap.Explainer(<span class="built_in">rm</span>)</span><br><span class="line">shap_values = explainer(X)</span><br><span class="line">shap.summary_plot(shap_values, X)</span><br></pre></td></tr></table></figure></div>
<p>Random Forest Mean Squared Error: 22.497981999999997<br>Random Forest R^2 Score: 0.6727447252627369</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/28/009.png" alt="photo"></p>
<h1 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.discriminant_analysis import LinearDiscriminantAnalysis</span><br><span class="line"></span><br><span class="line">lda = LinearDiscriminantAnalysis()</span><br><span class="line">lda.fit(X_train, y_train)</span><br><span class="line">y_pred_lda = lda.predict(X_test)</span><br><span class="line">mse_lda = mean_squared_error(y_test, y_pred_lda)</span><br><span class="line">r2_lda = r2_score(y_test, y_pred_lda)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Linear Discriminant Analysis Mean Squared Error: {mse_lda}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'Linear Discriminant Analysis R^2 Score: {r2_lda}'</span>)</span><br><span class="line"></span><br><span class="line">feature_importances_lda = lda.coef_[0]</span><br><span class="line">features = X.columns</span><br><span class="line">importance_df_lda = pd.DataFrame({<span class="string">'Feature'</span>: features, <span class="string">'Importance'</span>: feature_importances_lda})</span><br><span class="line">importance_df_lda.sort_values(by=<span class="string">'Importance'</span>, ascending=False, inplace=True)</span><br><span class="line">importance_df_lda</span><br></pre></td></tr></table></figure></div>
<p>Linear Discriminant Analysis Mean Squared Error: 30.66<br>Linear Discriminant Analysis R^2 Score: 0.5540201461871341</p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=5)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred_knn = knn.predict(X_test)</span><br><span class="line">mse_knn = mean_squared_error(y_test, y_pred_knn)</span><br><span class="line">r2_knn = r2_score(y_test, y_pred_knn)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'KNN Mean Squared Error: {mse_knn}'</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">'KNN R^2 Score: {r2_knn}'</span>)</span><br></pre></td></tr></table></figure></div>
<p>KNN Mean Squared Error: 25.003800000000002<br>KNN R^2 Score: 0.6362951380050184</p>
<h1 id="模型横向比较"><a href="#模型横向比较" class="headerlink" title="模型横向比较"></a>模型横向比较</h1><table>
<thead>
<tr>
<th>模型</th>
<th>MSE ↓</th>
<th>R² ↑</th>
<th>特点总结</th>
</tr>
</thead>
<tbody><tr>
<td>XGBoost (优化后)</td>
<td>22.01</td>
<td>0.680</td>
<td>树模型，调参后效果最好之一，兼顾偏差与方差，特征重要性可解释性强。</td>
</tr>
<tr>
<td>LightGBM</td>
<td>25.26</td>
<td>0.633</td>
<td>与XGBoost类似，但默认参数下稍逊，可能因数据量不大导致优势未显现。</td>
</tr>
<tr>
<td>随机森林</td>
<td>22.50</td>
<td>0.673</td>
<td>稳定性高，效果接近XGBoost，调参空间不如Boosting大。</td>
</tr>
<tr>
<td>LDA</td>
<td>30.66</td>
<td>0.554</td>
<td>线性判别方法，更适合分类；在回归任务上受限，表现最差。</td>
</tr>
<tr>
<td>KNN</td>
<td>25.00</td>
<td>0.636</td>
<td>简单直观，依赖局部邻域；在高维数据中容易过拟合或欠拟合。</td>
</tr>
</tbody></table>
<h2 id="差异分析"><a href="#差异分析" class="headerlink" title="差异分析"></a>差异分析</h2><ol>
<li><p><strong>树模型（XGBoost / LightGBM / 随机森林）表现最佳</strong>  </p>
<ul>
<li>它们能捕捉非线性关系，适合处理信用评分这类复杂特征交互的任务。  </li>
<li><strong>XGBoost 调参后效果最好（R²≈0.68）</strong>，说明该数据集对树模型的适配性很好。  </li>
<li><strong>随机森林 与 XGBoost 表现接近</strong>，但略逊，因为 Boosting 更好地优化了偏差。  </li>
<li><strong>LightGBM</strong> 在大数据下优势明显，但在你这种数据量（200左右样本）下未完全发挥。</li>
</ul>
</li>
<li><p><strong>线性方法（LDA）表现最差</strong>  </p>
<ul>
<li>信用评分与特征之间关系并非单纯线性，导致 LDA 只能捕捉有限信息。  </li>
<li>R²≈0.55，MSE最大，说明解释力有限。</li>
</ul>
</li>
<li><p><strong>KNN 居中但不稳定</strong>  </p>
<ul>
<li>表现优于 LDA，但不如树模型。  </li>
<li>优点是简单、无需训练；缺点是容易受到特征尺度影响，且在高维空间中“邻近”的意义变弱。</li>
</ul>
</li>
</ol>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li><strong>最佳模型推荐：XGBoost（调参后）</strong><br>兼具预测准确性和可解释性，适合在信用评分建模中作为主力模型。  </li>
<li><strong>随机森林</strong> 可作为备选基准模型，在稳定性上更强，但可解释性略弱。  </li>
<li><strong>LightGBM</strong> 如果数据规模增大 可能会超过XGBoost。  </li>
<li><strong>LDA 和 KNN</strong> 更适合作为参考或对比，实际预测能力有限。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--数据预处理&amp;特征工程</title>
    <url>/zhihaojiang.github.io/2025/09/29/20250929%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86&amp;%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>查看第10章的代码 发现其主要是特征工程与数据预处理的代码 因此本章主要罗列各种特征工程与数据预处理的方法</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'股票客户流失.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>账户资金（元）</th>
<th>最后一次交易距今时间（天）</th>
<th>上月交易佣金（元）</th>
<th>本券商使用时长（年）</th>
<th>是否流失</th>
</tr>
</thead>
<tbody><tr>
<td>22686.5</td>
<td>297</td>
<td>149.25</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>190055.0</td>
<td>42</td>
<td>284.75</td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td>29733.5</td>
<td>233</td>
<td>269.25</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>185667.5</td>
<td>44</td>
<td>211.50</td>
<td>3</td>
<td>0</td>
</tr>
<tr>
<td>33648.5</td>
<td>213</td>
<td>353.50</td>
<td>0</td>
<td>1</td>
</tr>
</tbody></table>
<h1 id="查看数据分布"><a href="#查看数据分布" class="headerlink" title="查看数据分布"></a>查看数据分布</h1><p><strong>热力图</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line">sns.heatmap(df.corr(), annot=True, cmap=<span class="string">'YlGnBu'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/001.png" alt="photo"></p>
<p><strong>直方图和QQ图</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy import stats</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.figure(figsize=(12, 4))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 直方图 + KDE</span></span><br><span class="line">    plt.subplot(1, 2, 1)</span><br><span class="line">    sns.histplot(<span class="built_in">df</span>[col].dropna(), kde=True, bins=30)</span><br><span class="line">    plt.title(f<span class="string">'{col} 分布'</span>)</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">    plt.ylabel(<span class="string">'Frequency'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># QQ图</span></span><br><span class="line">    plt.subplot(1, 2, 2)</span><br><span class="line">    stats.probplot(<span class="built_in">df</span>[col].dropna(), dist=<span class="string">"norm"</span>, plot=plt)</span><br><span class="line">    plt.title(f<span class="string">'{col} QQ 图'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/002.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/003.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/004.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/005.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/006.png" alt="photo"></p>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><p>首先查看是否存在缺失值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<h2 id="删除缺失值"><a href="#删除缺失值" class="headerlink" title="删除缺失值"></a>删除缺失值</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方法1 删除缺失率 &gt; 50% 的列</span></span><br><span class="line">df.dropna(thresh=len(<span class="built_in">df</span>)*0.5, axis=1, inplace=True)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法2 删除含缺失的行</span></span><br><span class="line">df.dropna(inplace=True)</span><br></pre></td></tr></table></figure></div>

<h2 id="简单填充缺失值"><a href="#简单填充缺失值" class="headerlink" title="简单填充缺失值"></a>简单填充缺失值</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数值型 中位数或均值填充</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'age'</span>].fillna(<span class="built_in">df</span>[<span class="string">'age'</span>].median(), inplace=True) <span class="comment"># .mean()是均值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 类别型 众数填充</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'gender'</span>].fillna(<span class="built_in">df</span>[<span class="string">'gender'</span>].mode()[0], inplace=True)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者 固定值</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'income'</span>].fillna(-1, inplace=True)  <span class="comment"># -1 表示缺失</span></span><br></pre></td></tr></table></figure></div>

<h2 id="模型填充缺失值"><a href="#模型填充缺失值" class="headerlink" title="模型填充缺失值"></a>模型填充缺失值</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># KNN填充</span></span><br><span class="line">from sklearn.impute import KNNImputer</span><br><span class="line">imputer = KNNImputer(n_neighbors=5)</span><br><span class="line">df_filled = pd.DataFrame(imputer.fit_transform(<span class="built_in">df</span>), columns=df.columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多重插补法</span></span><br><span class="line">from sklearn.experimental import enable_iterative_imputer</span><br><span class="line">from sklearn.impute import IterativeImputer</span><br><span class="line">imp = IterativeImputer(random_state=0)</span><br><span class="line">df_filled = pd.DataFrame(imp.fit_transform(<span class="built_in">df</span>), columns=df.columns)</span><br></pre></td></tr></table></figure></div>

<h2 id="保留缺失值"><a href="#保留缺失值" class="headerlink" title="保留缺失值"></a>保留缺失值</h2><p>缺失值本身可能就是一种信息</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数值型缺失值标记</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'income_missing'</span>] = <span class="built_in">df</span>[<span class="string">'income'</span>].isnull().astype(int)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类别变量可以直接保留为NaN 或替换为 Missing</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'occupation'</span>].fillna(<span class="string">'Missing'</span>, inplace=True)</span><br></pre></td></tr></table></figure></div>

<h2 id="可视化缺失值"><a href="#可视化缺失值" class="headerlink" title="可视化缺失值"></a>可视化缺失值</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import missingno as msno</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵图 查看缺失位置</span></span><br><span class="line">msno.matrix(<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 条形图 各列缺失比例</span></span><br><span class="line">msno.bar(<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 相关性热力图 缺失是否相关</span></span><br><span class="line">msno.heatmap(<span class="built_in">df</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/007.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/008.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/009.png" alt="photo"></p>
<p>热力图是空白的是因为数据集中没有缺失值</p>
<h1 id="异常值检测"><a href="#异常值检测" class="headerlink" title="异常值检测"></a>异常值检测</h1><h2 id="箱线图可视化异常值"><a href="#箱线图可视化异常值" class="headerlink" title="箱线图可视化异常值"></a>箱线图可视化异常值</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/010.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/011.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/012.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/013.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/014.png" alt="photo"></p>
<h2 id="3-Sigma-准则检测"><a href="#3-Sigma-准则检测" class="headerlink" title="3 Sigma 准则检测"></a>3 Sigma 准则检测</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy import stats</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    z_scores = np.abs(stats.zscore(<span class="built_in">df</span>[col].dropna()))</span><br><span class="line">    outliers = <span class="built_in">df</span>[z_scores &gt; 3]</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"列 {col} 中的异常值数量: {len(outliers)}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>列 账户资金（元） 中的异常值数量: 0<br>列 最后一次交易距今时间（天） 中的异常值数量: 0<br>列 上月交易佣金（元） 中的异常值数量: 0<br>列 本券商使用时长（年） 中的异常值数量: 0<br>列 是否流失 中的异常值数量: 0</p>
<h2 id="IQR检测"><a href="#IQR检测" class="headerlink" title="IQR检测"></a>IQR检测</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">    Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line">    lower_bound = Q1 - 1.5 * IQR</span><br><span class="line">    upper_bound = Q3 + 1.5 * IQR</span><br><span class="line"></span><br><span class="line">    outliers = <span class="built_in">df</span>[(<span class="built_in">df</span>[col] &lt; lower_bound) | (<span class="built_in">df</span>[col] &gt; upper_bound)]</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"列 {col} 中的异常值数量: {len(outliers)}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>列 账户资金（元） 中的异常值数量: 0<br>列 最后一次交易距今时间（天） 中的异常值数量: 0<br>列 上月交易佣金（元） 中的异常值数量: 0<br>列 本券商使用时长（年） 中的异常值数量: 0<br>列 是否流失 中的异常值数量: 0</p>
<h2 id="百分位数检测"><a href="#百分位数检测" class="headerlink" title="百分位数检测"></a>百分位数检测</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    lower = <span class="built_in">df</span>[col].quantile(0.01)</span><br><span class="line">    upper = <span class="built_in">df</span>[col].quantile(0.99)</span><br><span class="line">    df_clipped = <span class="built_in">df</span>[(<span class="built_in">df</span>[col] &gt;= lower) &amp; (<span class="built_in">df</span>[col] &lt;= upper)]</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"列 {col} 中的异常值数量: {len(df) - len(df_clipped)}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>列 账户资金（元） 中的异常值数量: 135<br>列 最后一次交易距今时间（天） 中的异常值数量: 66<br>列 上月交易佣金（元） 中的异常值数量: 135<br>列 本券商使用时长（年） 中的异常值数量: 0<br>列 是否流失 中的异常值数量: 0</p>
<h2 id="散点图查看数值型特征之间的关系"><a href="#散点图查看数值型特征之间的关系" class="headerlink" title="散点图查看数值型特征之间的关系"></a>散点图查看数值型特征之间的关系</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter(<span class="built_in">df</span>[<span class="string">'账户资金（元）'</span>], <span class="built_in">df</span>[<span class="string">'最后一次交易距今时间（天）'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/015.png" alt="photo"></p>
<h2 id="孤立森林检测"><a href="#孤立森林检测" class="headerlink" title="孤立森林检测"></a>孤立森林检测</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import IsolationForest</span><br><span class="line">iso = IsolationForest(contamination=0.05)  <span class="comment"># 预估异常比例5%</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'anomaly'</span>] = iso.fit_predict(<span class="built_in">df</span>[[<span class="string">'账户资金（元）'</span>, <span class="string">'最后一次交易距今时间（天）'</span>]])</span><br><span class="line">outliers = <span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">'anomaly'</span>] == -1]</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"检测到的异常值数量: {len(outliers)}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>检测到的异常值数量: 349</p>
<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><h2 id="直接删除"><a href="#直接删除" class="headerlink" title="直接删除"></a>直接删除</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = <span class="built_in">df</span>[~outliers].copy()</span><br></pre></td></tr></table></figure></div>

<h2 id="截断"><a href="#截断" class="headerlink" title="截断"></a>截断</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def winsorize_iqr(<span class="built_in">df</span>, col, <span class="built_in">factor</span>=1.5):</span><br><span class="line">    <span class="string">""</span><span class="string">"用 IQR 边界截断异常值"</span><span class="string">""</span></span><br><span class="line">    Q1 = <span class="built_in">df</span>[col].quantile(0.25)</span><br><span class="line">    Q3 = <span class="built_in">df</span>[col].quantile(0.75)</span><br><span class="line">    IQR = Q3 - Q1</span><br><span class="line">    lower_bound = Q1 - <span class="built_in">factor</span> * IQR</span><br><span class="line">    upper_bound = Q3 + <span class="built_in">factor</span> * IQR</span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">df</span>[col].clip(lower=lower_bound, upper=upper_bound)</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'income_winsorized'</span>] = winsorize_iqr(<span class="built_in">df</span>, <span class="string">'income'</span>, <span class="built_in">factor</span>=3)  <span class="comment"># 3倍IQR</span></span><br></pre></td></tr></table></figure></div>

<h2 id="z-score处理"><a href="#z-score处理" class="headerlink" title="z-score处理"></a>z-score处理</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def detect_outliers_zscore(<span class="built_in">df</span>, col, threshold=3):</span><br><span class="line">    <span class="string">""</span><span class="string">"使用 Z-score 检测异常值"</span><span class="string">""</span></span><br><span class="line">    z_scores = np.abs(stats.zscore(<span class="built_in">df</span>[col].dropna()))</span><br><span class="line">    outlier_mask = np.zeros(len(<span class="built_in">df</span>), dtype=bool)</span><br><span class="line">    outlier_mask[<span class="built_in">df</span>[col].notna()] = z_scores &gt; threshold</span><br><span class="line">    <span class="built_in">return</span> outlier_mask</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若数据是接近正态的 用 Z-score 检测</span></span><br><span class="line">z_outliers = detect_outliers_zscore(<span class="built_in">df</span>, <span class="string">'score'</span>, threshold=3)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'score_clean'</span>] = <span class="built_in">df</span>[<span class="string">'score'</span>].<span class="built_in">where</span>(~z_outliers, <span class="built_in">df</span>[<span class="string">'score'</span>].median())  <span class="comment"># 用中位数填充异常</span></span><br></pre></td></tr></table></figure></div>

<h2 id="对数变换"><a href="#对数变换" class="headerlink" title="对数变换"></a>对数变换</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 仅支持全为整数且右偏的数据</span></span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'账户资金（元）_log'</span>] = np.log1p(<span class="built_in">df</span>[<span class="string">'账户资金（元）'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比</span></span><br><span class="line">plt.figure(figsize=(12, 4))</span><br><span class="line">plt.subplot(1, 2, 1)</span><br><span class="line">sns.histplot(<span class="built_in">df</span>[<span class="string">'账户资金（元）'</span>], kde=True)</span><br><span class="line"></span><br><span class="line">plt.subplot(1, 2, 2)</span><br><span class="line">sns.histplot(<span class="built_in">df</span>[<span class="string">'账户资金（元）_log'</span>], kde=True)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/016.png" alt="photo"></p>
<h2 id="分箱"><a href="#分箱" class="headerlink" title="分箱"></a>分箱</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 等频分箱（Quantile-based），自动处理极端值</span></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'账户资金（元）_binned'</span>] = pd.qcut(<span class="built_in">df</span>[<span class="string">'账户资金（元）'</span>], q=10, duplicates=<span class="string">'drop'</span>)  <span class="comment"># 分10箱</span></span><br><span class="line">sns.countplot(x=<span class="built_in">df</span>[<span class="string">'账户资金（元）_binned'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或自定义边界（把 &gt;200000 的都归为 "High"）</span></span><br><span class="line">bins = [0, 30000, 60000, 100000, np.inf]</span><br><span class="line">labels = [<span class="string">'Low'</span>, <span class="string">'Medium'</span>, <span class="string">'High'</span>, <span class="string">'Very High'</span>]</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'账户资金（元）_group'</span>] = pd.cut(<span class="built_in">df</span>[<span class="string">'账户资金（元）'</span>], bins=bins, labels=labels, include_lowest=True)</span><br><span class="line">sns.countplot(x=<span class="built_in">df</span>[<span class="string">'账户资金（元）_group'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/29/017.png" alt="photo"></p>
<h2 id="保留异常值"><a href="#保留异常值" class="headerlink" title="保留异常值"></a>保留异常值</h2><p>有时候异常值本身就是一种信号 例如借款金额非常大的值</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">'账户资金（元）_is_outlier'</span>] = (<span class="built_in">df</span>[<span class="string">'账户资金（元）'</span>] &gt; 200000).astype(int)</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--人脸识别</title>
    <url>/zhihaojiang.github.io/2025/09/30/20250930%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">names = os.listdir(<span class="string">'olivettifaces'</span>)</span><br><span class="line"></span><br><span class="line">names[0:5]</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">img0 = Image.open(<span class="string">'olivettifaces/'</span> + names[0]) <span class="comment"># MAC或者类unix是用一个斜杠，Windows用两个反斜杠</span></span><br><span class="line">img0.show()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">img0 = img0.convert(<span class="string">'L'</span>)</span><br><span class="line">img0 = img0.resize((<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">arr = np.array(img0)</span><br><span class="line"></span><br><span class="line">arr</span><br></pre></td></tr></table></figure></div>
<p>array([[186,  76,  73, …, 100, 103, 106],<br>       [196,  85,  68, …,  85, 106, 103],<br>       [193,  69,  79, …,  82,  99, 100],<br>       …,<br>       [196,  87, 193, …, 103,  66,  52],<br>       [219, 179, 202, …, 150, 127, 109],<br>       [244, 228, 230, …, 198, 202, 206]], dtype=uint8)</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">pd.DataFrame(arr)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">arr = arr.reshape(1, -1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr)</span><br></pre></td></tr></table></figure></div>
<p>[[186  76  73 … 198 202 206]]</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(arr.flatten().tolist())</span><br></pre></td></tr></table></figure></div>
<p>[186, 76, 73, 87, 89…]</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> names:</span><br><span class="line">    <span class="keyword">if</span> i.startswith(<span class="string">"._"</span>):  <span class="comment"># Mac的隐藏文件 跳过</span></span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    img = Image.open(<span class="string">'olivettifaces/'</span> + i)</span><br><span class="line">    img = img.convert(<span class="string">'L'</span>)</span><br><span class="line">    img = img.resize((<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">    arr = np.array(img)</span><br><span class="line">    X.append(arr.reshape(1, -1).flatten().tolist())</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">X = pd.DataFrame(X)</span><br><span class="line"></span><br><span class="line">X</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(X.shape)</span><br></pre></td></tr></table></figure></div>
<p>(400, 1024)</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(int(names[0].<span class="built_in">split</span>(<span class="string">'_'</span>)[0]))</span><br></pre></td></tr></table></figure></div>
<p>10</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> names:</span><br><span class="line">    <span class="keyword">if</span> i.startswith(<span class="string">"._"</span>):  <span class="comment"># Mac的隐藏文件 跳过</span></span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    img = Image.open(<span class="string">'olivettifaces/'</span> + i)</span><br><span class="line">    y.append(int(i.split(<span class="string">'_'</span>)[0]))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure></div>
<p>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11…]</p>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)</span><br></pre></td></tr></table></figure></div>

<h1 id="PCA降维"><a href="#PCA降维" class="headerlink" title="PCA降维"></a>PCA降维</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">pca = PCA(n_components=100)</span><br><span class="line">pca.fit(X_train)</span><br><span class="line"></span><br><span class="line">X_train_pca = pca.transform(X_train)</span><br><span class="line">X_test_pca = pca.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X_train_pca.shape)</span><br><span class="line"><span class="built_in">print</span>(X_test_pca.shape)</span><br></pre></td></tr></table></figure></div>
<p>(320, 100)<br>(80, 100)</p>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(X_train_pca, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = knn.predict(X_test_pca)</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br><span class="line"></span><br><span class="line">score = knn.score(X_test_pca, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure></div>
<p>0.9125<br>0.9125</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line">y_pred = rm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>0.975</p>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMClassifier</span><br><span class="line"></span><br><span class="line">lgbm = LGBMClassifier(random_state=42)</span><br><span class="line">lgbm.fit(X_train, y_train)</span><br><span class="line">y_pred = lgbm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>0.8875</p>
<h1 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"></span><br><span class="line">nb = GaussianNB()</span><br><span class="line">nb.fit(X_train, y_train)</span><br><span class="line">y_pred = nb.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>0.925</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.svm import SVC</span><br><span class="line"></span><br><span class="line">svm = SVC(random_state=42)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line">y_pred = svm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>
<p>0.95</p>
<h1 id="模型横向对比"><a href="#模型横向对比" class="headerlink" title="模型横向对比"></a>模型横向对比</h1><table>
<thead>
<tr>
<th>模型</th>
<th>特点</th>
<th>是否降维</th>
<th>测试准确率</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>KNN</td>
<td>基于邻近样本投票</td>
<td>✔ (PCA → 100维)</td>
<td>0.9125</td>
<td>简单直观，效果较好</td>
<td>预测时计算量大，对高维数据敏感</td>
</tr>
<tr>
<td>随机森林</td>
<td>多棵决策树投票</td>
<td>✘ (原始 1024维)</td>
<td>0.9750</td>
<td>精度高，抗过拟合，特征重要性可解释</td>
<td>训练速度较慢，模型体积较大</td>
</tr>
<tr>
<td>LightGBM</td>
<td>基于梯度提升的树模型</td>
<td>✘ (原始 1024维)</td>
<td>0.8875</td>
<td>训练预测快，适合大规模数据</td>
<td>在小数据集上易过拟合或欠拟合</td>
</tr>
<tr>
<td>朴素贝叶斯 (GaussianNB)</td>
<td>基于概率的生成模型</td>
<td>✘</td>
<td>0.9250</td>
<td>简单快速，鲁棒性好</td>
<td>特征独立性假设过强，可能丢失信息</td>
</tr>
<tr>
<td>SVM (RBF kernel)</td>
<td>最大化间隔的判别模型</td>
<td>✘</td>
<td>0.9500</td>
<td>对高维小样本表现好，分类边界清晰</td>
<td>参数调优敏感，计算复杂度高</td>
</tr>
</tbody></table>
<h2 id="综合结论"><a href="#综合结论" class="headerlink" title="综合结论"></a>综合结论</h2><ul>
<li><strong>最优结果：随机森林 (97.5%)</strong> 在未降维的高维特征下表现最好。  </li>
<li><strong>次优结果：SVM (95%)</strong> 适合这种小样本高维特征的分类。  </li>
<li><strong>轻量方案：朴素贝叶斯 (92.5%)</strong> 简单快速，适合 baseline。  </li>
<li><strong>KNN (91.25%)</strong> 降维后效果不错，但预测效率差。  </li>
<li><strong>LightGBM (88.75%)</strong> 对小样本不够稳定，不如 RF/SVM。</li>
</ul>
<blockquote>
<ul>
<li>推荐 <strong>随机森林 / SVM</strong>，它们在小样本情况下表现最稳。  </li>
<li>如果需要实时性和轻量，可以考虑 <strong>朴素贝叶斯 + PCA</strong>。</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--信用卡数据</title>
    <url>/zhihaojiang.github.io/2025/09/30/20250930%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'信用卡数据.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>编号</th>
<th>年龄</th>
<th>负债比率</th>
<th>月收入</th>
<th>贷款数量</th>
<th>家属人数</th>
<th>分类</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>29</td>
<td>0.22</td>
<td>7800</td>
<td>1</td>
<td>3</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>52</td>
<td>0.46</td>
<td>4650</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>28</td>
<td>0.10</td>
<td>3000</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>29</td>
<td>0.20</td>
<td>5916</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>5</td>
<td>27</td>
<td>1.28</td>
<td>1300</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody></table>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<h1 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h1><h2 id="查看异常值"><a href="#查看异常值" class="headerlink" title="查看异常值"></a>查看异常值</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[col])</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/001.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/002.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/003.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/004.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/005.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/006.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/007.png" alt="photo"></p>
<h2 id="查看数据分布"><a href="#查看数据分布" class="headerlink" title="查看数据分布"></a>查看数据分布</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy import stats</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    plt.figure(figsize=(12, 4))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 直方图 + KDE</span></span><br><span class="line">    plt.subplot(1, 2, 1)</span><br><span class="line">    sns.histplot(<span class="built_in">df</span>[col].dropna(), kde=True, bins=30)</span><br><span class="line">    plt.title(f<span class="string">'{col} 分布'</span>)</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">    plt.ylabel(<span class="string">'Frequency'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># QQ图</span></span><br><span class="line">    plt.subplot(1, 2, 2)</span><br><span class="line">    stats.probplot(<span class="built_in">df</span>[col].dropna(), dist=<span class="string">"norm"</span>, plot=plt)</span><br><span class="line">    plt.title(f<span class="string">'{col} QQ 图'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/008.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/009.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/010.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/011.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/012.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/013.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/014.png" alt="photo"></p>
<p>查看数据可知 数据存在异常值 查看数据分布得知 数据是长尾分布 并且目标的数据是不平衡的数据集</p>
<h2 id="对数变换"><a href="#对数变换" class="headerlink" title="对数变换"></a>对数变换</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line">cols = [<span class="string">'负债比率'</span>, <span class="string">'月收入'</span>, <span class="string">'贷款数量'</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">    <span class="built_in">df</span>[col+<span class="string">'_log'</span>] = np.log1p(<span class="built_in">df</span>[col])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对比</span></span><br><span class="line">    plt.figure(figsize=(12, 4))</span><br><span class="line">    plt.subplot(1, 2, 1)</span><br><span class="line">    sns.histplot(<span class="built_in">df</span>[col], kde=True)</span><br><span class="line"></span><br><span class="line">    plt.subplot(1, 2, 2)</span><br><span class="line">    sns.histplot(<span class="built_in">df</span>[col+<span class="string">'_log'</span>], kde=True)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/015.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/016.png" alt="photo"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/09/30/017.png" alt="photo"></p>
<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = df.drop(columns=[<span class="string">'负债比率'</span>, <span class="string">'月收入'</span>, <span class="string">'贷款数量'</span>])</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=[<span class="string">'分类'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'分类'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> = RandomForestClassifier(random_state=42)</span><br><span class="line">rm.fit(X_train, y_train)</span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line">y_pred = rm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>200</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>20</td>
<td>0</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.91</td>
<td>1.00</td>
<td>0.95</td>
<td>200</td>
</tr>
<tr>
<td>1</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>20</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>220</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.45</td>
<td>0.50</td>
<td>0.48</td>
<td>220</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.91</td>
<td>0.87</td>
<td>220</td>
</tr>
</tbody></table>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb = XGBClassifier(random_state=42)</span><br><span class="line">xgb.fit(X_train, y_train)</span><br><span class="line">y_pred = xgb.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>197</td>
<td>3</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>19</td>
<td>1</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.91</td>
<td>0.98</td>
<td>0.95</td>
<td>200</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.05</td>
<td>0.08</td>
<td>20</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.90</strong></td>
<td>220</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.58</td>
<td>0.52</td>
<td>0.52</td>
<td>220</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.85</td>
<td>0.90</td>
<td>0.87</td>
<td>220</td>
</tr>
</tbody></table>
<h1 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from lightgbm import LGBMClassifier</span><br><span class="line"></span><br><span class="line">lgbm = LGBMClassifier(random_state=42)</span><br><span class="line">lgbm.fit(X_train, y_train)</span><br><span class="line">y_pred = lgbm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>197</td>
<td>3</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>20</td>
<td>0</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.91</td>
<td>0.98</td>
<td>0.94</td>
<td>200</td>
</tr>
<tr>
<td>1</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>20</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.90</strong></td>
<td>220</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.45</td>
<td>0.49</td>
<td>0.47</td>
<td>220</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.90</td>
<td>0.86</td>
<td>220</td>
</tr>
</tbody></table>
<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=5)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>197</td>
<td>3</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>20</td>
<td>0</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.91</td>
<td>0.98</td>
<td>0.94</td>
<td>200</td>
</tr>
<tr>
<td>1</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>20</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.90</strong></td>
<td>220</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.45</td>
<td>0.49</td>
<td>0.47</td>
<td>220</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.90</td>
<td>0.86</td>
<td>220</td>
</tr>
</tbody></table>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.svm import SVC</span><br><span class="line"></span><br><span class="line">svm = SVC(kernel=<span class="string">'linear'</span>)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line">y_pred = svm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>实际 \ 预测</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>200</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>20</td>
<td>0</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>类别</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.91</td>
<td>1.00</td>
<td>0.95</td>
<td>200</td>
</tr>
<tr>
<td>1</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>20</td>
</tr>
<tr>
<td><strong>accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.91</strong></td>
<td>220</td>
</tr>
<tr>
<td><strong>macro avg</strong></td>
<td>0.45</td>
<td>0.50</td>
<td>0.48</td>
<td>220</td>
</tr>
<tr>
<td><strong>weighted avg</strong></td>
<td>0.83</td>
<td>0.91</td>
<td>0.87</td>
<td>220</td>
</tr>
</tbody></table>
<h1 id="模型横向比较"><a href="#模型横向比较" class="headerlink" title="模型横向比较"></a>模型横向比较</h1><table>
<thead>
<tr>
<th>模型</th>
<th>Accuracy</th>
<th>Recall(类别1)</th>
<th>Precision(类别1)</th>
<th>主要问题</th>
</tr>
</thead>
<tbody><tr>
<td>随机森林</td>
<td>0.91</td>
<td>0.00</td>
<td>0.00</td>
<td>完全没预测出类别1</td>
</tr>
<tr>
<td>XGBoost</td>
<td>0.90</td>
<td>0.05</td>
<td>0.25</td>
<td>能预测到1个类别1，但严重偏向类别0</td>
</tr>
<tr>
<td>LightGBM</td>
<td>0.90</td>
<td>0.00</td>
<td>0.00</td>
<td>和随机森林类似，类别1全漏掉</td>
</tr>
<tr>
<td>KNN</td>
<td>0.90</td>
<td>0.00</td>
<td>0.00</td>
<td>全部预测为类别0</td>
</tr>
<tr>
<td>SVM (线性核)</td>
<td>0.91</td>
<td>0.00</td>
<td>0.00</td>
<td>完全没识别类别1</td>
</tr>
</tbody></table>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><ol>
<li><p><strong>总体表现</strong>  </p>
<ul>
<li>所有模型在 <strong>总体准确率 (accuracy ~0.90–0.91)</strong> 上看似不错，但这主要来自于对 <strong>类别0</strong> 的正确预测。  </li>
<li><strong>类别1（少数类）几乎完全无法识别，F1=0。</strong></li>
</ul>
</li>
<li><p><strong>类别分布极度不均衡</strong>  </p>
<ul>
<li>从混淆矩阵看，真实标签中类别1只有20个（占比 &lt; 10%）。  </li>
<li>模型都选择了“保守预测类别0”，因为这样可以最小化整体错误率。</li>
</ul>
</li>
<li><p><strong>XGBoost 稍微好一些</strong>  </p>
<ul>
<li>至少捕捉到了1个类别1（recall=0.05），但 precision 很低（0.25），说明模型在识别少数类上还是力不从心。</li>
</ul>
</li>
</ol>
<h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><p>要解决“类别1完全被忽视”的问题，可以尝试以下方法：</p>
<ol>
<li><p><strong>数据层面</strong>  </p>
<ul>
<li><strong>过采样少数类</strong>：用 SMOTE 等方法扩充类别1。  </li>
<li><strong>欠采样多数类</strong>：平衡正负样本。  </li>
<li><strong>组合方法</strong>：如 SMOTEENN（过采样+清理噪声）。</li>
</ul>
</li>
<li><p><strong>模型层面</strong>  </p>
<ul>
<li><strong>类别权重调整</strong>：在 <code>RandomForestClassifier</code>、<code>XGBClassifier</code>、<code>LGBMClassifier</code>、<code>SVC</code> 中都可以加 <code>class_weight='balanced'</code> 或手动设置 <code>{0:1, 1:10}</code> 类似的比例。  </li>
<li><strong>调节阈值</strong>：现在默认阈值是 0.5，可以通过 ROC/PR 曲线选择更适合的阈值，提高对少数类的 recall。  </li>
<li><strong>专门针对不平衡的算法</strong>：比如 <code>BalancedRandomForest</code>、<code>EasyEnsemble</code>、<code>CatBoost</code>（支持内置类别平衡）。</li>
</ul>
</li>
<li><p><strong>评价指标改进</strong>  </p>
<ul>
<li>不要只看 accuracy，更适合看 <strong>Recall/F1-score（尤其是少数类）</strong> 或 <strong>AUC-ROC / AUC-PR</strong>。</li>
</ul>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>目前模型对多数类预测很好，但由于样本严重不平衡，<strong>少数类（类别1）几乎被完全忽略</strong>。你需要通过 <strong>采样方法 + 类别权重 + 阈值调整</strong> 来改善模型对类别1的识别。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--新闻</title>
    <url>/zhihaojiang.github.io/2025/09/30/20250930%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E6%96%B0%E9%97%BB/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'新闻.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>关键词</th>
<th>标题</th>
<th>网址</th>
<th>来源</th>
<th>时间</th>
</tr>
</thead>
<tbody><tr>
<td>华能信托</td>
<td>信托公司2019年上半年经营业绩概览</td>
<td><a class="link" href="http://www.financialnews.com.cn/jrsb_m/xt/zx/2">http://www.financialnews.com.cn/jrsb_m/xt/zx/2<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>…</td>
<td>中国金融新闻网</td>
<td>2019年07月23日 00:00</td>
</tr>
<tr>
<td>华能信托</td>
<td>首单信托型企业ABS获批</td>
<td><a class="link" href="http://www.jjckb.cn/2018-10/23/c_137552198.htm">http://www.jjckb.cn/2018-10/23/c_137552198.htm<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></td>
<td>经济参考网</td>
<td>2018年10月23日 12:21</td>
</tr>
<tr>
<td>华能信托</td>
<td>华能贵诚信托孙磊:金融科技助力打造开放信托生态</td>
<td><a class="link" href="https://baijiahao.baidu.com/s?id=1639276579449">https://baijiahao.baidu.com/s?id=1639276579449<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>…</td>
<td>同花顺财经</td>
<td>2019年07月17日 10:49</td>
</tr>
<tr>
<td>华能信托</td>
<td>华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施</td>
<td><a class="link" href="https://finance.qq.com/a/20190716/007898.htm">https://finance.qq.com/a/20190716/007898.htm<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></td>
<td>腾讯财经</td>
<td>2019年07月16日 18:53</td>
</tr>
<tr>
<td>华能信托</td>
<td>格力电器股权转让意向方闭门开会 华能信托赫然在列</td>
<td><a class="link" href="https://finance.sina.com.cn/trust/roll/2019-05">https://finance.sina.com.cn/trust/roll/2019-05<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>…</td>
<td>新浪</td>
<td>2019年05月22日 22:53</td>
</tr>
</tbody></table>
<h1 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">words = []</span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    words.append(<span class="string">' '</span>.<span class="built_in">join</span>(jieba.cut(row[<span class="string">'标题'</span>])))</span><br></pre></td></tr></table></figure></div>

<h1 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">vect = TfidfVectorizer()</span><br><span class="line">X = vect.fit_transform(words)</span><br></pre></td></tr></table></figure></div>
<h1 id="词袋法"><a href="#词袋法" class="headerlink" title="词袋法"></a>词袋法</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 除了TF-IDF 还可以使用词袋法</span></span><br><span class="line">from sklearn.feature_extraction.text import CountVectorizer</span><br><span class="line">vect = CountVectorizer()</span><br><span class="line">X = vect.fit_transform(words)</span><br></pre></td></tr></table></figure></div>

<h1 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">kms = KMeans(n_clusters=10, random_state=123)</span><br><span class="line">labels = kms.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'cluster'</span>] = labels</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(10):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"\n类别 {i}"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">'cluster'</span>] == i][<span class="string">'标题'</span>].<span class="built_in">head</span>(5).to_list())</span><br></pre></td></tr></table></figure></div>

<p>类别 0<br>[‘体育场地共享 群众健身受惠’, ‘江苏省体育局构建全民健身设施网络体系’, ‘乐享全民健身公益体育彩票就在你我身边’, ‘惠州将举行系列体育活动迎接全民健身日的到来’, ‘惠州将举行系列体育活动迎接全民健身日的到来’]</p>
<p>类别 1<br>[‘杨广伟:未来10年 人工智能一定会改变房地产行业’, ‘文献述评:人工智能在精神科的应用’, ‘严重提醒!骗子都用上AI技术了!你却还不知道啥是人工智能?’, ‘“芯时代、芯征程、芯机遇”人工智能与机器视觉高峰论坛如期而至’, ‘“读心术”新高地,基于血谱光学成像的情感人工智能’]</p>
<p>类别 2<br>[‘华能国际:华能资本是华能贵诚信托有限公司大股东’, ‘贵诚信托’, ‘华能贵诚信托有限公司’, ‘华能贵诚信托有限公司’, ‘华能贵诚信托有限公司’]</p>
<p>类别 3<br>[‘数字媒体的体育版权经营逻辑’, ‘关心下一代华夏国际体育训练营丨美国体育训练营’, ‘左手优酷体育右手苏宁体育 阿里体育组队围攻腾讯体育’, ‘新赛季“抢人”大战正酣 优酷体育会员悄然下架’, ‘学校体育资源开放,步子再快一点’]</p>
<p>类别 4<br>[‘全球《财富》榜再次更新,阿里巴巴腾讯被反超?京东成最大黑马!’, ‘腾讯、阿里巴巴、京东……等名字的由来,你知道哪些?’, ‘格力全品类上线京东家电 与京东展开深度合作’, ‘格力“联姻”京东 预计2年后进行业前四’, ‘博鳌快讯 | 唐学斌:京东、360看中的是彩生活的社区服务模式’]</p>
<p>类别 5<br>[‘信托公司2019年上半年经营业绩概览’, ‘2018年信托业人均创利304万元 华润、华能贵诚跌出万亿俱乐部’, ‘去年信托业人均创利304万元,华能贵诚信托跌出万亿俱乐部’, ‘华能贵诚信托换帅,孙磊出任总经理’, ‘持单家公司股票超产品净值20% 华能贵诚信托被罚20万元’]</p>
<p>类别 6<br>[‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’]</p>
<p>类别 7<br>[‘数据科学哪家强?Python和R的对决 - 博客园新闻手机版’, ‘数字化阅读空间 | 怎么用Python迅速获取网站数据?’, ‘今天破解了压缩文件的密码:使用python轻松编写破解程序’, ‘程序员如何利用 Python 解决女朋友不看天气的坏习惯?’, ‘向Excel说再见,神级编辑器统一表格与Python’]</p>
<p>类别 8<br>[‘…电视总台七夕特别节目《天下有情人》浪漫升级,引领传统文化新…’, ‘北京文化“封神”:爆款如何持续’, ‘深挖“仓颉造字”历史文化,寿光这个村新时代文明实践有高招’, ‘让夜间经济更有文化味 哪里才是真正“网红打卡地”?’, ‘嘉兴:“伯鸿城市书房”构筑风雅桐乡最美文化地标’]</p>
<p>类别 9<br>[‘首单信托型企业ABS获批’, ‘华能贵诚信托孙磊:金融科技助力打造开放信托生态’, ‘华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施’, ‘格力电器股权转让意向方闭门开会 华能信托赫然在列’, ‘直击格力电器意向投资者见面会:参会者华能信托背后现国务院国资委…’]</p>
<h1 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.cluster import DBSCAN</span><br><span class="line"></span><br><span class="line">dbs = DBSCAN(eps=0.5, min_samples=5)</span><br><span class="line">dbs.fit(X)</span><br><span class="line">labels = dbs.labels_</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'cluster'</span>] = labels</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(10):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"\n类别 {i}"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">'cluster'</span>] == i][<span class="string">'标题'</span>].<span class="built_in">head</span>(5).to_list())</span><br></pre></td></tr></table></figure></div>

<p>类别 0<br>[‘五矿信托首任总经理辞职 接任者或为华能信托王卓’, ‘五矿信托首任总经理辞职 接任者或为华能信托王卓’, ‘五矿信托首任总经理辞职 接任者或为华能信托王卓’, ‘五矿信托首任总经理辞职 接任者或为华能信托王卓’, ‘五矿信托首任总经理辞职 接任者或为华能信托王卓’]</p>
<p>类别 1<br>[‘华夏幸福关于拟与华能信托签署《增资协议》的公告’, ‘华夏幸福关于拟与华能信托签署《增资协议》的公告’, ‘华夏幸福关于拟与华能信托签署《增资协议》的公告’, ‘华夏幸福关于拟与华能信托签署《增资协议》的公告’, ‘华夏幸福关于拟与华能信托签署《增资协议》的公告’]</p>
<p>类别 2<br>[‘普邦股份:华能信托.普邦1号集合资金信托计划信托合同’, ‘普邦股份:华能信托.普邦1号集合资金信托计划信托合同’, ‘普邦股份:华能信托.普邦1号集合资金信托计划信托合同’, ‘普邦股份:华能信托.普邦1号集合资金信托计划信托合同’, ‘普邦股份:华能信托.普邦1号集合资金信托计划信托合同’]</p>
<p>类别 3<br>[‘华能信托试水首单不良资产收益权转让已有46家信托公司与银登中心…’, ‘华能信托试水首单不良资产收益权转让已有46家信托公司与银登中心…’, ‘华能信托试水首单不良资产收益权转让已有46家信托公司与银登中心…’, ‘华能信托试水首单不良资产收益权转让已有46家信托公司与银登中心…’, ‘华能信托试水首单不良资产收益权转让已有46家信托公司与银登中心…’]</p>
<p>类别 4<br>[‘北京银行携手华能、中航信托创新慈善信托模式’, ‘北京银行携手华能、中航信托创新慈善信托模式’, ‘北京银行携手华能、中航信托创新慈善信托模式’, ‘北京银行携手华能、中航信托创新慈善信托模式’, ‘北京银行携手华能、中航信托创新慈善信托模式’]</p>
<p>类别 5<br>[‘ACCA-华能信托“财经领袖培养计划”第一期学员选拔结果公布’, ‘ACCA-华能信托“财经领袖培养计划”第一期学员选拔结果公布’, ‘ACCA-华能信托“财经领袖培养计划”第一期学员选拔结果公布’, ‘ACCA-华能信托“财经领袖培养计划”第一期学员选拔结果公布’, ‘ACCA-华能信托“财经领袖培养计划”第一期学员选拔结果公布’]</p>
<p>类别 6<br>[‘华能贵诚信托有限公司’, ‘华能贵诚信托有限公司’, ‘华能贵诚信托有限公司’, ‘华能贵诚信托有限公司’, ‘华能贵诚信托有限公司’]</p>
<p>类别 7<br>[‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’]</p>
<p>类别 8<br>[‘用益-信托日报:平安江苏中信华能位列前四!58家信托上半年净利排位!’, ‘用益-信托日报:平安江苏中信华能位列前四!58家信托上半年净利排位!’, ‘用益-信托日报:平安江苏中信华能位列前四!58家信托上半年净利排位!’, ‘用益-信托日报:平安江苏中信华能位列前四!58家信托上半年净利排位!’, ‘用益-信托日报:平安江苏中信华能位列前四!58家信托上半年净利排位!’]</p>
<p>类别 9<br>[]</p>
<h1 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.cluster import AgglomerativeClustering</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比如 TF-IDF 输出是稀疏矩阵 需要转 dense</span></span><br><span class="line">X_dense = X.toarray()</span><br><span class="line"></span><br><span class="line">agg = AgglomerativeClustering(n_clusters=10, metric=<span class="string">'cosine'</span>, linkage=<span class="string">'average'</span>)</span><br><span class="line">labels = agg.fit_predict(X_dense)</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'cluster'</span>] = labels</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(10):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"\n类别 {i}"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">'cluster'</span>] == i][<span class="string">'标题'</span>].<span class="built_in">head</span>(5).to_list())</span><br></pre></td></tr></table></figure></div>
<p>类别 0<br>[‘华能信托:信托公司参与消费金融的新机会与模式分析’, ‘文献述评:人工智能在精神科的应用’, ‘严重提醒!骗子都用上AI技术了!你却还不知道啥是人工智能?’, ‘“芯时代、芯征程、芯机遇”人工智能与机器视觉高峰论坛如期而至’, ‘华为Atlas:AI遥感的“碧空慧眼”’]</p>
<p>类别 1<br>[‘既要人工智能高效发展,还要符合伦理,该怎么做?’, ‘又一项人工智能技术被确认,自动避开行人,开车睡觉或将成为现实’, ‘欧洲联盟人工智能生态系统调查’, ‘人工智能是一种受欢迎的推动力 可以为GDP增加数百万美元’, ‘法律人工智能的十大前沿问题’]</p>
<p>类别 2<br>[‘信托公司2019年上半年经营业绩概览’, ‘助推人工智能创新资源聚集珠海’, ‘湖南大力开展“科技成果转化年”活动’, ‘看看韩雪住的豪宅,室内做了很多 “科技”设计,进门才知很实用’, ‘活动汇丨成都8月科技互联网活动知多少?’]</p>
<p>类别 3<br>[‘杨广伟:未来10年 人工智能一定会改变房地产行业’, ‘渗透!人工智能将在10年内占领房地产市场?’, ‘西媒盘点:2016年中国打响了人工智能发展的发令枪’, ‘盘点全球各国人工智能战略:中国打响发令枪’, ‘为什么全球的富豪主要集中在科技领域?’]</p>
<p>类别 4<br>[‘亚马逊的StyleSnap是一款人工智能工具’, ‘谷歌正在使用人工智能来预测风电场的输出功率’, ‘谷歌正在使用人工智能来预测风电场的输出功率’, ‘这类纪录片用“硬核影像”见证“硬核科技”’, ‘三维传感组件公司“安思疆科技”获亿元A轮融资 北京清控金信资本…’]</p>
<p>类别 5<br>[‘&gt; 科技局’]</p>
<p>类别 6<br>[‘首单信托型企业ABS获批’, ‘华能贵诚信托孙磊:金融科技助力打造开放信托生态’, ‘华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施’, ‘格力电器股权转让意向方闭门开会 华能信托赫然在列’, ‘直击格力电器意向投资者见面会:参会者华能信托背后现国务院国资委…’]</p>
<p>类别 7<br>[‘Python3.7知其然知其所以然-第六章 字符串’]</p>
<p>类别 8<br>[‘对话|山村女教师自制体育器材:听孩子说想当老师,我流泪了’, ‘乖乖女不适合娱乐圈?她第一个不同意!’, ‘娱乐圈里的真·糊咖混得有多惨?’, ‘去年是分手季,今年是恋情季,娱乐圈的八月都组团吗’, ‘娱乐记者大起底!传出421页明星爆料,421文档究竟是怎么回事?’]</p>
<p>类别 9<br>[‘8月起停播娱乐性较强古装剧偶像剧’, ‘广电:展播期间不得播娱乐性较强的古装剧偶像剧’, ‘教育部禁止高校及实习单位安排学生到娱乐性场所实习’]</p>
<h1 id="GMM"><a href="#GMM" class="headerlink" title="GMM"></a>GMM</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.mixture import GaussianMixture</span><br><span class="line"></span><br><span class="line">gmm = GaussianMixture(n_components=10, covariance_type=<span class="string">'full'</span>)</span><br><span class="line">gmm.fit(X_dense)</span><br><span class="line">labels = gmm.predict(X_dense)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'cluster'</span>] = labels</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(10):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"\n类别 {i}"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">'cluster'</span>] == i][<span class="string">'标题'</span>].<span class="built_in">head</span>(5).to_list())</span><br></pre></td></tr></table></figure></div>
<p>类别 0<br>[‘杨广伟:未来10年 人工智能一定会改变房地产行业’, ‘文献述评:人工智能在精神科的应用’, ‘严重提醒!骗子都用上AI技术了!你却还不知道啥是人工智能?’, ‘“芯时代、芯征程、芯机遇”人工智能与机器视觉高峰论坛如期而至’, ‘“读心术”新高地,基于血谱光学成像的情感人工智能’]</p>
<p>类别 1<br>[‘华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施’, ‘阿尔法蛋现身人工智能与教育大数据峰会,智能科技获点赞’, ‘装病骗政府645万,科技远不是你想的那样’, ‘昔日网游第一股迅游科技实控人被动减持,商誉压顶’, ‘ChinaJoy 2019丨ITheat热点科技展台人气火爆 这些精彩看点不容错过’]</p>
<p>类别 2<br>[‘来腾讯音乐娱乐蔡徐坤全新EP派对探寻不一《YOUNG》的青春答案’, ‘TGC腾讯数字文创:腾讯的文化抱负’, ‘腾讯云进入日本市场 今年目标是使国际营收增长至多5倍’, ‘湖南省政府与腾讯公司签署深化合作框架协议’, ‘腾讯(00700)需要喜茶’]</p>
<p>类别 3<br>[‘华能贵诚信托孙磊:金融科技助力打造开放信托生态’, ‘华能贵诚信托换帅,孙磊出任总经理’, ‘华能国际:华能资本是华能贵诚信托有限公司大股东’, ‘2018年上半年62家信托公司净利润排名 平安中信华能位列前三’, ‘速睹62家信托上半年业绩!平安中信华能位列前三’]</p>
<p>类别 4<br>[‘信托公司2019年上半年经营业绩概览’, ‘首单信托型企业ABS获批’, ‘格力电器股权转让意向方闭门开会 华能信托赫然在列’, ‘直击格力电器意向投资者见面会:参会者华能信托背后现国务院国资委…’, ‘格力电器股权转让意向投资者见面会召开 自称华能信托的人士到场’]</p>
<p>类别 5<br>[‘数字媒体的体育版权经营逻辑’, ‘关心下一代华夏国际体育训练营丨美国体育训练营’, ‘左手优酷体育右手苏宁体育 阿里体育组队围攻腾讯体育’, ‘新赛季“抢人”大战正酣 优酷体育会员悄然下架’, ‘学校体育资源开放,步子再快一点’]</p>
<p>类别 6<br>[‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’, ‘国金ABS云 · 早报丨招行与华能信托将合作发行99亿元ABS’]</p>
<p>类别 7<br>[‘阿里巴巴的食堂长啥样?上海网红美食杭州首站开在这’, ‘阿里巴巴朋新宇:为何中台能帮企业突破增长瓶颈?’, ‘阿里巴巴搭起数字鹊桥:4000万人种下情侣树 600万人绑定淘宝亲情号’, ‘阿里巴巴大数据折射中国式“我爱你”:54%码商夫妻店由老婆管帐’, ‘阿里巴巴合伙人之一 跟了马云19年后 分了40亿给她’]</p>
<p>类别 8<br>[‘…电视总台七夕特别节目《天下有情人》浪漫升级,引领传统文化新…’, ‘北京文化“封神”:爆款如何持续’, ‘深挖“仓颉造字”历史文化,寿光这个村新时代文明实践有高招’, ‘让夜间经济更有文化味 哪里才是真正“网红打卡地”?’, ‘嘉兴:“伯鸿城市书房”构筑风雅桐乡最美文化地标’]</p>
<p>类别 9<br>[‘…或200亿收购中江信托 50亿爆雷“烫手山芋”如何处置?;华能信托…’, ‘…或200亿收购中江信托 50亿爆雷“烫手山芋”如何处置?;华能信托…’, ‘华能信托换帅总经理孙磊任职资格获批’, ‘华能信托、东莞信托昨日双双增资 今年信托公司注册资本增加总额逾…’, ‘肖钢密集调研资产证券化业务 走访华能信托和中信信托’]</p>
<h1 id="HDBSCAN"><a href="#HDBSCAN" class="headerlink" title="HDBSCAN"></a>HDBSCAN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.cluster import HDBSCAN</span><br><span class="line"></span><br><span class="line">hdbscan = HDBSCAN(min_cluster_size=5, min_samples=3)</span><br><span class="line">hdbscan.fit(X_dense)</span><br><span class="line">labels = hdbscan.labels_</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'cluster'</span>] = labels</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(10):</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"\n类别 {i}"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">'cluster'</span>] == i][<span class="string">'标题'</span>].<span class="built_in">head</span>(5).to_list())</span><br></pre></td></tr></table></figure></div>
<p>类别 0<br>[‘灵超尤长靖节目互动被无耻造谣?坤音娱乐老板惹众怒,竟贷款道歉’, ‘尤长靖无辜躺枪?秦周懿言语中伤尤长靖,香蕉娱乐要求正式道歉’, ‘坤音娱乐频出问题,自卜凡解约风波后,老板也因骂尤长靖而惹争议’, ‘尤长靖无辜躺枪?秦周懿言语中伤尤长靖,香蕉娱乐要求正式道歉’, ‘坤音娱乐频出问题,自卜凡解约风波后,老板也因骂尤长靖而惹争议’]</p>
<p>类别 1<br>[‘乐队鼓手要失业?索尼用人工智能自动为音乐打节拍’, ‘来腾讯音乐娱乐蔡徐坤全新EP派对探寻不一《YOUNG》的青春答案’, ‘中国原声民歌节展现传统音乐非遗’, ‘来腾讯音乐娱乐蔡徐坤全新EP派对探寻不一《YOUNG》的青春答案’, ‘腾讯音乐“等风来”’]</p>
<p>类别 2<br>[‘广州:中考体育跳绳满分标准逐步提高’, ‘体育分值提至70分 “三大球”为选考项目’, ‘体育分值提至70分 “三大球”为选考项目’, ‘广州市中考体育部分加入足球、篮球、排球为选考项目’, ‘「最新」沪学校体育艺术项目将形成小初高“一条龙”!这里有你关心…’]</p>
<p>类别 3<br>[‘学好少儿编程,未来轻松掌控人工智能时代’, ‘长春人工智能编程’, ‘长春人工智能编程’, ‘编程小少年有个人工智能大梦想’, ‘编程小少年有个人工智能大梦想’]</p>
<p>类别 4<br>[‘让夜间经济更有文化味 哪里才是真正“网红打卡地”?’, ‘文化增活力 旅游添魅力 文旅融合讓濟南旅游悄然發生著變化’, ‘讲好中国故事 展示文化魅力’, ‘视频|临清首届汉服文化旅游周开幕 千年魅力文化尽在山水间’, ‘「财经纵横」戴斌:旅游研究与文化建设,初心在哪里…’]</p>
<p>类别 5<br>[‘一波三折的腾讯手游《拉结尔》最终定档3月底正式上线!’, ‘腾讯独家代理手游《权力的游戏》首测,SLG游戏或打破手游布局!’, ‘腾讯独家代理手游《权力的游戏》首测,SLG游戏或打破手游布局!’, ‘腾讯完美强强联合《完美世界》手游,信仰测试定档1月16日’, ‘那些为腾讯赚了上千亿的游戏人,都去哪了?’]</p>
<p>类别 6<br>[‘中国又掌握一项核心科技:火箭残骸指哪儿落哪儿’, ‘Python虚拟环境详解’, ‘腾讯拿它也没办法,详解为什么《剑网3:指尖江湖》不氪金’, ‘腾讯等它内测等了35000多个小时,剑网3指尖江湖把时间花哪儿了?’, ‘腾讯等它内测等了35000多个小时,剑网3指尖江湖把时间花哪儿了?’]</p>
<p>类别 7<br>[‘美股全线高开,标普500指数涨0.7%,中概股反弹,阿里巴巴涨逾3%’, ‘FAANG全线下跌!美股小幅低开,阿里巴巴跌逾2%’, ‘美股小幅低开,阿里巴巴跌逾2%’, ‘阿里巴巴集团:股票分割将于7月30日生效!’, ‘阿里巴巴宣布股票分割,是为回港上市做准备吗?’]</p>
<p>类别 8<br>[‘Python的武器库11:os模块’, ‘Python的武器库10:Pillow模块’, ‘Python的武器库09:psutil模块’, ‘提供给开发者 10 款最好的 Python IDE’, ‘提供给开发者 10 款最好的 Python IDE’]</p>
<p>类别 9<br>[‘体育惠民,让全城“动起来”’, ‘为什么Python在中国突然就火了起来了呢?’, ‘为什么Python在中国突然就火了起来了呢?’, ‘为什么Python在中国突然就火了起来了呢?’, ‘为什么我觉得Python烂的要死?原因有八’]</p>
<h1 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics.pairwise import cosine_similarity</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算余弦相似度</span></span><br><span class="line">cos_sim = cosine_similarity(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印前 5 条新闻的相似度矩阵</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"前5条新闻的余弦相似度："</span>)</span><br><span class="line"><span class="built_in">print</span>(pd.DataFrame(cos_sim[:5, :5]))</span><br><span class="line"></span><br><span class="line">similar_idx = cos_sim[0].argsort()[::-1][1:6]  <span class="comment"># 降序，跳过自己</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\n与第1条新闻最相似的5条："</span>)</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> similar_idx:</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"相似度={cos_sim[0, idx]:.3f} -&gt; {df.loc[idx, '标题']}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>前5条新闻的余弦相似度：<br>     0         1         2         3         4<br>0  1.0  0.000000  0.000000  0.000000  0.000000<br>1  0.0  1.000000  0.063591  0.055208  0.055039<br>2  0.0  0.063591  1.000000  0.464255  0.084141<br>3  0.0  0.055208  0.464255  1.000000  0.073049<br>4  0.0  0.055039  0.084141  0.073049  1.000000</p>
<p>与第1条新闻最相似的5条：<br>相似度=0.292 -&gt; 速睹62家信托上半年业绩!平安中信华能位列前三<br>相似度=0.215 -&gt; 2018年上半年62家信托公司净利润排名 平安中信华能位列前三<br>相似度=0.210 -&gt; 数字媒体的体育版权经营逻辑<br>相似度=0.138 -&gt; 5.94亿重组遭问询 汇金科技否认标的公司卖资产粉饰业绩<br>相似度=0.121 -&gt; 华能信托:信托公司参与消费金融的新机会与模式分析</p>
<h1 id="聚类模型横向对比"><a href="#聚类模型横向对比" class="headerlink" title="聚类模型横向对比"></a>聚类模型横向对比</h1><table>
<thead>
<tr>
<th>模型</th>
<th>聚类数量</th>
<th>噪声点</th>
<th>聚类特征 / 评论</th>
<th>示例类标题特点</th>
</tr>
</thead>
<tbody><tr>
<td>K-means</td>
<td>10</td>
<td>无</td>
<td>均匀分配簇，容易出现重复或相似内容被拆开</td>
<td>类别 0: 全民健身类；类别 1: AI技术类；类别 2: 华能信托多条重复标题</td>
</tr>
<tr>
<td>DBSCAN</td>
<td>多个簇，但部分簇为空或重复</td>
<td>存在噪声</td>
<td>聚类基于密度，相似度高的新闻容易形成簇，但参数敏感；簇内容重复严重</td>
<td>类别 0–8 多条重复“华能信托”新闻；类别 9 为空</td>
</tr>
<tr>
<td>层次聚类 (Agglomerative, cosine)</td>
<td>10</td>
<td>无</td>
<td>用余弦距离更贴合 TF-IDF，部分小类只含极少标题</td>
<td>类别 5 只有“&gt; 科技局”；类别 6 聚合了信托新闻</td>
</tr>
<tr>
<td>GMM (GaussianMixture)</td>
<td>10</td>
<td>无</td>
<td>假设数据服从高斯分布，簇比较均匀，但可能出现语义混杂</td>
<td>类别 0: AI新闻类；类别 1: 科技/信托混合；类别 4: 信托新闻类</td>
</tr>
<tr>
<td>HDBSCAN (cosine)</td>
<td>自动</td>
<td>存在噪声 (-1)</td>
<td>能发现任意形状簇，噪声点分离，主题聚合较好</td>
<td>类别 0: 娱乐八卦；类别 1: 音乐；类别 2: 体育新闻；噪声点主要是孤立新闻</td>
</tr>
</tbody></table>
<h2 id="横向对比总结"><a href="#横向对比总结" class="headerlink" title="横向对比总结"></a>横向对比总结</h2><ol>
<li><strong>K-means</strong>：簇数量固定，容易出现重复或相似标题分到不同簇；对离散和稀疏向量敏感。  </li>
<li><strong>DBSCAN</strong>：可以发现任意形状簇，但对 <code>eps</code> 参数非常敏感；可能出现重复簇或空簇。  </li>
<li><strong>层次聚类</strong>：用余弦距离效果比欧氏更好，但对小类敏感；能得到层次结构。  </li>
<li><strong>GMM</strong>：适合高斯分布数据，簇之间概率分布清晰，但主题可能混合。  </li>
<li><strong>HDBSCAN</strong>：最适合稀疏高维文本，自动确定簇数量，能标记噪声点，<strong>主题聚合性最好</strong>。</li>
</ol>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--电影推荐系统</title>
    <url>/zhihaojiang.github.io/2025/09/30/20250930%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'电影推荐系统.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>Unnamed: 0</th>
<th>电影编号</th>
<th>名称</th>
<th>类别</th>
<th>用户编号</th>
<th>评分</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1</td>
<td>玩具总动员（1995）</td>
<td>冒险|动画|儿童|喜剧|幻想</td>
<td>1</td>
<td>4.0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>玩具总动员（1995）</td>
<td>冒险|动画|儿童|喜剧|幻想</td>
<td>5</td>
<td>4.0</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>玩具总动员（1995）</td>
<td>冒险|动画|儿童|喜剧|幻想</td>
<td>7</td>
<td>4.5</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>玩具总动员（1995）</td>
<td>冒险|动画|儿童|喜剧|幻想</td>
<td>15</td>
<td>2.5</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>玩具总动员（1995）</td>
<td>冒险|动画|儿童|喜剧|幻想</td>
<td>17</td>
<td>4.5</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = df.drop(columns=[<span class="string">'Unnamed: 0'</span>])</span><br></pre></td></tr></table></figure></div>

<h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">user_movie = df.pivot_table(index=<span class="string">'用户编号'</span>, columns=<span class="string">'名称'</span>, values=<span class="string">'评分'</span>)</span><br><span class="line">user_movie.head()</span><br></pre></td></tr></table></figure></div>

<h1 id="计算相关性"><a href="#计算相关性" class="headerlink" title="计算相关性"></a>计算相关性</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">FG = user_movie[<span class="string">'阿甘正传（1994）'</span>]</span><br><span class="line"></span><br><span class="line">corr_FG = user_movie.corrwith(FG)</span><br><span class="line">similarity = pd.DataFrame(corr_FG, columns=[<span class="string">'相关系数'</span>])</span><br><span class="line">similarity.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>名称</th>
<th>相关系数</th>
</tr>
</thead>
<tbody><tr>
<td>007之黄金眼（1995）</td>
<td>0.217441</td>
</tr>
<tr>
<td>100个女孩（2000）</td>
<td>NaN</td>
</tr>
<tr>
<td>100条街道（2016）</td>
<td>NaN</td>
</tr>
<tr>
<td>101忠狗续集:伦敦大冒险（2003）</td>
<td>NaN</td>
</tr>
<tr>
<td>101忠狗（1961）</td>
<td>0.141023</td>
</tr>
</tbody></table>
<h1 id="查看相关的电影"><a href="#查看相关的电影" class="headerlink" title="查看相关的电影"></a>查看相关的电影</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 去掉自身和缺失值</span></span><br><span class="line">similar_movies = similarity.dropna().sort_values(by=<span class="string">'相关系数'</span>, ascending=False)</span><br><span class="line">similar_movies = similar_movies[similar_movies.index != <span class="string">'阿甘正传（1994）'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取前10</span></span><br><span class="line">top10 = similar_movies.head(10)</span><br><span class="line"><span class="built_in">print</span>(top10)</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>名称</th>
<th>相关系数</th>
</tr>
</thead>
<tbody><tr>
<td>Savannah Smiles（1982）</td>
<td>1.0</td>
</tr>
<tr>
<td>Badassdom骑士（2013）</td>
<td>1.0</td>
</tr>
<tr>
<td>亲密的陌生人（有信心的时间）（2004）</td>
<td>1.0</td>
</tr>
<tr>
<td>珀西杰克逊：怪兽之海（2013）</td>
<td>1.0</td>
</tr>
<tr>
<td>追逐者（1994）</td>
<td>1.0</td>
</tr>
<tr>
<td>地狱（2016）</td>
<td>1.0</td>
</tr>
<tr>
<td>爬行之夜（1986）</td>
<td>1.0</td>
</tr>
<tr>
<td>睡衣派对大屠杀，（1982）</td>
<td>1.0</td>
</tr>
<tr>
<td>我男朋友的回归（1993）</td>
<td>1.0</td>
</tr>
<tr>
<td>如何像英国人一样做爱（2014）</td>
<td>1.0</td>
</tr>
</tbody></table>
<h1 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">reader = Reader(rating_scale=(<span class="built_in">df</span>[<span class="string">'评分'</span>].min(), <span class="built_in">df</span>[<span class="string">'评分'</span>].max()))</span><br><span class="line">data = Dataset.load_from_df(<span class="built_in">df</span>[[<span class="string">'用户编号'</span>, <span class="string">'名称'</span>, <span class="string">'评分'</span>]], reader)</span><br><span class="line">trainset, testset = surprise_train_test_split(data, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line">svd_model = SVD()</span><br><span class="line">svd_model.fit(trainset)</span><br><span class="line">svd_pred = svd_model.test(testset)</span><br><span class="line">svd_rmse = accuracy.rmse(svd_pred)</span><br><span class="line">svd_mae = accuracy.mae(svd_pred)</span><br></pre></td></tr></table></figure></div>
<p>RMSE: 0.8793<br>MAE:  0.6738</p>
<h1 id="KNN-预测电影评分"><a href="#KNN-预测电影评分" class="headerlink" title="KNN 预测电影评分"></a>KNN 预测电影评分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">knn = NearestNeighbors(metric=<span class="string">'cosine'</span>, algorithm=<span class="string">'brute'</span>)</span><br><span class="line">R = user_movie.fillna(0).values</span><br><span class="line">knn.fit(R)</span><br><span class="line"></span><br><span class="line">def knn_predict(user_id, movie_name, user_movie, knn_model, k=5):</span><br><span class="line">    user_vector = user_movie.loc[user_id].fillna(0).values.reshape(1, -1)</span><br><span class="line">    distances, indices = knn_model.kneighbors(user_vector, n_neighbors=k+1)</span><br><span class="line">    neighbors = indices.flatten()[1:]  <span class="comment"># 排除自己</span></span><br><span class="line">    ratings = []</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> neighbors:</span><br><span class="line">        rating = user_movie.iloc[n][movie_name]</span><br><span class="line">        <span class="keyword">if</span> not np.isnan(rating):</span><br><span class="line">            ratings.append(rating)</span><br><span class="line">    <span class="keyword">if</span> len(ratings) == 0:</span><br><span class="line">        <span class="built_in">return</span> user_movie[movie_name].mean()</span><br><span class="line">    <span class="built_in">return</span> np.mean(ratings)</span><br><span class="line"></span><br><span class="line">pred = knn_predict(1, <span class="string">'阿甘正传（1994）'</span>, user_movie, knn)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"KNN 预测评分: {pred:.4f}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>KNN 预测评分: 3.7500</p>
<h1 id="user-user协同过滤"><a href="#user-user协同过滤" class="headerlink" title="user-user协同过滤"></a>user-user协同过滤</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">user_id = 10</span><br><span class="line">movie_name = <span class="string">'阿甘正传（1994）'</span></span><br><span class="line"></span><br><span class="line">user_corr = user_movie.corrwith(user_movie.loc[user_id], axis=1)</span><br><span class="line"><span class="comment"># 取已评分用户</span></span><br><span class="line">rated_users = user_movie[movie_name].dropna()</span><br><span class="line"><span class="comment"># 用加权平均预测</span></span><br><span class="line">pred = np.dot(user_corr[rated_users.index], rated_users) / user_corr[rated_users.index].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"加权平均预测评分: {pred:.4f}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>加权平均预测评分: nan</p>
<h1 id="Item-Item-协同过滤"><a href="#Item-Item-协同过滤" class="headerlink" title="Item-Item 协同过滤"></a>Item-Item 协同过滤</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">user_id = 1</span><br><span class="line">movie_name = <span class="string">'阿甘正传（1994）'</span></span><br><span class="line"></span><br><span class="line">movie_corr = user_movie.corrwith(user_movie[movie_name])</span><br><span class="line">rated_movies = user_movie.loc[user_id].dropna()</span><br><span class="line">pred = np.dot(movie_corr[rated_movies.index], rated_movies) / movie_corr[rated_movies.index].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"基于电影相似度的预测评分: {pred:.4f}"</span>)</span><br></pre></td></tr></table></figure></div>
<p>基于电影相似度的预测评分: nan</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--中医辨证</title>
    <url>/zhihaojiang.github.io/2025/10/09/20251009%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%B8%AD%E5%8C%BB%E8%BE%A8%E8%AF%81/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'中医辨证.xlsx'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>病人编号</th>
<th>病人症状</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>消化不良,便秘</td>
</tr>
<tr>
<td>2</td>
<td>心悸,失眠</td>
</tr>
<tr>
<td>3</td>
<td>腰疼,脱发,眼干</td>
</tr>
<tr>
<td>4</td>
<td>腹胀,便秘,哮喘,胸闷气短,消化不良</td>
</tr>
<tr>
<td>5</td>
<td>神经衰弱,失眠,月经不调</td>
</tr>
</tbody></table>
<h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">transactions = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">df</span>[<span class="string">'病人症状'</span>].tolist():</span><br><span class="line">    transactions.append(i.split(<span class="string">','</span>))</span><br></pre></td></tr></table></figure></div>

<h1 id="Apriori"><a href="#Apriori" class="headerlink" title="Apriori"></a>Apriori</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>Apriori 基于向下封闭原则</p>
<blockquote>
<p>如果一个项集是频繁的，那么它的所有子集也一定是频繁的<br>如果一个项集不是频繁的，那么它的所有超集也不可能频繁</p>
</blockquote>
<p>我们先找出每个单个症状出现的频率<br>然后只保留出现频率高（支持度高）的症状<br>再用它们组合成双项、三项……，逐步扩展<br>并在每次扩展时剪枝，减少不可能频繁的组合</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> results:  <span class="comment"># 遍历results中的每一个频繁项集</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> i.ordered_statistics:  <span class="comment"># 获取频繁项集中的关联规则</span></span><br><span class="line">        X = j.items_base  <span class="comment"># 关联规则的前件</span></span><br><span class="line">        Y = j.items_add  <span class="comment"># 关联规则的后件</span></span><br><span class="line">        x = <span class="string">', '</span>.<span class="built_in">join</span>([item <span class="keyword">for</span> item <span class="keyword">in</span> X])  <span class="comment"># 连接前件中的元素</span></span><br><span class="line">        y = <span class="string">', '</span>.<span class="built_in">join</span>([item <span class="keyword">for</span> item <span class="keyword">in</span> Y])  <span class="comment"># 连接后件中的元素</span></span><br><span class="line">        <span class="keyword">if</span> x != <span class="string">''</span>:  <span class="comment"># 防止出现关联规则前件为空的情况</span></span><br><span class="line">            <span class="built_in">print</span>(x + <span class="string">' -&gt; '</span> + y)  <span class="comment"># 通过字符串拼接的方式更好呈现结果</span></span><br></pre></td></tr></table></figure></div>

<h1 id="FP-Growth"><a href="#FP-Growth" class="headerlink" title="FP-Growth"></a>FP-Growth</h1><h2 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h2><p>Apriori 的问题是“候选项集太多”，计算量指数级增加。<br>FP-Growth 采用 压缩存储 和 模式增长 思想：</p>
<ol>
<li>把所有样本转成一棵频繁模式树（FP-Tree），只存出现次数；</li>
<li>然后从树结构中“挖”出所有频繁项集，而不用穷举所有组合。</li>
</ol>
<p>这样可以极大提升效率，尤其在上千条病例时，FP-Growth 比 Apriori 快 10～100 倍。</p>
<h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules</span><br><span class="line"></span><br><span class="line">freq_fp = fpgrowth(df_hot, min_support=0.05, use_colnames=True)</span><br><span class="line">rules_fp = association_rules(freq_fp, metric=<span class="string">"confidence"</span>, min_threshold=0.6)</span><br><span class="line">rules_fp.sort_values(by=<span class="string">'lift'</span>, ascending=False, inplace=True)</span><br><span class="line"></span><br><span class="line">rules_fp.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>antecedents</th>
<th>consequents</th>
<th>antecedent support</th>
<th>consequent support</th>
<th>support</th>
<th>confidence</th>
<th>lift</th>
<th>representativity</th>
<th>leverage</th>
<th>conviction</th>
<th>zhangs_metric</th>
<th>jaccard</th>
<th>certainty</th>
<th>kulczynski</th>
</tr>
</thead>
<tbody><tr>
<td>(腹胀, 消化不良)</td>
<td>(便秘)</td>
<td>0.076</td>
<td>0.184</td>
<td>0.076</td>
<td>1.000000</td>
<td>5.434783</td>
<td>1.0</td>
<td>0.062016</td>
<td>inf</td>
<td>0.883117</td>
<td>0.413043</td>
<td>1.000000</td>
<td>0.706522</td>
</tr>
<tr>
<td>(腹胀)</td>
<td>(便秘, 消化不良)</td>
<td>0.092</td>
<td>0.160</td>
<td>0.076</td>
<td>0.826087</td>
<td>5.163043</td>
<td>1.0</td>
<td>0.061280</td>
<td>4.830000</td>
<td>0.888013</td>
<td>0.431818</td>
<td>0.792961</td>
<td>0.650543</td>
</tr>
<tr>
<td>(胸闷气短)</td>
<td>(哮喘)</td>
<td>0.140</td>
<td>0.124</td>
<td>0.088</td>
<td>0.628571</td>
<td>5.069124</td>
<td>1.0</td>
<td>0.070640</td>
<td>2.3</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h1 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h1><h2 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h2><p>Word2Vec 是一种词嵌入模型（embedding），最初用于自然语言处理。<br>思想非常简单：<br>如果两个词经常出现在相同的上下文中，它们的意义就可能相似。<br>这就是分布式语义假设（Distributional Hypothesis）。</p>
<p>模型通过两种方式学习：</p>
<blockquote>
<p>CBOW（Continuous Bag of Words）：用周围词预测中间词；<br>Skip-gram：用当前词预测周围词</p>
</blockquote>
<p>训练后，每个词（症状）都会得到一个向量表示<br>向量之间的余弦相似度代表症状的语义相似度</p>
<p>如果我们把每个病例当作一句话，症状当作词语，Word2Vec 就能学出“哪些症状经常一起出现”的语义模式</p>
<p>例如模型可能学出</p>
<blockquote>
<p>头痛 与 眩晕 相似度高（0.89）<br>咳嗽 与 咽干 相似度高（0.84）</p>
</blockquote>
<p>说明它们经常一起出现，甚至可以作为同一证候的表现。</p>
<p>这种方法从连续分布的角度理解“症状间的语义接近度”，<br>比 Apriori 的硬规则更柔和、能度量相似强度。</p>
<h2 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">model = Word2Vec(sentences=transactions, vector_size=50, window=3, min_count=1, sg=1)</span><br><span class="line">symptom = all_symptoms[0]</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"与『{symptom}』最相似的症状："</span>)</span><br><span class="line"><span class="built_in">print</span>(model.wv.most_similar(symptom, topn=5))</span><br></pre></td></tr></table></figure></div>
<p>与『便秘』最相似的症状：<br>[(‘哮喘’, 0.32900574803352356), (‘神经衰弱’, 0.30445194244384766), (‘腰疼’, 0.29307475686073303), (‘心悸’, 0.29051631689071655), (‘失眠’, 0.2569029927253723)]</p>
<h1 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h1><h2 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h2><p>K-Means 是一种经典的无监督学习算法。<br>它的目标是：把样本自动分成 k 个簇，使得同一簇内部相似度高、不同簇之间差异大。</p>
<p>算法步骤：</p>
<ol>
<li>随机选 k 个初始中心；</li>
<li>把每个样本分配到距离最近的中心；</li>
<li>重新计算各簇的中心；</li>
<li>重复直到收敛。</li>
</ol>
<p><strong>数学目标</strong></p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.002ex;" xmlns="http://www.w3.org/2000/svg" width="20.228ex" height="6.941ex" role="img" focusable="false" viewBox="0 -1740.7 8940.8 3067.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="munderover" transform="translate(1833.7,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(537.8,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g><g data-mml-node="munder" transform="translate(3444.3,0)"><g data-mml-node="mo" transform="translate(84.4,0)"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(0,-1115.5) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(572,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msub" transform="translate(1239,0)"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(5223.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(5501.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6296.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(7296.3,0)"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mi" transform="translate(636,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msup" transform="translate(8226.3,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mn" transform="translate(311,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
<p>在中医理论中，不同病人虽然症状各异，但可以归为几种“证型”：</p>
<blockquote>
<p>气滞血瘀型<br>湿热内蕴型<br>阴虚火旺型<br>……</p>
</blockquote>
<p>KMeans 可以把患者按照症状向量（One-Hot 形式）聚类，<br>从而自动分出潜在的证型群体。<br>之后可以观察每类群体中最常见的症状组合，就能从数据中“还原证候分类”。</p>
<h2 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.cluster import KMeans</span><br><span class="line"></span><br><span class="line">kmeans = KMeans(n_clusters=4, random_state=42)</span><br><span class="line">labels = kmeans.fit_predict(df_hot)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">'聚类标签'</span>] = labels</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><h2 id="原理-4"><a href="#原理-4" class="headerlink" title="原理"></a>原理</h2><p>PCA（Principal Component Analysis）是一种降维算法，<br>通过线性变换找到数据中最主要的变化方向（主成分）。<br>核心思想：<br>找一组正交方向，使得投影后样本的方差最大。</p>
<p>换句话说：<br>它用尽量少的维度（通常 2～3 个）去保留最多的信息。</p>
<p>症状矩阵维度非常高（每个症状一列），<br>直接观察不方便。<br>PCA 可以把这些高维数据投影到二维平面，<br>让我们直观地看到：<br>	•	不同患者在症状空间中的分布；<br>	•	不同聚类（证型）之间是否分离清晰；<br>	•	哪些症状是主要的区分因素（主成分载荷高的症状）。</p>
<p>这样医生或研究者可以快速识别：</p>
<p>“这群患者的症状模式相似、可能属于同一证型。”</p>
<h2 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">all_symptoms = sorted(list(<span class="built_in">set</span>(<span class="built_in">sum</span>(transactions, []))))</span><br><span class="line">df_hot = pd.DataFrame([[1 <span class="keyword">if</span> s <span class="keyword">in</span> t <span class="keyword">else</span> 0 <span class="keyword">for</span> s <span class="keyword">in</span> all_symptoms] <span class="keyword">for</span> t <span class="keyword">in</span> transactions],</span><br><span class="line">                      columns=all_symptoms)</span><br><span class="line">                      </span><br><span class="line">                      </span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=2)</span><br><span class="line">reduced_data = pca.fit_transform(df_hot)</span><br><span class="line">plt.figure(figsize=(7,6))</span><br><span class="line">plt.scatter(reduced_data[:,0], reduced_data[:,1], c=labels, cmap=<span class="string">'rainbow'</span>, s=30)</span><br><span class="line">plt.title(<span class="string">"患者症状分布图"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"主成分1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"主成分2"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/001.png" alt="photo"></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--产品评价</title>
    <url>/zhihaojiang.github.io/2025/10/09/20251009%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E4%BA%A7%E5%93%81%E8%AF%84%E4%BB%B7/</url>
    <content><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文代码均保存在<br><a class="link" href="https://github.com/super-213/business_data_analysis">https://github.com/super-213/business_data_analysis<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>有需要的可以自行下载</p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import jieba</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line">from sklearn.metrics import accuracy_score, classification_report</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = pd.read_excel(<span class="string">'产品评价.xlsx'</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<h1 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">def clean_text(text):</span><br><span class="line">    <span class="built_in">return</span> <span class="string">' '</span>.<span class="built_in">join</span>(jieba.cut(str(text)))</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">'评论_clean'</span>] = <span class="built_in">df</span>[<span class="string">'评论'</span>].apply(clean_text)</span><br></pre></td></tr></table></figure></div>

<h1 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># TF-IDF特征</span></span><br><span class="line">vectorizer = TfidfVectorizer(max_features=5000)</span><br><span class="line">X = vectorizer.fit_transform(<span class="built_in">df</span>[<span class="string">'评论_clean'</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">'评价'</span>]</span><br></pre></td></tr></table></figure></div>

<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.naive_bayes import MultinomialNB</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.svm import LinearSVC</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from xgboost import XGBClassifier</span><br><span class="line">from sklearn.neural_network import MLPClassifier</span><br><span class="line"></span><br><span class="line">models = {</span><br><span class="line">    <span class="string">'朴素贝叶斯'</span>: MultinomialNB(),</span><br><span class="line">    <span class="string">'逻辑回归'</span>: LogisticRegression(max_iter=200),</span><br><span class="line">    <span class="string">'支持向量机'</span>: LinearSVC(),</span><br><span class="line">    <span class="string">'随机森林'</span>: RandomForestClassifier(n_estimators=100, random_state=42),</span><br><span class="line">    <span class="string">'XGBoost'</span>: XGBClassifier(use_label_encoder=False, eval_metric=<span class="string">'logloss'</span>),</span><br><span class="line">    <span class="string">'MLP'</span>: MLPClassifier(random_state=42)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():</span><br><span class="line">    model.fit(X_train, y_train)</span><br><span class="line">    y_pred = model.predict(X_test)</span><br><span class="line">    acc = accuracy_score(y_test, y_pred)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">'\n模型：{name}'</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'准确率：'</span>, acc)</span><br><span class="line">    <span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>模型：朴素贝叶斯<br>准确率： 0.875<br>              precision    recall  f1-score   support</p>
<pre><code>       0       1.00      0.70      0.83        91
       1       0.82      1.00      0.90       125

accuracy                           0.88       216
</code></pre>
<p>   macro avg       0.91      0.85      0.86       216<br>weighted avg       0.90      0.88      0.87       216</p>
<p>模型：逻辑回归<br>准确率： 0.9814814814814815<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.97      0.99      0.98        91
       1       0.99      0.98      0.98       125

accuracy                           0.98       216
</code></pre>
<p>   macro avg       0.98      0.98      0.98       216<br>weighted avg       0.98      0.98      0.98       216</p>
<p>模型：支持向量机<br>准确率： 0.9629629629629629<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.93      0.99      0.96        91
       1       0.99      0.94      0.97       125

accuracy                           0.96       216
</code></pre>
<p>   macro avg       0.96      0.97      0.96       216<br>weighted avg       0.96      0.96      0.96       216</p>
<p>模型：随机森林<br>准确率： 0.9768518518518519<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.96      0.99      0.97        91
       1       0.99      0.97      0.98       125

accuracy                           0.98       216
</code></pre>
<p>   macro avg       0.97      0.98      0.98       216<br>weighted avg       0.98      0.98      0.98       216</p>
<p>模型：XGBoost<br>准确率： 0.9675925925925926<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.94      0.99      0.96        91
       1       0.99      0.95      0.97       125

accuracy                           0.97       216
</code></pre>
<p>   macro avg       0.96      0.97      0.97       216<br>weighted avg       0.97      0.97      0.97       216</p>
<p>模型：MLP<br>准确率： 0.9583333333333334<br>              precision    recall  f1-score   support</p>
<pre><code>       0       0.93      0.98      0.95        91
       1       0.98      0.94      0.96       125

accuracy                           0.96       216
</code></pre>
<p>   macro avg       0.96      0.96      0.96       216<br>weighted avg       0.96      0.96      0.96       216</p>
</blockquote>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import jieba</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from tensorflow.keras.preprocessing.text import Tokenizer</span><br><span class="line">from tensorflow.keras.preprocessing.sequence import pad_sequences</span><br><span class="line">from tensorflow.keras.models import Sequential</span><br><span class="line">from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout</span><br><span class="line">from tensorflow.keras.callbacks import EarlyStopping</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenizer 序列化</span></span><br><span class="line">max_words = 10000 <span class="comment"># 词表大小</span></span><br><span class="line">max_len = 100 <span class="comment"># 每条评论的最大长度</span></span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=max_words)</span><br><span class="line">tokenizer.fit_on_texts(<span class="built_in">df</span>[<span class="string">'评论_clean'</span>])</span><br><span class="line"></span><br><span class="line">X = tokenizer.texts_to_sequences(<span class="built_in">df</span>[<span class="string">'评论_clean'</span>])</span><br><span class="line">X = pad_sequences(X, maxlen=max_len)</span><br><span class="line">y = np.array(<span class="built_in">df</span>[<span class="string">'评价'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据划分</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=0.2, random_state=42</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    Embedding(max_words, 128, input_length=max_len),</span><br><span class="line">    Conv1D(128, 3, activation=<span class="string">'relu'</span>),</span><br><span class="line">    GlobalMaxPooling1D(),</span><br><span class="line">    Dropout(0.5),</span><br><span class="line">    Dense(64, activation=<span class="string">'relu'</span>),</span><br><span class="line">    Dropout(0.3),</span><br><span class="line">    Dense(1, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">early_stop = EarlyStopping(monitor=<span class="string">'val_loss'</span>, patience=3, restore_best_weights=True)</span><br><span class="line"></span><br><span class="line"><span class="built_in">history</span> = model.fit(</span><br><span class="line">    X_train, y_train,</span><br><span class="line">    validation_split=0.2,</span><br><span class="line">    epochs=10,</span><br><span class="line">    batch_size=64,</span><br><span class="line">    callbacks=[early_stop],</span><br><span class="line">    verbose=1</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">loss, acc = model.evaluate(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"\n测试集准确率: {acc:.4f}"</span>)</span><br><span class="line"></span><br><span class="line">def predict_comment(text):</span><br><span class="line">    text_cut = <span class="string">' '</span>.<span class="built_in">join</span>(jieba.cut(text))</span><br><span class="line">    <span class="built_in">seq</span> = tokenizer.texts_to_sequences([text_cut])</span><br><span class="line">    <span class="built_in">seq</span> = pad_sequences(<span class="built_in">seq</span>, maxlen=max_len)</span><br><span class="line">    pred = model.predict(<span class="built_in">seq</span>)[0][0]</span><br><span class="line">    <span class="built_in">return</span> <span class="string">"好评 "</span> <span class="keyword">if</span> pred &gt; 0.5 <span class="keyword">else</span> <span class="string">"差评 "</span>, <span class="built_in">float</span>(pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(predict_comment(<span class="string">"这款手机手感非常棒，运行速度快"</span>))</span><br><span class="line"><span class="built_in">print</span>(predict_comment(<span class="string">"质量太差了，用了两天就坏"</span>))</span><br></pre></td></tr></table></figure></div>

<p>测试集准确率: 0.9676<br>1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 681ms/step<br>(‘好评’, 0.999203622341156)<br>1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step<br>(‘差评’, 0.03876214474439621)</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">'accuracy'</span>], label=<span class="string">'training accuracy'</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'val_accuracy'</span>], label=<span class="string">'validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/002.png" alt="photo"></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>基于最小二乘法拟合碳化硅外延层厚度</title>
    <url>/zhihaojiang.github.io/2025/10/09/20251009%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E6%8B%9F%E5%90%88%E7%A2%B3%E5%8C%96%E7%A1%85%E5%A4%96%E5%BB%B6%E5%B1%82%E5%8E%9A%E5%BA%A6/</url>
    <content><![CDATA[<h1 id="基于最小二乘法拟合碳化硅外延层厚度"><a href="#基于最小二乘法拟合碳化硅外延层厚度" class="headerlink" title="基于最小二乘法拟合碳化硅外延层厚度"></a>基于最小二乘法拟合碳化硅外延层厚度</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>随着国家大力发展半导体为代表的新兴产业，碳化硅外延层厚度作为第三代半导体器件性能的关键参数之一，对器件性能有着重要影响。因此，外延层厚度的测定有其必要性。本文围绕红外干涉法在外延层厚度测量中的应用展开研究，系统建立了单次反射与多光束干涉情形下的厚度反演模型，提出了<strong>基于最小二乘法与相邻极值点差法的交叉验证算法</strong>，利用了附件1 – 4完成模型的验证与精度分析。<br><strong>针对问题1</strong>，基于双光束干涉效应，考虑外延层 - 衬底界面单次反射情形，构建了反射率关于掺杂载流子浓度、红外光谱的波长的<strong>Drude-Lorentz模型</strong>。依据菲涅耳公式得出理论反射率的表达式，通过<strong>非线性最小二乘</strong>拟合确定最优载流子浓度，将其回代并利用相邻极值点差法进行交叉验证，从而确保厚度测量的可靠性。</p>
<p><strong>针对问题2</strong>，基于问题1建立的数学模型，首先针对数据进行预处理，有效克服了红外光谱中噪声与拼接误差带来的干扰，选取<strong>1818cm^-1</strong>以后的高波数段。将该模型应用于附件1与附件2中，反演出外延层厚度为<strong>8.5383um</strong>。通过残差重采样评估，结果表明相对误差约为<strong>0.066%</strong>，具有良好的重复性与可靠性。</p>
<p><strong>针对问题3</strong>，进一步考虑多光束干涉效应，推导得出形成显著多光束干涉的必要条件：界面反射系数需足够大且光学厚度满足相长干涉条件。理论分析表明，多光束干涉会引入高频振荡分量，导致厚度反演结果系统性偏大。基于此，构建了包含多次反射项的扩展模型。应用于附件3与附件4，判定其均存在显著多光束干涉，经修正后反演厚度为<strong>3.19um</strong>，最后将复折射率中的消光系数考虑后代入模型对问题2结果计算得到<strong>8.5392um</strong>。</p>
<p>关键词：碳化硅；Drude-Lorentz模型；介电函数；最小二乘；相邻极值点差法</p>
<h1 id="一、问题重述"><a href="#一、问题重述" class="headerlink" title="一、问题重述"></a>一、问题重述</h1><h2 id="1-1问题背景"><a href="#1-1问题背景" class="headerlink" title="1.1问题背景"></a>1.1问题背景</h2><p>随着国家大力发展半导体为代表的新兴产业，碳化硅作为第三代新型半导体材料，因其优越的综合性能备受瞩目。碳化硅外延层厚度是外延材料的关键参数之一，对器件性能有着重要影响。因此，建立一套完善的测试标准是极其必要的。</p>
<h2 id="1-2问题重述"><a href="#1-2问题重述" class="headerlink" title="1.2问题重述"></a>1.2问题重述</h2><p>红外干涉法是一种常见的无损测量外延层厚度的方法，其基本原理是，由于外延层与衬底存在掺杂载流子浓度的差异，导致其折射率不同，外延层的折射率通常不是常数，它与掺杂载流子浓度、红外光谱的波长等参数有关。红外光入射到外延层后，一部分从外延层表面反射出来，另一部分从衬底表面反射回来，这两束光在一定条件下会产生干涉条纹。通过分析红外光谱的波长、外延层的折射率和红外光的入射角等参数确定外延层的厚度。</p>
<p><strong>问题1</strong>：假设外延层和衬底界面只有一次反射、透射所产生的干涉条纹时：<br>（1）建立确定外延层厚度的数学模型。</p>
<p><strong>问题2</strong>：依据第1问的模型：<br>（1）设计测量外延层厚度的算法。<br>（2） 根据题目中所提供的碳化硅晶圆片的光谱实测数据，计算外延层厚度，分析结果的可靠性。</p>
<p><strong>问题3</strong>：假设光波可以在外延层界面和衬底界面产生多次反射、透射产生多光束干涉时：<br>（1）探讨产生多光束干涉的必要条件，以及多光束干涉对外延层厚度计算精度可能产生的影响。<br>（2）依据产生多光束干涉的必要条件，分析题目中提供的硅晶圆片的测试结果是否产生多光束干涉，设计测量外延层厚度的数学模型和算法，并计算相应结果。如若多光束干涉的出现影响到了外延层厚度计算精度，尽可能消除其影响，计算消除影响后的结果。</p>
<h1 id="二、问题分析"><a href="#二、问题分析" class="headerlink" title="二、问题分析"></a>二、问题分析</h1><h2 id="2-1问题一的分析"><a href="#2-1问题一的分析" class="headerlink" title="2.1问题一的分析"></a>2.1问题一的分析</h2><p>问题1主要要求我们给出测量碳化硅的外延层厚度的模型，探究外延层厚度与红外光谱的波长、外延层的折射率和红外光的入射角之间的关系。根据题目条件，已知红外光谱的波长和红外光的入射角，问题关键在于求出外延层折射率。由于外延层折射率与掺杂载流子浓度、红外光谱的波长等参数有关，红外波段下，碳化硅的光学性质受自由载流子与晶格振动的共同影响，<strong>Drude-Lorentz</strong> 模型能较好地描述这种复杂的介电响应，取复折射率的实部即为碳化硅外延层折射率，依据菲涅耳公式得出理论反射率的表达式，通过<strong>最小二乘法</strong>拟合得到最优载流子浓度和厚度的有效方法。最后，依据实际反射率的极值点差法计算厚度，并与拟合厚度对比，利用相邻极值点差法进行交叉验证，从而确保厚度测量的可靠性。 </p>
<h2 id="2-2问题二的分析"><a href="#2-2问题二的分析" class="headerlink" title="2.2问题二的分析"></a>2.2问题二的分析</h2><p>问题2主要是根据问题1建立的数学模型，计算外延层厚度，并给出可靠性分析。通过分析原始数据的特性，将数据进行<strong>归一化、Savitizky-Golay滤波去噪、PCHIP插值重采样</strong>的预处理，设定外延层厚度和载流子浓度初值，通过最小二乘法拟合得到最优载流子浓度，分析理论反射率与实验反射率之间的对误差，将拟合得到的最优载流子浓度作为已知参数，利用相邻极值点差法得到平均厚度，进一步使用残差重采样得到外延层厚度。验证三种方法误差是否在95%置信区间以内，保障了模型的可靠性。 </p>
<h2 id="2-3-问题三的分析"><a href="#2-3-问题三的分析" class="headerlink" title="2.3 问题三的分析"></a>2.3 问题三的分析</h2><p>问题3主要是推导产生多光束干涉的必要条件，探讨其出现是否会影响到外延层厚度计算精度。根据查阅相关文献，多光束干涉应该先满足产生干涉现象的条件：反射率足够大，任意两相邻反射光满足相位差，满足相干长度条件，满足弱吸收条件。再根据问题2设计的算法，验证其是否对外延层厚度计算精度的影响。 </p>
<h1 id="三、模型假设"><a href="#三、模型假设" class="headerlink" title="三、模型假设"></a>三、模型假设</h1><ol>
<li>碳化硅外延层表面洁净，具有良好的光学表面。</li>
<li>忽略测试环境对测试结果可能的影响。</li>
<li>实验测得的数据真实可靠。</li>
<li>碳化硅衬底与外延层载流子掺杂浓度差异足够大。</li>
<li>碳化硅衬底厚度远大于外延层厚度。</li>
</ol>
<h1 id="四、符号说明"><a href="#四、符号说明" class="headerlink" title="四、符号说明"></a>四、符号说明</h1><table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1036.6 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container></td>
<td>空气介质折射率</td>
</tr>
<tr>
<td>$$n_1$</td>
<td>外延层的折射率</td>
</tr>
<tr>
<td>$$n_2$</td>
<td>衬底的折射率</td>
</tr>
<tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 520 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container></td>
<td>外延层几何厚度</td>
</tr>
<tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.425ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 1514 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="394" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="mi" transform="translate(833,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g></svg></mjx-container></td>
<td>光程差</td>
</tr>
<tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.005ex" height="1.645ex" role="img" focusable="false" viewBox="0 -717 444 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g></svg></mjx-container></td>
<td>相位差</td>
</tr>
<tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex;" xmlns="http://www.w3.org/2000/svg" width="1.958ex" height="1.355ex" role="img" focusable="false" viewBox="0 -442 865.6 599.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></g></svg></mjx-container></td>
<td>S偏振反射系数</td>
</tr>
<tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.41ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1065 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g></g></g></g></svg></mjx-container></td>
<td>P偏振反射系数</td>
</tr>
<tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.483ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1097.3 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></svg></mjx-container></td>
<td>理论反射率</td>
</tr>
</tbody></table>
<p>（剩余符号在后续有做说明）</p>
<h1 id="五、模型准备"><a href="#五、模型准备" class="headerlink" title="五、模型准备"></a>五、模型准备</h1><p>为分析光在“空气-外延层-衬底”多层结构中的传播与干涉行为，本文基于波动光学理论，建立相应的光学模型。本节主要涵盖角度计算、光程差与相位差的计算以及偏振状态的求解，具体如下：</p>
<h2 id="5-1角度的确定"><a href="#5-1角度的确定" class="headerlink" title="5.1角度的确定"></a>5.1角度的确定</h2><p>红外光在空气、外延层、衬底三层介质中传播时，其传播方向遵循斯涅耳定律，该定律描述了光从一种介质入射至另一种介质时，入射角与折射角的关联。</p>
<ol>
<li>入射光由空气进入外延层，入射角为 theta_0，折射角为 theta_1，则有：</li>
</ol>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="18.87ex" height="1.97ex" role="img" focusable="false" viewBox="0 -705 8340.4 870.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(2431.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2597.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3781.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(4837,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(6040.2,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(7268.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7434.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></p>
<p>由此可得：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.343ex;" xmlns="http://www.w3.org/2000/svg" width="27.537ex" height="6.923ex" role="img" focusable="false" viewBox="0 -2024.2 12171.5 3060"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(2688,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msqrt" transform="translate(3743.8,0)"><g transform="translate(1020,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1722.4,0)"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="msub" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="msub" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><rect width="1236.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mi" transform="translate(2212.6,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(3440.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(3607.2,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(4512.8,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g><g data-mml-node="mn" transform="translate(5281.8,1176.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,214.2)"><path data-c="221A" d="M983 1739Q988 1750 1001 1750Q1008 1750 1013 1745T1020 1733Q1020 1726 742 244T460 -1241Q458 -1250 439 -1250H436Q424 -1250 424 -1248L410 -1166Q395 -1083 367 -920T312 -601L201 44L137 -83L111 -57L187 96L264 247Q265 246 369 -357Q470 -958 473 -963L727 384Q979 1729 983 1739Z"></path></g><rect width="7407.8" height="60" x="1020" y="1904.2"></rect></g></g></g></svg></mjx-container></p>
<ol start="2">
<li>入射光由外延层（折射率为 n_1）进入衬底（折射率为 n_2），入射角与进入外延层的折射角相等为 theta_1，折射角为 theta_2，则有：</li>
</ol>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="18.87ex" height="1.934ex" role="img" focusable="false" viewBox="0 -705 8340.4 855"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(2431.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2597.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3781.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(4837,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(6040.2,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(7268.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7434.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
<p>由此可得：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.343ex;" xmlns="http://www.w3.org/2000/svg" width="27.537ex" height="6.923ex" role="img" focusable="false" viewBox="0 -2024.2 12171.5 3060"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(2688,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msqrt" transform="translate(3743.8,0)"><g transform="translate(1020,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1722.4,0)"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="msub" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="msub" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><rect width="1236.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mi" transform="translate(2212.6,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(394,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(672,0)"></path></g><g data-mml-node="mo" transform="translate(3440.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(3607.2,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(4512.8,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g><g data-mml-node="mn" transform="translate(5281.8,1176.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,214.2)"><path data-c="221A" d="M983 1739Q988 1750 1001 1750Q1008 1750 1013 1745T1020 1733Q1020 1726 742 244T460 -1241Q458 -1250 439 -1250H436Q424 -1250 424 -1248L410 -1166Q395 -1083 367 -920T312 -601L201 44L137 -83L111 -57L187 96L264 247Q265 246 369 -357Q470 -958 473 -963L727 384Q979 1729 983 1739Z"></path></g><rect width="7407.8" height="60" x="1020" y="1904.2"></rect></g></g></g></svg></mjx-container></p>
<h2 id="5-2光程差、相位差的计算"><a href="#5-2光程差、相位差的计算" class="headerlink" title="5.2光程差、相位差的计算"></a>5.2光程差、相位差的计算</h2><p>在红外干涉法测量外延层厚度的过程中，“空气→外延层”界面反射形成的反射光1以及“外延层→衬底”界面反射形成的反射光2。由于反射光2较反射光1额外穿过厚度为 d 的外延层，二者之间就产生了光程差，进而导致相位差，最终决定干涉增强或减弱。<br><strong>1.光程差：</strong><br>两束参与干涉的反射光之间的光程差由两束光的传播路径差异与半波损失带来的额外光程差一起决定。<br>首先需分析半波损失的影响：当光从光疏介质入射至光密介质发生反射时,反射光会发生相位突变，带来 \lambda/2 的额外光程差。由于两束光都是由光疏介质进入光密介质，所以都存在半波损失并产生 \lambda/2 的额外光程差，不过因其大小相等且方向一致，二者相互抵消。因此，不考虑半波损失带来的影响。<br>由下图可得，总光程差为反射光2在外延层内的往返路径与反射光1在空气中的路径差：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="43.854ex" height="1.994ex" role="img" focusable="false" viewBox="0 -716 19383.4 881.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="394" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="mi" transform="translate(833,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(1791.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2847.6,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(4106.3,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(4606.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(5356.6,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(6337.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(7338,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(8097,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(9079.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(10079.4,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(11338.2,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(11838.4,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(12588.4,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mo" transform="translate(13694.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(14750,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msub" transform="translate(15250,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(16286.5,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(16973.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(18311.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(18477.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/003.png" alt="photo"><br><strong>2.相位差：</strong><br>两束光通过折射率不同的介质时，因光程差会产生相位变，即：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.579ex;" xmlns="http://www.w3.org/2000/svg" width="28.283ex" height="4.704ex" role="img" focusable="false" viewBox="0 -1381 12501 2079"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mo" transform="translate(721.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1777.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g></g><g data-mml-node="mi" transform="translate(463.5,-686)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><rect width="1270" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3509.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(4010,0)"><path data-c="394" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="mi" transform="translate(4843,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(5801.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6857.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="msub" transform="translate(1070,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(2106.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(2793.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(4131.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(4297.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mi" transform="translate(2530.2,-686)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><rect width="5403.4" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>当光从一种介质入射到另一个介质时，会形成一个入射平面，其是由入射光线的传播方向与界面法向量所确定的平面。<br>根据光的电场方向，存在s偏振和p偏振两种偏振，由于光矢量振动方向的本质差异，分别垂直和平行于入射平面。它们在两种介质分界面发生反射时，反射光与入射光的复振幅比值由菲涅耳公式推导得出[1]，界面反射系数正是用于描述这两种偏振光在反射过程中振幅变化规律的关键物理量，然后对于空气与外延层上界面依据菲涅耳公式有：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -4.366ex;" xmlns="http://www.w3.org/2000/svg" width="51.804ex" height="9.862ex" role="img" focusable="false" viewBox="0 -2429.6 22897.3 4359.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g><g data-mml-node="mo" transform="translate(1167.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2223.2,0)"><g data-mml-node="mrow" transform="translate(220,1311.6)"><g data-mml-node="mstyle"><g data-mml-node="mfrac"><g data-mml-node="msub" transform="translate(906.8,676)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="2610.2" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mo" transform="translate(3072.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mstyle" transform="translate(4072.7,0)"><g data-mml-node="mfrac"><g data-mml-node="msub" transform="translate(906.8,676)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><rect width="2610.2" height="60" x="120" y="220"></rect></g></g></g><g data-mml-node="mrow" transform="translate(220,-1078)"><g data-mml-node="mstyle"><g data-mml-node="mfrac"><g data-mml-node="msub" transform="translate(906.8,676)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="2610.2" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mo" transform="translate(3072.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mstyle" transform="translate(4072.7,0)"><g data-mml-node="mfrac"><g data-mml-node="msub" transform="translate(906.8,676)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><rect width="2610.2" height="60" x="120" y="220"></rect></g></g></g><rect width="7122.9" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(9586.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(9864.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(11030.8,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g><g data-mml-node="mo" transform="translate(12174.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(13230,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(14008,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><rect width="8649.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>将其统一到一个式子里，即：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.927ex;" xmlns="http://www.w3.org/2000/svg" width="12.489ex" height="5.024ex" role="img" focusable="false" viewBox="0 -1369 5520.1 2220.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(728.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1784.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>对于 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 503 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g></g></svg></mjx-container> 分量，有<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.909ex;" xmlns="http://www.w3.org/2000/svg" width="19.894ex" height="4.438ex" role="img" focusable="false" viewBox="0 -1118 8793.1 1961.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g><g data-mml-node="mo" transform="translate(1167.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2223.2,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2674.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(2952.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4118.9,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4996.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6052.5,0)"><g data-mml-node="mi" transform="translate(1070.3,676)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><rect width="2500.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>而对于 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.061ex" height="1.023ex" role="img" focusable="false" viewBox="0 -442 469 452"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container> 分量，有<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="22.339ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 9873.7 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,-150) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1143.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2199.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(2977.2,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3428.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(3706.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4872.9,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5750.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(6806.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7573.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(8911.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(9077.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container><br>其中 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.593ex" role="img" focusable="false" viewBox="0 -693 600 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g></g></g></svg></mjx-container> 为有效折射率。为方便计算，后文将 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.593ex" role="img" focusable="false" viewBox="0 -693 600 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g></g></g></svg></mjx-container> 简写为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>。</p>
<p>各界面的菲涅尔反射系数和透射系数分别记为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1241.1 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1241.1 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1241.1 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1241.1 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container> 和 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.791ex" role="img" focusable="false" viewBox="0 -626 1151.1 791.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.791ex" role="img" focusable="false" viewBox="0 -626 1151.1 791.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.756ex" role="img" focusable="false" viewBox="0 -626 1151.1 776"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.756ex" role="img" focusable="false" viewBox="0 -626 1151.1 776"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>。下标表示光从一个介质传播到另一个介质的方向，例如：  </p>
<ul>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1241.1 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container> 表示光从折射率为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1036.6 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container> 的介质入射到折射率为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1036.6 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container> 的介质时的反射系数，  </li>
<li>其他符号可依此类推。</li>
</ul>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.927ex;" xmlns="http://www.w3.org/2000/svg" width="31.821ex" height="4.775ex" role="img" focusable="false" viewBox="0 -1259 14065.1 2110.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2574.7,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(6310.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(6588.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(7754.9,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(9273.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(10329.5,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.891ex;" xmlns="http://www.w3.org/2000/svg" width="31.821ex" height="4.74ex" role="img" focusable="false" viewBox="0 -1259 14065.1 2095"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2574.7,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(6310.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(6588.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(7754.9,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(9273.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(10329.5,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>有了菲涅尔反射比和透射比，那我们就可以求出各反射光波的振幅，假设入射光的振幅为1，因此我们可以求出第1条到第\ j\ 条反射光的振幅分别为</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.708ex;" xmlns="http://www.w3.org/2000/svg" width="53.592ex" height="2.9ex" role="img" focusable="false" viewBox="0 -968.8 23687.5 1281.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1241.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(1519.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(2685.8,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(3836.9,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(4988,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(6229.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(7470.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(7748.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(8914.9,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(10066,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(11217.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-253.5) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(12458.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(13699.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(13977.3,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(15144,0)"><path data-c="22EF" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250ZM525 250Q525 274 542 292T585 310Q609 310 627 294T646 251Q646 226 629 208T586 190T543 207T525 250ZM972 250Q972 274 989 292T1032 310Q1056 310 1074 294T1093 251Q1093 226 1076 208T1033 190T990 207T972 250Z"></path></g><g data-mml-node="mo" transform="translate(16482.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(16760.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(17927.3,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(19078.4,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(20229.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,497.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(21958.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,497.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/004.png" alt="photo"></p>
<h1 id="六、模型的建立与求解"><a href="#六、模型的建立与求解" class="headerlink" title="六、模型的建立与求解"></a>六、模型的建立与求解</h1><h2 id="6-1-问题一模型的建立"><a href="#6-1-问题一模型的建立" class="headerlink" title="6.1 问题一模型的建立"></a>6.1 问题一模型的建立</h2><p>由于折射率同时受掺杂载流子浓度和红外光波长的影响，载流子浓度不能作为定量引入，本节基于 <strong>Drude-Lorentz</strong> 理论建立了折射率与载流子浓度、红外光波长的模型。考虑到红外光的偏振特性，分别针对S偏振和P偏振光，用<strong>菲涅耳公式</strong>计算各界面的反射系数，进而得到理论反射率。随后通过最小二乘法，将理论反射率与实验反射率进行拟合，以此确定<strong>最优的载流子浓度和外延层厚度</strong>。再将最优载流子浓度重新代入上述模型，拟合得到折射率，依据波长与反射率曲线中干涉条纹的相邻极值点，利用极值点差法计算外延层的厚度。最后，将通过统计得到的实际外延层厚度与拟合得到的外延层厚度进行对比，验证计算结果的准确性，上述数学模型的流程图如图3：<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/005.png" alt="photo"></p>
<h3 id="6-1-1-Drude-Lorentz-模型"><a href="#6-1-1-Drude-Lorentz-模型" class="headerlink" title="6.1.1 Drude - Lorentz 模型"></a>6.1.1 Drude - Lorentz 模型</h3><p>由题目可知，碳化硅外延层的折射率并非常数，其数值同时依赖于掺杂载流子浓度与红外光波长。若采用固定折射率值，忽略其影响将导致厚度计算结果出现偏差。因此，本节引入能够同时描述载流子浓度\ \rho\ 、波长\ \lambda\ 以及折射率三者关联的<strong>Drude - Lorentz 模型</strong>。<br>该模型是描述介质光学响应的经典物理模型，反应了折射率与波长、掺杂载流子浓度之间的关系，能够拟合和预测材料在宽光谱范围的光学性质，主要受两种机制影响：<br><strong>1.自由载流子效应Drude项</strong>：掺杂引入的自由电子或空穴在外加光场作用下发生振荡，对介电响应产生贡献。该效应随波长增加而愈发显著，表现为折射率随波长增大而减小。<br><strong>2.晶格振动与束缚电子效应Lorentz项</strong>：材料本身的晶格振动和电子在能带间的跃迁也会影响介电响应，通常在特定共振频率附近表现出强烈的色散和吸收。<br>综上，经典介电函数式[2][3]为：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.006ex;" xmlns="http://www.w3.org/2000/svg" width="49.358ex" height="6.911ex" role="img" focusable="false" viewBox="0 -1726.1 21816.4 3054.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D700" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path></g><g data-mml-node="mo" transform="translate(466,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(855,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(1477,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2143.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(3199.6,0)"><g data-mml-node="mi"><path data-c="1D700" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path></g><g data-mml-node="mi" transform="translate(499,-150) scale(0.707)"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g><g data-mml-node="mo" transform="translate(4677.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(5678.1,0)"><g data-mml-node="msubsup" transform="translate(1906.9,844.2)"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mn" transform="translate(655,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(655,-247) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-719.9)"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mn" transform="translate(655,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1280.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(2281,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(2626,0)"><g data-mml-node="mi"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="mi" transform="translate(551,-150) scale(0.707)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g></g><g data-mml-node="mi" transform="translate(3812.5,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g></g><rect width="4634.5" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10774.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="munder" transform="translate(11775,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="mi" transform="translate(576.3,-1084.4) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mfrac" transform="translate(13385.7,0)"><g data-mml-node="mrow" transform="translate(2407.7,892.2)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(646,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="msubsup" transform="translate(987.3,0)"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mn" transform="translate(655,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(655,-287.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-784.5)"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mn" transform="translate(655,353.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(655,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1572.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2572.3,0)"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mn" transform="translate(655,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(3853.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(4853.3,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(5198.3,0)"><g data-mml-node="mi"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="mi" transform="translate(551,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mi" transform="translate(6090.7,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g></g><rect width="6912.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(20538.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(20927.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(21427.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<p>其中，</p>
<ul>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.579ex;" xmlns="http://www.w3.org/2000/svg" width="8.82ex" height="4.615ex" role="img" focusable="false" viewBox="0 -1342 3898.6 2040"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(899.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mstyle" transform="translate(1955.6,0)"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mi" transform="translate(1070,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g><g data-mml-node="mi" transform="translate(680,-686)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><rect width="1703" height="60" x="120" y="220"></rect></g></g></g></g></svg></mjx-container>，角频率与波长的关系；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.927ex;" xmlns="http://www.w3.org/2000/svg" width="11.428ex" height="5.343ex" role="img" focusable="false" viewBox="0 -1509.9 5051.3 2361.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mn" transform="translate(655,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(655,-247) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g><g data-mml-node="mo" transform="translate(1338.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mstyle" transform="translate(2394.2,0)"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(618.8,676)"><g data-mml-node="mi"><path data-c="1D70C" d="M58 -216Q25 -216 23 -186Q23 -176 73 26T127 234Q143 289 182 341Q252 427 341 441Q343 441 349 441T359 442Q432 442 471 394T510 276Q510 219 486 165T425 74T345 13T266 -10H255H248Q197 -10 165 35L160 41L133 -71Q108 -168 104 -181T92 -202Q76 -216 58 -216ZM424 322Q424 359 407 382T357 405Q322 405 287 376T231 300Q217 269 193 170L176 102Q193 26 260 26Q298 26 334 62Q367 92 389 158T418 266T424 322Z"></path></g><g data-mml-node="msup" transform="translate(517,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mn" transform="translate(499,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D700" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path></g><g data-mml-node="mn" transform="translate(499,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="msup" transform="translate(902.6,0)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(911,289) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g></g></g><rect width="2417.1" height="60" x="120" y="220"></rect></g></g></g></g></svg></mjx-container>，等离子体频率平方表达式；</li>
</ul>
<p>各符号含义如下：</p>
<ul>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.98ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 433 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g></g></svg></mjx-container>：真空中的光速；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.842ex" height="1.38ex" role="img" focusable="false" viewBox="0 -452 1256.1 609.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D700" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path></g><g data-mml-node="mi" transform="translate(499,-150) scale(0.707)"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g></g></svg></mjx-container>：高频极限介电常数；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="2.4ex" height="1.652ex" role="img" focusable="false" viewBox="0 -443 1060.7 730.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mi" transform="translate(655,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g></g></g></svg></mjx-container>：等离子体频率；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.17ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 517 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70C" d="M58 -216Q25 -216 23 -186Q23 -176 73 26T127 234Q143 289 182 341Q252 427 341 441Q343 441 349 441T359 442Q432 442 471 394T510 276Q510 219 486 165T425 74T345 13T266 -10H255H248Q197 -10 165 35L160 41L133 -71Q108 -168 104 -181T92 -202Q76 -216 58 -216ZM424 322Q424 359 407 382T357 405Q322 405 287 376T231 300Q217 269 193 170L176 102Q193 26 260 26Q298 26 334 62Q367 92 389 158T418 266T424 322Z"></path></g></g></g></svg></mjx-container>：载流子浓度；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.054ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 466 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g></g></svg></mjx-container>：元电荷；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.042ex" height="1.397ex" role="img" focusable="false" viewBox="0 -452 902.6 617.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D700" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path></g><g data-mml-node="mn" transform="translate(499,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container>：真空介电常数；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.974ex" height="1.59ex" role="img" focusable="false" viewBox="0 -691.8 1314.6 702.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(911,363) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g></g></g></g></svg></mjx-container>：载流子的有效质量；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="2.684ex" height="1.486ex" role="img" focusable="false" viewBox="0 -441 1186.5 657"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="mi" transform="translate(551,-150) scale(0.707)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g></g></g></g></svg></mjx-container>：Drude 阻尼系数；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="3.054ex" height="1.668ex" role="img" focusable="false" viewBox="0 -443 1349.9 737.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="TeXAtom" transform="translate(655,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g></svg></mjx-container>：第 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.462ex;" xmlns="http://www.w3.org/2000/svg" width="0.932ex" height="1.957ex" role="img" focusable="false" viewBox="0 -661 412 865"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></svg></mjx-container> 个 Lorentz 振子的共振频率；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="2.019ex" height="1.663ex" role="img" focusable="false" viewBox="0 -441 892.3 735.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="mi" transform="translate(551,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></svg></mjx-container>：第 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.462ex;" xmlns="http://www.w3.org/2000/svg" width="0.932ex" height="1.957ex" role="img" focusable="false" viewBox="0 -661 412 865"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></svg></mjx-container> 个 Lorentz 振子的阻尼系数。</li>
</ul>
<p>上述常数和系数在已有文献中给定 [4]。</p>
<p>通过麦克斯韦方程组与介质本构关系推导 [3]，复折射率 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.525ex" height="2.312ex" role="img" focusable="false" viewBox="0 -772 2000 1022"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,-50) translate(-278 0)"><path data-c="2DC" d="M374 597Q337 597 269 627T160 658Q101 658 34 606L24 597L12 611Q1 624 1 626Q1 627 27 648T55 671Q120 722 182 722Q219 722 286 692T395 661Q454 661 521 713L531 722L543 708Q554 695 554 693Q554 692 528 671T500 648Q434 597 374 597Z"></path></g></g></g><g data-mml-node="mo" transform="translate(600,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(989,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(1611,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> 可由介电函数得到：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 38.908ex;"><svg style="vertical-align: -1.538ex; min-width: 38.908ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="4.208ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -1180)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 1180) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="6520.8 -1180 1 1860"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,-145.3)"><g data-mml-node="mtd"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,-50) translate(-278 0)"><path data-c="2DC" d="M374 597Q337 597 269 627T160 658Q101 658 34 606L24 597L12 611Q1 624 1 626Q1 627 27 648T55 671Q120 722 182 722Q219 722 286 692T395 661Q454 661 521 713L531 722L543 708Q554 695 554 693Q554 692 528 671T500 648Q434 597 374 597Z"></path></g></g></g><g data-mml-node="mo" transform="translate(600,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(989,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(1611,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msqrt" transform="translate(3333.6,0)"><g transform="translate(1020,0)"><g data-mml-node="mi"><path data-c="1D700" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path></g><g data-mml-node="mo" transform="translate(466,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(855,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(1477,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(0,115.3)"><path data-c="221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path></g><rect width="1866" height="60" x="1020" y="1205.3"></rect></g><g data-mml-node="mo" transform="translate(6497.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(7553.1,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(8153.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(8542.1,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(9164.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9775.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(10775.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(11120.6,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(11641.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(12030.6,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(12652.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -1180 1 1860"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:2" transform="translate(0,604.7)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
<p>其中：</p>
<ul>
<li>实部 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.525ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2000 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(600,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(989,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(1611,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> 为碳化硅外延层的折射率 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1036.6 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container>；</li>
<li>虚部 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.346ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1921 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(521,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(910,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(1532,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> 为消光系数。</li>
</ul>
<h3 id="6-1-2-光的反射率模型"><a href="#6-1-2-光的反射率模型" class="headerlink" title="6.1.2 光的反射率模型"></a>6.1.2 光的反射率模型</h3><p>针对光在空气 - 外延层 - 衬底三层介质中的反射，需结合界面反射系数与双光束干涉原理进行分析，最终建立反射率与外延层厚度、波长、载流子浓度等参数的关系。<br><strong>1.单界面反射系数</strong><br>对于空气 - 外延层界面，反射系数r_{01}表达式为：<br>空气–外延层界面（0→1）的反射系数为：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.927ex;" xmlns="http://www.w3.org/2000/svg" width="55.142ex" height="5.051ex" role="img" focusable="false" viewBox="0 -1381 24372.6 2232.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2574.7,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="8649.3" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(11464,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(11742,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msubsup" transform="translate(12908.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(14427.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(15483.3,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="8649.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>外延层–衬底界面（1→2）的反射系数为：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.891ex;" xmlns="http://www.w3.org/2000/svg" width="55.142ex" height="5.016ex" role="img" focusable="false" viewBox="0 -1381 24372.6 2217"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2574.7,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><rect width="8649.3" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(11464,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(11742,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msubsup" transform="translate(12908.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(14427.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(15483.3,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1203.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(2541.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2707.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3835.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4835.9,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(6039.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7377.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7543.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><rect width="8649.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p><strong>2. 双光束干涉</strong></p>
<p>考虑到为双光束干涉，总反射系数只需考虑第一束与第二束光的振幅比例与相位差。分别对 S 偏振和 P 偏振进行分析，可得总振幅反射系数 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.73ex;" xmlns="http://www.w3.org/2000/svg" width="4.497ex" height="2.258ex" role="img" focusable="false" viewBox="0 -675.5 1987.8 998.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-314.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.735ex;" xmlns="http://www.w3.org/2000/svg" width="4.497ex" height="2.553ex" role="img" focusable="false" viewBox="0 -803.3 1987.8 1128.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-317.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g></g></g></svg></mjx-container> 和总反射率 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.73ex;" xmlns="http://www.w3.org/2000/svg" width="5.194ex" height="2.275ex" role="img" focusable="false" viewBox="0 -683 2295.8 1005.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-314.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.735ex;" xmlns="http://www.w3.org/2000/svg" width="5.194ex" height="2.553ex" role="img" focusable="false" viewBox="0 -803.3 2295.8 1128.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-317.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g></g></g></svg></mjx-container> 的表达式如下：</p>
<p><strong>S 偏振：</strong></p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.617ex;" xmlns="http://www.w3.org/2000/svg" width="43.076ex" height="2.76ex" role="img" focusable="false" viewBox="0 -947.5 19039.7 1220.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-264.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2265.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(3321.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(4784.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(5784.9,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(6936,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(8087.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(9328.2,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10985.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(11263.3,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msubsup" transform="translate(12429.9,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-264.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(15003.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(16059.3,0)"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msubsup" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-264.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2265.8,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g></g><g data-mml-node="mn" transform="translate(2576.8,476.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
<p>由于 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.703ex;" xmlns="http://www.w3.org/2000/svg" width="42.678ex" height="2.589ex" role="img" focusable="false" viewBox="0 -833.9 18863.7 1144.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1151.1,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2580,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(3635.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(4358,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(5358.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(5747.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-295) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(6988.3,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(8091.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(9147.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(9869.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(10869.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(11258.9,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-295) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(12500,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(13603.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(14659.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(15381.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(16381.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-295) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(17622.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-295) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>，代入后得：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.95ex;" xmlns="http://www.w3.org/2000/svg" width="77.271ex" height="3.48ex" role="img" focusable="false" viewBox="0 -1118 34153.8 1538"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-264.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2573.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(3629.4,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><svg width="278" height="1340" y="-420" x="27.5" viewBox="0 -166 278 1340"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,2.012)"></path></svg></g><g data-mml-node="msubsup" transform="translate(333,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1796.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mrow" transform="translate(2796.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path></g><g data-mml-node="mn" transform="translate(458,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1180.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2180.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2569.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3810.6,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4636.1,0) translate(0 -0.5)"><path data-c="29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path></g></g><g data-mml-node="msubsup" transform="translate(7890.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(9131.8,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10788.8,0)"><svg width="278" height="1340" y="-420" x="27.5" viewBox="0 -166 278 1340"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,2.012)"></path></svg></g></g><g data-mml-node="mn" transform="translate(11154.8,647.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(15465.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(16521.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(16910.3,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(18151.4,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(19199.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(20199.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msubsup" transform="translate(20699.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(21940.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mi" transform="translate(23348.3,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(24686.3,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(24852.9,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mo" transform="translate(25519.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(26519.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(26908.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(28149.5,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mrow" transform="translate(29141.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M202 -349V850H394V810H242V-309H394V-349H202Z"></path></g><g data-mml-node="mn" transform="translate(417,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1139.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2139.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2528.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,413) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3769.6,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4595.1,0) translate(0 -0.5)"><path data-c="5D" d="M22 810V850H214V-349H22V-309H174V810H22Z"></path></g></g></g></g></svg></mjx-container></p>
<p><strong>P 偏振：</strong></p>
<p>同理可得：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.735ex;" xmlns="http://www.w3.org/2000/svg" width="24.854ex" height="2.817ex" role="img" focusable="false" viewBox="0 -920 10985.3 1244.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-317.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2265.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(3321.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(4784.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(5784.9,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(6936,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(8087.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(9328.2,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g></g></g></svg></mjx-container></p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.95ex;" xmlns="http://www.w3.org/2000/svg" width="77.271ex" height="3.48ex" role="img" focusable="false" viewBox="0 -1118 34153.8 1538"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-317.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2573.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(3629.4,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><svg width="278" height="1340" y="-420" x="27.5" viewBox="0 -166 278 1340"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,2.012)"></path></svg></g><g data-mml-node="msubsup" transform="translate(333,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1796.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mrow" transform="translate(2796.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path></g><g data-mml-node="mn" transform="translate(458,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1180.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2180.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2569.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3810.6,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4636.1,0) translate(0 -0.5)"><path data-c="29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path></g></g><g data-mml-node="msubsup" transform="translate(7890.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(9131.8,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10788.8,0)"><svg width="278" height="1340" y="-420" x="27.5" viewBox="0 -166 278 1340"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,2.012)"></path></svg></g></g><g data-mml-node="mn" transform="translate(11154.8,647.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(15465.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(16521.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(16910.3,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(18151.4,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(19199.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(20199.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msubsup" transform="translate(20699.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(21940.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mi" transform="translate(23348.3,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(24686.3,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(24852.9,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mo" transform="translate(25519.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(26519.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(26908.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(28149.5,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mrow" transform="translate(29141.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M202 -349V850H394V810H242V-309H394V-349H202Z"></path></g><g data-mml-node="mn" transform="translate(417,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1139.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2139.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2528.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(484,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3769.6,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4595.1,0) translate(0 -0.5)"><path data-c="5D" d="M22 810V850H214V-349H22V-309H174V810H22Z"></path></g></g></g></g></svg></mjx-container></p>
<p><strong>3.总反射率的计算</strong><br>实验光通常是非偏振光，它等概率包含S偏振和P偏振[5]。因此总的理论反射率为：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="36.89ex" height="5.145ex" role="img" focusable="false" viewBox="0 -1588.2 16305.4 2274.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1097.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1486.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2773.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3217.8,0)"><path data-c="1D70C" d="M58 -216Q25 -216 23 -186Q23 -176 73 26T127 234Q143 289 182 341Q252 427 341 441Q343 441 349 441T359 442Q432 442 471 394T510 276Q510 219 486 165T425 74T345 13T266 -10H255H248Q197 -10 165 35L160 41L133 -71Q108 -168 104 -181T92 -202Q76 -216 58 -216ZM424 322Q424 359 407 382T357 405Q322 405 287 376T231 300Q217 269 193 170L176 102Q193 26 260 26Q298 26 334 62Q367 92 389 158T418 266T424 322Z"></path></g><g data-mml-node="mo" transform="translate(3734.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4179.4,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(4699.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5366.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(6422,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(8995.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(10051.4,0)"><g data-mml-node="mrow" transform="translate(220,784.9)"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-314.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2518,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(3518.3,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,490.8) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-317.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g></g></g><g data-mml-node="mn" transform="translate(2877,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="6014.1" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<h3 id="6-1-3-最小二乘优化模型"><a href="#6-1-3-最小二乘优化模型" class="headerlink" title="6.1.3 最小二乘优化模型"></a>6.1.3 最小二乘优化模型</h3><p>基于理论反射率与附件给定的反射率，我们构建最小二乘优化问题进行数值优化，通过拟合可得到最优载流子浓度以及外延层厚度，进而确定复折射率随波长的分布，目标函数如下：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="34.638ex" height="6.74ex" role="img" focusable="false" viewBox="0 -1733 15309.8 2978.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(270.3,-657.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D70C" d="M58 -216Q25 -216 23 -186Q23 -176 73 26T127 234Q143 289 182 341Q252 427 341 441Q343 441 349 441T359 442Q432 442 471 394T510 276Q510 219 486 165T425 74T345 13T266 -10H255H248Q197 -10 165 35L160 41L133 -71Q108 -168 104 -181T92 -202Q76 -216 58 -216ZM424 322Q424 359 407 382T357 405Q322 405 287 376T231 300Q217 269 193 170L176 102Q193 26 260 26Q298 26 334 62Q367 92 389 158T418 266T424 322Z"></path></g><g data-mml-node="mo" transform="translate(517,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(795,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1073,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g><g data-mml-node="mfrac" transform="translate(1833.7,0)"><g data-mml-node="mn" transform="translate(495.5,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(220,-686)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><rect width="1251" height="60" x="120" y="220"></rect></g><g data-mml-node="munderover" transform="translate(3491.3,0)"><g data-mml-node="mo" transform="translate(40.3,0)"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(0,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(390.7,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g><g data-mml-node="msup" transform="translate(5182.5,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(1037,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1426,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2712.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3324.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4324.3,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(792,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(5421.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(5810.5,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7097.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7542.1,0)"><path data-c="1D70C" d="M58 -216Q25 -216 23 -186Q23 -176 73 26T127 234Q143 289 182 341Q252 427 341 441Q343 441 349 441T359 442Q432 442 471 394T510 276Q510 219 486 165T425 74T345 13T266 -10H255H248Q197 -10 165 35L160 41L133 -71Q108 -168 104 -181T92 -202Q76 -216 58 -216ZM424 322Q424 359 407 382T357 405Q322 405 287 376T231 300Q217 269 193 170L176 102Q193 26 260 26Q298 26 334 62Q367 92 389 158T418 266T424 322Z"></path></g><g data-mml-node="mo" transform="translate(8059.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8503.7,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(9023.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9412.7,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g><g data-mml-node="mn" transform="translate(9723.7,477.1) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
<p>其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.389ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2823.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1148,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2434.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> 表示在第 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.986ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 878 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container> 个波长点 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.911ex" height="1.927ex" role="img" focusable="false" viewBox="0 -694 1286.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container> 处测得的实验反射率数据。</p>
<h3 id="6-1-4-相邻极值点差法交叉验证模型"><a href="#6-1-4-相邻极值点差法交叉验证模型" class="headerlink" title="6.1.4 相邻极值点差法交叉验证模型"></a>6.1.4 相邻极值点差法交叉验证模型</h3><p>为了进一步验证拟合得到的外延层厚度 d 的可靠性，利用最优载流子浓度计算折射率，再采用相邻极值点差法计算厚度，并与拟合结果对比。该方法基于干涉条纹的周期性特征，通过相邻峰值对应的波数差推导厚度，是红外干涉法中经典的简化测量手段，具体步骤如下：<br><strong>1.最优载流子浓度求折射率</strong><br>得到最优载流子浓度后，将其代入(1)式得到：</p>
<p>$$<br>\varepsilon(\lambda) = \varepsilon_\infty </p>
<ul>
<li>\frac{ \dfrac{\rho e^2}{\varepsilon_0 m^\ast} }{ \left( \dfrac{2\pi c}{\lambda} \right)^2 + i \gamma_D \left( \dfrac{2\pi c}{\lambda} \right) }</li>
</ul>
<ul>
<li>\sum_j \frac{ S_j \omega_{0j}^2 }{ \omega_{0j}^2 - \left( \dfrac{2\pi c}{\lambda} \right)^2 - i \gamma_j \left( \dfrac{2\pi c}{\lambda} \right) }<br>$$</li>
</ul>
<p>通过复折射率与介电函数的关联(2)式得到：</p>
<p>$$<br>\widetilde{n}_1^<em>(\omega) = \sqrt{\varepsilon(\omega)} = n_1^</em>(\omega) + i k_1(\omega)<br>$$</p>
<p>提取复折射率的实部，此为碳化硅外延层实际折射率。</p>
<p><strong>2. 干涉极值条件</strong></p>
<p>双光束干涉通过波峰与波谷的简单叠加，会产生<strong>相长干涉</strong>和<strong>相消干涉</strong>。设第 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.986ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 878 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container> 级峰值对应的波长为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.911ex" height="1.927ex" role="img" focusable="false" viewBox="0 -694 1286.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>，对应的外延层等效厚度为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="5.677ex" height="2.237ex" role="img" focusable="false" viewBox="0 -694 2509.4 989"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g></g></g></g></g></svg></mjx-container>。</p>
<p><strong>相长干涉：</strong><br>当总光程差为波长的整数倍时，两束光同相叠加，反射率达到极大值：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 43.28ex;"><svg style="vertical-align: -0.616ex; min-width: 43.28ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="2.364ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -772.5)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 772.5) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="7486.8 -772.5 1 1045"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,22.5)"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msubsup" transform="translate(500,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(633,413) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mn" transform="translate(633,-247) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1536.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1925.6,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3212.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3601.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(4046.1,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(6555.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7000.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(8338.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(8504.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(9410.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(9799.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(11086.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11752.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(12808.7,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(13686.7,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -772.5 1 1045"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:3" transform="translate(0,772.5)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
<p><strong>相消干涉：</strong><br>当总光程差为波长的半整数倍时，两束光反相叠加，反射率达到极小值：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 51.502ex;"><svg style="vertical-align: -2.148ex; min-width: 51.502ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="5.428ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -1449.5)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 1449.5) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="9304 -1449.5 1 2399"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msubsup" transform="translate(500,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(633,413) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mn" transform="translate(633,-247) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1536.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1925.6,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3212.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3601.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(4046.1,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(6555.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7000.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(8338.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(8504.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(9410.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(9799.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(11086.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11752.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(12808.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mi" transform="translate(736,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1836.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mfrac" transform="translate(2836.4,0)"><g data-mml-node="mn" transform="translate(220,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mn" transform="translate(220,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="700" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3776.4,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g><g data-mml-node="msub" transform="translate(17321.1,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -1449.5 1 2399"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:4"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
<p><strong>4. 实际厚度推导</strong></p>
<p>对于两个相邻的第 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.986ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 878 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container> 和 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.883ex" height="1.692ex" role="img" focusable="false" viewBox="0 -666 2600.4 748"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1100.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2100.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container> 级峰值对应的波长 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.911ex" height="1.927ex" role="img" focusable="false" viewBox="0 -694 1286.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container> 和 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex;" xmlns="http://www.w3.org/2000/svg" width="4.956ex" height="2.041ex" role="img" focusable="false" viewBox="0 -694 2190.5 902"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container>，有：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 43.28ex;"><svg style="vertical-align: -0.616ex; min-width: 43.28ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="2.364ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -772.5)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 772.5) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="7486.8 -772.5 1 1045"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,22.5)"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msubsup" transform="translate(500,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(633,413) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mn" transform="translate(633,-247) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1536.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1925.6,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3212.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3601.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(4046.1,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(6555.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7000.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(8338.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(8504.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(9410.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(9799.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(11086.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11752.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(12808.7,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(13686.7,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -772.5 1 1045"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:3" transform="translate(0,772.5)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 55.07ex;"><svg style="vertical-align: -0.616ex; min-width: 55.07ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="2.364ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -772.5)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 772.5) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="10092.5 -772.5 1 1045"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,22.5)"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msubsup" transform="translate(500,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(633,413) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mn" transform="translate(633,-247) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1536.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1925.6,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4116.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4505.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(4949.7,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(7459.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7903.8,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(9241.8,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(9408.4,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(10314,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(10703,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12893.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(13560.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(14616.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(15005.1,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(16105.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(17105.5,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(17605.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msub" transform="translate(17994.5,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -772.5 1 1045"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:4" transform="translate(0,772.5)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
<p>由于 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.911ex" height="1.927ex" role="img" focusable="false" viewBox="0 -694 1286.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container> 与 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex;" xmlns="http://www.w3.org/2000/svg" width="4.956ex" height="2.041ex" role="img" focusable="false" viewBox="0 -694 2190.5 902"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container> 相邻，波长差异较小，假设在相邻极值点之间折射率变化很小，因此我们可将它们取近似值即相邻极值点对应数据的平均值，具体如下：</p>
<p>$$<br>n_1^<em>(\lambda_m) \approx n_1^</em>(\lambda_{m+1}) = \bar{n}<em>1^* = \frac{n_1^<em>(\lambda_m) + n_1^</em>(\lambda</em>{m+1})}{2}<br>$$</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="62.853ex" height="4.855ex" role="img" focusable="false" viewBox="0 -1460 27780.9 2146"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(2410.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2799.2,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4086.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4752.8,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mi" transform="translate(5808.6,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7146.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7313.3,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(8218.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(8607.8,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10798.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11465.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mover" transform="translate(12520.9,0)"><g data-mml-node="mrow"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,637)"><svg width="2410.2" height="237" x="0" y="148" viewBox="602.6 148 2410.2 237"><path data-c="2013" d="M0 248V285H499V248H0Z" transform="scale(7.231,1)"></path></svg></g></g><g data-mml-node="mo" transform="translate(15208.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(16264.7,0)"><g data-mml-node="mrow" transform="translate(220,710)"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(2410.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2799.2,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4086.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4697.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5697.5,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(7035.5,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(7202.2,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(8107.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(8496.7,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10687.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mn" transform="translate(5508.1,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="11276.2" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>联立公式 (3) 与 (4) 可得：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 54.593ex;"><svg style="vertical-align: -1.995ex; min-width: 54.593ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="5.122ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -1382)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 1382) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="9987.1 -1382 1 2264"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,12)"><g data-mml-node="mtd"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(878,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2442.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(3498.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3887.4,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4987.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(5987.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(6487.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msub" transform="translate(6876.8,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mstyle" transform="translate(9067.4,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(10345.1,0)"><path data-c="21D2" d="M580 514Q580 525 596 525Q601 525 604 525T609 525T613 524T615 523T617 520T619 517T622 512Q659 438 720 381T831 300T927 263Q944 258 944 250T935 239T898 228T840 204Q696 134 622 -12Q618 -21 615 -22T600 -24Q580 -24 580 -17Q580 -13 585 0Q620 69 671 123L681 133H70Q56 140 56 153Q56 168 72 173H725L735 181Q774 211 852 250Q851 251 834 259T789 283T735 319L725 327H72Q56 332 56 347Q56 360 70 367H681L671 377Q638 412 609 458T580 514Z"></path></g><g data-mml-node="mstyle" transform="translate(11345.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(12622.9,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(13778.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(14834.5,0)"><g data-mml-node="msub" transform="translate(1474.6,676)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1509.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2509.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g><rect width="4899.8" height="60" x="120" y="220"></rect></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -1382 1 2264"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:5" transform="translate(0,762)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
<p>将式 (5) 代入式 (3)，可得第 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.986ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 878 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container> 对相邻极值对应的等效厚度：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 37.936ex;"><svg style="vertical-align: -2.097ex; min-width: 37.936ex;" xmlns="http://www.w3.org/2000/svg" width="100%" height="5.324ex" role="img" focusable="false"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.0181,-0.0181) translate(0, -1426.7)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 1426.7) matrix(1 0 0 -1 0 0) scale(55.25)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="6305.9 -1426.7 1 2353.3"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,56.7)"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g><g data-mml-node="mo" transform="translate(2696,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2974,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3604.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4660.3,0)"><g data-mml-node="mrow" transform="translate(1875.8,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1509.1,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msub" transform="translate(2009.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msubsup" transform="translate(500,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mo" transform="translate(633,328.9) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mn" transform="translate(633,-297.3) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1758.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(2259,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(3597,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(3763.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(4891.4,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(5391.7,0)"><path data-c="394" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="msub" transform="translate(6224.7,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g><rect width="7711.5" height="60" x="120" y="220"></rect></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -1426.7 1 2353.3"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:6" transform="translate(0,806.7)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(389,0)"></path><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" transform="translate(889,0)"></path></g></g></g></g></svg></g></g></g></g></svg></mjx-container></p>
<p>其中：</p>
<ul>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.564ex;" xmlns="http://www.w3.org/2000/svg" width="19.704ex" height="2.26ex" role="img" focusable="false" viewBox="0 -749.5 8709.2 999"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="394" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="msub" transform="translate(833,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2397.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mrow" transform="translate(3453.4,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2690.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(3691,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4977.8,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g></g></g></g></svg></mjx-container>，取绝对值是为了避免因波长随级数增大而减小导致负差值；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.595ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="2.163ex" role="img" focusable="false" viewBox="0 -693 1036.6 956.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mo" transform="translate(633,363) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mn" transform="translate(633,-263.2) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container> 为相邻波长处折射率的平均值；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="5.453ex" height="1.934ex" role="img" focusable="false" viewBox="0 -705 2410.2 855"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(1338,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1504.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container> 为对应角度余弦的平均值（见前文近似）。</li>
</ul>
<p><strong>5. 统计得到最终的实际厚度 d</strong></p>
<p>对于每一对相邻极值 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="11.199ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4950 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1675.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(2120.5,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(2370.5,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4561,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>，代入公式 (6) 可计算出对应的等效厚度：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="31.812ex" height="2.237ex" role="img" focusable="false" viewBox="0 -694 14061.1 989"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g><g data-mml-node="mo" transform="translate(2696,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(2974,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3059.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(3504.2,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(3754.2,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g><g data-mml-node="mo" transform="translate(2696,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(2974,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6813.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(7258.3,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(7675,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(9013.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mtext" transform="translate(9458.3,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(9708.3,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g><g data-mml-node="mo" transform="translate(2696,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2974,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(4025,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(4803,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container></p>
<p>其中 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.378ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 1051 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g></svg></mjx-container> 为测量到的总极值点数（即波长峰值或谷值个数），因此共有 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="6.275ex" height="1.731ex" role="img" focusable="false" viewBox="0 -683 2773.4 765"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(1273.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2273.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container> 个相邻间隔。</p>
<p>最终，取这些厚度的算术平均值作为外延层的实际厚度：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="23.47ex" height="6.74ex" role="img" focusable="false" viewBox="0 -1733 10374 2978.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(797.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1853.6,0)"><g data-mml-node="mn" transform="translate(1356.7,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(1273.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2273.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><rect width="2973.4" height="60" x="120" y="220"></rect></g><g data-mml-node="munderover" transform="translate(5233.7,0)"><g data-mml-node="mo" transform="translate(101.4,0)"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(61.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(878,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1656,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(0,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(1051,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1829,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msub" transform="translate(7047.2,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(553,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(500,0)"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(1056,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1362,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1862,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2140,0)"></path></g><g data-mml-node="mo" transform="translate(2696,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2974,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></mjx-container></p>
<p><strong>6. 相对误差交叉验证</strong><br>为验证计算解决的可靠性，将统计得到最终的实际厚度 d^\prime  和拟合得到的厚度 d 进行一个对比。由于相对误差更能反映测量结果的可信程度，本节引入了相对误差这一概念进行交叉验证。<br>通过计算拟合值与实际值之差与实际值的比值两者之间的偏差，其定义为：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.575ex;" xmlns="http://www.w3.org/2000/svg" width="15.45ex" height="5.345ex" role="img" focusable="false" viewBox="0 -1666.5 6829 2362.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mi" transform="translate(759,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(1800.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(2856.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,709.5)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msup" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g><g data-mml-node="mo" transform="translate(1297.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(2297.9,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2817.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g></g><g data-mml-node="msup" transform="translate(1369.2,-686)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,289) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g><rect width="3295.9" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mn" transform="translate(3568.9,1195.5) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p>
<p>由于测量噪声及模型近似，计算得到的厚度存在波动。通过相对误差评估结果的合理性。若相对误差在10%以内，则认为厚度计算是可靠的。<br>综上，上述数学模型的流程图为：</p>
<h2 id="6-2-问题二模型的建立与求解"><a href="#6-2-问题二模型的建立与求解" class="headerlink" title="6.2 问题二模型的建立与求解"></a>6.2 问题二模型的建立与求解</h2><p>根据问题一的数学模型，可以通过编写程序得到结果，其算法流程图为<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/006.png" alt="photo"></p>
<h3 id="6-2-1数据分布分析"><a href="#6-2-1数据分布分析" class="headerlink" title="6.2.1数据分布分析"></a>6.2.1数据分布分析</h3><p>将数据导入并绘图，根据图5可知，附件1和附件2中均存在一定的噪声；存在反射率为0的数据；附件2中存在反射率大于100%的数据。部分数据显然是不符合物理意义的。因此，有必要进行数据预处理。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/007.png" alt="photo"></p>
<p>我们选取行业内常用的1818cm^-1以后的高波数区间[7]。该区段干涉条纹分辨率清晰，信噪比较高，存在稳定的周期，能够在减少低波数段不确定性影响的同时，提高碳化硅外延层厚度和载流子浓度拟合结果的准确性。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/008.png" alt="photo"></p>
<h3 id="6-2-2数据预处理"><a href="#6-2-2数据预处理" class="headerlink" title="6.2.2数据预处理"></a>6.2.2数据预处理</h3><p><strong>STEP1：数据归一化</strong><br>数据导入后，去除反射率为 0 的数据点，并将反射率限制在(0,\ 100]之间，为了后续计算，将反射率统一归一化到(0,\ 1]区间，以保证与理论反射率计算的一致性。</p>
<p><strong>STEP2：Savitizky-Golay滤波去噪</strong><br>为了抑制高频噪声并突出干涉条纹的主要特征，我们对归一化后的曲线进行平滑处理，具体采用自适应的Savitizky-Golay滤波方法，该方法通过局部多项式回归实现噪声滤除，从而避免削弱条纹峰谷结构。</p>
<p><strong>STEP3：PCHIP插值重采样</strong><br>由于我们去除了一些异常值，因此我们进一步查看当前数据的采样步长，发现附件一的采样步长约为0.482，附件2的采样步长为0.500，可以发现，两者的采样步长非常接近但不是一致的。为了便于对比与统一拟合，我们采用PCHIP插值方法对平滑后的两组数据以0.5cm^-1为步长重新采样。</p>
<h3 id="6-2-3算法流程"><a href="#6-2-3算法流程" class="headerlink" title="6.2.3算法流程"></a>6.2.3算法流程</h3><ol>
<li>Drude–Lorentz模型<br>首先我们根据Drude–Lorentz模型，求得复折射率，接着使用菲涅耳公式分别计算 s 偏振和 p 偏振下的界面反射系数，通过双干涉模型得到理论反射率曲线，对于实验中常见的非偏振光情形，反射率取s、p 偏振两种偏振结果的平均。</li>
<li>最小二乘拟合模型<br>然后使用最小二乘拟合，将理论反射率和实验中的反射率差值的平方作为优化目标，优化会得到拟合载流子浓度和拟合厚度，我们将得到的拟合载流子浓度回带入Drude–Lorentz模型求得折射率。</li>
<li>相邻极值点差法模型<br>紧接着通过相邻极值点差法计算厚度，方法核心是：<br><strong>（1）提取反射率极值点</strong>：条纹的极值对应不同干涉阶次，每两个相邻极值对应的波数间隔与厚度相关。<br><strong>（2）计算波数间隔</strong>：对极值波数求差，计算得到相邻波数的间隔、计算平均间隔和标准差。<br><strong>（3）折射率修正与厚度计算</strong>：将拟合得到的载流子浓度代入折射率计算公式得到修正的折射率，通过厚度计算公式得到每个相邻极值的厚度，最后取相邻厚度的平均值作为实际厚度。</li>
</ol>
<p>由于测量噪声及模型近似，计算得到的厚度存在波动。通过相对误差评估结果的合理性。若相对误差在10%以内，则认为厚度计算是可靠的。<br>在相邻极值点差法中，对于区间范围的选择，依据选取干涉条纹明显的、信噪比高的、极值间隔规律的区域。综合上述依据，选择1818-4000{cm}^{-1}波数区间，这个区间既保证条纹清晰、极值点充分，又能减少低波数段强吸收带来的不确定性，能够得到稳定且可信的厚度值。</p>
<ol start="4">
<li>进一步分析<br>为了进一步评估结果的可靠性，我们采用残差重采样的方法对拟合结果进行不确定度评估，在最小二乘拟合时，实验测得的反射率-模型计算得到的反射率就会得到一个残差，对残差做有放回的抽样，叠加到模型预测上得到伪观测，然后对伪观测重新拟合，从而获得一组拟合参数分布。<br>该方法的原理在于：残差可视为实验数据中未被模型解释的噪声部分，其统计特征反映了测量与模型误差。通过对残差进行重采样并叠加到模型预测值上，可在保持模型结构不变的前提下构造新的样本，进而模拟不同可能的实验观测情形。多次迭代后，拟合参数的分布即可反映模型在不确定性下的稳健性。</li>
</ol>
<h3 id="6-2-4模型求解"><a href="#6-2-4模型求解" class="headerlink" title="6.2.4模型求解"></a>6.2.4模型求解</h3><p>我们使用python求解计算得到载流子浓度、外延层厚度、折射率</p>
<p><strong>表1 问题2的求解</strong></p>
<table>
<thead>
<tr>
<th>载流子浓度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container> (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="4.117ex" height="1.885ex" role="img" focusable="false" viewBox="0 -833.2 1819.7 833.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></g><g data-mml-node="TeXAtom" transform="translate(866,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></g></g></svg></mjx-container>)</th>
<th>外延层厚度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 520 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container> (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="3.249ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 1436 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mtext" transform="translate(603,0)"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></g></g></g></svg></mjx-container>)</th>
<th>折射率 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></th>
</tr>
</thead>
<tbody><tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.947ex" height="2.005ex" role="img" focusable="false" viewBox="0 -864 3512.6 886"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(1722.4,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,393.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></td>
<td>8.54</td>
<td>2.184</td>
</tr>
</tbody></table>
<p>拟合得到的归一化相对误差约为6.60*10^-3，即理论反射率与实验反射率之间的平均相对偏差仅约为 0.660%。这一极小的误差表明，所建立的Drude-Lorentz单层膜模型能够准确描述外延层的光学响应，拟合结果在整个波段范围内与实验测量值高度一致，验证了模型在反映载流子浓度、外延层厚度及折射率等参数方面的可靠性和有效性。<br>进一步，将实验反射率与理论反射率进行对比，如下图7：<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/009.png" alt="photo"></p>
<p>观察到实验数据与理论数据绝对反射率偏差最大不超过3%，并且两者相位是几乎重合的，说明模型拟合得很好。<br>（1）相邻极值点差法得到的结果：<br>通过相邻极值点差法计算厚度得到平均厚度为：8.348um+-2.580um。<br>（2）残差重采样得到的结果：<br>通过残差重采样方法对厚度进行统计分析。<br>分析残差重采样样本中载流子浓度和厚度的分布特性，如下图所示<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/09/010.png" alt="photo"></p>
<p>由于残差重采样样本的分布偏离正态，采用百分位法计算 95% 置信区间，以更准确地反映参数的不确定性。<br>因此，得到外延层厚度为：8.68um，95%置信区间为：[6.14-11.57].<br>三个结果高度一致，均在可接受的误差范围内，进一步验证了外延层厚度的可靠性。</p>
<h2 id="6-3-问题三模型的建立与求解"><a href="#6-3-问题三模型的建立与求解" class="headerlink" title="6.3 问题三模型的建立与求解"></a>6.3 问题三模型的建立与求解</h2><h3 id="6-3-1-多光束干涉必要条件推导"><a href="#6-3-1-多光束干涉必要条件推导" class="headerlink" title="6.3.1 多光束干涉必要条件推导"></a>6.3.1 多光束干涉必要条件推导</h3><p><strong>1. 光学基本公式</strong></p>
<p>首先给出菲涅耳反射系数和透射系数。设空气、外延层、衬底的折射率分别为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1036.6 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1036.6 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1036.6 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container>，外延层几何厚度为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 520 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container>。各界面的菲涅耳反射系数和透射系数分别记为：</p>
<ul>
<li>反射系数：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1241.1 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1241.1 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1241.1 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1241.1 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></li>
<li>透射系数：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.791ex" role="img" focusable="false" viewBox="0 -626 1151.1 791.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.791ex" role="img" focusable="false" viewBox="0 -626 1151.1 791.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.756ex" role="img" focusable="false" viewBox="0 -626 1151.1 776"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.604ex" height="1.756ex" role="img" focusable="false" viewBox="0 -626 1151.1 776"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></li>
</ul>
<p>下标表示光从一个介质传播到另一个介质的方向，例如 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.808ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1241.1 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container> 表示从折射率为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.375ex" role="img" focusable="false" viewBox="0 -442 1036.6 607.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container> 的介质入射到折射率为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.345ex" height="1.339ex" role="img" focusable="false" viewBox="0 -442 1036.6 592"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container> 的介质时的反射系数，其余类推。<br>因此有：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.927ex;" xmlns="http://www.w3.org/2000/svg" width="31.821ex" height="4.775ex" role="img" focusable="false" viewBox="0 -1259 14065.1 2110.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2574.7,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(6310.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(6588.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(7754.9,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(9273.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(10329.5,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.891ex;" xmlns="http://www.w3.org/2000/svg" width="31.821ex" height="4.74ex" role="img" focusable="false" viewBox="0 -1259 14065.1 2095"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2574.7,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(6310.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(6588.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(7754.9,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(9273.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(10329.5,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1258.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2259,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><rect width="3495.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>有了菲涅尔反射比和透射比，那我们就可以求出各反射光波的振幅，假设入射光的振幅为1，因此我们可以求出第1条到第j条反射光的振幅分别为</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.708ex;" xmlns="http://www.w3.org/2000/svg" width="53.592ex" height="2.9ex" role="img" focusable="false" viewBox="0 -968.8 23687.5 1281.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1241.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(1519.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(2685.8,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(3836.9,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(4988,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(6229.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(7470.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(7748.2,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(8914.9,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(10066,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(11217.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-253.5) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(12458.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(13699.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(13977.3,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(15144,0)"><path data-c="22EF" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250ZM525 250Q525 274 542 292T585 310Q609 310 627 294T646 251Q646 226 629 208T586 190T543 207T525 250ZM972 250Q972 274 989 292T1032 310Q1056 310 1074 294T1093 251Q1093 226 1076 208T1033 190T990 207T972 250Z"></path></g><g data-mml-node="mo" transform="translate(16482.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mstyle" transform="translate(16760.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(17927.3,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(19078.4,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(20229.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,497.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(21958.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,497.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></p>
<p>任意两相邻反射光之间的相位差为：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.579ex;" xmlns="http://www.w3.org/2000/svg" width="16.79ex" height="4.704ex" role="img" focusable="false" viewBox="0 -1381 7421 2079"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mo" transform="translate(721.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1777.6,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="msub" transform="translate(1070,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(2106.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(2793.2,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(4131.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(4297.9,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mi" transform="translate(2530.2,-686)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><rect width="5403.4" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>由于各反射光相干，总反射振幅为所有反射波的叠加：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.709ex;" xmlns="http://www.w3.org/2000/svg" width="105.83ex" height="6.549ex" role="img" focusable="false" viewBox="0 -1697.4 46776.9 2894.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,134.8)"><g data-mml-node="mtd"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mtd" transform="translate(451,0)"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(1333.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2796.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(3797.1,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(4948.2,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(6099.3,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(7340.4,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(9219.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(10219.9,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(11371,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(12522.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(13763.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(15004.3,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(1278,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1623,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(17237.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(18237.4,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(19388.5,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(20539.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-253.5) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(21780.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(23021.8,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(1278,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1623,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(25254.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(26254.8,0)"><path data-c="22EF" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250ZM525 250Q525 274 542 292T585 310Q609 310 627 294T646 251Q646 226 629 208T586 190T543 207T525 250ZM972 250Q972 274 989 292T1032 310Q1056 310 1074 294T1093 251Q1093 226 1076 208T1033 190T990 207T972 250Z"></path></g><g data-mml-node="mtext" transform="translate(27593.5,0)"><path data-c="A0" d=""></path></g></g><g data-mml-node="mtd" transform="translate(30294.5,0)"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(1333.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2796.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(3797.1,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(4948.2,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(6099.3,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(7340.4,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="munderover" transform="translate(9164.1,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(124.5,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(368.4,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g><g data-mml-node="msup" transform="translate(10774.8,0)"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="msub" transform="translate(597,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1838.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3079.2,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4736.2,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mi" transform="translate(5366.2,876.6) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g></g></g></svg></mjx-container></p>
<p>该级数为等比级数，公比 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.564ex;" xmlns="http://www.w3.org/2000/svg" width="14.771ex" height="2.533ex" role="img" focusable="false" viewBox="0 -870 6528.8 1119.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1519.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(2760.2,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4417.2,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(4973,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(6028.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>，故可求和：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.085ex;" xmlns="http://www.w3.org/2000/svg" width="23.868ex" height="5.583ex" role="img" focusable="false" viewBox="0 -1546 10549.8 2467.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(728.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(1784.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(3247.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mfrac" transform="translate(4248.1,0)"><g data-mml-node="mrow" transform="translate(550.7,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1151.1,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(2302.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3543.3,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-756)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(1722.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(2963.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(4204.7,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g></g><rect width="6061.7" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>利用能量守恒关系（无吸收时）：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.594ex;" xmlns="http://www.w3.org/2000/svg" width="37.182ex" height="2.594ex" role="img" focusable="false" viewBox="0 -883.9 16434.6 1146.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1151.1,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2580,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(3635.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(4358,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msubsup" transform="translate(5358.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(6877.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(7932.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(8655.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msubsup" transform="translate(9655.3,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(11174.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(12230,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(12952.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(13952.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(15193.5,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></p>
<p>并结合 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="10.393ex" height="1.694ex" role="img" focusable="false" viewBox="0 -583 4593.8 748.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2574.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(3352.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>、<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="10.393ex" height="1.658ex" role="img" focusable="false" viewBox="0 -583 4593.8 733"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1518.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2574.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(3352.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container>，可进一步简化得：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.085ex;" xmlns="http://www.w3.org/2000/svg" width="18.295ex" height="5.583ex" role="img" focusable="false" viewBox="0 -1546 8086.2 2467.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(728.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1784.6,0)"><g data-mml-node="mrow" transform="translate(470,676)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1463.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2463.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3704.7,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-756)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(1722.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(2963.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(4204.7,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g></g><rect width="6061.7" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>此式给出振幅为 1 的入射光经单层膜系反射后所得反射光的合振幅，单层膜的反射率则为：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.483ex;" xmlns="http://www.w3.org/2000/svg" width="41.87ex" height="6.097ex" role="img" focusable="false" viewBox="0 -1597.4 18506.4 2694.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(1036.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2092.6,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(2370.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msup" transform="translate(2821.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mn" transform="translate(311,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(3813.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(4869.7,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msup" transform="translate(5320.7,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(484,413) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g></g><g data-mml-node="mo" transform="translate(6486,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(7541.8,0)"><g data-mml-node="mrow" transform="translate(470,763.5)"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-287.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1463.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2463.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-287.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(3926.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(4927.1,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msub" transform="translate(5427.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(6668.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mi" transform="translate(8076,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(9414,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(9580.6,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-784.5)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(1722.4,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,353.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msubsup" transform="translate(2963.6,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(484,353.6) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-297.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(4426.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(5427.1,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msub" transform="translate(5927.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(7168.2,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mi" transform="translate(8576,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(9914,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(10080.6,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g><rect width="10724.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p><strong>2.必要条件</strong><br><strong>（1）反射率足够大</strong><br>一个无穷级数<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.014ex;" xmlns="http://www.w3.org/2000/svg" width="16.557ex" height="6.549ex" role="img" focusable="false" viewBox="0 -1562.5 7318.2 2894.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munderover"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(124.5,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(368.4,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g><g data-mml-node="msup" transform="translate(1610.7,0)"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="msub" transform="translate(597,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1838.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(3079.2,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4736.2,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mi" transform="translate(5366.2,876.6) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></svg></mjx-container><br>只有在<strong>收敛</strong>的情况下，总反射振幅 r 能够得到一个具体的值，即需要满足<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.95ex;" xmlns="http://www.w3.org/2000/svg" width="15.02ex" height="3.032ex" role="img" focusable="false" viewBox="0 -920 6638.8 1340"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo"><svg width="278" height="1340" y="-420" x="27.5" viewBox="0 -166 278 1340"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,2.012)"></path></svg></g><g data-mml-node="msub" transform="translate(333,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1574.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msup" transform="translate(2815.2,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4472.2,0)"><svg width="278" height="1340" y="-420" x="27.5" viewBox="0 -166 278 1340"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,2.012)"></path></svg></g></g><g data-mml-node="mo" transform="translate(5083,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(6138.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></p>
<p>由于 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.837ex;" xmlns="http://www.w3.org/2000/svg" width="9.404ex" height="2.805ex" role="img" focusable="false" viewBox="0 -870 4156.6 1240"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo"><svg width="278" height="1240" y="-370" x="27.5" viewBox="0 -153.6 278 1240"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,1.862)"></path></svg></g><g data-mml-node="msup" transform="translate(333,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1123,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1990,0)"><svg width="278" height="1240" y="-370" x="27.5" viewBox="0 -153.6 278 1240"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" transform="scale(1,1.862)"></path></svg></g></g><g data-mml-node="mo" transform="translate(2600.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(3656.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>，上式等价于：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.564ex;" xmlns="http://www.w3.org/2000/svg" width="11.022ex" height="2.26ex" role="img" focusable="false" viewBox="0 -749.5 4871.8 999"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="msub" transform="translate(1519.1,0)"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(2760.2,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g></g><g data-mml-node="mo" transform="translate(3316,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(4371.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></p>
<p><strong>（2）相干长度条件</strong><br>相干长度L_c是描述光源时间相干性的物理量，定义为光波在传播方向上能保持相位相关性的最大距离差，它与光源的频谱带宽∆v存在以下傅里叶变换关系：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="9.517ex" height="4.081ex" role="img" focusable="false" viewBox="0 -1118 4206.7 1804"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g><g data-mml-node="mo" transform="translate(1348,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2403.7,0)"><g data-mml-node="mi" transform="translate(685,676)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="394" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="mi" transform="translate(833,0)"><path data-c="1D708" d="M74 431Q75 431 146 436T219 442Q231 442 231 434Q231 428 185 241L137 51H140L150 55Q161 59 177 67T214 86T261 119T312 165Q410 264 445 394Q458 442 496 442Q509 442 519 434T530 411Q530 390 516 352T469 262T388 162T267 70T106 5Q81 -2 71 -2Q66 -2 59 -1T51 1Q45 5 45 11Q45 13 88 188L132 364Q133 377 125 380T86 385H65Q59 391 59 393T61 412Q65 431 74 431Z"></path></g></g><rect width="1563" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>要观察到清晰的 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.462ex;" xmlns="http://www.w3.org/2000/svg" width="0.932ex" height="1.957ex" role="img" focusable="false" viewBox="0 -661 412 865"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></svg></mjx-container> 阶干涉条纹，第 1 束光与第 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.462ex;" xmlns="http://www.w3.org/2000/svg" width="0.932ex" height="1.957ex" role="img" focusable="false" viewBox="0 -661 412 865"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></svg></mjx-container> 束光相遇时必须仍能发生干涉。这就要求它们之间的<strong>光程差</strong>：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="24.161ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10679.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="394" d="M51 0Q46 4 46 7Q46 9 215 357T388 709Q391 716 416 716Q439 716 444 709Q447 705 616 357T786 7Q786 4 781 0H51ZM507 344L384 596L137 92L383 91H630Q630 93 507 344Z"></path></g><g data-mml-node="mi" transform="translate(833,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(1791.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2847.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3236.6,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(3870.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(4871,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(5371,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5982.2,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mn" transform="translate(6482.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(6982.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7582.4,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(8269.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(9607.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(9773.8,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></p>
<p>必须小于相干长度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.421ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1070.2 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g></g></g></svg></mjx-container>。</p>
<p>对于高阶干涉（即 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.462ex;" xmlns="http://www.w3.org/2000/svg" width="5.583ex" height="1.968ex" role="img" focusable="false" viewBox="0 -666 2467.6 870"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(689.8,0)"><path data-c="226B" d="M55 539T55 547T60 561T74 567Q81 567 207 498Q297 449 365 412Q633 265 636 261Q639 255 639 250Q639 241 626 232Q614 224 365 88Q83 -65 79 -66Q76 -67 73 -67Q65 -67 60 -61T55 -47Q55 -39 61 -33Q62 -33 95 -15T193 39T320 109L321 110H322L323 111H324L325 112L326 113H327L329 114H330L331 115H332L333 116L334 117H335L336 118H337L338 119H339L340 120L341 121H342L343 122H344L345 123H346L347 124L348 125H349L351 126H352L353 127H354L355 128L356 129H357L358 130H359L360 131H361L362 132L363 133H364L365 134H366L367 135H368L369 136H370L371 137L372 138H373L374 139H375L376 140L378 141L576 251Q63 530 62 533Q55 539 55 547ZM360 539T360 547T365 561T379 567Q386 567 512 498Q602 449 670 412Q938 265 941 261Q944 255 944 250Q944 241 931 232Q919 224 670 88Q388 -65 384 -66Q381 -67 378 -67Q370 -67 365 -61T360 -47Q360 -39 366 -33Q367 -33 400 -15T498 39T625 109L626 110H627L628 111H629L630 112L631 113H632L634 114H635L636 115H637L638 116L639 117H640L641 118H642L643 119H644L645 120L646 121H647L648 122H649L650 123H651L652 124L653 125H654L656 126H657L658 127H659L660 128L661 129H662L663 130H664L665 131H666L667 132L668 133H669L670 134H671L672 135H673L674 136H675L676 137L677 138H678L679 139H680L681 140L683 141L881 251Q368 530 367 533Q360 539 360 547Z"></path></g><g data-mml-node="mn" transform="translate(1967.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>），这就要求相干长度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.421ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1070.2 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g></g></g></svg></mjx-container> 必须足够长。不过，保证至少两束光能发生干涉的基本条件是：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="14.934ex" height="1.952ex" role="img" focusable="false" viewBox="0 -705 6600.6 862.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g><g data-mml-node="mo" transform="translate(1348,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(2403.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(2903.7,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3503.7,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(4190.4,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(5528.4,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(5695.1,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></p>
<p><strong>（3）弱吸收条件</strong><br>光在介质中传播的强度衰减遵循比尔-朗伯定律：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="13.207ex" height="2.433ex" role="img" focusable="false" viewBox="0 -825.2 5837.6 1075.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mo" transform="translate(504,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(893,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(1358,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2024.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(3080.6,0)"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mn" transform="translate(473,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="msup" transform="translate(3957.1,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(1418,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g></g></g></g></g></svg></mjx-container></p>
<p>要使多光束干涉显著，必须保证足够多的高阶光束仍有足够的强度参与叠加。如果吸收太强，指数衰减因子会使高阶项迅速衰减到零,从而退化为双光束干涉。因此，弱吸收更利于多光束显著。</p>
<h3 id="6-3-2外延层厚度测量的精度"><a href="#6-3-2外延层厚度测量的精度" class="headerlink" title="6.3.2外延层厚度测量的精度"></a>6.3.2外延层厚度测量的精度</h3><p>在碳化硅外延层的光学测厚中，由于衬底与外延缓层界面反射率差异显著，入射光会在高反射率界面间发生多次反射，形成复杂的多光束干涉效应。不仅导致干涉条纹峰的相位发生偏移，还会引起条纹的混合叠加以及强度重分布，使得传统的双光束干涉模型无法准确反演外延层厚度。若忽视这种多光束干涉的影响，厚度计算结果会出现系统性误差，影响碳化硅外延层厚度测量的精度和可靠性。因此，需要考虑消光系数对厚度的影响。</p>
<h3 id="6-3-3-模型的求解"><a href="#6-3-3-模型的求解" class="headerlink" title="6.3.3 模型的求解"></a>6.3.3 模型的求解</h3><p>将数据导入后，同样进行了归一化，将反射率归一化到(0,1] 区间，保证与理论反射率计算的一致性；采用Savitizky-Golay滤波去噪，抑制高频噪声、突出干涉条纹；进行PCHIP插值重采样，在保持数据单调性和主要趋势的前提下，避免插值过程中产生的伪振荡。<br>与问题2相比，对于Drude-Lorentz模型中的折射率，我们进一步考虑其虚部，采用复折射率的Drude-Lorentz 模型进行描述，将得到的外延层复折射率代入菲涅耳公式中得到理论反射率，理论反射率与实验反射率做最小二乘得到拟合载流子浓度和外延层厚度。</p>
<p><strong>表2 硅晶外延层厚度</strong></p>
<table>
<thead>
<tr>
<th>载流子浓度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container> (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="4.117ex" height="1.885ex" role="img" focusable="false" viewBox="0 -833.2 1819.7 833.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></g><g data-mml-node="TeXAtom" transform="translate(866,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></g></g></svg></mjx-container>)</th>
<th>外延层厚度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 520 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container> (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="3.249ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 1436 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mtext" transform="translate(603,0)"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></g></g></g></svg></mjx-container>)</th>
<th>折射率实部 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></th>
<th>消光系数 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container></th>
</tr>
</thead>
<tbody><tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="10.838ex" height="2.005ex" role="img" focusable="false" viewBox="0 -864 4790.6 886"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(778,0)"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(1278,0)"></path></g><g data-mml-node="mo" transform="translate(2000.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(3000.4,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,393.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></td>
<td>3.19</td>
<td>2.628</td>
<td>0.036</td>
</tr>
</tbody></table>
<p>将复折射率中的消光系数考虑后代入模型，消除影响后，重新对问题2结果进行计算得到：</p>
<p><strong>表3 碳化硅精确外延层厚度结果</strong></p>
<table>
<thead>
<tr>
<th>载流子浓度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container> (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="4.117ex" height="1.885ex" role="img" focusable="false" viewBox="0 -833.2 1819.7 833.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></g><g data-mml-node="TeXAtom" transform="translate(866,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></g></g></svg></mjx-container>)</th>
<th>外延层厚度 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 520 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container> (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="3.249ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 1436 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mtext" transform="translate(603,0)"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></g></g></g></svg></mjx-container>)</th>
<th>折射率 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></th>
</tr>
</thead>
<tbody><tr>
<td><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.947ex" height="2.005ex" role="img" focusable="false" viewBox="0 -864 3512.6 886"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msup" transform="translate(1722.4,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,393.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g></g></g></g></g></svg></mjx-container></td>
<td>8.5392</td>
<td>2.184</td>
</tr>
</tbody></table>
<h1 id="七、模型的评价与改进"><a href="#七、模型的评价与改进" class="headerlink" title="七、模型的评价与改进"></a>七、模型的评价与改进</h1><h2 id="7-1-模型的评价"><a href="#7-1-模型的评价" class="headerlink" title="7.1 模型的评价"></a>7.1 模型的评价</h2><p>本文基于干涉原理和Drude–Lorentz模型构建了外延层厚度与反射率的数学模型，利用最小二乘进行参数反演。结果表明，该模型能够较好地反映实验数据中的主要干涉条纹特征，拟合得到的厚度利用多种方法进行交叉验证，均在可接受的误差范围内，说明模型具有较好的物理合理性和适用性。<br>从结果上来看，模型在高波数段拟合准确，能够提取厚度，残差较小。各类模型参数均有实际的物理背景，保证了模型等可解释性，并且该模型不仅适用于碳化硅的外延层，还能够推广到硅晶的外延层等其他不同材料的外延层，具有可扩展性和普适性。</p>
<h2 id="7-2-模型的改进"><a href="#7-2-模型的改进" class="headerlink" title="7.2 模型的改进"></a>7.2 模型的改进</h2><p>尽管本文在实验数据拟合和厚度提取方面取得了较为理想的结果，但仅利用了高波数段计算外延层厚度，由于材料晶格振动和探测器响应的影响，模型拟合精度不足，未能充分考虑该区域的厚度信息。最小二乘拟合可能会导致模型陷入局部最优，可以利用遗传算法、粒子群优化等全局优化方法，结合局部搜索策略来提高稳健型，并且还可以引入贝叶斯优化或正则化约束来缓解参数之间的耦合，提高结果的稳健型和可靠性。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1]	母国光, 战元龄. 光学（第2版）[M]. 北京: 高等教育出版社, 2009.<br>[2]	KAZAN M. Oxygen behavior in aluminum nitride[J]. Journal of Applied Physics, 2005, 98: 103529. DOI:10.1063/1.2130713.<br>[3]	KAZAN M, OTTAVIANI L, MOUSSAED E, et al. Effect of introducing gettering sites and subsequent Au diffusion on the thermal conductivity and the free carrier concentration in n-type 4H-SiC[J]. Journal of Applied Physics, 2008, 103: 053707. DOI:10.1063/1.2883475.<br>[4]	马格林.一种新的SiC外延材料质量评估方法[D].西安电子科技大学,2011.<br>[5]	Handbook of Optics. Vol. 1: Geometrical and Physical Optics, Polarized Light, Components and InstrumentsM. 3rd ed. New York: McGraw-Hill Education, 2010.<br>[6]	Kato H S, Sato Y, Yamamoto M, et al. Surface-Specific Vibrational Spectroscopy of the Graphene Electrode/Aqueous Electrolyte Interface[J]. Journal of Physical Chemistry C, 2020, 124(21): 11447–11455. DOI:10.1021/acs.jpcc.0c01941<br>[7]	中关村天合宽禁带半导体技术创新联盟.4H-碳化硅同质外延层厚度的红外反射测量方法:T/IAWBS007—2018[S].北京:中国标准出版社,2018.</p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p><strong>附录A支撑材料文件列表</strong></p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>文件内容</th>
</tr>
</thead>
<tbody><tr>
<td><code>AI工具使用详情</code></td>
<td>关于 AI 工具的使用说明</td>
</tr>
<tr>
<td><code>problem1.ipynb</code></td>
<td>问题 1 和问题 2 的求解代码与结果</td>
</tr>
<tr>
<td><code>problem3.ipynb</code></td>
<td>问题 3 的求解代码与结果</td>
</tr>
<tr>
<td><code>Proview.ipynb</code></td>
<td>4 个附件的预处理结果</td>
</tr>
<tr>
<td><code>附件1.csv</code></td>
<td>处理后的附件 1 数据</td>
</tr>
<tr>
<td><code>附件2.csv</code></td>
<td>处理后的附件 2 数据</td>
</tr>
<tr>
<td><code>附件3.csv</code></td>
<td>处理后的附件 3 数据</td>
</tr>
<tr>
<td><code>附件4.csv</code></td>
<td>处理后的附件 4 数据</td>
</tr>
</tbody></table>
<p><strong>附录B程序代码</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from scipy.optimize import minimize</span><br><span class="line">from numpy.lib.scimath import arcsin</span><br><span class="line"></span><br><span class="line">e = 1.602e-19</span><br><span class="line">eps0 = 8.854e-12</span><br><span class="line">m = 0.3 * 9.11e-31</span><br><span class="line">c = 3e8</span><br><span class="line">eps_inf = 6.5</span><br><span class="line">gamma_D = 1e13</span><br><span class="line"></span><br><span class="line">omega_0 = 1.5e14</span><br><span class="line">gamma_L = 1e12</span><br><span class="line">S_L = 1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 3个振子分别测试</span></span><br><span class="line">lorentz_params = [</span><br><span class="line">    (1.5e14, 1e12, 1.0),</span><br><span class="line">    <span class="comment">#(2.5e14, 2e12, 0.5),</span></span><br><span class="line">    <span class="comment">#(3.5e14, 1.5e12, 0.8)</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">def pre(<span class="built_in">df</span>):</span><br><span class="line">    lambda_m = 1e-2 / <span class="built_in">df</span>[<span class="string">"波数 (cm-1)"</span>].values</span><br><span class="line">    R = <span class="built_in">df</span>[<span class="string">"反射率 (%)"</span>].values</span><br><span class="line">    mask = R &lt;= 1.0</span><br><span class="line">    lambda_m = lambda_m[mask]</span><br><span class="line">    R = R[mask]</span><br><span class="line">    idx = np.argsort(lambda_m)</span><br><span class="line">    <span class="built_in">return</span> lambda_m[idx], R[idx]</span><br><span class="line"></span><br><span class="line">df1 = pd.read_csv(<span class="string">"附件1.csv"</span>)</span><br><span class="line">df2 = pd.read_csv(<span class="string">"附件2.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 不同波数范围</span></span><br><span class="line"><span class="comment">#df1 = df1[df1["波数 (cm-1)"] &lt;= 1400]</span></span><br><span class="line">df1 = df1[df1[<span class="string">"波数 (cm-1)"</span>] &gt; 1818]</span><br><span class="line"><span class="comment">#df2 = df2[df2["波数 (cm-1)"] &lt;= 1400]</span></span><br><span class="line">df2 = df2[df2[<span class="string">"波数 (cm-1)"</span>] &gt; 1818]</span><br><span class="line"></span><br><span class="line">lambda1, R1 = pre(df1)</span><br><span class="line">lambda2, R2 = pre(df2)</span><br><span class="line"></span><br><span class="line">theta1 = np.radians(10)</span><br><span class="line">theta2 = np.radians(15)</span><br><span class="line">n0 = 1.0</span><br><span class="line"></span><br><span class="line">def drude_lorentz(lambda_m, N):</span><br><span class="line">    omega = 2 * np.pi * c / lambda_m</span><br><span class="line"></span><br><span class="line">    omega_p2 = N * e**2 / (eps0 * m)</span><br><span class="line">    eps = eps_inf - omega_p2 / (omega**2 + 1j*gamma_D*omega)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (omega_0, gamma_L, S_L) <span class="keyword">in</span> lorentz_params:</span><br><span class="line">        eps += S_L * omega_0**2 / (omega_0**2 - omega**2 - 1j*gamma_L*omega)</span><br><span class="line">    n_c = np.sqrt(eps)</span><br><span class="line">    n_real = np.real(n_c)</span><br><span class="line">    <span class="built_in">return</span> n_real</span><br><span class="line"></span><br><span class="line">def Fresnel_S_P(N, d, theta, lambda_array, n_sub=2.6, n0=1.0):</span><br><span class="line">    n_c = drude_lorentz(lambda_array, N)</span><br><span class="line">    theta_t = arcsin(n0 * np.sin(theta) / n_c)</span><br><span class="line">    theta_s = arcsin(n_c * np.sin(theta_t) / n_sub)</span><br><span class="line"></span><br><span class="line">    r01_s = (n0 * np.cos(theta) - n_c * np.cos(theta_t)) / (n0 * np.cos(theta) + n_c * np.cos(theta_t))</span><br><span class="line">    t01_s = 2 * n0 * np.cos(theta) / (n0 * np.cos(theta) + n_c * np.cos(theta_t))</span><br><span class="line">    t10_s = 2 * n_c * np.cos(theta_t) / (n0 * np.cos(theta) + n_c * np.cos(theta_t))</span><br><span class="line">    r12_s = (n_c * np.cos(theta_t) - n_sub * np.cos(theta_s)) / (n_c * np.cos(theta_t) + n_sub * np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    r01_p = (n_c * np.cos(theta) - n0 * np.cos(theta_t)) / (n_c * np.cos(theta) + n0 * np.cos(theta_t))</span><br><span class="line">    t01_p = 2 * n0 * np.cos(theta) / (n_c * np.cos(theta) + n0 * np.cos(theta_t))</span><br><span class="line">    t10_p = 2 * n_c * np.cos(theta_t) / (n_c * np.cos(theta) + n0 * np.cos(theta_t))</span><br><span class="line">    r12_p = (n_sub * np.cos(theta_t) - n_c * np.cos(theta_s)) / (n_sub * np.cos(theta_t) + n_c * np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    delta = 2 * np.pi * n_c * d * np.cos(theta_t) / lambda_array</span><br><span class="line"></span><br><span class="line">    rtot_s = r01_s + t01_s * t10_s * r12_s * np.exp(2j * delta)</span><br><span class="line">    rtot_p = r01_p + t01_p * t10_p * r12_p * np.exp(2j * delta)</span><br><span class="line"></span><br><span class="line">    Rs = np.abs(rtot_s) ** 2</span><br><span class="line">    Rp = np.abs(rtot_p) ** 2</span><br><span class="line">    <span class="built_in">return</span> Rs, Rp</span><br><span class="line"></span><br><span class="line">def obj(p_log):</span><br><span class="line">    N = 10**p_log[0]</span><br><span class="line">    d = 10**p_log[1]</span><br><span class="line">    Rs1, Rp1 = Fresnel_S_P(N, d, theta1, lambda1)</span><br><span class="line">    Rs2, Rp2 = Fresnel_S_P(N, d, theta2, lambda2)</span><br><span class="line">    Rth1 = 0.5*(Rs1 + Rp1)</span><br><span class="line">    Rth2 = 0.5*(Rs2 + Rp2)</span><br><span class="line">    </span><br><span class="line">    err1 = np.mean(((R1 - Rth1) / (R1 + <span class="number">1</span>e-<span class="number">12</span>))**2)</span><br><span class="line">    err2 = np.mean(((R2 - Rth2) / (R2 + <span class="number">1</span>e-<span class="number">12</span>))**2)</span><br><span class="line">    <span class="built_in">return</span> err1 + err2</span><br><span class="line">    </span><br><span class="line">res = minimize(obj, x0=[22, -5], bounds=[(2,26), (-7, -2)])</span><br><span class="line">N_fit = 10**res.x[0]</span><br><span class="line">d_fit = 10**res.x[1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"拟合载流子浓度 N: {N_fit:.3e} m^-3"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"拟合外延层厚度 d: {d_fit*1e6} 微米"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"折射率 n ≈ {drude_lorentz(10e-6, N_fit)}"</span>)</span><br><span class="line"></span><br><span class="line">df1 = pd.read_csv(<span class="string">"附件1.csv"</span>)</span><br><span class="line">df2 = pd.read_csv(<span class="string">"附件2.csv"</span>)</span><br><span class="line"></span><br><span class="line">lambda1, R1 = pre(df1)</span><br><span class="line">lambda2, R2 = pre(df2)</span><br><span class="line">def wavenumber_to_lambda(lambda_m):</span><br><span class="line">    <span class="built_in">return</span> 1e-2 / lambda_m</span><br><span class="line"></span><br><span class="line">def lambda_m_from_wavenumber_cm(nu_cm):</span><br><span class="line">    <span class="built_in">return</span> 1e-2 / nu_cm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 做一半发现多余了 shit山 就这么放在这里了</span></span><br><span class="line">def smooth(nu_cm, R, window=None, poly=None, baseline_deg=None):</span><br><span class="line">    <span class="built_in">return</span> R, R, np.zeros_like(R)</span><br><span class="line"></span><br><span class="line">def findPeaks(nu_cm, R_corr, smooth_window=11, poly=3, height=None, distance=None, prominence=None):</span><br><span class="line">    <span class="keyword">if</span> nu_cm[0] &gt; nu_cm[-1]:</span><br><span class="line">        nu_cm = nu_cm[::-1]; R_corr = R_corr[::-1]</span><br><span class="line">    R_for_peak = savgol_filter(R_corr, window_length=smooth_window, polyorder=poly) <span class="keyword">if</span> smooth_window&gt;3 <span class="keyword">else</span> R_corr</span><br><span class="line">    peaks, props = find_peaks(R_for_peak, height=height, distance=distance, prominence=prominence)</span><br><span class="line">    <span class="built_in">return</span> peaks, props, R_for_peak</span><br><span class="line"></span><br><span class="line">def computeSpacing(nu_cm, peaks_idx):</span><br><span class="line">    nu_peaks = nu_cm[peaks_idx]</span><br><span class="line">    dnu = np.diff(nu_peaks)</span><br><span class="line">    <span class="built_in">return</span> nu_peaks, dnu, dnu.mean() <span class="keyword">if</span> len(dnu)&gt;0 <span class="keyword">else</span> (nu_peaks, dnu, None)</span><br><span class="line"></span><br><span class="line">def thickness(delta_nu_cm, n_avg, theta_rad):</span><br><span class="line">    delta_nu_m = delta_nu_cm * 100.0</span><br><span class="line">    d_m = 1.0 / (2.0 * n_avg * np.cos(theta_rad) * delta_nu_m)</span><br><span class="line">    <span class="built_in">return</span> d_m</span><br><span class="line"></span><br><span class="line">def temp01(lambda_m, R, N_value, theta_rad,</span><br><span class="line">                            nu_min_cm=None, nu_max_cm=None,</span><br><span class="line">                            smooth_win_peak=15, peak_prominence=None, peak_distance=None):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    返回： d_est_m, d_std_est_m (基于条纹间隔 std), info dict</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    nu_cm = wavenumber_to_lambda(lambda_m)</span><br><span class="line">    <span class="keyword">if</span> nu_cm[0] &gt; nu_cm[-1]:</span><br><span class="line">        nu_cm = nu_cm[::-1]; R = R[::-1]; lambda_m = lambda_m[::-1]</span><br><span class="line">    <span class="keyword">if</span> nu_min_cm is None: nu_min_cm = nu_cm.min()</span><br><span class="line">    <span class="keyword">if</span> nu_max_cm is None: nu_max_cm = nu_cm.max()</span><br><span class="line">    mask = (nu_cm &gt;= nu_min_cm) &amp; (nu_cm &lt;= nu_max_cm)</span><br><span class="line">    nu_sel = nu_cm[mask]; R_sel = R[mask]; lam_sel = lambda_m[mask]</span><br><span class="line">    <span class="keyword">if</span> len(nu_sel) &lt; 10:</span><br><span class="line">        <span class="built_in">return</span> None, None, {<span class="string">"error"</span>:<span class="string">"selected band too small"</span>}</span><br><span class="line">    R_corr, R_smoothed, baseline = smooth(nu_sel, R_sel, window=15, poly=3, baseline_deg=2)</span><br><span class="line">    peaks_idx, props, R_for_peak = findPeaks(nu_sel, R_corr, smooth_window=smooth_win_peak,</span><br><span class="line">                                                     height=None, distance=peak_distance, prominence=peak_prominence)</span><br><span class="line">    <span class="keyword">if</span> len(peaks_idx) &lt; 3:</span><br><span class="line">        peaks_idx, props, R_for_peak = findPeaks(nu_sel, R_corr, smooth_window=7,</span><br><span class="line">                                                         height=None, distance=peak_distance, prominence=peak_prominence)</span><br><span class="line">    <span class="keyword">if</span> len(peaks_idx) &lt; 2:</span><br><span class="line">        <span class="built_in">return</span> None, None, {<span class="string">"error"</span>:<span class="string">"not enough peaks found"</span>, <span class="string">"n_peaks"</span>:len(peaks_idx)}</span><br><span class="line">    nu_peaks, dnu_array, dnu_mean = computeSpacing(nu_sel, peaks_idx)</span><br><span class="line">    dnu_std = dnu_array.std() <span class="keyword">if</span> len(dnu_array)&gt;0 <span class="keyword">else</span> 0.0</span><br><span class="line">    n_c_s = drude_lorentz(lambda_m, N_value)</span><br><span class="line">    lam_peaks = lambda_m_from_wavenumber_cm(nu_peaks)</span><br><span class="line">    n_real_interp = np.real(np.interp(lam_peaks, lambda_m, n_c_s))</span><br><span class="line">    n_avg = np.mean(n_real_interp)</span><br><span class="line">    d_est = thickness(dnu_mean, n_avg, theta_rad)</span><br><span class="line">    rel_err = np.sqrt( (dnu_std/dnu_mean <span class="keyword">if</span> dnu_mean!=0 <span class="keyword">else</span> 0.0)**2 + (np.std(n_real_interp)/n_avg <span class="keyword">if</span> n_avg!=0 <span class="keyword">else</span> 0.0)**2 )</span><br><span class="line">    d_std = d_est * rel_err</span><br><span class="line">    info = {<span class="string">"nu_peaks"</span>:nu_peaks, <span class="string">"dnu_array"</span>:dnu_array, <span class="string">"dnu_mean"</span>:dnu_mean, <span class="string">"dnu_std"</span>:dnu_std,</span><br><span class="line">            <span class="string">"n_at_peaks"</span>:n_real_interp, <span class="string">"n_avg"</span>:n_avg, <span class="string">"peaks_idx"</span>:peaks_idx, <span class="string">"R_for_peak"</span>:R_for_peak,</span><br><span class="line">            <span class="string">"nu_sel"</span>:nu_sel, <span class="string">"R_sel"</span>:R_sel, <span class="string">"lam_sel"</span>:lam_sel}</span><br><span class="line">    <span class="built_in">return</span> d_est, d_std, info</span><br><span class="line"></span><br><span class="line">nu_min = 1000</span><br><span class="line">nu_max = 4000</span><br><span class="line">d_est_m, d_std_m, info = temp01(lambda1, R1, N_fit, theta1, nu_min_cm=nu_min, nu_max_cm=nu_max,</span><br><span class="line">                                                 smooth_win_peak=21, peak_prominence=0.002, peak_distance=4)</span><br><span class="line"><span class="keyword">if</span> d_est_m is not None:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"条纹法估计 d = {:.3f} 微米 ± {:.3f} 微米"</span>.format(d_est_m*1e6, 3*d_std_m*1e6))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"错误："</span>, info)</span><br><span class="line"></span><br><span class="line">def computer_R(N, d, theta, lambda_array, n_sub=2.6, n0=1.0):</span><br><span class="line">    n_c = drude_lorentz(lambda_array, N)</span><br><span class="line"></span><br><span class="line">    theta_t = arcsin(n0 * np.sin(theta) / n_c)</span><br><span class="line"></span><br><span class="line">    theta_s = arcsin(n_c * np.sin(theta_t) / n_sub)</span><br><span class="line"></span><br><span class="line">    r01 = (n0 * np.cos(theta) - n_c * np.cos(theta_t)) / (n0 * np.cos(theta) + n_c * np.cos(theta_t))</span><br><span class="line">    r12 = (n_c * np.cos(theta_t) - n_sub * np.cos(theta_s)) / (n_c * np.cos(theta_t) + n_sub * np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    delta = 2 * np.pi * n_c * d * np.cos(theta_t) / lambda_array</span><br><span class="line"></span><br><span class="line">    r_total = (r01 + r12 * np.exp(2j * delta)) / (1 + r01 * r12 * np.exp(2j * delta))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> np.abs(r_total) ** 2</span><br><span class="line"></span><br><span class="line">def bootstrap(res, nboot=200):</span><br><span class="line">    ests = []</span><br><span class="line">    resids1 = R1 - computer_R(N_fit, d_fit, theta1, lambda1)</span><br><span class="line">    resids2 = R2 - computer_R(N_fit, d_fit, theta2, lambda2)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nboot):</span><br><span class="line">        r1 = computer_R(N_fit, d_fit, theta1, lambda1) + np.random.choice(resids1, size=len(resids1), replace=True)</span><br><span class="line">        r2 = computer_R(N_fit, d_fit, theta2, lambda2) + np.random.choice(resids2, size=len(resids2), replace=True)</span><br><span class="line"></span><br><span class="line">        def obj(p):</span><br><span class="line">            N_try, d_try = 10**p[0], 10**p[1]</span><br><span class="line">            err1 = np.mean((r1 - computer_R(N_try, d_try, theta1, lambda1))**2)</span><br><span class="line">            err2 = np.mean((r2 - computer_R(N_try, d_try, theta2, lambda2))**2)</span><br><span class="line">            <span class="built_in">return</span> err1 + err2</span><br><span class="line">        </span><br><span class="line">        try:</span><br><span class="line">            x0 = res.x + np.random.normal(0, 0.05, size=2)</span><br><span class="line">            rr = minimize(obj, x0=x0, bounds=[(20,26),(-6,-2)])</span><br><span class="line">            <span class="keyword">if</span> rr.success:</span><br><span class="line">                N_try, d_try = 10**rr.x[0], 10**rr.x[1]</span><br><span class="line">                <span class="keyword">if</span> 1e2 &lt; N_try &lt; 1e24 and 0.1e-6 &lt; d_try &lt; 50e-6:</span><br><span class="line">                    ests.append((N_try, d_try))</span><br><span class="line">        except:</span><br><span class="line">            <span class="built_in">continue</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">return</span> np.array(ests)</span><br><span class="line">ests = bootstrap(res, nboot=500)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(ests) &gt; 0:</span><br><span class="line">    N_mean, d_mean = ests.mean(axis=0)</span><br><span class="line"></span><br><span class="line">    N_lower, N_upper = np.percentile(ests[:,0], [2.5, 97.5])</span><br><span class="line">    d_lower, d_upper = np.percentile(ests[:,1], [2.5, 97.5])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"N_fit: {N_mean:.3e} (95% CI: {N_lower:.3e} - {N_upper:.3e})"</span>)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">"d_fit: {d_mean*1e6:.2f} 微米 (95% CI: {d_lower*1e6:.2f} - {d_upper*1e6:.2f} 微米)"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"无"</span>)</span><br><span class="line"></span><br><span class="line">problem3.ipynb</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from scipy.optimize import minimize</span><br><span class="line">from scipy.signal import savgol_filter</span><br><span class="line">from numpy.lib.scimath import arcsin</span><br><span class="line"></span><br><span class="line">e = 1.602e-19</span><br><span class="line">eps0 = 8.854e-12</span><br><span class="line">m = 0.3 * 9.11e-31</span><br><span class="line">c = 3e8</span><br><span class="line">eps_inf = 11.7</span><br><span class="line">gamma_D = 1e13</span><br><span class="line"></span><br><span class="line">omega_0 = 1.5e14</span><br><span class="line">gamma_L = 1e12</span><br><span class="line">S_L = 1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3个振子测试</span></span><br><span class="line">lorentz_params = [</span><br><span class="line">    (1.5e14, 1e12, 1.0),</span><br><span class="line">    <span class="comment">#(2.5e14, 2e12, 0.5),</span></span><br><span class="line">    <span class="comment">#(3.5e14, 1.5e12, 0.8)</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">def pre(<span class="built_in">df</span>):</span><br><span class="line">    lambda_m = 1e-2 / <span class="built_in">df</span>[<span class="string">"波数 (cm-1)"</span>].values</span><br><span class="line">    R = <span class="built_in">df</span>[<span class="string">"反射率 (%)"</span>].values</span><br><span class="line">    mask = R &lt;= 1.0</span><br><span class="line">    lambda_m = lambda_m[mask]</span><br><span class="line">    R = R[mask]</span><br><span class="line">    idx = np.argsort(lambda_m)</span><br><span class="line">    <span class="built_in">return</span> lambda_m[idx], R[idx]</span><br><span class="line"></span><br><span class="line">df3 = pd.read_csv(<span class="string">"附件3.csv"</span>)</span><br><span class="line">df4 = pd.read_csv(<span class="string">"附件4.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 不同波数段</span></span><br><span class="line"><span class="comment">#df1 = df1[df1["波数 (cm-1)"] &lt;= 1400]</span></span><br><span class="line">df3 = df3[df3[<span class="string">"波数 (cm-1)"</span>] &gt; 500]</span><br><span class="line"><span class="comment">#df2 = df2[df2["波数 (cm-1)"] &lt;= 1400]</span></span><br><span class="line">df4 = df4[df4[<span class="string">"波数 (cm-1)"</span>] &gt; 500]</span><br><span class="line"></span><br><span class="line">lambda1, R1 = pre(df3)</span><br><span class="line">lambda2, R2 = pre(df4)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">theta1 = np.radians(10)</span><br><span class="line">theta2 = np.radians(15)</span><br><span class="line">n0 = 1.0</span><br><span class="line"></span><br><span class="line">def drude_lorentz(lambda_m, N):</span><br><span class="line">    omega = 2 * np.pi * c / lambda_m</span><br><span class="line"></span><br><span class="line">    omega_p2 = N * e**2 / (eps0 * m)</span><br><span class="line">    eps = eps_inf - omega_p2 / (omega**2 + 1j*gamma_D*omega)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (omega_0, gamma_L, S_L) <span class="keyword">in</span> lorentz_params:</span><br><span class="line">        eps += S_L * omega_0**2 / (omega_0**2 - omega**2 - 1j*gamma_L*omega)</span><br><span class="line">    n_complex = np.sqrt(eps)</span><br><span class="line">    <span class="built_in">return</span> n_complex</span><br><span class="line"></span><br><span class="line">def Fresnel_S_P(N, d, theta, lambda_array, n_sub=3.42, n0=1.0):</span><br><span class="line">    n_complex = drude_lorentz(lambda_array, N)</span><br><span class="line">    theta_t = arcsin(n0 * np.sin(theta) / n_complex)</span><br><span class="line">    theta_s = arcsin(n_complex * np.sin(theta_t) / n_sub)</span><br><span class="line"></span><br><span class="line">    r01_s = (n0 * np.cos(theta) - n_complex * np.cos(theta_t)) / (n0 * np.cos(theta) + n_complex * np.cos(theta_t))</span><br><span class="line">    r12_s = (n_complex * np.cos(theta_t) - n_sub * np.cos(theta_s)) / (n_complex * np.cos(theta_t) + n_sub * np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    r01_p = (n_complex * np.cos(theta) - n0 * np.cos(theta_t)) / (n_complex * np.cos(theta) + n0 * np.cos(theta_t))</span><br><span class="line">    r12_p = (n_sub * np.cos(theta_t) - n_complex * np.cos(theta_s)) / (n_sub * np.cos(theta_t) + n_complex * np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    delta = 2 * np.pi * n_complex * d * np.cos(theta_t) / lambda_array</span><br><span class="line"></span><br><span class="line">    rtot_s = (r01_s + r12_s * np.exp(2j * delta)) / (1 + r01_s * r12_s * np.exp(2j * delta))</span><br><span class="line">    rtot_p = (r01_p + r12_p * np.exp(2j * delta)) / (1 + r01_p * r12_p * np.exp(2j * delta))</span><br><span class="line"></span><br><span class="line">    Rs = np.abs(rtot_s) ** 2</span><br><span class="line">    Rp = np.abs(rtot_p) ** 2</span><br><span class="line">    <span class="built_in">return</span> Rs, Rp</span><br><span class="line"></span><br><span class="line">def Fresnel_S_P_1(N, d, theta, lambda_array, n_sub=3.42, n0=1.0):</span><br><span class="line">    n_complex = drude_lorentz(lambda_array, N)</span><br><span class="line">    theta_t = arcsin(n0 * np.sin(theta) / n_complex)</span><br><span class="line">    theta_s = arcsin(n_complex * np.sin(theta_t) / n_sub)</span><br><span class="line"></span><br><span class="line">    r01_s = (n0*np.cos(theta) - n_complex*np.cos(theta_t)) / (n0*np.cos(theta) + n_complex*np.cos(theta_t))</span><br><span class="line">    r12_s = (n_complex*np.cos(theta_t) - n_sub*np.cos(theta_s)) / (n_complex*np.cos(theta_t) + n_sub*np.cos(theta_s))</span><br><span class="line">    r01_p = (n_complex*np.cos(theta) - n0*np.cos(theta_t)) / (n_complex*np.cos(theta) + n0*np.cos(theta_t))</span><br><span class="line">    r12_p = (n_sub*np.cos(theta_t) - n_complex*np.cos(theta_s)) / (n_sub*np.cos(theta_t) + n_complex*np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    delta = 2*np.pi * n_complex * d * np.cos(theta_t) / lambda_array</span><br><span class="line"></span><br><span class="line">    rtot_s = (r01_s + r12_s * np.exp(2j*delta)) / (1 + r01_s * r12_s * np.exp(2j*delta))</span><br><span class="line">    rtot_p = (r01_p + r12_p * np.exp(2j*delta)) / (1 + r01_p * r12_p * np.exp(2j*delta))</span><br><span class="line"></span><br><span class="line">    Rs = np.abs(rtot_s)**2</span><br><span class="line">    Rp = np.abs(rtot_p)**2</span><br><span class="line">    <span class="built_in">return</span> Rs, Rp</span><br><span class="line"></span><br><span class="line">def obj(params_log):</span><br><span class="line">    N = 10**params_log[0]</span><br><span class="line">    d = 10**params_log[1]</span><br><span class="line">    Rs1, Rp1 = Fresnel_S_P(N, d, theta1, lambda1)</span><br><span class="line">    Rs2, Rp2 = Fresnel_S_P(N, d, theta2, lambda2)</span><br><span class="line">    Rth1 = 0.5*(Rs1 + Rp1)</span><br><span class="line">    Rth2 = 0.5*(Rs2 + Rp2)</span><br><span class="line"></span><br><span class="line">    err1 = np.mean(((R1 - Rth1) / (R1 + <span class="number">1</span>e-<span class="number">12</span>))**2)</span><br><span class="line">    err2 = np.mean(((R2 - Rth2) / (R2 + <span class="number">1</span>e-<span class="number">12</span>))**2)</span><br><span class="line">    <span class="built_in">return</span> err1 + err2</span><br><span class="line">    </span><br><span class="line">res = minimize(obj, x0=[22, -5], bounds=[(1,26), (-9, -1)])</span><br><span class="line">N_fit = 10**res.x[0]</span><br><span class="line">d_fit = 10**res.x[1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"拟合载流子浓度 N = {N_fit:.3e} m^-3"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"拟合外延层厚度 d = {d_fit*1e6:.2f} μm"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"折射率 n ≈ {drude_lorentz(10e-6, N_fit)}"</span>)</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from scipy.optimize import minimize</span><br><span class="line">from scipy.signal import savgol_filter</span><br><span class="line">from numpy.lib.scimath import arcsin</span><br><span class="line"></span><br><span class="line">e = 1.602e-19</span><br><span class="line">eps0 = 8.854e-12</span><br><span class="line">m = 0.3 * 9.11e-31</span><br><span class="line">c = 3e8</span><br><span class="line">eps_inf = 6.5</span><br><span class="line">gamma_D = 1e13</span><br><span class="line"></span><br><span class="line">omega_0 = 1.5e14</span><br><span class="line">gamma_L = 1e12</span><br><span class="line">S_L = 1.0</span><br><span class="line"></span><br><span class="line">lorentz_params = [</span><br><span class="line">    (1.5e14, 1e12, 1.0),   <span class="comment"># 振子1</span></span><br><span class="line">    <span class="comment">#(2.5e14, 2e12, 0.5),</span></span><br><span class="line">    <span class="comment">#(3.5e14, 1.5e12, 0.8)</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">def pre(<span class="built_in">df</span>):</span><br><span class="line">    lambda_m = 1e-2 / <span class="built_in">df</span>[<span class="string">"波数 (cm-1)"</span>].values</span><br><span class="line">    R = <span class="built_in">df</span>[<span class="string">"反射率 (%)"</span>].values</span><br><span class="line">    mask = R &lt;= 1.0</span><br><span class="line">    lambda_m = lambda_m[mask]</span><br><span class="line">    R = R[mask]</span><br><span class="line">    idx = np.argsort(lambda_m)</span><br><span class="line">    <span class="built_in">return</span> lambda_m[idx], R[idx]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df3 = pd.read_csv(<span class="string">"附件1.csv"</span>)</span><br><span class="line">df4 = pd.read_csv(<span class="string">"附件2.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#df1 = df1[df1["波数 (cm-1)"] &lt;= 1400]</span></span><br><span class="line">df3 = df3[df3[<span class="string">"波数 (cm-1)"</span>] &gt; 1818]</span><br><span class="line"><span class="comment">#df2 = df2[df2["波数 (cm-1)"] &lt;= 1400]</span></span><br><span class="line">df4 = df4[df4[<span class="string">"波数 (cm-1)"</span>] &gt; 1818]</span><br><span class="line"></span><br><span class="line">lambda1, R1 = pre(df3)</span><br><span class="line">lambda2, R2 = pre(df4)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">theta1 = np.radians(10)</span><br><span class="line">theta2 = np.radians(15)</span><br><span class="line">n0 = 1.0</span><br><span class="line"></span><br><span class="line">def drude_lorentz(lambda_m, N):</span><br><span class="line">    omega = 2 * np.pi * c / lambda_m</span><br><span class="line">    omega_p2 = N * e**2 / (eps0 * m)</span><br><span class="line">    eps = eps_inf - omega_p2 / (omega**2 + 1j*gamma_D*omega)</span><br><span class="line">    <span class="keyword">for</span> (omega_0, gamma_L, S_L) <span class="keyword">in</span> lorentz_params:</span><br><span class="line">        eps += S_L * omega_0**2 / (omega_0**2 - omega**2 - 1j*gamma_L*omega)</span><br><span class="line">    n_complex = np.sqrt(eps)</span><br><span class="line">    <span class="built_in">return</span> n_complex</span><br><span class="line"></span><br><span class="line">def Fresnel_S_P(N, d, theta, lambda_array, n_sub=2.6, n0=1.0):</span><br><span class="line">    n_complex = drude_lorentz(lambda_array, N)</span><br><span class="line">    theta_t = arcsin(n0 * np.sin(theta) / n_complex)</span><br><span class="line">    theta_s = arcsin(n_complex * np.sin(theta_t) / n_sub)</span><br><span class="line"></span><br><span class="line">    r01_s = (n0 * np.cos(theta) - n_complex * np.cos(theta_t)) / \</span><br><span class="line">            (n0 * np.cos(theta) + n_complex * np.cos(theta_t))</span><br><span class="line">    r12_s = (n_complex * np.cos(theta_t) - n_sub * np.cos(theta_s)) / \</span><br><span class="line">            (n_complex * np.cos(theta_t) + n_sub * np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    r01_p = (n_complex * np.cos(theta) - n0 * np.cos(theta_t)) / \</span><br><span class="line">            (n_complex * np.cos(theta) + n0 * np.cos(theta_t))</span><br><span class="line">    r12_p = (n_sub * np.cos(theta_t) - n_complex * np.cos(theta_s)) / \</span><br><span class="line">            (n_sub * np.cos(theta_t) + n_complex * np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    delta = 2 * np.pi * n_complex * d * np.cos(theta_t) / lambda_array</span><br><span class="line"></span><br><span class="line">    rtot_s = (r01_s + r12_s * np.exp(2j * delta)) / (1 + r01_s * r12_s * np.exp(2j * delta))</span><br><span class="line">    rtot_p = (r01_p + r12_p * np.exp(2j * delta)) / (1 + r01_p * r12_p * np.exp(2j * delta))</span><br><span class="line"></span><br><span class="line">    Rs = np.abs(rtot_s) ** 2</span><br><span class="line">    Rp = np.abs(rtot_p) ** 2</span><br><span class="line">    <span class="built_in">return</span> Rs, Rp</span><br><span class="line"></span><br><span class="line">def Fresnel_S_P_1(N, d, theta, lambda_array, n_sub=2.6, n0=1.0):</span><br><span class="line">    n_complex = drude_lorentz(lambda_array, N)</span><br><span class="line">    theta_t = arcsin(n0 * np.sin(theta) / n_complex)</span><br><span class="line">    theta_s = arcsin(n_complex * np.sin(theta_t) / n_sub)</span><br><span class="line"></span><br><span class="line">    r01_s = (n0*np.cos(theta) - n_complex*np.cos(theta_t)) / (n0*np.cos(theta) + n_complex*np.cos(theta_t))</span><br><span class="line">    r12_s = (n_complex*np.cos(theta_t) - n_sub*np.cos(theta_s)) / (n_complex*np.cos(theta_t) + n_sub*np.cos(theta_s))</span><br><span class="line">    r01_p = (n_complex*np.cos(theta) - n0*np.cos(theta_t)) / (n_complex*np.cos(theta) + n0*np.cos(theta_t))</span><br><span class="line">    r12_p = (n_sub*np.cos(theta_t) - n_complex*np.cos(theta_s)) / (n_sub*np.cos(theta_t) + n_complex*np.cos(theta_s))</span><br><span class="line"></span><br><span class="line">    delta = 2*np.pi * n_complex * d * np.cos(theta_t) / lambda_array</span><br><span class="line"></span><br><span class="line">    rtot_s = (r01_s + r12_s * np.exp(2j*delta)) / (1 + r01_s * r12_s * np.exp(2j*delta))</span><br><span class="line">    rtot_p = (r01_p + r12_p * np.exp(2j*delta)) / (1 + r01_p * r12_p * np.exp(2j*delta))</span><br><span class="line"></span><br><span class="line">    Rs = np.abs(rtot_s)**2</span><br><span class="line">    Rp = np.abs(rtot_p)**2</span><br><span class="line">    <span class="built_in">return</span> Rs, Rp</span><br><span class="line"></span><br><span class="line">def obj(params_log):</span><br><span class="line">    N = 10**params_log[0]</span><br><span class="line">    d = 10**params_log[1]</span><br><span class="line">    Rs1, Rp1 = Fresnel_S_P(N, d, theta1, lambda1)</span><br><span class="line">    Rs2, Rp2 = Fresnel_S_P(N, d, theta2, lambda2)</span><br><span class="line">    Rth1 = 0.5*(Rs1 + Rp1)</span><br><span class="line">    Rth2 = 0.5*(Rs2 + Rp2)</span><br><span class="line">    err1 = np.mean(((R1 - Rth1) / (R1 + <span class="number">1</span>e-<span class="number">12</span>))**2)</span><br><span class="line">    err2 = np.mean(((R2 - Rth2) / (R2 + <span class="number">1</span>e-<span class="number">12</span>))**2)</span><br><span class="line">    <span class="built_in">return</span> err1 + err2</span><br><span class="line"></span><br><span class="line">res = minimize(obj, x0=[22, -5], bounds=[(1,26), (-9, -1)])</span><br><span class="line">N_fit = 10**res.x[0]</span><br><span class="line">d_fit = 10**res.x[1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"拟合载流子浓度 N ≈ {N_fit:.3e} m^-3"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"拟合外延层厚度 d ≈ {d_fit*1e6} μm"</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">"折射率 n ≈ {drude_lorentz(10e-6, N_fit)}"</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>Predicting Road Accident Risk</title>
    <url>/zhihaojiang.github.io/2025/10/11/20251013Predicting%20Road%20Accident%20Risk/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/competitions/playground-series-s5e10" >https://www.kaggle.com/competitions/playground-series-s5e10<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">MacOS专用字体设置</span></span><br><span class="line"><span class="string">MacOS 系统中使用的中文字体路径</span></span><br><span class="line"><span class="string">适用于MacOS15版本</span></span><br><span class="line"><span class="string">可直接复制到代码中使用</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib import font_manager</span><br><span class="line"><span class="comment"># 设置字体路径</span></span><br><span class="line">font_path = <span class="string">&#x27;/System/Library/Fonts/STHeiti Medium.ttc&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载字体</span></span><br><span class="line">my_font = font_manager.FontProperties(fname=font_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = my_font.get_name()</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = False  <span class="comment"># 正确显示负号</span></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">df_train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">df_train.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>id</th>
<th>road_type</th>
<th>num_lanes</th>
<th>curvature</th>
<th>speed_limit</th>
<th>lighting</th>
<th>weather</th>
<th>road_signs_present</th>
<th>public_road</th>
<th>time_of_day</th>
<th>holiday</th>
<th>school_season</th>
<th>num_reported_accidents</th>
<th>accident_risk</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>urban</td>
<td>2</td>
<td>0.06</td>
<td>35</td>
<td>daylight</td>
<td>rainy</td>
<td>False</td>
<td>True</td>
<td>afternoon</td>
<td>False</td>
<td>True</td>
<td>1</td>
<td>0.13</td>
</tr>
<tr>
<td>1</td>
<td>urban</td>
<td>4</td>
<td>0.99</td>
<td>35</td>
<td>daylight</td>
<td>clear</td>
<td>True</td>
<td>False</td>
<td>evening</td>
<td>True</td>
<td>True</td>
<td>0</td>
<td>0.35</td>
</tr>
<tr>
<td>2</td>
<td>rural</td>
<td>4</td>
<td>0.63</td>
<td>70</td>
<td>dim</td>
<td>clear</td>
<td>False</td>
<td>True</td>
<td>morning</td>
<td>True</td>
<td>False</td>
<td>2</td>
<td>0.30</td>
</tr>
<tr>
<td>3</td>
<td>highway</td>
<td>4</td>
<td>0.07</td>
<td>35</td>
<td>dim</td>
<td>rainy</td>
<td>True</td>
<td>True</td>
<td>morning</td>
<td>False</td>
<td>False</td>
<td>1</td>
<td>0.21</td>
</tr>
<tr>
<td>4</td>
<td>rural</td>
<td>1</td>
<td>0.58</td>
<td>60</td>
<td>daylight</td>
<td>foggy</td>
<td>False</td>
<td>False</td>
<td>evening</td>
<td>True</td>
<td>False</td>
<td>1</td>
<td>0.56</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_train.info()</span><br></pre></td></tr></table></figure></div>
<pre><code> Column                  Non-Null Count   Dtype  
</code></pre>
<hr>
<p> 0   id                      517754 non-null  int64<br> 1   road_type               517754 non-null  object<br> 2   num_lanes               517754 non-null  int64<br> 3   curvature               517754 non-null  float64<br> 4   speed_limit             517754 non-null  int64<br> 5   lighting                517754 non-null  object<br> 6   weather                 517754 non-null  object<br> 7   road_signs_present      517754 non-null  bool<br> 8   public_road             517754 non-null  bool<br> 9   time_of_day             517754 non-null  object<br> 10  holiday                 517754 non-null  bool<br> 11  school_season           517754 non-null  bool<br> 12  num_reported_accidents  517754 non-null  int64<br> 13  accident_risk           517754 non-null  float64</p>
<ul>
<li>id 编号</li>
<li>road_type 道路类型</li>
<li>num_lanes 车道数量</li>
<li>curvature 曲率</li>
<li>speed_limit 最高限速</li>
<li>lighting 照明条件</li>
<li>weather 天气条件</li>
<li>road_signs_present 是否有道路标识</li>
<li>public_road 是否为公共道路</li>
<li>time_of_day 时间（早中晚）</li>
<li>holiday 是否是假期</li>
<li>school_season 是否是开学季</li>
<li>num_reported_accidents 报告的交通事故数量</li>
<li>accident_risk 交通事故风险等级</li>
</ul>
<h1 id="缺失值检测"><a href="#缺失值检测" class="headerlink" title="缺失值检测"></a>缺失值检测</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_train.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>id                        0<br>road_type                 0<br>num_lanes                 0<br>curvature                 0<br>speed_limit               0<br>lighting                  0<br>weather                   0<br>road_signs_present        0<br>public_road               0<br>time_of_day               0<br>holiday                   0<br>school_season             0<br>num_reported_accidents    0<br>accident_risk             0<br>dtype: int64</p>
</blockquote>
<p>查看后可知 该数据集没有缺失值</p>
<h1 id="异常值"><a href="#异常值" class="headerlink" title="异常值"></a>异常值</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy import stats</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df_train.columns:</span><br><span class="line">    <span class="keyword">if</span> df_train[col].dtype != <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        z_scores = np.abs(stats.zscore(df_train[col].dropna()))</span><br><span class="line">        outliers = df_train[z_scores &gt; 3]</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;列 &#123;col&#125; 中的异常值数量: &#123;len(outliers)&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>列 id 中的异常值数量: 0<br>列 num_lanes 中的异常值数量: 0<br>列 curvature 中的异常值数量: 0<br>列 speed_limit 中的异常值数量: 0<br>列 road_signs_present 中的异常值数量: 0<br>列 public_road 中的异常值数量: 0<br>列 holiday 中的异常值数量: 0<br>列 school_season 中的异常值数量: 0<br>列 num_reported_accidents 中的异常值数量: 2649<br>列 accident_risk 中的异常值数量: 1163</p>
</blockquote>
<p>发现 num_reported_accidents 和 accident_risk 存在异常值 由于 accident_risk 是我们要预测的目标 这说明 accident_risk 中数据分布是不平衡的</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.boxplot(df_train[<span class="string">&#x27;num_reported_accidents&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;num_reported_accidents&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/001.png"
                      alt="photo"
                ></p>
<h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from scipy import stats</span><br><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df_train.columns:</span><br><span class="line">    <span class="keyword">if</span> df_train[col].dtype != <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        plt.figure(figsize=(12, 4))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 直方图 + KDE</span></span><br><span class="line">        plt.subplot(1, 2, 1)</span><br><span class="line">        sns.histplot(df_train[col].dropna(), kde=True, bins=30)</span><br><span class="line">        plt.title(f<span class="string">&#x27;&#123;col&#125; 分布&#x27;</span>)</span><br><span class="line">        plt.xlabel(col)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># QQ图</span></span><br><span class="line">        plt.subplot(1, 2, 2)</span><br><span class="line">        stats.probplot(df_train[col].dropna(), dist=<span class="string">&quot;norm&quot;</span>, plot=plt)</span><br><span class="line">        plt.title(f<span class="string">&#x27;&#123;col&#125; QQ 图&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/002.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/003.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/004.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/005.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/006.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/007.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/008.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/009.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/010.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/011.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_num = df_train.select_dtypes(include=[<span class="string">&#x27;int64&#x27;</span>, <span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;bool&#x27;</span>])</span><br><span class="line">sns.heatmap(df_num.corr(), annot=True, cmap=<span class="string">&#x27;YlGnBu&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/012.png"
                      alt="photo"
                ></p>
<p>我们可以看到 curvature speed_limit num_reported_accidents 和 accident_risk 之间有很强的相关性</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.boxplot(</span><br><span class="line">    x=<span class="string">&#x27;speed_limit&#x27;</span>,</span><br><span class="line">    y=<span class="string">&#x27;accident_risk&#x27;</span>,</span><br><span class="line">    data=df_train</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&#x27;speed_limit vs accident_risk&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/013.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.hexbin(df_train[<span class="string">&#x27;curvature&#x27;</span>], df_train[<span class="string">&#x27;accident_risk&#x27;</span>], gridsize=30, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Curvature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accident Risk&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Curvature vs Accident Risk&#x27;</span>)</span><br><span class="line">plt.colorbar(label=<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/014.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_train[<span class="string">&#x27;curvature_bin&#x27;</span>] = pd.qcut(df_train[<span class="string">&#x27;curvature&#x27;</span>], q=5)</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;curvature_bin&#x27;</span>, y=<span class="string">&#x27;accident_risk&#x27;</span>, data=df_train)</span><br><span class="line">plt.xticks(rotation=45)</span><br><span class="line">plt.title(<span class="string">&#x27;Accident Risk Distribution by Curvature Bins&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/015.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sns.boxplot(x=<span class="string">&#x27;num_reported_accidents&#x27;</span>, y=<span class="string">&#x27;accident_risk&#x27;</span>, data=df_train)</span><br><span class="line">plt.xticks(rotation=45)</span><br><span class="line">plt.title(<span class="string">&#x27;num_reported_accidents VS accident_risk&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/016.png"
                      alt="photo"
                ></p>
<p>在我们的直觉中 交通事故数量越多 交通事故风险等级越高 但从图中可以看出 报告的事故数量从0-5风险逐渐变大 在4和5时风险最大 而到6和7时 风险反而变小了 这里我认为是由于道路交通部门发现了这段路报告的事故数量异常高 因此采取了某些举措从而降低了风险</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots(2, 2, figsize=(10,8))</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;road_type&#x27;</span>, y=<span class="string">&#x27;accident_risk&#x27;</span>, data=df_train, ax=axes[0,0])</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;lighting&#x27;</span>, y=<span class="string">&#x27;accident_risk&#x27;</span>, data=df_train, ax=axes[0,1])</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;weather&#x27;</span>, y=<span class="string">&#x27;accident_risk&#x27;</span>, data=df_train, ax=axes[1,0])</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;time_of_day&#x27;</span>, y=<span class="string">&#x27;accident_risk&#x27;</span>, data=df_train, ax=axes[1,1])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/11/017.png"
                      alt="photo"
                ></p>
<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_obj = df_train.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>])</span><br><span class="line">df_obj.columns</span><br></pre></td></tr></table></figure></div>
<p>Index([‘road_type’, ‘lighting’, ‘weather’, ‘time_of_day’], dtype&#x3D;’object’)</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df_obj.columns:</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;列名：&#123;col&#125;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(df_obj[col].unique())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>列名：road_type<br>[‘urban’ ‘rural’ ‘highway’]</p>
<p>列名：lighting<br>[‘daylight’ ‘dim’ ‘night’]</p>
<p>列名：weather<br>[‘rainy’ ‘clear’ ‘foggy’]</p>
<p>列名：time_of_day<br>[‘afternoon’ ‘evening’ ‘morning’]</p>
</blockquote>
<p>由于road_type是无序的，我们对road_type进行one-hot编码<br>lighting和weather存在一定的顺序 这样模型能理解“夜晚比白天危险”、“雨天比晴天风险高”<br>time_of_day存在一定的顺序 因此使用正弦编码，模型这样可以感知“早晨和晚上”在周期上是相邻的，而不是数值差很大。</p>
<h2 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_train = pd.get_dummies(df_train, columns=[<span class="string">&#x27;road_type&#x27;</span>], drop_first=False)</span><br></pre></td></tr></table></figure></div>

<h2 id="标签编码"><a href="#标签编码" class="headerlink" title="标签编码"></a>标签编码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">lighting_map = &#123;<span class="string">&#x27;daylight&#x27;</span>: 0, <span class="string">&#x27;dim&#x27;</span>: 1, <span class="string">&#x27;night&#x27;</span>: 2&#125;</span><br><span class="line">weather_map = &#123;<span class="string">&#x27;clear&#x27;</span>: 0, <span class="string">&#x27;foggy&#x27;</span>: 1, <span class="string">&#x27;rainy&#x27;</span>: 2&#125;</span><br><span class="line"></span><br><span class="line">df_train[<span class="string">&#x27;lighting&#x27;</span>] = df_train[<span class="string">&#x27;lighting&#x27;</span>].map(lighting_map)</span><br><span class="line">df_train[<span class="string">&#x27;weather&#x27;</span>] = df_train[<span class="string">&#x27;weather&#x27;</span>].map(weather_map)</span><br></pre></td></tr></table></figure></div>

<h2 id="正弦编码"><a href="#正弦编码" class="headerlink" title="正弦编码"></a>正弦编码</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">time_map = &#123;<span class="string">&#x27;morning&#x27;</span>: 0, <span class="string">&#x27;afternoon&#x27;</span>: 1, <span class="string">&#x27;evening&#x27;</span>: 2&#125;</span><br><span class="line">df_train[<span class="string">&#x27;time_code&#x27;</span>] = df_train[<span class="string">&#x27;time_of_day&#x27;</span>].map(time_map)</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">df_train[<span class="string">&#x27;time_sin&#x27;</span>] = np.sin(2 * np.pi * df_train[<span class="string">&#x27;time_code&#x27;</span>] / 3)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_train = df_train.drop(columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;time_of_day&#x27;</span>, <span class="string">&#x27;curvature_bin&#x27;</span>, <span class="string">&#x27;time_code&#x27;</span>])</span><br></pre></td></tr></table></figure></div>

<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from xgboost import XGBRegressor</span><br><span class="line">from lightgbm import LGBMRegressor</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">models = &#123;</span><br><span class="line">    <span class="string">&#x27;XGBoost&#x27;</span>: XGBRegressor(random_state=42),</span><br><span class="line">    <span class="string">&#x27;LightGBM&#x27;</span>: LGBMRegressor(random_state=42)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>XGBoost 模型得分: 0.8852848521865487<br>XGBoost 模型 RMSE: 0.05628087549522937<br>[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003744 seconds.<br>You can set <code>force_row_wise=true</code> to remove the overhead.<br>And if memory is not enough, you can set <code>force_col_wise=true</code>.<br>[LightGBM] [Info] Total Bins 170<br>[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 14<br>[LightGBM] [Info] Start training from score 0.352605<br>LightGBM 模型得分: 0.8850232397713161<br>LightGBM 模型 RMSE: 0.05634501432550113</p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>随机森林</p>

    </div>
    <div class="notel-content">
      <p>你也可以使用随机森林进行 不过在我的电脑上随机森林运行时间比较长（1分30秒） 我就贴出了我自己运行的结果<br>RandomForest 模型得分: 0.8721398843806608<br>RandomForest 模型 RMSE: 0.059417996862623244</p>

    </div>
  </div>

<h1 id="测试集处理"><a href="#测试集处理" class="headerlink" title="测试集处理"></a>测试集处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_test = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># one-hot</span></span><br><span class="line">df_test = pd.get_dummies(df_test, columns=[<span class="string">&#x27;road_type&#x27;</span>], drop_first=False)</span><br><span class="line"></span><br><span class="line"><span class="comment"># label</span></span><br><span class="line">lighting_map = &#123;<span class="string">&#x27;daylight&#x27;</span>: 0, <span class="string">&#x27;dim&#x27;</span>: 1, <span class="string">&#x27;night&#x27;</span>: 2&#125;</span><br><span class="line">weather_map = &#123;<span class="string">&#x27;clear&#x27;</span>: 0, <span class="string">&#x27;foggy&#x27;</span>: 1, <span class="string">&#x27;rainy&#x27;</span>: 2&#125;</span><br><span class="line"></span><br><span class="line">df_test[<span class="string">&#x27;lighting&#x27;</span>] = df_test[<span class="string">&#x27;lighting&#x27;</span>].map(lighting_map)</span><br><span class="line">df_test[<span class="string">&#x27;weather&#x27;</span>] = df_test[<span class="string">&#x27;weather&#x27;</span>].map(weather_map)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sin</span></span><br><span class="line">time_map = &#123;<span class="string">&#x27;morning&#x27;</span>: 0, <span class="string">&#x27;afternoon&#x27;</span>: 1, <span class="string">&#x27;evening&#x27;</span>: 2&#125;</span><br><span class="line">df_test[<span class="string">&#x27;time_code&#x27;</span>] = df_test[<span class="string">&#x27;time_of_day&#x27;</span>].map(time_map)</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">df_test[<span class="string">&#x27;time_sin&#x27;</span>] = np.sin(2 * np.pi * df_test[<span class="string">&#x27;time_code&#x27;</span>] / 3)</span><br><span class="line"></span><br><span class="line">ids = df_test[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">df_test = df_test.drop(columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;time_of_day&#x27;</span>, <span class="string">&#x27;time_code&#x27;</span>])</span><br><span class="line"></span><br><span class="line">XGBoost = models[<span class="string">&#x27;XGBoost&#x27;</span>]</span><br><span class="line">y_pred_test = XGBoost.predict(df_test)</span><br></pre></td></tr></table></figure></div>

<h1 id="提交数据"><a href="#提交数据" class="headerlink" title="提交数据"></a>提交数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">submission = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;id&#x27;</span>: ids,</span><br><span class="line">    <span class="string">&#x27;accident_risk&#x27;</span>: y_pred_test</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=False)</span><br></pre></td></tr></table></figure></div>

<p>其成绩判定的方式是RMSE 我的成绩是0.05569</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>earthquake_data_tsunami</title>
    <url>/zhihaojiang.github.io/2025/10/16/20251016earthquake_data_tsunami/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/datasets/ahmeduzaki/global-earthquake-tsunami-risk-assessment-dataset/data" >https://www.kaggle.com/datasets/ahmeduzaki/global-earthquake-tsunami-risk-assessment-dataset/data<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="关于此文件"><a href="#关于此文件" class="headerlink" title="关于此文件"></a>关于此文件</h1><p>全球地震—海啸风险评估数据集，包含 2001–2022 年间全球范围内 782 次重大地震的地震参数与海啸潜势指标。该 CSV 数据集已预处理为机器学习可直接使用的格式，适用于海啸风险预测、地震分析及地震灾害评估等研究。</p>
<p>主要特征：<br>	•	共收录 782 条震级 ≥ 6.5 的地震记录</p>
<pre><code>•	包含 13 个标准化数值特征（如震级、深度、经纬度等）

•	含有海啸二元分类标签（38.9% 为海啸事件，61.1% 为非海啸事件）

•	数据完整，无缺失值

•	全球地理覆盖范围（纬度 -61.85° 至 71.63°）

•	时间跨度 22 年，涵盖主要地震事件
</code></pre>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;earthquake_data_tsunami.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>

<ol>
<li>magnitude（震级）<br> •    含义：地震释放能量的大小，通常以里氏震级（Richter scale）或矩震级（Moment Magnitude, Mw）表示。<br> •    作用：震级越大，地震释放的能量越多，造成海啸的可能性也越高。<br> •    典型范围：6.5 ~ 9.1</li>
</ol>
<p>⸻</p>
<ol start="2">
<li>cdi（Community Decimal Intensity，公众感受强度）<br> •    含义：由“美国地质调查局（USGS）感知地震报告”（Did You Feel It?）系统收集的公众感知强度，反映人们在震区的主观感受。<br> •    作用：反映地震在地表的影响程度，可间接表征地震破坏性与地表波传播能量。<br> •    典型范围：1.0（几乎未感知）～10.0（极度破坏）。</li>
</ol>
<p>⸻</p>
<ol start="3">
<li>mmi（Modified Mercalli Intensity，修订麦加利烈度）<br> •    含义：根据仪器测得的地震动强度计算的烈度，衡量地震在某地区造成的结构损害与人员感受。<br> •    作用：比 cdi 更客观，常用于地震危险性评估和建筑抗震设计参考。<br> •    典型范围：I（无感）～XII（完全毁坏），数据中通常以数值形式（1–12 或 1–10）表示。</li>
</ol>
<p>⸻</p>
<ol start="4">
<li>sig（Significance，事件重要性得分）<br> •    含义：由 USGS 定义的地震重要性综合评分，综合考虑震级、深度、烈度、人口密度等因素。<br> •    作用：用于衡量地震在灾害研究或警报系统中的重要程度。<br> •    典型范围：0～1000（数值越高表示事件越显著）。</li>
</ol>
<p>⸻</p>
<ol start="5">
<li>nst（Number of Seismic Stations，地震监测台站数）<br> •    含义：记录该次地震的地震台站数量。<br> •    作用：台站数量越多，定位与参数测定的精度越高；也反映区域监测网络密度。<br> •    典型范围：1～1000。</li>
</ol>
<p>⸻</p>
<ol start="6">
<li>dmin（Distance to Nearest Station，最近台站距离，单位：°）<br> •    含义：地震震中与最近地震台站之间的角距离（以地球球面角度计算）。<br> •    作用：距离越小，观测数据越精确；若距离较大，可能存在数据误差。<br> •    典型范围：0.0～10.0（°）。</li>
</ol>
<p>⸻</p>
<ol start="7">
<li>gap（Azimuthal Gap，方位间隙，单位：°）<br> •    含义：地震台站分布的最大方位空缺角度。<br> •    作用：用于评估地震定位的几何精度。Gap 值越大，定位不确定性越高。<br> •    典型范围：0～360（°）；通常 &lt;180° 表示分布良好。</li>
</ol>
<p>⸻</p>
<ol start="8">
<li>depth（Focal Depth，震源深度，单位：km）<br> •    含义：地震震源到地表的垂直距离。<br> •    作用：浅源地震（&lt;70 km）更易造成地表破坏和海啸；深源地震（&gt;300 km）影响范围广但破坏性较弱。<br> •    典型范围：0～700 km。</li>
</ol>
<p>⸻</p>
<ol start="9">
<li>latitude（纬度）<br> •    含义：地震震中所在的地理纬度，基于 WGS84 坐标系统。<br> •    作用：用于全球地理定位，可结合经度进行地震分布分析。<br> •    范围：-90°（南极）～+90°（北极）。</li>
</ol>
<p>⸻</p>
<ol start="10">
<li>longitude（经度）<br>•    含义：地震震中所在的地理经度，基于 WGS84 坐标系统。<br>•    作用：与纬度共同确定地震的具体地理位置。<br>•    范围：-180°～+180°。</li>
</ol>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.describe()</span><br><span class="line"></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<p>magnitude    0<br>cdi          0<br>mmi          0<br>sig          0<br>nst          0<br>dmin         0<br>gap          0<br>depth        0<br>latitude     0<br>longitude    0<br>Year         0<br>Month        0<br>tsunami      0<br>dtype: int64</p>
<h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><h2 id="海啸发生的位置"><a href="#海啸发生的位置" class="headerlink" title="海啸发生的位置"></a>海啸发生的位置</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import cartopy.crs as ccrs</span><br><span class="line">import cartopy.feature as cfeature</span><br><span class="line"></span><br><span class="line">df_tsu = <span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">&#x27;tsunami&#x27;</span>] == 1]</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(14, 7))</span><br><span class="line">ax = plt.axes(projection=ccrs.PlateCarree())</span><br><span class="line"></span><br><span class="line">ax.add_feature(cfeature.LAND, facecolor=<span class="string">&quot;#f0f0f0&quot;</span>)</span><br><span class="line">ax.add_feature(cfeature.COASTLINE, linewidth=0.5)</span><br><span class="line">ax.add_feature(cfeature.BORDERS, linewidth=0.3)</span><br><span class="line">ax.add_feature(cfeature.OCEAN, facecolor=<span class="string">&quot;#d8ecf3&quot;</span>)</span><br><span class="line"></span><br><span class="line">ax.set_extent([-180, 180, -80, 80], crs=ccrs.PlateCarree())</span><br><span class="line"></span><br><span class="line">sns.kdeplot(</span><br><span class="line">    x=df_tsu[<span class="string">&quot;longitude&quot;</span>],</span><br><span class="line">    y=df_tsu[<span class="string">&quot;latitude&quot;</span>],</span><br><span class="line">    cmap=<span class="string">&quot;Reds&quot;</span>,</span><br><span class="line">    fill=True,</span><br><span class="line">    alpha=0.6,</span><br><span class="line">    bw_adjust=1,</span><br><span class="line">    levels=50,</span><br><span class="line">    ax=ax</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sns.scatterplot(</span><br><span class="line">    x=df_tsu[<span class="string">&quot;longitude&quot;</span>],</span><br><span class="line">    y=df_tsu[<span class="string">&quot;latitude&quot;</span>],</span><br><span class="line">    color=<span class="string">&quot;red&quot;</span>,</span><br><span class="line">    s=10,</span><br><span class="line">    ax=ax</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&quot;Global Tsunami Event Density Map (2001–2022)&quot;</span>, fontsize=14)</span><br><span class="line">ax.gridlines(draw_labels=True, linewidth=0.3, color=<span class="string">&#x27;gray&#x27;</span>, alpha=0.5)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/001.png"
                      alt="photo"
                ></p>
<p>从散点图上看 大部份海啸发生的位置处于环太平洋地震带上<br>从密度图上看 在赤道附近 海啸发生的频率较高</p>
<p>说明 海啸的发生与地震发生的位置有关 并且越靠近赤道 海啸发生的频率越高</p>
<h2 id="海啸发生与时间的关系"><a href="#海啸发生与时间的关系" class="headerlink" title="海啸发生与时间的关系"></a>海啸发生与时间的关系</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_tsu[<span class="string">&quot;Date&quot;</span>] = pd.to_datetime(df_tsu[<span class="string">&quot;Year&quot;</span>].astype(str) + <span class="string">&quot;-&quot;</span> + df_tsu[<span class="string">&quot;Month&quot;</span>].astype(str) + <span class="string">&quot;-01&quot;</span>)</span><br><span class="line"></span><br><span class="line">ts_count = df_tsu.groupby(<span class="string">&quot;Date&quot;</span>).size()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(12,5))</span><br><span class="line">plt.plot(ts_count.index, ts_count.values, color=<span class="string">&quot;darkred&quot;</span>, linewidth=1.5)</span><br><span class="line">plt.title(<span class="string">&quot;Monthly Tsunami Event Count (2001–2022)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Time&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Tsunami Count&quot;</span>)</span><br><span class="line">plt.grid(True, linestyle=<span class="string">&quot;--&quot;</span>, alpha=0.5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>












<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/002.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 按年份和月份统计数量</span></span><br><span class="line">monthly_count = df_tsu.groupby([<span class="string">&quot;Year&quot;</span>, <span class="string">&quot;Month&quot;</span>]).size().reset_index(name=<span class="string">&quot;count&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个月的平均发生次数</span></span><br><span class="line">month_avg = monthly_count.groupby(<span class="string">&quot;Month&quot;</span>)[<span class="string">&quot;count&quot;</span>].mean()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(10, 5))</span><br><span class="line">plt.plot(month_avg.index, month_avg.values, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.xticks(range(1, 13))</span><br><span class="line">plt.title(<span class="string">&quot;Average Tsunami Occurrence Frequency by Month (2001–2022)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Month&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Average Number of Tsunamis&quot;</span>)</span><br><span class="line">plt.grid(True, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=0.5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/003.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按年份和月份统计</span></span><br><span class="line">heatmap_data = df_tsu.groupby([<span class="string">&quot;Year&quot;</span>, <span class="string">&quot;Month&quot;</span>]).size().unstack(fill_value=0)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(12, 6))</span><br><span class="line">sns.heatmap(heatmap_data, cmap=<span class="string">&quot;Reds&quot;</span>, linewidths=0.3)</span><br><span class="line">plt.title(<span class="string">&quot;Tsunami Occurrence Heatmap by Year and Month (2001–2022)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Month&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Year&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/004.png"
                      alt="photo"
                ></p>
<p>发现 2014年4月海啸数量特别多 查询相关资料后发现 当时智利西北部近海发生了8.0-8.2级的大地震 并且那年处于史上最强厄尔尼诺现象的发展阶段<br>具体查看2014年的数据</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df_2014_4 = df_tsu[(df_tsu[<span class="string">&quot;Year&quot;</span>] == 2014) &amp; (df_tsu[<span class="string">&quot;Month&quot;</span>] == 4)]</span><br><span class="line"></span><br><span class="line">df_tsu_2014_4 = df_2014_4[df_2014_4[<span class="string">&#x27;tsunami&#x27;</span>] == 1]</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(14, 7))</span><br><span class="line">ax = plt.axes(projection=ccrs.PlateCarree())</span><br><span class="line"></span><br><span class="line">ax.add_feature(cfeature.LAND, facecolor=<span class="string">&quot;#f0f0f0&quot;</span>)</span><br><span class="line">ax.add_feature(cfeature.COASTLINE, linewidth=0.5)</span><br><span class="line">ax.add_feature(cfeature.BORDERS, linewidth=0.3)</span><br><span class="line">ax.add_feature(cfeature.OCEAN, facecolor=<span class="string">&quot;#d8ecf3&quot;</span>)</span><br><span class="line"></span><br><span class="line">ax.set_extent([-180, 180, -80, 80], crs=ccrs.PlateCarree())</span><br><span class="line"></span><br><span class="line">sns.kdeplot(</span><br><span class="line">    x=df_tsu_2014_4[<span class="string">&quot;longitude&quot;</span>],</span><br><span class="line">    y=df_tsu_2014_4[<span class="string">&quot;latitude&quot;</span>],</span><br><span class="line">    cmap=<span class="string">&quot;Reds&quot;</span>,</span><br><span class="line">    fill=True,</span><br><span class="line">    alpha=0.6,</span><br><span class="line">    bw_adjust=1,</span><br><span class="line">    levels=50,</span><br><span class="line">    ax=ax</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sns.scatterplot(</span><br><span class="line">    x=df_tsu_2014_4[<span class="string">&quot;longitude&quot;</span>],</span><br><span class="line">    y=df_tsu_2014_4[<span class="string">&quot;latitude&quot;</span>],</span><br><span class="line">    color=<span class="string">&quot;red&quot;</span>,</span><br><span class="line">    s=10,</span><br><span class="line">    ax=ax</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&quot;Global Tsunami Event Density Map (2014-4)&quot;</span>, fontsize=14)</span><br><span class="line">ax.gridlines(draw_labels=True, linewidth=0.3, color=<span class="string">&#x27;gray&#x27;</span>, alpha=0.5)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/005.png"
                      alt="photo"
                ></p>
<h2 id="海啸与震源深度的关系"><a href="#海啸与震源深度的关系" class="headerlink" title="海啸与震源深度的关系"></a>海啸与震源深度的关系</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">sns.violinplot(</span><br><span class="line">    x=<span class="built_in">df</span>[<span class="string">&quot;tsunami&quot;</span>],</span><br><span class="line">    y=<span class="built_in">df</span>[<span class="string">&quot;depth&quot;</span>]</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&quot;Tsunami VS Depth&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/006.png"
                      alt="photo"
                ></p>
<h2 id="查看数据分布"><a href="#查看数据分布" class="headerlink" title="查看数据分布"></a>查看数据分布</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(10, 8))</span><br><span class="line">sns.heatmap(df.corr(), annot=True, cmap=<span class="string">&quot;coolwarm&quot;</span>, <span class="built_in">fmt</span>=<span class="string">&quot;.2f&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/007.png"
                      alt="photo"
                ></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.hist(bins=50, figsize=(20,12))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/008.png"
                      alt="photo"
                ></p>
<h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.preprocessing import QuantileTransformer</span><br><span class="line"></span><br><span class="line">qt = QuantileTransformer(output_distribution=<span class="string">&#x27;normal&#x27;</span>, random_state=42)</span><br><span class="line"><span class="built_in">df</span>[[<span class="string">&#x27;nst&#x27;</span>, <span class="string">&#x27;dmin&#x27;</span>, <span class="string">&#x27;gap&#x27;</span>, <span class="string">&#x27;depth&#x27;</span>, <span class="string">&#x27;sig&#x27;</span>]] = qt.fit_transform(<span class="built_in">df</span>[[<span class="string">&#x27;nst&#x27;</span>, <span class="string">&#x27;dmin&#x27;</span>, <span class="string">&#x27;gap&#x27;</span>, <span class="string">&#x27;depth&#x27;</span>, <span class="string">&#x27;sig&#x27;</span>]])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.hist(bins=50, figsize=(20,12))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/16/009.png"
                      alt="photo"
                ></p>
<h1 id="方法1：SphericalRBF-LGBM"><a href="#方法1：SphericalRBF-LGBM" class="headerlink" title="方法1：SphericalRBF+LGBM"></a>方法1：SphericalRBF+LGBM</h1><h2 id="背景：为什么不能直接对经纬度做-RBF"><a href="#背景：为什么不能直接对经纬度做-RBF" class="headerlink" title="背景：为什么不能直接对经纬度做 RBF"></a>背景：为什么不能直接对经纬度做 RBF</h2><p>如果你直接在纬度 (lat) 和经度 (lon) 上应用普通的 RBF 核：</p>
<p>$$<br>K(x, x’) &#x3D; exp(-γ · ||x - x’||²)<br>$$</p>
<p>看似可行，但数学上是错误的，因为地球是一个球面，而 (lat, lon) 是球面坐标，并不满足欧几里得距离的几何意义。</p>
<h2 id="对比：普通-RBF-vs-球面-RBF"><a href="#对比：普通-RBF-vs-球面-RBF" class="headerlink" title="对比：普通 RBF vs 球面 RBF"></a>对比：普通 RBF vs 球面 RBF</h2><table>
<thead>
<tr>
<th>特征</th>
<th>普通 RBF on (Lat, Lon)</th>
<th>球面 RBF (Spherical RBF)</th>
</tr>
</thead>
<tbody><tr>
<td>使用的距离</td>
<td>欧几里得距离（平面直线）</td>
<td>球面大圆距离（沿球面最短路径）</td>
</tr>
<tr>
<td>数学表达</td>
<td>$exp(-γ · ((Δlat)² + (Δlon)²))$</td>
<td>$exp(-γ · θ²)$，其中 $θ &#x3D; arccos(u · u’)$</td>
</tr>
<tr>
<td>坐标空间</td>
<td>平面坐标系</td>
<td>单位球面（通过三维向量化）</td>
</tr>
<tr>
<td>近极点失真</td>
<td>严重失真（经度差在高纬度几乎没意义）</td>
<td>自动修正（以真实角距离计算）</td>
</tr>
<tr>
<td>经度 180° 跨越问题</td>
<td>错误：179°E 与 179°W 被认为相距 358°</td>
<td>正确：球面上仅相距 2°</td>
</tr>
<tr>
<td>适用范围</td>
<td>小区域、局部近似（如城市级）</td>
<td>全球范围（地球、天体等球面数据）</td>
</tr>
</tbody></table>
<h2 id="几何原理详解"><a href="#几何原理详解" class="headerlink" title="几何原理详解"></a>几何原理详解</h2><p>假设两个点分别为：</p>
<ul>
<li>点 A：纬度 $lat₁$，经度 $lon₁$  </li>
<li>点 B：纬度 $lat₂$，经度 $lon₂$</li>
</ul>
<h3 id="普通-RBF-计算"><a href="#普通-RBF-计算" class="headerlink" title="普通 RBF 计算"></a>普通 RBF 计算</h3><p>$$<br>K &#x3D; exp(-γ · ((lat₁ - lat₂)² + (lon₁ - lon₂)²))<br>$$</p>
<ul>
<li>假设球面是平的。  </li>
<li>在赤道附近还能勉强近似，但在两极或跨经度时会严重失真。</li>
</ul>
<h3 id="Spherical-RBF-计算"><a href="#Spherical-RBF-计算" class="headerlink" title="Spherical RBF 计算"></a>Spherical RBF 计算</h3><p>先把每个点转换成球面单位向量：</p>
<p>$$<br>u &#x3D; [<br>  cos(lat) · cos(lon),<br>  cos(lat) · sin(lon),<br>  sin(lat)<br>]<br>$$</p>
<p>两个点的球面角距离为：</p>
<p>$$<br>θ &#x3D; arccos(u · u’)<br>$$</p>
<p>于是 RBF 特征为：</p>
<p>$$<br>K &#x3D; exp(-γ · θ²)<br>$$</p>
<p>这意味着两点的“相似度”由球面上沿弧线的角度距离决定，而非平面直线距离。</p>
<h2 id="在-SphericalRBF-类中如何实现"><a href="#在-SphericalRBF-类中如何实现" class="headerlink" title="在 SphericalRBF 类中如何实现"></a>在 SphericalRBF 类中如何实现</h2><table>
<thead>
<tr>
<th>代码部分</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>_to_unit()</code></td>
<td>把 <code>(lat, lon)</code> → 单位球面坐标 <code>(x, y, z)</code></td>
</tr>
<tr>
<td><code>fit()</code></td>
<td>用 KMeans 在球面上找一组中心点</td>
</tr>
<tr>
<td><code>transform()</code></td>
<td>计算每个样本到这些中心的球面角距离 θ，并用 $exp(-γ·θ²)$ 得到特征值</td>
</tr>
<tr>
<td>输出特征</td>
<td>每个样本对应一组“地理位置相似度”特征，可供机器学习模型使用</td>
</tr>
</tbody></table>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator, TransformerMixin</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">class SphericalRBF(BaseEstimator, TransformerMixin):</span><br><span class="line">    def __init__(self, n_clusters=5, gamma=<span class="string">&quot;auto&quot;</span>, random_state=None):</span><br><span class="line">        self.n_clusters = n_clusters</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.random_state = random_state</span><br><span class="line"></span><br><span class="line">    def _to_unit(self, lat, lon):</span><br><span class="line">        lat, lon = np.radians(lat), np.radians(lon)</span><br><span class="line">        x = np.cos(lat)*np.cos(lon)</span><br><span class="line">        y = np.cos(lat)*np.sin(lon)</span><br><span class="line">        z = np.sin(lat)</span><br><span class="line">        <span class="built_in">return</span> np.c_[x, y, z]</span><br><span class="line"></span><br><span class="line">    def fit(self, X, y=None, sample_weight=None):</span><br><span class="line">        X_array = X.values</span><br><span class="line">        U = self._to_unit(X_array[:, 0], X_array[:, 1])</span><br><span class="line">        self.kmeans_ = KMeans(</span><br><span class="line">            n_clusters=self.n_clusters,</span><br><span class="line">            n_init=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">            random_state=self.random_state</span><br><span class="line">        ).fit(U, sample_weight=sample_weight)</span><br><span class="line"></span><br><span class="line">        dot = U @ self.kmeans_.cluster_centers_.T</span><br><span class="line">        ang = np.arccos(np.clip(dot, -1.0, 1.0))</span><br><span class="line">        med = np.median(ang[ang &gt; 0]) <span class="keyword">if</span> np.any(ang &gt; 0) <span class="keyword">else</span> 0.1</span><br><span class="line">        self.gamma_ = (1.0 / (2 * med ** 2)) <span class="keyword">if</span> self.gamma == <span class="string">&quot;auto&quot;</span> <span class="keyword">else</span> <span class="built_in">float</span>(self.gamma)</span><br><span class="line">        <span class="built_in">return</span> self</span><br><span class="line"></span><br><span class="line">    def transform(self, X):</span><br><span class="line">        X_array = X.values</span><br><span class="line">        U = self._to_unit(X_array[:, 0], X_array[:, 1])</span><br><span class="line">        dot = U @ self.kmeans_.cluster_centers_.T</span><br><span class="line">        ang = np.arccos(np.clip(dot, -1.0, 1.0))</span><br><span class="line">        <span class="built_in">return</span> np.exp(-self.gamma_ * ang ** 2)</span><br><span class="line"></span><br><span class="line">    def get_feature_names_out(self, names=None):</span><br><span class="line">        <span class="built_in">return</span> np.array([f<span class="string">&quot;geo_cluster_&#123;i&#125;&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_clusters)])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[<span class="string">&#x27;tsunami&#x27;</span>]),<span class="built_in">df</span>[<span class="string">&#x27;tsunami&#x27;</span>], test_size=0.2, stratify=<span class="built_in">df</span>[<span class="string">&#x27;tsunami&#x27;</span>], random_state=42)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">geo_sim = SphericalRBF(n_clusters=5, random_state=42)</span><br><span class="line"></span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.compose import ColumnTransformer</span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer([</span><br><span class="line">    (<span class="string">&quot;geo&quot;</span>, geo_sim, [<span class="string">&quot;latitude&quot;</span>, <span class="string">&quot;longitude&quot;</span>]),</span><br><span class="line">    (<span class="string">&quot;num&quot;</span>, StandardScaler(), [<span class="string">&#x27;magnitude&#x27;</span>,<span class="string">&#x27;cdi&#x27;</span>,<span class="string">&#x27;mmi&#x27;</span>,<span class="string">&#x27;sig&#x27;</span>,<span class="string">&#x27;nst&#x27;</span>,<span class="string">&#x27;dmin&#x27;</span>,<span class="string">&#x27;gap&#x27;</span>,<span class="string">&#x27;depth&#x27;</span>,<span class="string">&#x27;Year&#x27;</span>,<span class="string">&#x27;Month&#x27;</span>])</span><br><span class="line">])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from lightgbm import LGBMClassifier</span><br><span class="line"></span><br><span class="line">LGBM = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor),</span><br><span class="line">     (<span class="string">&#x27;model&#x27;</span>, LGBMClassifier(</span><br><span class="line">        objective=<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">        random_state=42,</span><br><span class="line">        n_estimators=500,</span><br><span class="line">        learning_rate=0.05,</span><br><span class="line">        num_leaves=31,</span><br><span class="line">        verbosity=-1</span><br><span class="line"></span><br><span class="line">    ))</span><br><span class="line">])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line">tree_clf = cross_val_score(LGBM, X=df.drop(columns=[<span class="string">&#x27;tsunami&#x27;</span>]), y=<span class="built_in">df</span>[<span class="string">&#x27;tsunami&#x27;</span>], scoring=<span class="string">&quot;accuracy&quot;</span>, cv=10)</span><br><span class="line"></span><br><span class="line">cv_scores = cross_val_score(LGBM,</span><br><span class="line">                            X=df.drop(columns=[<span class="string">&#x27;tsunami&#x27;</span>]),</span><br><span class="line">                            y=<span class="built_in">df</span>[<span class="string">&#x27;tsunami&#x27;</span>],</span><br><span class="line">                            scoring=<span class="string">&#x27;accuracy&#x27;</span>,</span><br><span class="line">                            cv=10)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pd.Series(cv_scores).describe())</span><br></pre></td></tr></table></figure></div>
<p>count    10.000000<br>mean      0.813859<br>std       0.196426<br>min       0.512821<br>25%       0.673036<br>50%       0.935897<br>75%       0.948718<br>max       1.000000<br>dtype: float64</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">LGBM.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">train_acc = LGBM.score(X_train, y_train)</span><br><span class="line">test_acc = LGBM.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Train Accuracy: &#123;train_acc:.3f&#125;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Test Accuracy:  &#123;test_acc:.3f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<p>Train Accuracy: 1.000<br>Test Accuracy:  0.936</p>
<h1 id="方法2：三维球面坐标展开"><a href="#方法2：三维球面坐标展开" class="headerlink" title="方法2：三维球面坐标展开"></a>方法2：三维球面坐标展开</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df2 = df.copy()</span><br><span class="line"></span><br><span class="line">df2[<span class="string">&#x27;x&#x27;</span>] = np.cos(df2[<span class="string">&#x27;latitude&#x27;</span>]) * np.cos(df2[<span class="string">&#x27;longitude&#x27;</span>])</span><br><span class="line">df2[<span class="string">&#x27;y&#x27;</span>] = np.cos(df2[<span class="string">&#x27;latitude&#x27;</span>]) * np.sin(df2[<span class="string">&#x27;longitude&#x27;</span>])</span><br><span class="line">df2[<span class="string">&#x27;z&#x27;</span>] = np.sin(df2[<span class="string">&#x27;latitude&#x27;</span>])</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = df2.drop(columns=[<span class="string">&#x27;tsunami&#x27;</span>, <span class="string">&#x27;latitude&#x27;</span>, <span class="string">&#x27;longitude&#x27;</span>])</span><br><span class="line">y = df2[<span class="string">&#x27;tsunami&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y,</span><br><span class="line">    test_size=0.2,</span><br><span class="line">    stratify=y,</span><br><span class="line">    random_state=42</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">LGBM2 = LGBMClassifier(</span><br><span class="line">    random_state=42,</span><br><span class="line">    n_estimators=500,</span><br><span class="line">    learning_rate=0.05,</span><br><span class="line">    num_leaves=31, </span><br><span class="line">    verbosity=-1</span><br><span class="line">    )</span><br><span class="line">scores = cross_val_score(LGBM2, X, y, cv=10, scoring=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(scores.mean(), scores.std())</span><br><span class="line"></span><br><span class="line">LGBM2.fit(X_train, y_train)</span><br><span class="line">train_acc = LGBM2.score(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Train Accuracy: &#123;train_acc:.3f&#125;&quot;</span>)</span><br><span class="line">test_acc = LGBM2.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;Test Accuracy:  &#123;test_acc:.3f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<p>0.7195715676728336 0.23385761172061434<br>Train Accuracy: 1.000<br>Test Accuracy:  0.911</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Lifestyle_and_Health_Risk_Prediction_Synthetic_Dataset</title>
    <url>/zhihaojiang.github.io/2025/10/21/20251021Lifestyle_and_Health_Risk_Prediction/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/datasets/miadul/lifestyle-and-health-risk-prediction" >https://www.kaggle.com/datasets/miadul/lifestyle-and-health-risk-prediction<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span> = pd.read_csv(<span class="string">&#x27;Lifestyle_and_Health_Risk_Prediction_Synthetic_Dataset.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>&lt;class ‘pandas.core.frame.DataFrame’&gt;<br>RangeIndex: 5000 entries, 0 to 4999<br>Data columns (total 12 columns):</p>
<h1 id="Column-Non-Null-Count-Dtype"><a href="#Column-Non-Null-Count-Dtype" class="headerlink" title="Column        Non-Null Count  Dtype"></a>Column        Non-Null Count  Dtype</h1><hr>
<p> 0   age           5000 non-null   int64<br> 1   weight        5000 non-null   int64<br> 2   height        5000 non-null   int64<br> 3   exercise      5000 non-null   object<br> 4   sleep         5000 non-null   float64<br> 5   sugar_intake  5000 non-null   object<br> 6   smoking       5000 non-null   object<br> 7   alcohol       5000 non-null   object<br> 8   married       5000 non-null   object<br> 9   profession    5000 non-null   object<br> 10  bmi           5000 non-null   float64<br> 11  health_risk   5000 non-null   object<br>dtypes: float64(2), int64(3), object(7)<br>memory usage: 468.9+ KB</p>
</blockquote>
<h1 id="缺失值查看和处理"><a href="#缺失值查看和处理" class="headerlink" title="缺失值查看和处理"></a>缺失值查看和处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>age             0<br>weight          0<br>height          0<br>exercise        0<br>sleep           0<br>sugar_intake    0<br>smoking         0<br>alcohol         0<br>married         0<br>profession      0<br>bmi             0<br>health_risk     0<br>dtype: int64</p>
</blockquote>
<h1 id="异常值查看与处理"><a href="#异常值查看与处理" class="headerlink" title="异常值查看与处理"></a>异常值查看与处理</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> df.select_dtypes(include=[<span class="string">&#x27;number&#x27;</span>]).columns:</span><br><span class="line">    plt.boxplot(<span class="built_in">df</span>[column])</span><br><span class="line">    plt.title(column)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/001.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/002.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/003.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/004.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/005.png"
                      alt="photo"
                ></p>
<p>发现bmi存在异常值 鉴于bmi过高会导致健康风险 查看两者的关系</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">df_bmi_50 = <span class="built_in">df</span>[<span class="built_in">df</span>[<span class="string">&#x27;bmi&#x27;</span>] &gt; 50]</span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;health_risk&#x27;</span>, y=<span class="string">&#x27;bmi&#x27;</span>, data=df_bmi_50)</span><br><span class="line">plt.title(<span class="string">&#x27;BMI与健康风险的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;BMI&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/006.png"
                      alt="photo"
                ></p>
<p>可以看到 健康风险较高的人群 其bmi最大值较高 但是在bmi&gt;50的人群中 健康风险低的人群 bmi平均值要比健康风险高的人群高 这说明 衡量健康风险不仅仅看bmi 还要考虑其他因素</p>
<h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;profession&#x27;</span>].value_counts().plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;职业分布&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/011.png"
                      alt="photo"
                ><br>数据集中不同职业的数量分布是均衡的</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">age_groups = pd.cut(<span class="built_in">df</span>[<span class="string">&#x27;age&#x27;</span>], bins=5)</span><br><span class="line">ct = pd.crosstab(age_groups, <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ct_pct = ct.div(ct.sum(axis=1), axis=0)</span><br><span class="line">ct_pct.plot(</span><br><span class="line">    kind=<span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">    stacked=True,</span><br><span class="line">    figsize=(10, 6),</span><br><span class="line">    color=[<span class="string">&#x27;#f8f3d4&#x27;</span>, <span class="string">&#x27;#00b8a9&#x27;</span>]</span><br><span class="line">    )</span><br><span class="line">plt.title(<span class="string">&#x27;健康风险与年龄分组的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;年龄分组&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;百分比&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=45)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/007.png"
                      alt="photo"
                ></p>
<p>可以看到 随着年龄的增加 健康风险也在增加</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">ct = pd.crosstab(<span class="built_in">df</span>[<span class="string">&#x27;exercise&#x27;</span>], <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line"></span><br><span class="line">exercise_order = [<span class="string">&#x27;none&#x27;</span>, <span class="string">&#x27;low&#x27;</span>, <span class="string">&#x27;medium&#x27;</span>, <span class="string">&#x27;high&#x27;</span>]</span><br><span class="line">ct = ct.reindex(exercise_order, fill_value=0)</span><br><span class="line"></span><br><span class="line">ct_pct = ct.div(ct.sum(axis=1), axis=0) </span><br><span class="line">ct_pct.plot(</span><br><span class="line">    kind=<span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">    stacked=True,</span><br><span class="line">    figsize=(8, 6),</span><br><span class="line">    color=[<span class="string">&#x27;#f8f3d4&#x27;</span>, <span class="string">&#x27;#00b8a9&#x27;</span>]</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&#x27;锻炼频率与健康风险的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;锻炼频率&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;百分比&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=0)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/012.png"
                      alt="photo"
                ></p>
<p>发现 锻炼频率高的人群 健康风险有明显的降低</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sleep_groups = pd.cut(<span class="built_in">df</span>[<span class="string">&#x27;sleep&#x27;</span>], bins=5)</span><br><span class="line">ct = pd.crosstab(sleep_groups, <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line"></span><br><span class="line">ct_pct = ct.div(ct.sum(axis=1), axis=0)</span><br><span class="line">ct_pct.plot(</span><br><span class="line">    kind=<span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">    stacked=True,</span><br><span class="line">    figsize=(10, 6),</span><br><span class="line">    color=[<span class="string">&#x27;#f8f3d4&#x27;</span>, <span class="string">&#x27;#00b8a9&#x27;</span>]</span><br><span class="line">    )</span><br><span class="line">plt.title(<span class="string">&#x27;健康风险与睡眠时长的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;睡眠分组&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;百分比&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=45)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/013.png"
                      alt="photo"
                ></p>
<p>发现 睡眠时长长的人群 健康风险更低<br>更长的睡眠时间说明其睡眠质量更好 休息得更充分 这有助于提高健康水平</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">ct = pd.crosstab(<span class="built_in">df</span>[<span class="string">&#x27;sugar_intake&#x27;</span>], <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line"></span><br><span class="line">sugar_order = [<span class="string">&#x27;low&#x27;</span>, <span class="string">&#x27;medium&#x27;</span>, <span class="string">&#x27;high&#x27;</span>]</span><br><span class="line">ct = ct.reindex(sugar_order, fill_value=0)</span><br><span class="line"></span><br><span class="line">ct_pct = ct.div(ct.sum(axis=1), axis=0) </span><br><span class="line">ct_pct.plot(</span><br><span class="line">    kind=<span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">    stacked=True,</span><br><span class="line">    figsize=(8, 6),</span><br><span class="line">    color=[<span class="string">&#x27;#f8f3d4&#x27;</span>, <span class="string">&#x27;#00b8a9&#x27;</span>]</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&#x27;糖摄入量与健康风险的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;糖摄入量&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;百分比&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=0)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/008.png"
                      alt="photo"
                ></p>
<p>发现 糖摄入量高的人群 其健康风险更高 这可能是因为糖对身体的影响更大 会有患糖尿病的风险 导致健康风险增加</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ct = pd.crosstab(<span class="built_in">df</span>[<span class="string">&#x27;smoking&#x27;</span>], <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line"></span><br><span class="line">smoking_order = [<span class="string">&#x27;yes&#x27;</span>, <span class="string">&#x27;no&#x27;</span>]</span><br><span class="line">ct = ct.reindex(smoking_order, fill_value=0)</span><br><span class="line"></span><br><span class="line">ct_pct = ct.div(ct.sum(axis=1), axis=0) </span><br><span class="line">ct_pct.plot(</span><br><span class="line">    kind=<span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">    stacked=True,</span><br><span class="line">    figsize=(8, 6),</span><br><span class="line">    color=[<span class="string">&#x27;#f8f3d4&#x27;</span>, <span class="string">&#x27;#00b8a9&#x27;</span>]</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&#x27;吸烟与健康风险的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;吸烟&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;百分比&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=0)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/014.png"
                      alt="photo"
                ></p>
<p>发现 不吸烟的人健康风险要比吸烟人的健康风险低<br>吸烟有患肺癌的风险</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ct = pd.crosstab(<span class="built_in">df</span>[<span class="string">&#x27;alcohol&#x27;</span>], <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line"></span><br><span class="line">alcohol_order = [<span class="string">&#x27;yes&#x27;</span>, <span class="string">&#x27;no&#x27;</span>]</span><br><span class="line">ct = ct.reindex(alcohol_order, fill_value=0)</span><br><span class="line"></span><br><span class="line">ct_pct = ct.div(ct.sum(axis=1), axis=0) </span><br><span class="line">ct_pct.plot(</span><br><span class="line">    kind=<span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">    stacked=True,</span><br><span class="line">    figsize=(8, 6),</span><br><span class="line">    color=[<span class="string">&#x27;#f8f3d4&#x27;</span>, <span class="string">&#x27;#00b8a9&#x27;</span>]</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&#x27;饮酒与健康风险的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;饮酒&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;百分比&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=0)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/009.png"
                      alt="photo"
                ></p>
<p>发现 不饮酒的人健康风险要比饮酒的人健康风险低<br>饮酒有患肝脏疾病的风险</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">ct = pd.crosstab(<span class="built_in">df</span>[<span class="string">&#x27;married&#x27;</span>], <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line"></span><br><span class="line">married_order = [<span class="string">&#x27;yes&#x27;</span>, <span class="string">&#x27;no&#x27;</span>]</span><br><span class="line">ct = ct.reindex(married_order, fill_value=0)</span><br><span class="line"></span><br><span class="line">ct_pct = ct.div(ct.sum(axis=1), axis=0) </span><br><span class="line">ct_pct.plot(</span><br><span class="line">    kind=<span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">    stacked=True,</span><br><span class="line">    figsize=(8, 6),</span><br><span class="line">    color=[<span class="string">&#x27;#f8f3d4&#x27;</span>, <span class="string">&#x27;#00b8a9&#x27;</span>]</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&#x27;婚姻状态与健康风险的关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;婚姻状态&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;百分比&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=0)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;健康风险&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/10/21/010.png"
                      alt="photo"
                ></p>
<p>婚姻状况与健康风险的关系不明显 可以把这个特征删除</p>
<h1 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h1><p>对于exercise、sugar_intake、smoking、alcohol、married、health_risk<br>这些类别型特征是有明显大小关系的 因此使用标签编码保留其大小区别<br>对于profession由于特征中的值是无关的 并且特征中的唯一值只有8个 因此我们可以用独热编码</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#标签编码</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;exercise&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;exercise&#x27;</span>].map(&#123;<span class="string">&#x27;none&#x27;</span>: 0, <span class="string">&#x27;low&#x27;</span>: 1, <span class="string">&#x27;medium&#x27;</span>: 2, <span class="string">&#x27;high&#x27;</span>: 3&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;sugar_intake&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;sugar_intake&#x27;</span>].map(&#123;<span class="string">&#x27;low&#x27;</span>: 0, <span class="string">&#x27;medium&#x27;</span>: 1, <span class="string">&#x27;high&#x27;</span>: 2&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;smoking&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;smoking&#x27;</span>].map(&#123;<span class="string">&#x27;yes&#x27;</span>: 1, <span class="string">&#x27;no&#x27;</span>: 0&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;alcohol&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;alcohol&#x27;</span>].map(&#123;<span class="string">&#x27;yes&#x27;</span>: 1, <span class="string">&#x27;no&#x27;</span>: 0&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;married&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;married&#x27;</span>].map(&#123;<span class="string">&#x27;yes&#x27;</span>: 1, <span class="string">&#x27;no&#x27;</span>: 0&#125;)</span><br><span class="line"><span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>] = <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>].map(&#123;<span class="string">&#x27;low&#x27;</span>: 0, <span class="string">&#x27;high&#x27;</span>: 1&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 独热编码</span></span><br><span class="line"><span class="built_in">df</span> = pd.get_dummies(<span class="built_in">df</span>, columns=[<span class="string">&#x27;profession&#x27;</span>], drop_first=True)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除&#x27;married&#x27;列</span></span><br><span class="line"><span class="built_in">df</span> = df.drop(columns=[<span class="string">&#x27;married&#x27;</span>])</span><br></pre></td></tr></table></figure></div>

<h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X = df.drop(columns=[<span class="string">&#x27;health_risk&#x27;</span>])</span><br><span class="line">y = <span class="built_in">df</span>[<span class="string">&#x27;health_risk&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><br></pre></td></tr></table></figure></div>

<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from xgboost import XGBClassifier</span><br><span class="line">from lightgbm import LGBMClassifier</span><br><span class="line"></span><br><span class="line">model = &#123;</span><br><span class="line">    <span class="string">&#x27;logistic_regression&#x27;</span>: LogisticRegression(),</span><br><span class="line">    <span class="string">&#x27;random_forest&#x27;</span>: RandomForestClassifier(),</span><br><span class="line">    <span class="string">&#x27;svm&#x27;</span>: SVC(),</span><br><span class="line">    <span class="string">&#x27;XGB&#x27;</span>: XGBClassifier(),</span><br><span class="line">    <span class="string">&#x27;LGBM&#x27;</span>: LGBMClassifier()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report,confusion_matrix</span><br><span class="line">model_scores = pd.DataFrame(</span><br><span class="line">    index=model.keys(),</span><br><span class="line">    columns=[</span><br><span class="line">        <span class="string">&quot;accuracy&quot;</span>,</span><br><span class="line">        <span class="string">&quot;precision&quot;</span>,</span><br><span class="line">        <span class="string">&quot;recall&quot;</span>,</span><br><span class="line">        <span class="string">&quot;f1_score&quot;</span>,</span><br><span class="line">        <span class="string">&quot;cross_val_score&quot;</span></span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, clf <span class="keyword">in</span> model.items():</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;&#123;name&#125;模型训练完成&quot;</span>)</span><br><span class="line">    y_pred = clf.predict(X_test)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;&#123;name&#125;模型测试结果&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;----------------------------------------&#x27;</span>)</span><br><span class="line">    model_scores.loc[name, <span class="string">&quot;accuracy&quot;</span>] = accuracy_score(y_test, y_pred)</span><br><span class="line">    model_scores.loc[name, <span class="string">&quot;precision&quot;</span>] = precision_score(y_test, y_pred)</span><br><span class="line">    model_scores.loc[name, <span class="string">&quot;recall&quot;</span>] = recall_score(y_test, y_pred)</span><br><span class="line">    model_scores.loc[name, <span class="string">&quot;f1_score&quot;</span>] = f1_score(y_test, y_pred)</span><br></pre></td></tr></table></figure></div>

<h1 id="k折交叉验证"><a href="#k折交叉验证" class="headerlink" title="k折交叉验证"></a>k折交叉验证</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, clf <span class="keyword">in</span> model.items():</span><br><span class="line">    scores = cross_val_score(clf, X, y, cv=5)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;&#123;name&#125;模型的交叉验证得分: &#123;scores.mean()&#125;&quot;</span>)</span><br><span class="line">    model_scores.loc[name, <span class="string">&quot;cross_val_score&quot;</span>] = scores.mean()</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">model_scores.head()</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1_Score</th>
<th>Cross_Val_Score</th>
</tr>
</thead>
<tbody><tr>
<td>logistic_regression</td>
<td>0.858</td>
<td>0.893056</td>
<td>0.908192</td>
<td>0.90056</td>
<td>0.8652</td>
</tr>
<tr>
<td>random_forest</td>
<td>0.99</td>
<td>0.992938</td>
<td>0.992938</td>
<td>0.992938</td>
<td>0.993</td>
</tr>
<tr>
<td>svm</td>
<td>0.804</td>
<td>0.829897</td>
<td>0.909605</td>
<td>0.867925</td>
<td>0.8076</td>
</tr>
<tr>
<td>XGB</td>
<td>0.995</td>
<td>0.997171</td>
<td>0.995763</td>
<td>0.996466</td>
<td>0.9966</td>
</tr>
<tr>
<td>LGBM</td>
<td>0.997</td>
<td>0.997179</td>
<td>0.998588</td>
<td>0.997883</td>
<td>0.9968</td>
</tr>
</tbody></table>
<h1 id="特征重要性"><a href="#特征重要性" class="headerlink" title="特征重要性"></a>特征重要性</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">name = [<span class="string">&#x27;random_forest&#x27;</span>, <span class="string">&#x27;XGB&#x27;</span>, <span class="string">&#x27;LGBM&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> name:</span><br><span class="line">    importances = pd.Series(model[name].feature_importances_, index=X_train.columns).sort_values(ascending=False)</span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">&quot;&#123;name&#125;模型特征重要性排序&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(importances)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;----------------------------------------&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<div class="tabs" id="tab-importance"><ul class="nav-tabs"><li class="tab active"><a class="#importance-1">random_forest</a></li><li class="tab"><a class="#importance-2">XGB</a></li><li class="tab"><a class="#importance-3">LGBM</a></li></ul><div class="tab-content"><div class="tab-pane active" id="importance-1"><p><strong>random_forest模型特征重要性排序</strong><br>age                         0.268261<br>bmi                         0.182540<br>smoking                     0.100002<br>exercise                    0.094879<br>sleep                       0.085877<br>weight                      0.079399<br>sugar_intake                0.065287<br>alcohol                     0.063469<br>height                      0.038578<br>profession_teacher          0.003532<br>profession_doctor           0.003400<br>profession_student          0.003397<br>profession_engineer         0.003007<br>profession_driver           0.002944<br>profession_farmer           0.002875<br>profession_office_worker    0.002553<br>dtype: float64</p></div><div class="tab-pane" id="importance-2"><p><strong>XGB模型特征重要性排序</strong><br>bmi                         0.198563<br>smoking                     0.173180<br>age                         0.148690<br>alcohol                     0.139040<br>exercise                    0.122766<br>sugar_intake                0.114938<br>sleep                       0.075064<br>profession_doctor           0.007731<br>profession_engineer         0.005987<br>profession_student          0.004006<br>profession_farmer           0.002454<br>profession_driver           0.002379<br>weight                      0.002147<br>height                      0.001987<br>profession_teacher          0.001068<br>profession_office_worker    0.000000<br>dtype: float32</p></div><div class="tab-pane" id="importance-3"><p><strong>LGBM模型特征重要性排序</strong><br>sleep                       614<br>sugar_intake                416<br>exercise                    406<br>smoking                     371<br>bmi                         339<br>alcohol                     337<br>age                         298<br>height                       99<br>weight                       66<br>profession_doctor            14<br>profession_engineer          10<br>profession_farmer            10<br>profession_student            8<br>profession_teacher            7<br>profession_driver             5<br>profession_office_worker      0<br>dtype: int32</p></div></div></div>

]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>配置服务器jupyter notebook</title>
    <url>/zhihaojiang.github.io/2025/11/25/20251125%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8jupyter%20notebook/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本教程是通过我的Linux虚拟机进行教学的，自己租赁或购买的Linux服务器同理，教程是通用的</p>
<h1 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h1><ol>
<li>安装python</li>
<li>安装pip</li>
</ol>
<p>这两个安装非常简单，自己从网上查找教程</p>
<h1 id="安装anaconda"><a href="#安装anaconda" class="headerlink" title="安装anaconda"></a>安装anaconda</h1><h2 id="从anaconda官网下载相应的版本"><a href="#从anaconda官网下载相应的版本" class="headerlink" title="从anaconda官网下载相应的版本"></a>从anaconda官网下载相应的版本</h2><p><a class="link"   href="https://repo.anaconda.com/archive/" >anaconda下载地址<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>进入后选择相应的版本，请注意。文件名中aarch64是arm处理器的版本；X86是inter处理器的版本，根据你处理器型号下载，不要下载错了。</p>
<h2 id="使用wget进行下载"><a href="#使用wget进行下载" class="headerlink" title="使用wget进行下载"></a>使用wget进行下载</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2025.06-1-Linux-aarch64.sh</span><br></pre></td></tr></table></figure></div>

<p>下载好后还可以用ls查看是否下载完成，可以看到，我这里已经下载完成了</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2025.06-1-Linux-aarch64.sh</span><br><span class="line">--2025-11-24 06:01:19--  https://repo.anaconda.com/archive/Anaconda3-2025.06-1-Linux-aarch64.sh</span><br><span class="line">Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:bf9e, ...</span><br><span class="line">Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 929680981 (887M) [application/octet-stream]</span><br><span class="line">Saving to: ‘Anaconda3-2025.06-1-Linux-aarch64.sh’</span><br><span class="line"></span><br><span class="line">Anaconda3-2025.06-1-Li 100%[==========================&gt;] 886.61M  12.2MB/s    <span class="keyword">in</span> 79s     </span><br><span class="line"></span><br><span class="line">2025-11-24 06:02:39 (11.3 MB/s) - ‘Anaconda3-2025.06-1-Linux-aarch64.sh’ saved [929680981/929680981]</span><br><span class="line"></span><br><span class="line">zhihaojiang@linux-24-10-node5:~$ <span class="built_in">ls</span></span><br><span class="line">Anaconda3-2025.06-1-Linux-aarch64.sh</span><br></pre></td></tr></table></figure></div>

<h2 id="接下来赋予安装包权限"><a href="#接下来赋予安装包权限" class="headerlink" title="接下来赋予安装包权限"></a>接下来赋予安装包权限</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x Anaconda3-2025.06-1-Linux-aarch64.sh</span><br></pre></td></tr></table></figure></div>
<h2 id="运行安装脚本"><a href="#运行安装脚本" class="headerlink" title="运行安装脚本"></a>运行安装脚本</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">bash Anaconda3-2025.06-1-Linux-aarch64.sh</span><br></pre></td></tr></table></figure></div>

<p>运行后如下所示，根据他给的提示，一路yes和回车即可</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10-node5:~$ bash Anaconda3-2025.06-1-Linux-aarch64.sh</span><br><span class="line"></span><br><span class="line">Welcome to Anaconda3 2025.06-1</span><br><span class="line"></span><br><span class="line">In order to <span class="built_in">continue</span> the installation process, please review the license</span><br><span class="line">agreement.</span><br><span class="line">Please, press ENTER to <span class="built_in">continue</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></div>

<h2 id="使配置生效"><a href="#使配置生效" class="headerlink" title="使配置生效"></a>使配置生效</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></div>

<p>运行后你会发现你的名称前面会多个“(base)”</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">zhihaojiang@linux-24-10-node5:~$ <span class="built_in">source</span> ~/.bashrc</span><br><span class="line">(base) zhihaojiang@linux-24-10-node5:~$</span><br></pre></td></tr></table></figure></div>
<p>这个是conda的默认环境</p>
<p>可以查看conda版本</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">(base) zhihaojiang@linux-24-10-node5:~$ conda --version</span><br><span class="line">conda 25.5.1</span><br></pre></td></tr></table></figure></div>

<h1 id="安装Jupyter"><a href="#安装Jupyter" class="headerlink" title="安装Jupyter"></a>安装Jupyter</h1><p>运行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">conda install jupyter</span><br></pre></td></tr></table></figure></div>
<p>其会显示</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">(base) zhihaojiang@linux-24-10-node5:~$ conda install jupyter</span><br><span class="line">2 channel Terms of Service accepted</span><br><span class="line">Channels:</span><br><span class="line"> - defaults</span><br><span class="line">Platform: linux-aarch64</span><br><span class="line">Collecting package metadata (repodata.json): <span class="keyword">done</span></span><br><span class="line">Solving environment: <span class="keyword">done</span></span><br></pre></td></tr></table></figure></div>

<h2 id="创建配置"><a href="#创建配置" class="headerlink" title="创建配置"></a>创建配置</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure></div>

<p>会显示</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">(base) zhihaojiang@linux-24-10-node5:~$ jupyter notebook --generate-config</span><br><span class="line">Writing default config to: /home/zhihaojiang/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure></div>
<p>看见Writing default config to:XXX.py 就说明配置创建了</p>
<h2 id="设置密码"><a href="#设置密码" class="headerlink" title="设置密码"></a>设置密码</h2><p>这里的密码一定要设置，因为我们使用是是通过地址加端口使用Jupyter notebook的因此不设置密码是无法使用的</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter notebook password</span><br></pre></td></tr></table></figure></div>
<p>其会让你输入两次密码</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">(base) zhihaojiang@linux-24-10-node5:~$ jupyter notebook password</span><br><span class="line">Enter password: </span><br><span class="line">Verify password: </span><br><span class="line">[JupyterPasswordApp] Wrote hashed password to /home/zhihaojiang/.jupyter/jupyter_server_config.json</span><br></pre></td></tr></table></figure></div>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">nano ~/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure></div>
<p>在文件中添加如下配置</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">c = get_config()</span><br><span class="line">c.NotebookApp.ip = <span class="string">&#x27;0.0.0.0&#x27;</span></span><br><span class="line">c.NotebookApp.port = 8888</span><br><span class="line">c.NotebookApp.open_browser = False</span><br><span class="line">c.NotebookApp.allow_root = True</span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">&#x27;/home/你自己的用户名</span></span><br></pre></td></tr></table></figure></div>

<p>我这里端口是8888，若你的这个端口被占用了，可以更换成别的没被占用的端口</p>
<h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><p>运行</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure></div>
<p>即可启动</p>
<p>若看见如下输出就说明启动成功</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">(base) zhihaojiang@linux-24-10-node5:~$ jupyter notebook</span><br><span class="line">[I 2025-11-24 06:14:22.857 ServerApp] Extension package panel.io.jupyter_server_extension took 0.5411s to import</span><br><span class="line">[I 2025-11-24 06:14:22.858 ServerApp] jupyter_lsp | extension was successfully linked.</span><br><span class="line">[I 2025-11-24 06:14:22.859 ServerApp] jupyter_server_terminals | extension was successfully linked.</span><br></pre></td></tr></table></figure></div>

<h1 id="进入Jupyter-notebook"><a href="#进入Jupyter-notebook" class="headerlink" title="进入Jupyter notebook"></a>进入Jupyter notebook</h1><p>在浏览器中输入你自己服务器的IP:端口，输入之前设置的密码后就可以开始使用了</p>
<h1 id="关闭服务器中的Jupyter"><a href="#关闭服务器中的Jupyter" class="headerlink" title="关闭服务器中的Jupyter"></a>关闭服务器中的Jupyter</h1><p>只要在服务器中输入ctrl+C就可以关闭了<br>如下看见Shutdown confirmed就安全关闭了</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">^C[I 2025-11-24 06:15:32.461 ServerApp] interrupted</span><br><span class="line">[I 2025-11-24 06:15:32.462 ServerApp] Serving notebooks from <span class="built_in">local</span> directory: /home/zhihaojiang</span><br><span class="line">    0 active kernels</span><br><span class="line">    Jupyter Server 2.15.0 is running at:</span><br><span class="line">    http://linux-24-10-node5:8888/tree</span><br><span class="line">        http://127.0.0.1:8888/tree</span><br><span class="line">Shut down this Jupyter server (y/[n])? y</span><br><span class="line">[C 2025-11-24 06:15:33.784 ServerApp] Shutdown confirmed</span><br><span class="line">[I 2025-11-24 06:15:33.795 ServerApp] Shutting down 6 extensions</span><br><span class="line">(base) zhihaojiang@linux-24-10-node5:~$ </span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>广告投放策略与效益</title>
    <url>/zhihaojiang.github.io/2025/11/06/20251106%E5%B9%BF%E5%91%8A%E6%8A%95%E6%94%BE%E7%AD%96%E7%95%A5%E4%B8%8E%E6%95%88%E7%9B%8A/</url>
    <content><![CDATA[<h1 id="广告投放策略与效益"><a href="#广告投放策略与效益" class="headerlink" title="广告投放策略与效益"></a>广告投放策略与效益</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本研究通过对广告投放数据的可视化分析，探索了CPC、GMV、ROI等核心指标与广告效果之间的关系，旨在揭示不同投放策略下的效益差异，并为广告主提供优化建议。<br>分析CPC成本的合理性，表明大部分广告投放策略的CPC费用集中在中低成本区间，但仍存在一些高花费低转化的现象。<br>对ROI的分析，发现广告投放效益受季节性波动、外部事件影响显著。反映了外部环境对广告投放效果的强烈影响。<br>CTR分析揭示了广告投放的吸引力，整体CTR偏低，尤其是在0.05至0.10区间内形成明显的峰值，表明大多数广告的点击率较低。反映了广告定向和素材优化的空间。高CTR广告较为稀少，优化广告定向和提升广告创意质量能够显著提高CTR和转化率。<br>关于CPC流量与自然流量的关系，分析结果表明，两者并未表现出显著的正相关，表明CPC流量并未有效促进自然流量的增长。这表明广告投放未能有效提升品牌知名度或用户搜索意图，可能与内容质量、品牌效应和SEO策略不足有关。<br>回归分析表明自然访问量和CPC访问量对有效订单数具有显著正向影响，<br>R^2为0.770，表明两者是影响广告效果的核心因素。自然访问量每增加1单位，有效订单数将增加0.2053单位，而CPC访问量每增加1单位，有效订单数将增加0.1891单位。</p>
<p>关键词：CPC; GMV; ROI ; CTR; 广告投放</p>
<h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>在当前数字化广告投放中，如何精准地评估广告效果，优化广告投放策略，已成为企业提高营销效益和竞争力的关键。特别是在电商、餐饮等行业，广告投放的效果直接影响到销量和用户转化。因此，合理评估广告投放的成本与回报关系，深入分析影响广告效果的关键因素，已成为优化广告策略的核心任务。<br>广告投放的成本和回报是衡量广告效果的核心指标。CPC直接反映了广告主获取流量的成本，而GMV和ROI则衡量了广告投放带来的实际收入与营销投入之间的关系。通过对这三者的分析，企业能够判断广告费用的投入是否合理，是否存在高花费低转化的现象，以及如何提高广告投放的效益。<br>在广告投放过程中，点击率作为衡量广告吸引力的前置指标，其与下单转化率之间的关系也至关重要。广告的点击率是否健康，直接影响到转化率的提升。因此，深入探讨CTR与下单转化率之间的关系，有助于揭示CPC流量质量对转化效果的影响，为进一步优化广告策略提供理论依据。<br>本文将通过对多个门店和日期的广告数据进行系统分析，探讨CPC成本、GMV、ROI和CTR等核心指标的分布特征与相互关系，分析CPC流量与自然流量的协同效应，并提出优化广告投放策略的建议。研究结果将为广告主提供数据支持，帮助其实现更高效的广告预算分配和更精确的投放策略。</p>
<h1 id="二、数据特征"><a href="#二、数据特征" class="headerlink" title="二、数据特征"></a>二、数据特征</h1><h2 id="2-1-查看数据"><a href="#2-1-查看数据" class="headerlink" title="2.1 查看数据"></a>2.1 查看数据</h2><p>在处理任何数据集时，第一步是对数据进行初步的审视，包括查看各特征的名称、类型、分布及其所代表的含义等。通过导入数据并使用columns函数查看特征名称，发现数据中涉及了多个关键指标，如CPC、GMV、ROI等。为了深入理解这些特征，我们查询并解释了它们的具体定义与业务意义。</p>
<h3 id="2-1-1-数据含义"><a href="#2-1-1-数据含义" class="headerlink" title="2.1.1 数据含义"></a>2.1.1 数据含义</h3><p>在数据集的多个关键指标中，CPC、GMV、ROI是广告投放分析中最为核心的三个变量。以下是它们的详细定义及其对广告效果评估的意义：<br>CPC（每次点击费用）<br>定义：广告主每获得一次点击所需支付的费用。<br>意义：衡量广告流量获取成本，CPC越低说明花同样的钱能吸引更多用户访问。</p>
<p>GMV（成交总额）<br>定义：通过广告或平台产生的商品交易总金额。<br>意义：衡量销售规模。GMV 大说明广告带来了高销售额。</p>
<p>ROI（投资回报率）<br>定义：广告带来的收入与广告投入之间的比值。<br>意义：ROI 表示每花 1 元广告费带来多少销售额，ROI 越高越好。</p>
<h2 id="2-2-数据分布"><a href="#2-2-数据分布" class="headerlink" title="2.2 数据分布"></a>2.2 数据分布</h2><h3 id="2-2-1-CPC单次点击费用"><a href="#2-2-1-CPC单次点击费用" class="headerlink" title="2.2.1 CPC单次点击费用"></a>2.2.1 CPC单次点击费用</h3><p>针对“CPC单次点击费用”这一核心广告投放成本指标，从描述性统计、分布形态、可视化特征及业务含义四个维度展开系统分析，旨在全面刻画该变量的数据分布特性。<br>通过计算基本统计量，我们初步掌握该特征的集中趋势、离散程度与分布形态。相关指标如下表所示</p>
<table>
<thead>
<tr>
<th>最小值</th>
<th align="left">最大值</th>
<th align="left">均值</th>
<th>中位数</th>
</tr>
</thead>
<tbody><tr>
<td>0.02</td>
<td align="left">2.98</td>
<td align="left">1.389</td>
<td>1.38</td>
</tr>
<tr>
<td>四分位距</td>
<td align="left">标准差</td>
<td align="left">峰度</td>
<td>偏度</td>
</tr>
<tr>
<td>0.3</td>
<td align="left">0.304</td>
<td align="left">2.077</td>
<td>0.212</td>
</tr>
</tbody></table>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/001.png"
                      alt="photo"
                ></p>
<p>样本中所有广告点击的平均成本约为 1.39 元。作为衡量整体水平的核心指标，它反映了当前投放策略下的平均获客成本。<br>中位数为1.38，与均值高度接近，未受极端值显著干扰。说明大部分广告点击成本集中在合理区间内。<br>标准差为0.304，四分位距为0.3，表明数据分布紧凑，无明显的异常值。并且IQR&#x2F;Std\approx1，说明数据近似正态。<br>峰度为2.077，标准正态分布的峰度为3，这属于低峰态，意味着分布曲线比正态分布更平坦，数据在中心区域不如正态分布集中，两侧更宽。从柱状图也可以看到在峰值两侧呈现较平缓的下降趋势，而非陡峭的钟形。表明CPC值在主流区间内分布较为均匀，无明显集中或缺失，有利于稳定投放策略。<br>偏度为0.212，属于轻微右偏，在广告投放场景中，右偏是常见现象——部分高竞争关键词或优质流量渠道的CPC天然较高。</p>
<h3 id="2-2-2-CPC总费用"><a href="#2-2-2-CPC总费用" class="headerlink" title="2.2.2 CPC总费用"></a>2.2.2 CPC总费用</h3><p>CPC总费用，即单次点击成本×点击量，该指标反映广告投放在特定单元上的总体支出水平。</p>
<table>
<thead>
<tr>
<th>最小值</th>
<th align="left">最大值</th>
<th align="left">均值</th>
<th>中位数</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td align="left">846.4</td>
<td align="left">129.58</td>
<td>76.2</td>
</tr>
<tr>
<td>四分位距</td>
<td align="left">标准差</td>
<td align="left">峰度</td>
<td>偏度</td>
</tr>
<tr>
<td>150.09</td>
<td align="left">134.539</td>
<td align="left">5.317</td>
<td>2.091</td>
</tr>
</tbody></table>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/002.png"
                      alt="photo"
                ></p>
<p>均值为129.58，表示样本中各单元的平均总费用约为129.58 元。但从图中可以看到，数据分布是长尾分布，均值受极端值影响较大，不能作为典型值使用。而中位数为76.2，在此分布中，中位数更具有代表性。<br>标准差为134.539表明数据波动剧烈。四分位距 IQR &#x3D; 150.09意味费用跨度很大。<br>偏度&#x3D; 2.091是严重右偏<br>意味着绝大多数的费用较低，但存在少量极高费用，这些“头部”显著拉高了均值。<br>在广告投放场景中，这通常是二八定律的体现——少数关键词或计划贡献了大部分支出。<br>峰度为5.317，标准正态分布峰度为3。此处峰度&gt;3，属于高峰态。<br>意味着分布曲线比正态分布更尖峭，中心区域更集中，同时两侧尾部更厚即存在更多极端值。高峰态和严重右偏说明存在头部效应，即少数高消耗单元主导总支出。</p>
<h1 id="三、广告效果评估"><a href="#三、广告效果评估" class="headerlink" title="三、广告效果评估"></a>三、广告效果评估</h1><p>聚焦CPC、 ROI 和效率，我们需要弄清楚：</p>
<ol>
<li>CPC 成本是否合理？是否存在“高花费低转化”？</li>
<li>ROI 是否 &gt; 1？哪些门店&#x2F;日期 ROI 异常高或低？</li>
<li>点击率（CTR）是否健康？</li>
<li>下单转化率是否受 CPC 流量质量影响？</li>
</ol>
<h2 id="3-1-CPC成本合理性"><a href="#3-1-CPC成本合理性" class="headerlink" title="3.1 CPC成本合理性"></a>3.1 CPC成本合理性</h2><p>利用密度图查看CPC总费用和下单转换率之间的关系如图</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/003.png"
                      alt="photo"
                ></p>
<p>上图反应了两个变量的联合概率密度分布，可以看到主要数据集中在左下部，次区域的CPC总费用在[0,200]之间，下单转换率在[0.1,0,3]之间，说明大部分投放广告的策略是中等消费和中低转换率。<br>下单转换率在0.3以上的属于高转换率，可以看到高转换率区域主要分布在中低费用区间，在此区域的部分是高性价比区域——少量低成本单元实现了高转化率，这可能与广告的精准投放、新上线、合理推流相关，若要提高转化率性价比，推荐借鉴这些广告的推送方式以及广告的形式。</p>
<h2 id="3-2-GMV-ROI周度趋势"><a href="#3-2-GMV-ROI周度趋势" class="headerlink" title="3.2 GMV ROI周度趋势"></a>3.2 GMV ROI周度趋势</h2><p>针对门店周度GMV ROI这一关键经营效率指标，从整体趋势、门店间对比、季节性&#x2F;事件性波动展开深入分析。GMV ROI &#x3D; GMV&#x2F;营销投入成本，反映单位营销费用带来的销售回报，是衡量门店盈利能力与投放效率的核心指标。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/004.png"
                      alt="photo"
                ></p>
<p>从整体趋势上看，其呈现明显的季节波动。<br>2019年11月–2020年1月：多数门店ROI呈上升趋势，尤其在2020年1月达到阶段性高点。这可能受春节前消费高峰或年终促销活动驱动。<br>部分门店如蛙小辣美蛙火锅杯[五角场店]在2020年1月ROI飙升至16以上，表现突出。<br>2020年2月–2020年3月：受新冠疫情影响，多数门店ROI出现断崖式下跌。多条折线在2020年2月跌至低谷。如蛙小辣·美蛙火锅杯[虹口足球场店]降至4以下。表明疫情对线下餐饮业冲击巨大，营销投入回报率显著下降。<br>2020年4月–2020年6月：逐步复苏，部分门店恢复至疫情前水平，甚至超越。如蛙小辣火锅杯（五角场店）在2020年6月回升至14+，表现强劲。蛙小辣火锅杯（龙阳路店）在2020年5月后稳步上升。<br>2020年7月–2020年10月：趋于稳定，部分门店出现小幅回落。如粉色线蛙小辣·美蛙火锅杯[真如店]在2020年7月后逐渐下滑。<br>整体呈现疫情后复苏→平稳运行→小幅回调的典型路径。</p>
<p>还可以看到，部分店铺的曲线出现停滞的现象，其主要出现在2020年2月–2020年3月，正好是疫情发生的时间点。根据国家统计局数据显示，2020年我国全年餐饮收入39527亿元，同比下降16.6%。受疫情影响，全年超2000家餐厅关闭，平均每月达200多家。<br>因此可以得出那些餐饮受疫情影响，不得不说关闭以减少亏损。</p>
<h2 id="3-3-点击率健康性分析"><a href="#3-3-点击率健康性分析" class="headerlink" title="3.3 点击率健康性分析"></a>3.3 点击率健康性分析</h2><p>CTR反映广告被展示后用户点击的比例，是衡量广告相关性与吸引力的重要前置指标。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/005.png"
                      alt="photo"
                ></p>
<p>从上图可能得出绝大多数门店的CTR集中在 0.0 ~ 0.15 区间内，尤其在 0.05 ~ 0.10 附近形成一个尖锐峰值，之后迅速衰减，右侧几乎无数据。说明当前广告投放的整体CTR水平偏低，不过这也是一个常见的现象，像电商&#x2F;本地生活类广告CTR通常在1%~10%之间。<br>在 CTR &gt; 0.15 后，门店数急剧下降，CT R &gt; 0.2 的门店几乎为零。说明高CTR单元极为稀少，可能是优质素材、精准定向或特殊场景带来的偶然结果。</p>
<h2 id="3-4-下单转化率与-CPC-流量质量关系"><a href="#3-4-下单转化率与-CPC-流量质量关系" class="headerlink" title="3.4 下单转化率与 CPC 流量质量关系"></a>3.4 下单转化率与 CPC 流量质量关系</h2><p>聚焦每日CPC投入与每日下单转化率两个关键指标的时间序列变化，揭示：<br>1.	广告预算投入是否带来预期转化？<br>2.	两者是否存在协同或背离关系？<br>3.	是否存在高投入低转化或低投入高转化的异常时段？<br>4.	如何基于趋势优化每日预算分配？</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/006.png"
                      alt="photo"
                ></p>
<h3 id="3-4-1-整体趋势分析"><a href="#3-4-1-整体趋势分析" class="headerlink" title="3.4.1 整体趋势分析"></a>3.4.1 整体趋势分析</h3><p>整体趋势为：投入先升后降，转化率起伏明显<br>2019年10月–2020年1月：<br>CPC投入稳步上升，最高达2500+元&#x2F;日。下单转化率在0.15<del>0.25区间波动，无明显增长。表明此阶段高投入未带来转化提升，可能存在边际效益递减或流量质量下降。<br>2020年2月–2020年3月：<br>CPC投入断崖式下跌至100</del>300元&#x2F;日。下单转化率不降反升，从0.15升至0.20。疫情导致线下消费受限，转化效率反而提升——用户更理性、更精准点击，转化率自然上升。同时，广告主主动缩减预算，导致CPC投入骤降，形成低投入，高转化的理想组合。<br>2020年4月–2020年6月：<br>CPC投入逐步回升，但未恢复至疫情前水平维持在。下单转化率持续攀升，多次突破0.25，甚至达到0.30。表明复苏期用户活跃度高、转化意愿强，广告投放效率显著提升。<br>2020年7月–2020年9月：<br>CPC投入趋于稳定，波动范围缩小。下单转化率保持高位震荡，偶有峰值。表明运营进入稳态，转化效率已建立新基准。</p>
<h3 id="3-4-2-相关性分析"><a href="#3-4-2-相关性分析" class="headerlink" title="3.4.2 相关性分析"></a>3.4.2 相关性分析</h3><p>2019年10月–2020年1月：投入与转化基本无正相关，甚至部分时段负相关。这可能与流量泛化、素材疲劳、竞争加剧导致花钱买不到好转化。<br>2020年2月–2020年3月：投入下降但是转化上升，表现出强烈负相关。疫情导致用户行为改变，广告主减少无效投放，留下高质量流量，转化率被动提升。<br>2020年4月–2020年9月：投入小幅上升，转化维持高位——弱正相关或无相关。表明转化效率已建立“新平衡”，投入增加不再显著影响转化率，说明运营策略成熟。<br>两者不存在稳定的线性关系，而是受外部环境、用户行为、投放策略共同驱动的动态关系。</p>
<h1 id="四、自然流量与CPC流量"><a href="#四、自然流量与CPC流量" class="headerlink" title="四、自然流量与CPC流量"></a>四、自然流量与CPC流量</h1><h2 id="4-1-每日CPC访问量与自然访问量趋势"><a href="#4-1-每日CPC访问量与自然访问量趋势" class="headerlink" title="4.1 每日CPC访问量与自然访问量趋势"></a>4.1 每日CPC访问量与自然访问量趋势</h2><p>聚焦每日CPC访问量与每日自然访问量两个指标的时间序列变化，揭示：<br>1.	广告投放是否有效带动整体流量增长？<br>2.	自然流量是否具备独立增长能力？<br>3.	两者是否存在协同效应或替代效应？</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/007.png"
                      alt="photo"
                ></p>
<p>整体趋势为CPC流量主导，自然流量稳步增长<br>2019年10月–2020年1月：<br>CPC访问量稳步上升，最高达2000+人次&#x2F;日。自然访问量在100<del>250区间波动，无明显增长。表明此阶段流量增长主要依赖广告投放，自然流量未形成规模效应。<br>2020年2月–2020年3月：<br>CPC访问量断崖式下跌至100</del>300人次&#x2F;日。自然访问量不降反升，从100升至150+，甚至短暂突破200。疫情导致线下消费受限，用户更依赖线上搜索与推荐，自然流量被动提升；同时广告主缩减预算，CPC流量骤降，形成低CPC+高自然的组合。<br>2020年4月–2020年6月：<br>CPC访问量逐步回升，但未恢复至疫情前水平。自然访问量持续攀升，多次突破200，甚至达到250+。表明复苏期用户活跃度高、搜索意愿强，自然流量增长动力强劲。<br>2020年7月–2020年9月：<br>CPC访问量趋于稳定，波动范围缩小。自然访问量保持高位震荡，偶有峰值。表明运营进入稳态，自然流量已建立新基准，不再完全依赖CPC。</p>
<h2 id="4-2-CPC曝光量与CPC访问量的关系"><a href="#4-2-CPC曝光量与CPC访问量的关系" class="headerlink" title="4.2 CPC曝光量与CPC访问量的关系"></a>4.2 CPC曝光量与CPC访问量的关系</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/008.png"
                      alt="photo"
                ></p>
<p>整体趋势是强正相关，但存在离散度数据点大致沿一条从原点出发的直线分布，表明曝光量越高，访问量越高，符合广告投放的基本逻辑。<br>虽然整体呈正相关，但点并非严格落在一条直线上，存在一定波动，说明不同广告单元的CTR存在差异。<br>点密度集中在中低曝光区间。<br>在高密度区，曝光量为 1000<del>4000，访问量 100</del>300 区间。此区域点最密集，表明这是最常见的广告单元表现区间。对应CTR ≈ 10% 到 7.5%，属于行业常见范围。<br>稀疏区处于右上角，这些属于大预算单元，访问量高，但CTR不一定更高，如6000曝光却只有400访问——CTR≈6.7%。</p>
<h2 id="4-3-自然曝光量与自然访问量的关系"><a href="#4-3-自然曝光量与自然访问量的关系" class="headerlink" title="4.3 自然曝光量与自然访问量的关系"></a>4.3 自然曝光量与自然访问量的关系</h2><p>聚焦自然曝光量与自然访问量两个自然流量指标的联合分布，揭示：<br>1.	自然曝光是否有效转化为访问？<br>2.	两者是否存在线性或非线性关系？<br>3.	自然点击率是否稳定？是否存在波动区间？</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/009.png"
                      alt="photo"
                ></p>
<p>整体趋势呈现强正相关，但存在离散度。<br>主趋势线明显,数据点大致沿一条从原点出发的直线分布，表明“自然曝光量越高，自然访问量越高”，符合搜索引擎与用户行为的基本逻辑。<br>离散度适中,虽然整体呈正相关，但点并非严格落在一条直线上，存在一定波动，说明不同自然流量入口的点击效率存在差异。</p>
<p>自然点击率分析：<br>CTR &#x3D; 访问量 &#x2F; 曝光量，是衡量自然流量吸引力的核心指标。我们可通过散点图推断CTR的分布特征：<br>在曝光量&#x3D;2000，访问量&#x3D;200处，CTR &#x3D; 10%<br>在曝光量&#x3D;4000，访问量&#x3D;300处，CTR &#x3D; 7.5%<br>在曝光量&#x3D;7000，访问量&#x3D;730处，CTR &#x3D; 10.4%<br>随着曝光量增加，CTR呈轻微下降趋势（从10%降至7.5%），但在极高曝光量处又回升至10.4%。<br>这可能与大曝光单元可能覆盖更泛化的流量，导致点击效率降低；但“爆款”内容或关键词因用户主动搜索意愿强，CTR反而更高。<br>这说明：<br>1．	并非曝光越多越好，需关注单位曝光带来的访问量。<br>2．	应优先优化高曝光低CTR单元，提升其标题、摘要、排名或内容质量。</p>
<h2 id="4-4-CPC访问量与自然访问量"><a href="#4-4-CPC访问量与自然访问量" class="headerlink" title="4.4 CPC访问量与自然访问量"></a>4.4 CPC访问量与自然访问量</h2><p>聚焦CPC访问量与自然访问量两个流量指标的联合分布，揭示：<br>1.	付费流量是否带动自然流量增长？<br>2.	两者是否存在正相关、负相关或无相关？<br>3.	是否存在高CPC低自然或低CPC高自然的异常单元？<br>4.	流量结构是否健康？是否存在过度依赖付费流量的风险？</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/010.png"
                      alt="photo"
                ></p>
<p>整体趋势呈现弱相关或无显著线性相关。无明显主趋势线数据点呈云团状分布，表明两者不存在稳定的线性关系。<br>点密度分布集中在低CPC低自然区间。高密度区：CPC访问量 0<del>200，自然访问量 50</del>300 区间，此区域点最密集，表明这是最常见的流量组合。对应中等付费+中等自然单元，流量结构相对健康。<br>数据点无明显线性趋势，表明CPC访问量与自然访问量之间不存在强相关性。</p>
<h2 id="4-5-自然流量与CPC流量关系分析总结"><a href="#4-5-自然流量与CPC流量关系分析总结" class="headerlink" title="4.5 自然流量与CPC流量关系分析总结"></a>4.5 自然流量与CPC流量关系分析总结</h2><p>付费流量并未显著带动自然流量增长，两者更多是独立运作的渠道。这意味着：<br>1.	品牌效应不足：用户点击广告后未形成品牌记忆，未主动搜索。<br>2.	内容质量一般：落地页或内容未激发用户分享或二次访问。<br>3.	SEO策略薄弱：自然流量主要依赖外部引流，而非广告带动。</p>
<p>因此不应期望付费流量直接带动自然流量，而应通过内容建设、品牌塑造、SEO优化等手段提升自然流量独立增长能力。应建立流量结构健康度指标，指导预算分配。<br>例如可通过引导用户搜索品牌词、设置品牌专区、优化落地页SEO等方式，将付费流量转化为自然流量。<br>通过再营销广告、关键词拓展等方式，将自然流量用户重新召回，提升LTV。<br>在保证总访问量的前提下，优先分配预算给高自然占比单元，降低对付费流量的依赖。<br>在高CPC低自然单元中，设计A&#x2F;B测试验证不同落地页、引导语、品牌露出的效果，观察是否能提升自然流量。<br>在低CPC高自然单元中，尝试增加付费预算，观察其能否维持高自然流量并带来规模效应。
 </p>
<h1 id="五、归因分析"><a href="#五、归因分析" class="headerlink" title="五、归因分析"></a>五、归因分析</h1><p>针对自然访问量和CPC访问量，关注两者对订单数量的贡献比例。从定性分析和定量分析两种角度进行解释。</p>
<h2 id="5-1-定性分析"><a href="#5-1-定性分析" class="headerlink" title="5.1 定性分析"></a>5.1 定性分析</h2><p>SHAP值是一种基于博弈论的特征贡献分配方法，满足公平性公理，能为每个样本中的每个特征分配一个贡献值。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/011.png"
                      alt="photo"
                ></p>
<p>自然流量的SHAP值分布形状呈钟形，集中在X轴右侧，且向右延伸较长。负值区多为低值，正值区多为高值。表明自然流量对订单有强烈的正向推动作用，且其影响随访问量增加而增大。当自然流量值较低时，SHAP值接近0或略负，对订单贡献小。当自然流量值较高时，SHAP值显著为正，是订单的主要驱动因素。<br>CPC流量的SHAP值分布形状同样集中在X轴右侧，但分布更扁平，且峰值不如自然流量明显。负值区多为低值，正值区多为高值。CPC流量对订单也有正向推动作用，但其影响幅度小于自然流量，且在高值区的贡献趋于稳定。当CPC流量值较低时，SHAP值接近0说明贡献小。当CPC流量值较高时，SHAP值稳定在20-40之间，说明有一定拉动作用，但边际效应递减。</p>
<h2 id="5-2-定量分析"><a href="#5-2-定量分析" class="headerlink" title="5.2 定量分析"></a>5.2 定量分析</h2><p>利用最小二乘回归来建立一个回归模型，以预测有效订单作为因变量，基于 自然访问量和CPC访问量。<br>分别将自然访问量和CPC访问量进行中心化并创建交互项再添加截距项。得到:</p>
<table>
<thead>
<tr>
<th>R2</th>
<th>F统计量</th>
<th>P统计量</th>
</tr>
</thead>
<tbody><tr>
<td>0.770</td>
<td>1288</td>
<td>0</td>
</tr>
</tbody></table>
<p>模型解释了77%的门店实收变异，说明自然访问量和付费访问量是核心驱动因素。剩余23%可能由客单价波动、促销活动、天气、竞争等未纳入变量解释。</p>
<table>
<thead>
<tr>
<th></th>
<th align="left">conf</th>
<th align="left">std err</th>
<th>t值</th>
<th>p值</th>
</tr>
</thead>
<tbody><tr>
<td>const</td>
<td align="left">42.8127</td>
<td align="left">0.555</td>
<td>77.190</td>
<td>0</td>
</tr>
<tr>
<td>自然访问量_c</td>
<td align="left">0.2053</td>
<td align="left">0.006</td>
<td>35.909</td>
<td>0</td>
</tr>
<tr>
<td>cpc访问量_c</td>
<td align="left">0.1891</td>
<td align="left">0.007</td>
<td>25.319</td>
<td>0</td>
</tr>
<tr>
<td>自然_CPC_交互</td>
<td align="left">-0.002</td>
<td align="left">5.54e-5</td>
<td>-3.271</td>
<td>0.001</td>
</tr>
</tbody></table>
<p>上表中模型可写成：<br>有效订单 &#x3D; 0.2053自然访问量_c + 0.1891cpc访问量_c - 0.0002自然_CPC_交互 + 42.8127<br>自然访问量_c：<br>这个系数表示自然访问量每增加1个单位，有效订单数将增加0.2053单位。并且该系数非常显著，t值为35.909，p值接近0，表明自然访问量对有效订单的影响是正向且显著的。</p>
<p>CPC访问量_c：<br>这个系数表示CPC访问量每增加1个单位，有效订单数将增加0.1891单位。t值为25.319，p值接近0，说明CPC访问量对有效订单的影响也是正向且显著的。<br>自然_CPC_交互:<br>	交互项的系数为负值，表示自然访问量和CPC访问量之间的交互效应对有效订单有负向影响。即当自然访问量和CPC访问量同时增加时，对有效订单的影响会稍微减弱。尽管这个系数非常小，但它依然显著，说明二者之间存在一定的交互效应。
 </p>
<h1 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h1><p>本研究通过对广告投放中CPC、GMV、ROI等关键指标的深入分析，揭示了不同广告投放策略下的效益差异，并对优化广告策略提供了理论依据。发现：<br>1.	CPC成本合理性与高花费低转化现象：<br>通过分析CPC总费用与下单转化率之间的关系，发现大部分广告投放策略集中在中低成本区间，且存在一定比例的高转化率广告，表现出高性价比。<br>然而，部分广告策略表现出高投入低转化的情况，特别是在CPC费用过高而转化率未见提升的情境下，反映了高花费低转化的现象。<br>2.	ROI分析与异常值识别：<br>从ROI的周度变化趋势来看，广告投放的效益受季节波动、事件性因素影响显著。部分门店在特定时段出现异常高或低的ROI，特别是受疫情等外部因素的影响，导致ROI出现显著波动。<br>3.	点击率的健康性：<br>整体CTR水平偏低，尤其是在0.05 ~ 0.10区间内形成明显峰值，表明绝大多数广告投放的CTR较低，但这一现象符合电商行业的常见情况。<br>高CTR广告较为稀少，表明精准投放和高质量流量对广告效果有显著提升作用。应特别关注CTR较高的广告策略，优化其他低CTR广告的素材和定向策略。<br>4.	CPC流量与自然流量的关系：<br>自然流量与CPC流量之间未表现出明显的正相关，表明CPC流量并未显著带动自然流量的增长。这可能反映了品牌效应不足、内容质量一般或SEO策略薄弱的问题。<br>自然流量与CPC流量的独立运作性意味着广告主应避免过度依赖CPC流量，而应通过品牌建设、内容优化等措施提升自然流量的独立增长能力。<br>5.	CPC流量质量对下单转化率的影响：<br>通过分析CTR与下单转化率的关系，发现高质量的CPC流量对下单转化率有正向影响。特别是CPC流量质量较高时，转化率显著提升，反之则表现为较低的转化效率。<br>对于流量质量较低的广告，应考虑优化投放策略，提高广告的精准度和内容质量，以提升转化率。</p>
<p><strong>参考文献</strong><br>[1] 高洁.（2025）. C公司搜索广告投放效果分析及优化策略研究. 广州大学.<br>[2] 王楠.（2025）. W公司在亚马逊美国站的广告投放策略优化研究. 广东工业大学.<br>[3] 尤运琴.（2023）. Y品牌家居互联网广告精准营销策略优化研究. 华东师范大学.<br>[4] 代文强, 初维佳, 钟婧.（2022）. CPC模式下保量合同的在线展示广告投放策略优化. 中国管理科学, 30(10), 168–178.</p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p><strong>附录A支撑材料文件列表</strong></p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>文件内容</th>
</tr>
</thead>
<tbody><tr>
<td>cpc_EDA.ipynb</td>
<td>数据可视化源代码</td>
</tr>
<tr>
<td>cpc.csv</td>
<td>数据集</td>
</tr>
</tbody></table>
<p><strong>附录B程序代码(部分)</strong></p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import matplotlib.dates as mdates</span><br><span class="line"></span><br><span class="line">df_time = df.groupby(<span class="string">&#x27;日期&#x27;</span>).agg(&#123;<span class="string">&#x27;cpc总费用&#x27;</span>:<span class="string">&#x27;sum&#x27;</span>,<span class="string">&#x27;下单转换率&#x27;</span>:<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;gmvroi&#x27;</span>:<span class="string">&#x27;mean&#x27;</span>&#125;).reset_index()</span><br><span class="line">fig, ax1 = plt.subplots(figsize=(12,6))</span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line"></span><br><span class="line">ax1.plot(df_time[<span class="string">&#x27;日期&#x27;</span>], df_time[<span class="string">&#x27;cpc总费用&#x27;</span>], color=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;CPC总费用&#x27;</span>)</span><br><span class="line">ax2.plot(df_time[<span class="string">&#x27;日期&#x27;</span>], df_time[<span class="string">&#x27;下单转换率&#x27;</span>], color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;下单转化率&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;日期&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;CPC总费用&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;下单转化率&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">ax1.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelcolor=<span class="string">&#x27;orange&#x27;</span>)</span><br><span class="line">ax2.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelcolor=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax1.xaxis.set_major_locator(mdates.WeekdayLocator(interval=4))  <span class="comment"># 每月显示一次</span></span><br><span class="line">ax1.xaxis.set_major_formatter(mdates.DateFormatter(<span class="string">&#x27;%Y-%m-%d&#x27;</span>))</span><br><span class="line">plt.xticks(rotation=45)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;每日CPC投入与下单转化率趋势&#x27;</span>)</span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import statsmodels.api as sm</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">X = <span class="built_in">df</span>[[<span class="string">&#x27;自然访问量&#x27;</span>, <span class="string">&#x27;cpc访问量&#x27;</span>]].copy()</span><br><span class="line"></span><br><span class="line">X[<span class="string">&#x27;自然访问量_c&#x27;</span>] = X[<span class="string">&#x27;自然访问量&#x27;</span>] - X[<span class="string">&#x27;自然访问量&#x27;</span>].mean()</span><br><span class="line">X[<span class="string">&#x27;cpc访问量_c&#x27;</span>] = X[<span class="string">&#x27;cpc访问量&#x27;</span>] - X[<span class="string">&#x27;cpc访问量&#x27;</span>].mean()</span><br><span class="line"></span><br><span class="line">X[<span class="string">&#x27;自然_CPC_交互&#x27;</span>] = X[<span class="string">&#x27;自然访问量_c&#x27;</span>] * X[<span class="string">&#x27;cpc访问量_c&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_reg = X[[<span class="string">&#x27;自然访问量_c&#x27;</span>, <span class="string">&#x27;cpc访问量_c&#x27;</span>, <span class="string">&#x27;自然_CPC_交互&#x27;</span>]]</span><br><span class="line">X_reg = sm.add_constant(X_reg)</span><br><span class="line"></span><br><span class="line">y_order = <span class="built_in">df</span>[<span class="string">&#x27;有效订单&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model_order = sm.OLS(y_order, X_reg).fit()</span><br><span class="line"><span class="built_in">print</span>(model_order.summary())</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>brain tumor dataset</title>
    <url>/zhihaojiang.github.io/2025/12/02/20251202brain%20tumor%20dataset/</url>
    <content><![CDATA[<h1 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h1><p><a class="link"   href="https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset" >https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h1 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers</span><br><span class="line">from tensorflow.keras.applications.densenet import preprocess_input</span><br></pre></td></tr></table></figure></div>

<h1 id="检查是否启用了GPU"><a href="#检查是否启用了GPU" class="headerlink" title="检查是否启用了GPU"></a>检查是否启用了GPU</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(tf.config.list_physical_devices(<span class="string">&quot;GPU&quot;</span>))</span><br></pre></td></tr></table></figure></div>
<p>[PhysicalDevice(name&#x3D;’&#x2F;physical_device:GPU:0’, device_type&#x3D;’GPU’)]</p>
<h1 id="构造数据集"><a href="#构造数据集" class="headerlink" title="构造数据集"></a>构造数据集</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 参数</span></span><br><span class="line">BATCH_SIZE = 32</span><br><span class="line">IMG_SIZE = (224, 224)</span><br><span class="line">DATA_DIR = <span class="string">&quot;/Volumes/HIKSEMI/ipynb/Kaggle/Brain Tumor Dataset&quot;</span></span><br><span class="line"></span><br><span class="line">train_ds_raw = tf.keras.preprocessing.image_dataset_from_directory(</span><br><span class="line">    DATA_DIR,</span><br><span class="line">    validation_split=0.2,</span><br><span class="line">    subset=<span class="string">&quot;training&quot;</span>,</span><br><span class="line">    seed=123,</span><br><span class="line">    color_mode=<span class="string">&quot;rgb&quot;</span>,</span><br><span class="line">    image_size=IMG_SIZE,</span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">)</span><br><span class="line">val_ds_raw = tf.keras.preprocessing.image_dataset_from_directory(</span><br><span class="line">    DATA_DIR,</span><br><span class="line">    validation_split=0.2,</span><br><span class="line">    subset=<span class="string">&quot;validation&quot;</span>,</span><br><span class="line">    seed=123,</span><br><span class="line">    color_mode=<span class="string">&quot;rgb&quot;</span>,</span><br><span class="line">    image_size=IMG_SIZE,</span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>
<p>Found 10560 files belonging to 4 classes.<br>Using 8448 files for training.<br>Found 10560 files belonging to 4 classes.<br>Using 2112 files for validation.</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">class_names = train_ds_raw.class_names</span><br><span class="line">num_classes = len(class_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;类别:&quot;</span>, class_names)</span><br><span class="line"></span><br><span class="line">AUTOTUNE = tf.data.AUTOTUNE</span><br><span class="line">train_ds = train_ds_raw.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)</span><br><span class="line">val_ds = val_ds_raw.cache().prefetch(buffer_size=AUTOTUNE)</span><br></pre></td></tr></table></figure></div>

<h1 id="查看不同标签图片的数量"><a href="#查看不同标签图片的数量" class="headerlink" title="查看不同标签图片的数量"></a>查看不同标签图片的数量</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">counts = np.bincount([y <span class="keyword">for</span> x, y <span class="keyword">in</span> train_ds.unbatch()])</span><br><span class="line">plt.bar(range(len(class_names)), counts)</span><br><span class="line">plt.xticks(range(len(class_names)), class_names)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/02/001.png"
                      alt="photo"
                ></p>
<h1 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">IMG_SIZE = (224, 224)</span><br><span class="line"></span><br><span class="line">data_augmentation = tf.keras.Sequential([</span><br><span class="line">    layers.RandomFlip(<span class="string">&quot;horizontal_and_vertical&quot;</span>),</span><br><span class="line">    layers.RandomRotation(0.15), <span class="comment"># 随机旋转</span></span><br><span class="line">    layers.RandomZoom(0.2), <span class="comment"># 随机缩放</span></span><br><span class="line">    layers.RandomContrast(0.2), <span class="comment"># 随机对比度</span></span><br><span class="line">    layers.RandomBrightness(0.2) <span class="comment"># 随机亮度</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure></div>

<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># DenseNet121</span></span><br><span class="line">base_model = tf.keras.applications.DenseNet121(</span><br><span class="line">    include_top=False,</span><br><span class="line">    weights=<span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">    input_shape=(224, 224, 3)</span><br><span class="line">)</span><br><span class="line">base_model.trainable = False</span><br><span class="line"></span><br><span class="line">model = models.Sequential([</span><br><span class="line">    data_augmentation,</span><br><span class="line">    layers.Lambda(preprocess_input),</span><br><span class="line">    base_model,</span><br><span class="line">    layers.GlobalAveragePooling2D(),</span><br><span class="line">    layers.Dropout(0.3),</span><br><span class="line">    layers.Dense(128, activation=<span class="string">&#x27;relu&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2(1e-4)),</span><br><span class="line">    layers.Dense(4, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure></div>

<h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><h2 id="第一阶段"><a href="#第一阶段" class="headerlink" title="第一阶段"></a>第一阶段</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=tf.keras.optimizers.Adam(1e-3),</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第一阶段&quot;</span>)</span><br><span class="line"></span><br><span class="line">history1 = model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    validation_data=val_ds,</span><br><span class="line">    epochs=10,</span><br><span class="line">    callbacks=[</span><br><span class="line">        tf.keras.callbacks.EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, patience=3, restore_best_weights=True)</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<p>Epoch 1&#x2F;10<br>2025-11-16 07:24:40.974143: I tensorflow&#x2F;core&#x2F;grappler&#x2F;optimizers&#x2F;custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 183s 645ms&#x2F;step - accuracy: 0.6757 - loss: 0.8693 - val_accuracy: 0.8177 - val_loss: 0.4993<br>Epoch 2&#x2F;10<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 135s 511ms&#x2F;step - accuracy: 0.7649 - loss: 0.6108 - val_accuracy: 0.8191 - val_loss: 0.5096<br>Epoch 3&#x2F;10<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 143s 540ms&#x2F;step - accuracy: 0.7749 - loss: 0.5895 - val_accuracy: 0.8329 - val_loss: 0.4379<br>Epoch 4&#x2F;10<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 140s 531ms&#x2F;step - accuracy: 0.7840 - loss: 0.5671 - val_accuracy: 0.7779 - val_loss: 0.5830<br>Epoch 5&#x2F;10<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 135s 511ms&#x2F;step - accuracy: 0.7770 - loss: 0.5739 - val_accuracy: 0.8030 - val_loss: 0.4965<br>Epoch 6&#x2F;10<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 142s 539ms&#x2F;step - accuracy: 0.7874 - loss: 0.5575 - val_accuracy: 0.8376 - val_loss: 0.4554</p>
<h2 id="第二阶段"><a href="#第二阶段" class="headerlink" title="第二阶段"></a>第二阶段</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">base_model.trainable = True</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> base_model.layers[:-80]:</span><br><span class="line">    layer.trainable = False</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;第二阶段&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;可训练参数: &#123;sum([tf.size(v).numpy() for v in model.trainable_variables])&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=tf.keras.optimizers.Adam(1e-5),</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">callbacks = [</span><br><span class="line">    tf.keras.callbacks.EarlyStopping(</span><br><span class="line">        monitor=<span class="string">&#x27;val_loss&#x27;</span>, </span><br><span class="line">        patience=5, </span><br><span class="line">        restore_best_weights=True</span><br><span class="line">    ),</span><br><span class="line">    tf.keras.callbacks.ReduceLROnPlateau(</span><br><span class="line">        monitor=<span class="string">&#x27;val_loss&#x27;</span>, </span><br><span class="line">        <span class="built_in">factor</span>=0.5, </span><br><span class="line">        patience=3,</span><br><span class="line">        min_lr=1e-7</span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">history2 = model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    validation_data=val_ds,</span><br><span class="line">    epochs=40,</span><br><span class="line">    callbacks=callbacks</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<p>…<br>Epoch 39&#x2F;40<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 273s 1s&#x2F;step - accuracy: 0.9297 - loss: 0.2094 - val_accuracy: 0.9081 - val_loss: 0.2820 - learning_rate: 5.0000e-06<br>Epoch 40&#x2F;40<br>264&#x2F;264 ━━━━━━━━━━━━━━━━━━━━ 324s 1s&#x2F;step - accuracy: 0.9315 - loss: 0.1987 - val_accuracy: 0.9058 - val_loss: 0.2970 - learning_rate: 5.0000e-06</p>
<h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">val_loss, val_acc = model.evaluate(val_ds_raw)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;验证集准确率: &#123;val_acc:.3f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(12, 5))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">plt.subplot(1, 2, 1)</span><br><span class="line">plt.plot(history2.history[<span class="string">&quot;accuracy&quot;</span>], label=<span class="string">&quot;Train Accuracy&quot;</span>)</span><br><span class="line">plt.plot(history2.history[<span class="string">&quot;val_accuracy&quot;</span>], label=<span class="string">&quot;Val Accuracy&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;Accuracy over Epochs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失</span></span><br><span class="line">plt.subplot(1, 2, 2)</span><br><span class="line">plt.plot(history2.history[<span class="string">&quot;loss&quot;</span>], label=<span class="string">&quot;Train Loss&quot;</span>)</span><br><span class="line">plt.plot(history2.history[<span class="string">&quot;val_loss&quot;</span>], label=<span class="string">&quot;Val Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;Loss over Epochs&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/02/002.png"
                      alt="photo"
                ></p>
<h1 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">model.save(<span class="string">&quot;brain_tumor_model_3.keras&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型已保存为 brain_tumor_model_3.keras&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<h1 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">model = tf.keras.models.load_model(</span><br><span class="line">    <span class="string">&quot;brain_tumor_model_3.keras&quot;</span>,</span><br><span class="line">    custom_objects=&#123;<span class="string">&quot;preprocess_input&quot;</span>: preprocess_input&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">class_names = train_ds_raw.class_names</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> val_ds_raw.take(1):</span><br><span class="line">    preds = model.predict(images)</span><br><span class="line">    pred_labels = np.argmax(preds, axis=1)</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(12, 12))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(9):</span><br><span class="line">        plt.subplot(3, 3, i + 1)</span><br><span class="line">        plt.imshow(images[i].numpy().astype(<span class="string">&quot;uint8&quot;</span>))</span><br><span class="line">        true_label = class_names[labels[i]]</span><br><span class="line">        pred_label = class_names[pred_labels[i]]</span><br><span class="line">        color = <span class="string">&quot;green&quot;</span> <span class="keyword">if</span> true_label == pred_label <span class="keyword">else</span> <span class="string">&quot;red&quot;</span></span><br><span class="line">        plt.title(f<span class="string">&quot;Pred: &#123;pred_label&#125;\nTrue: &#123;true_label&#125;&quot;</span>, color=color)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/02/003.png"
                      alt="photo"
                ></p>
<h1 id="分类报告"><a href="#分类报告" class="headerlink" title="分类报告"></a>分类报告</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn.metrics import confusion_matrix, classification_report</span><br><span class="line"></span><br><span class="line">y_true = []</span><br><span class="line">y_pred = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> val_ds:</span><br><span class="line">    preds = model.predict(images, verbose=0)</span><br><span class="line">    preds_class = np.argmax(preds, axis=1)</span><br><span class="line">    y_true.extend(labels.numpy())</span><br><span class="line">    y_pred.extend(preds_class)</span><br><span class="line"></span><br><span class="line">y_true = np.array(y_true)</span><br><span class="line">y_pred = np.array(y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Classification Report:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_true, y_pred, digits=4))</span><br><span class="line"></span><br><span class="line">cm = confusion_matrix(y_true, y_pred)</span><br><span class="line">cm_norm = cm.astype(<span class="string">&#x27;float&#x27;</span>) / cm.sum(axis=1)[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8,6))</span><br><span class="line">sns.heatmap(cm_norm, annot=True, <span class="built_in">fmt</span>=<span class="string">&quot;.2f&quot;</span>, cmap=<span class="string">&quot;Blues&quot;</span>, cbar=True)</span><br><span class="line">plt.title(<span class="string">&quot;Classification Report&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">val_acc = np.mean(y_true == y_pred)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;验证集准确率: &#123;val_acc:.4f&#125;&quot;</span>)</span><br></pre></td></tr></table></figure></div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/02/004.png"
                      alt="photo"
                ></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>商业数据分析--大作业</title>
    <url>/zhihaojiang.github.io/2025/12/03/20251204%E5%95%86%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90--%E5%A4%A7%E4%BD%9C%E4%B8%9A/</url>
    <content><![CDATA[<h1 id="基于开源数据的广告投放策略与效益"><a href="#基于开源数据的广告投放策略与效益" class="headerlink" title="基于开源数据的广告投放策略与效益"></a>基于开源数据的广告投放策略与效益</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本研究通过对开源数据的广告投放数据的可视化分析，探索了CPC、GMV、ROI等核心指标与广告效果之间的关系，旨在揭示不同投放策略下的效益差异，并为广告主提供优化建议。<br>分析CPC成本的合理性，表明大部分广告投放策略的CPC费用集中在中低成本区间，但仍存在一些高花费低转化的现象。<br>对ROI的分析，发现广告投放效益受季节性波动、外部事件影响显著。反映了<strong>外部环境对广告投放效果的强烈影响</strong>。<br>CTR分析揭示了广告投放的吸引力，整体CTR偏低，尤其是在0.05至0.10区间内形成明显的峰值，表明大多数广告的点击率较低。反映了广告定向和素材优化的空间。高CTR广告较为稀少，<strong>优化广告定向和提升广告创意质量能够显著提高CTR和转化率</strong>。<br>关于CPC流量与自然流量的关系，分析结果表明，两者并未表现出显著的正相关，<strong>表明CPC流量并未有效促进自然流量的增长</strong>。这表明广告投放未能有效提升品牌知名度或用户搜索意图，可能与内容质量、品牌效应和SEO策略不足有关。<br>回归分析表明<strong>自然访问量和CPC访问量对有效订单数具有显著正向影响</strong>，<br>R^2为0.770，表明两者是<strong>影响广告效果的核心因素</strong>。自然访问量每增加1单位，有效订单数将增加0.2053单位，而CPC访问量每增加1单位，有效订单数将增加0.1891单位。<br>进一步使用catBoost模型预测，模型在测试集上达到\mathbit{R}^\mathbf{2}=0.823，交叉验证均值达到0.842且标准差仅为0.026,充分验证了模型的预测能力和稳健性。<br><strong>关键词：CPC GMV ROI  广告投放 catBoost</strong></p>
<h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><h2 id="1-1研究背景"><a href="#1-1研究背景" class="headerlink" title="1.1研究背景"></a>1.1研究背景</h2><p>在当前数字化广告投放中，如何精准地评估广告效果，优化广告投放策略，已成为企业提高营销效益和竞争力的关键。特别是在电商、餐饮等行业，广告投放的效果直接影响到销量和用户转化。因此，合理评估广告投放的成本与回报关系，深入分析影响广告效果的关键因素，已成为优化广告策略的核心任务。</p>
<h2 id="1-2研究目的"><a href="#1-2研究目的" class="headerlink" title="1.2研究目的"></a>1.2研究目的</h2><p>广告投放的成本和回报是衡量广告效果的核心指标。CPC直接反映了广告主获取流量的成本，而GMV和ROI则衡量了广告投放带来的实际收入与营销投入之间的关系。通过对这三者的分析，企业能够判断广告费用的投入是否合理，是否存在高花费低转化的现象，以及如何提高广告投放的效益。</p>
<h2 id="1-3研究意义"><a href="#1-3研究意义" class="headerlink" title="1.3研究意义"></a>1.3研究意义</h2><p>在广告投放过程中，点击率作为衡量广告吸引力的前置指标，其与下单转化率之间的关系也至关重要。广告的点击率是否健康，直接影响到转化率的提升。因此，深入探讨CTR与下单转化率之间的关系，有助于揭示CPC流量质量对转化效果的影响，为进一步优化广告策略提供理论依据。<br>本文将通过对多个门店和日期的广告数据进行系统分析，探讨CPC成本、GMV、ROI和CTR等核心指标的分布特征与相互关系，分析CPC流量与自然流量的协同效应，并提出优化广告投放策略的建议。研究结果将为广告主提供数据支持，帮助其实现更高效的广告预算分配和更精确的投放策略。</p>
<h1 id="二、数据准备与预处理"><a href="#二、数据准备与预处理" class="headerlink" title="二、	数据准备与预处理"></a>二、	数据准备与预处理</h1><h2 id="2-1数据来源"><a href="#2-1数据来源" class="headerlink" title="2.1数据来源"></a>2.1数据来源</h2><p>数据来源于开源平台gitcode。此开源项目提供了一个多维度的外卖行业数据集，包含广告点击成本、订单信息和门店数据三大模块，非常适合用于外卖门店的运营分析。通过该数据集，可以深入分析门店经营状况，评估广告投放效果，洞察顾客消费行为，以及研究地域市场潜力。</p>
<h2 id="2-2-数据集概述"><a href="#2-2-数据集概述" class="headerlink" title="2.2 数据集概述"></a>2.2 数据集概述</h2><p>通过导入数据并使用columns函数查看特征名称，发现数据中涉及了多个关键指标，如CPC、GMV、ROI等。为了深入理解这些特征，查询并解释了它们的具体定义与业务意义。</p>
<h3 id="2-2-1数据含义："><a href="#2-2-1数据含义：" class="headerlink" title="2.2.1数据含义："></a>2.2.1数据含义：</h3><p>在数据集的多个关键指标中，CPC、GMV、ROI是广告投放分析中最为核心的三个变量。以下是它们的详细定义及其对广告效果评估的意义：</p>
<p><strong>CPC（每次点击费用）</strong><br>定义：广告主每获得一次点击所需支付的费用。<br>意义：衡量广告流量获取成本，CPC越低说明花同样的钱能吸引更多用户访问。</p>
<p><strong>GMV（成交总额）</strong><br>定义：通过广告或平台产生的商品交易总金额。<br>意义：衡量销售规模。GMV 大说明广告带来了高销售额。</p>
<p><strong>ROI（投资回报率）</strong><br>定义：广告带来的收入与广告投入之间的比值。<br>意义：ROI 表示每花 1 元广告费带来多少销售额，ROI 越高越好。</p>
<h3 id="2-2-2-数据分布"><a href="#2-2-2-数据分布" class="headerlink" title="2.2.2 数据分布"></a>2.2.2 数据分布</h3><p><strong>CPC单次点击费用</strong><br>针对“CPC单次点击费用”这一核心广告投放成本指标，从描述性统计、分布形态、可视化特征及业务含义四个维度展开系统分析，旨在全面刻画该变量的数据分布特性。<br>通过计算基本统计量，我们初步掌握该特征的集中趋势、离散程度与分布形态。相关指标如下表所示</p>
<table>
<thead>
<tr>
<th>最小值</th>
<th align="left">最大值</th>
<th align="left">均值</th>
<th>中位数</th>
</tr>
</thead>
<tbody><tr>
<td>0.02</td>
<td align="left">2.98</td>
<td align="left">1.389</td>
<td>1.38</td>
</tr>
<tr>
<td>四分位距</td>
<td align="left">标准差</td>
<td align="left">峰度</td>
<td>偏度</td>
</tr>
<tr>
<td>0.3</td>
<td align="left">0.304</td>
<td align="left">2.077</td>
<td>0.212</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/001.png" alt="photo"></p>
<p>样本中所有广告点击的平均成本约为1.39元。作为衡量整体水平的核心指标，它反映了当前投放策略下的平均获客成本。<br>中位数为1.38，与均值高度接近，未受极端值显著干扰。说明大部分广告点击成本集中在合理区间内。<br>标准差为0.304，四分位距为0.3，表明数据分布紧凑，无明显的异常值。并且IQR/Std\approx1，说明数据近似正态。<br>峰度为2.077，标准正态分布的峰度为3，这属于低峰态，意味着分布曲线比正态分布更平坦，数据在中心区域不如正态分布集中，两侧更宽。从柱状图也可以看到在峰值两侧呈现较平缓的下降趋势，而非陡峭的钟形。表明CPC值在主流区间内分布较为均匀，无明显集中或缺失，有利于稳定投放策略。<br>偏度为0.212，属于轻微右偏，在广告投放场景中，右偏是常见现象——部分高竞争关键词或优质流量渠道的CPC天然较高。</p>
<p><strong>CPC总费用</strong><br>CPC总费用，即单次点击成本×点击量，该指标反映广告投放在特定单元上的总体支出水平。</p>
<table>
<thead>
<tr>
<th>最小值</th>
<th align="left">最大值</th>
<th align="left">均值</th>
<th>中位数</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td align="left">846.4</td>
<td align="left">129.58</td>
<td>76.2</td>
</tr>
<tr>
<td>四分位距</td>
<td align="left">标准差</td>
<td align="left">峰度</td>
<td>偏度</td>
</tr>
<tr>
<td>150.09</td>
<td align="left">134.539</td>
<td align="left">5.317</td>
<td>2.091</td>
</tr>
</tbody></table>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/002.png" alt="photo"></p>
<p>均值为129.58，表示样本中各单元的平均总费用约为129.58 元。但从图中可以看到，数据分布是长尾分布，均值受极端值影响较大，不能作为典型值使用。而中位数为76.2，在此分布中，中位数更具有代表性。<br>标准差为134.539表明数据波动剧烈。四分位距 IQR = 150.09意味费用跨度很大。<br>偏度= 2.091是严重右偏，意味着绝大多数的费用较低，但存在少量极高费用，这些“头部”显著拉高了均值。<br>在广告投放场景中，这通常是二八定律的体现——少数关键词或计划贡献了大部分支出。<br>峰度为5.317，标准正态分布峰度为3。此处峰度&gt;3，属于高峰态。<br>意味着分布曲线比正态分布更尖峭，中心区域更集中，同时两侧尾部更厚即存在更多极端值。高峰态和严重右偏说明存在头部效应，即少数高消耗单元主导总支出。</p>
<h2 id="2-3数据预处理"><a href="#2-3数据预处理" class="headerlink" title="2.3数据预处理"></a>2.3数据预处理</h2><h3 id="2-3-1数据清洗"><a href="#2-3-1数据清洗" class="headerlink" title="2.3.1数据清洗"></a>2.3.1数据清洗</h3><p>查看数据缺失情况，发现部分数据像cpc单次点击费用、无效订单、自然曝光量等存在9-12列缺失值，查看数据集形状后得知数据一共有1177列，删除9-12列并不影响数据集的完整性，因此选择删除缺失值。<br>查看数据集内容后发现，某些本不应该出现服输的特征其最小值是负数，说明这个是个异常值，将其去除；查看最大值，发现像gmvroi、cpc曝光量等特征等最大值异常偏大，过大的值会导致后续模型训练时被模型学习导致泛化性不佳，因此针对此使用winsorize将最大值值限制在95%分位数以下。</p>
<h3 id="2-3-2特征编码"><a href="#2-3-2特征编码" class="headerlink" title="2.3.2特征编码"></a>2.3.2特征编码</h3><p><strong>(a)正弦编码：</strong><br>对于数据中存在的日期特征，查看后看到其在数据中的保存形式为2019/12/12 11:54，即包含了年份、月份、日期、时间，显然这个特征包含的信息非常丰富，因此将其拆分成4个特征分别用”日期_年份”、 ”日期_月份”、 ”日期_日”、 ”日期_时间”来表示，我们都知道，日期是一个周期性的量，而正弦、余弦函数也是呈现周期性质，因此我们对月份、日使用正弦编码，这样对于后续创建模型时，模型就能学习到此特征的周期性。</p>
<p><strong>（b）对数变换</strong><br>电商访问量和曝光量数据往往呈现右偏分布,且数值范围跨度较大,因此对核心流量指标进行对数变换,以降低异常值的影响并改善数据的正态性。具体对自然访问量、CPC访问量、门店访问量、自然曝光量和CPC曝光量五个特征进行log1p变换:</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="18.661ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 8248 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="TeXAtom" transform="translate(861,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(783,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g></g><g data-mml-node="mtext" transform="translate(1802,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mo" transform="translate(2329.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(3385.5,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(3635.5,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(3933.5,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(4418.5,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mo" transform="translate(4895.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(5284.5,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(6006.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(7007,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(7859,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<p>log1p变换相比直接取对数的优势在于能够有效处理零值情况,避免数学运算错误。这一变换不仅压缩了数据的动态范围,还使得模型能够更好地学习不同量级数据间的关系模式。</p>
<h3 id="2-3-3-数据转换"><a href="#2-3-3-数据转换" class="headerlink" title="2.3.3 数据转换"></a>2.3.3 数据转换</h3><p>CTR——即点击率是广告中一个重要的指标，在此数据集中没有给出，但可以通过:<br>CTR=访问量/曝光量<br>CTR特征能够量化不同流量渠道的质量差异,为模型提供更丰富的信息维度。</p>
<h1 id="三、数据分析与可视化"><a href="#三、数据分析与可视化" class="headerlink" title="三、	数据分析与可视化"></a>三、	数据分析与可视化</h1><h2 id="3-1广告效果评估"><a href="#3-1广告效果评估" class="headerlink" title="3.1广告效果评估"></a>3.1广告效果评估</h2><p>聚焦CPC、 ROI 和效率，我们需要弄清楚：</p>
<ol>
<li>CPC成本是否合理？是否存在高花费低转化的现象？</li>
<li>ROI是否大于1？哪些门店/日期 ROI异常高或低？</li>
<li>点击率（CTR）是否健康？</li>
<li>下单转化率是否受CPC流量质量影响？</li>
</ol>
<h3 id="3-1-1-CPC成本合理性"><a href="#3-1-1-CPC成本合理性" class="headerlink" title="3.1.1 CPC成本合理性"></a>3.1.1 CPC成本合理性</h3><p>利用密度图查看CPC总费用和下单转换率之间的关系如图。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/003.png" alt="photo"></p>
<p>上图反应了两个变量的联合概率密度分布，可以看到主要数据集中在左下部，次区域的CPC总费用在[0,200]之间，下单转换率在[0.1,0,3]之间，说明大部分投放广告的策略是中等消费和中低转换率。<br>下单转换率在0.3以上的属于高转换率，可以看到高转换率区域主要分布在中低费用区间，在此区域的部分是高性价比区域——少量低成本单元实现了高转化率，这可能与广告的精准投放、新上线、合理推流相关，若要提高转化率性价比，推荐借鉴这些广告的推送方式以及广告的形式。</p>
<h3 id="3-1-2-GMV-ROI周度趋势"><a href="#3-1-2-GMV-ROI周度趋势" class="headerlink" title="3.1.2 GMV ROI周度趋势"></a>3.1.2 GMV ROI周度趋势</h3><p>针对门店周度GMV ROI这一关键经营效率指标，从整体趋势、门店间对比、季节性/事件性波动展开深入分析。GMV ROI = GMV/营销投入成本，反映单位营销费用带来的销售回报，是衡量门店盈利能力与投放效率的核心指标。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/004.png" alt="photo"></p>
<p>从整体趋势上看，其呈现明显的季节波动。<br><strong>2019年11月–2020年1月</strong>：多数门店ROI呈上升趋势，尤其在2020年1月达到阶段性高点。这可能受春节前消费高峰或年终促销活动驱动。<br>部分门店如蛙小辣美蛙火锅杯[五角场店]在2020年1月ROI飙升至16以上，表现突出。<br><strong>2020年2月–2020年3月</strong>：受新冠疫情影响，多数门店ROI出现断崖式下跌。多条折线在2020年2月跌至低谷。如蛙小辣·美蛙火锅杯[虹口足球场店]降至4以下。表明疫情对线下餐饮业冲击巨大，营销投入回报率显著下降。<br><strong>2020年4月–2020年6月</strong>：逐步复苏，部分门店恢复至疫情前水平，甚至超越。如蛙小辣火锅杯（五角场店）在2020年6月回升至14+，表现强劲。蛙小辣火锅杯（龙阳路店）在2020年5月后稳步上升。<br>2020年7月–2020年10月：趋于稳定，部分门店出现小幅回落。如粉色线蛙小辣·美蛙火锅杯[真如店]在2020年7月后逐渐下滑。<br>整体呈现疫情后复苏到平稳运行再到小幅回调的典型路径。</p>
<p>还可以看到，部分店铺的曲线出现停滞的现象，其主要出现在2020年2月–2020年3月，正好是疫情发生的时间点。根据国家统计局数据显示，2020年我国全年餐饮收入39527亿元，同比下降16.6%。受疫情影响，全年超2000家餐厅关闭，平均每月达200多家。<br>因此可以得出那些餐饮受疫情影响，不得不关闭以减少亏损。</p>
<h3 id="3-1-3-点击率健康性分析"><a href="#3-1-3-点击率健康性分析" class="headerlink" title="3.1.3 点击率健康性分析"></a>3.1.3 点击率健康性分析</h3><p>CTR反映广告被展示后用户点击的比例，是衡量广告相关性与吸引力的重要前置指标。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/005.png" alt="photo"></p>
<p>从上图可能得出绝大多数门店的CTR集中在 0.0 ~ 0.15 区间内，尤其在 0.05 ~ 0.10 附近形成一个尖锐峰值，之后迅速衰减，右侧几乎无数据。说明当前广告投放的整体CTR水平偏低，不过这也是一个常见的现象，像电商/本地生活类广告CTR通常在1%~10%之间。<br>在 CTR &gt; 0.15 后，门店数急剧下降，CT R &gt; 0.2 的门店几乎为零。说明高CTR单元极为稀少，可能是优质素材、精准定向或特殊场景带来的偶然结果。</p>
<h3 id="3-1-4-下单转化率与-CPC-流量质量关系"><a href="#3-1-4-下单转化率与-CPC-流量质量关系" class="headerlink" title="3.1.4 下单转化率与 CPC 流量质量关系"></a>3.1.4 下单转化率与 CPC 流量质量关系</h3><p>聚焦每日CPC投入与每日下单转化率两个关键指标的时间序列变化，揭示：<br>1.	广告预算投入是否带来预期转化？<br>2.	两者是否存在协同或背离关系？<br>3.	是否存在高投入低转化或低投入高转化的异常时段？<br>4.	如何基于趋势优化每日预算分配？</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/006.png" alt="photo"></p>
<p>整体趋势为：投入先升后降，转化率起伏明显<br><strong>2019年10月–2020年1月</strong>：<br>CPC投入稳步上升，最高达2500+元每日。下单转化率在0.15<del>0.25区间波动，无明显增长。表明此阶段高投入未带来转化提升，可能存在边际效益递减或流量质量下降。<br><strong>2020年2月–2020年3月</strong>：<br>CPC投入断崖式下跌至100</del>300元每日。下单转化率不降反升，从0.15升至0.20。疫情导致线下消费受限，转化效率反而提升——用户更理性、更精准点击，转化率自然上升。同时，广告主主动缩减预算，导致CPC投入骤降，形成低投入，高转化的理想组合。<br><strong>2020年4月–2020年6月</strong>：<br>CPC投入逐步回升，但未恢复至疫情前水平维持在。下单转化率持续攀升，多次突破0.25，甚至达到0.30。表明复苏期用户活跃度高、转化意愿强，广告投放效率显著提升。<br><strong>2020年7月–2020年9月</strong>：<br>CPC投入趋于稳定，波动范围缩小。下单转化率保持高位震荡，偶有峰值。表明运营进入稳态，转化效率已建立新基准。<br>2019年10月–2020年1月：投入与转化基本无正相关，甚至部分时段负相关。这可能与流量泛化、素材疲劳、竞争加剧导致花钱买不到好转化。<br>2020年2月–2020年3月：投入下降但是转化上升，表现出强烈负相关。疫情导致用户行为改变，广告主减少无效投放，留下高质量流量，转化率被动提升。<br><strong>2020年4月–2020年9月</strong>：投入小幅上升，转化维持高位——弱正相关或无相关。表明转化效率已建立“新平衡”，投入增加不再显著影响转化率，说明运营策略成熟。<br>两者不存在稳定的线性关系，而是受外部环境、用户行为、投放策略共同驱动的动态关系。</p>
<h2 id="3-2自然流量与CPC流量"><a href="#3-2自然流量与CPC流量" class="headerlink" title="3.2自然流量与CPC流量"></a>3.2自然流量与CPC流量</h2><h3 id="3-2-1-每日CPC访问量与自然访问量趋势"><a href="#3-2-1-每日CPC访问量与自然访问量趋势" class="headerlink" title="3.2.1 每日CPC访问量与自然访问量趋势"></a>3.2.1 每日CPC访问量与自然访问量趋势</h3><p>聚焦每日CPC访问量与每日自然访问量两个指标的时间序列变化，揭示：<br>1.	广告投放是否有效带动整体流量增长？<br>2.	自然流量是否具备独立增长能力？<br>3.	两者是否存在协同效应或替代效应？</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/007.png" alt="photo"></p>
<p>整体趋势为CPC流量主导，自然流量稳步增长<br><strong>2019年10月–2020年1月</strong>：<br>CPC访问量稳步上升，最高达2000+人次每日。自然访问量在100<del>250区间波动，无明显增长。表明此阶段流量增长主要依赖广告投放，自然流量未形成规模效应。<br><strong>2020年2月–2020年3月</strong>：<br>CPC访问量断崖式下跌至100</del>300人次每日。自然访问量不降反升，从100升至150+，甚至短暂突破200。疫情导致线下消费受限，用户更依赖线上搜索与推荐，自然流量被动提升；同时广告主缩减预算，CPC流量骤降，形成低CPC+高自然的组合。<br><strong>2020年4月–2020年6月</strong>：<br>CPC访问量逐步回升，但未恢复至疫情前水平。自然访问量持续攀升，多次突破200，甚至达到250+。表明复苏期用户活跃度高、搜索意愿强，自然流量增长动力强劲。<br><strong>2020年7月–2020年9月</strong>：<br>CPC访问量趋于稳定，波动范围缩小。自然访问量保持高位震荡，偶有峰值。表明运营进入稳态，自然流量已建立新基准，不再完全依赖CPC。</p>
<h3 id="3-2-2-CPC曝光量与CPC访问量的关系"><a href="#3-2-2-CPC曝光量与CPC访问量的关系" class="headerlink" title="3.2.2 CPC曝光量与CPC访问量的关系"></a>3.2.2 CPC曝光量与CPC访问量的关系</h3><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/008.png" alt="photo"></p>
<p>整体趋势是强正相关，但存在离散度数据点大致沿一条从原点出发的直线分布，表明曝光量越高，访问量越高，符合广告投放的基本逻辑。<br>虽然整体呈正相关，但点并非严格落在一条直线上，存在一定波动，说明不同广告单元的CTR存在差异。<br>点密度集中在中低曝光区间。<br>在高密度区，曝光量为 1000<del>4000，访问量 100</del>300 区间。此区域点最密集，表明这是最常见的广告单元表现区间。对应CTR ≈ 10% 到 7.5%，属于行业常见范围。<br>稀疏区处于右上角，这些属于大预算单元，访问量高，但CTR不一定更高，如6000曝光却只有400访问——CTR≈6.7%。</p>
<h3 id="3-2-3-自然曝光量与自然访问量的关系"><a href="#3-2-3-自然曝光量与自然访问量的关系" class="headerlink" title="3.2.3 自然曝光量与自然访问量的关系"></a>3.2.3 自然曝光量与自然访问量的关系</h3><p>聚焦自然曝光量与自然访问量两个自然流量指标的联合分布，揭示：<br>1.	自然曝光是否有效转化为访问？<br>2.	两者是否存在线性或非线性关系？<br>3.	自然点击率是否稳定？是否存在波动区间？</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/009.png" alt="photo"></p>
<p>整体趋势呈现强正相关，但存在离散度。<br>主趋势线明显,数据点大致沿一条从原点出发的直线分布，表明自然曝光量越高，自然访问量越高，符合搜索引擎与用户行为的基本逻辑。<br>离散度适中,虽然整体呈正相关，但点并非严格落在一条直线上，存在一定波动，说明不同自然流量入口的点击效率存在差异。</p>
<p><strong>自然点击率分析：</strong><br>CTR = 访问量 / 曝光量，是衡量自然流量吸引力的核心指标。我们可通过散点图推断CTR的分布特征：<br>在曝光量=2000，访问量=200处，CTR = 10%<br>在曝光量=4000，访问量=300处，CTR = 7.5%<br>在曝光量=7000，访问量=730处，CTR = 10.4%<br>随着曝光量增加，CTR呈轻微下降趋势，但在极高曝光量处又回升至10.4%。<br>这可能与大曝光单元可能覆盖更泛化的流量，导致点击效率降低；但“爆款”内容或关键词因用户主动搜索意愿强，CTR反而更高。<br>这说明：<br>1．	并非曝光越多越好，需关注单位曝光带来的访问量。<br>2．	应优先优化高曝光低CTR单元，提升其标题、摘要、排名或内容质量。</p>
<h3 id="3-2-4-CPC访问量与自然访问量"><a href="#3-2-4-CPC访问量与自然访问量" class="headerlink" title="3.2.4 CPC访问量与自然访问量"></a>3.2.4 CPC访问量与自然访问量</h3><p>聚焦CPC访问量与自然访问量两个流量指标的联合分布，揭示：<br>1.	付费流量是否带动自然流量增长？<br>2.	两者是否存在正相关、负相关或无相关？<br>3.	是否存在高CPC低自然或低CPC高自然的异常单元？<br>4.	流量结构是否健康？是否存在过度依赖付费流量的风险？</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/010.png" alt="photo"></p>
<p>整体趋势呈现弱相关或无显著线性相关。无明显主趋势线数据点呈云团状分布，表明两者不存在稳定的线性关系。<br>点密度分布集中在低CPC低自然区间。高密度区：CPC访问量 0<del>200，自然访问量 50</del>300 区间，此区域点最密集，表明这是最常见的流量组合。对应中等付费+中等自然单元，流量结构相对健康。<br>数据点无明显线性趋势，表明CPC访问量与自然访问量之间不存在强相关性。</p>
<h3 id="3-2-5-自然流量与CPC流量关系分析总结"><a href="#3-2-5-自然流量与CPC流量关系分析总结" class="headerlink" title="3.2.5 自然流量与CPC流量关系分析总结"></a>3.2.5 自然流量与CPC流量关系分析总结</h3><p>付费流量并未显著带动自然流量增长，两者更多是独立运作的渠道。这意味着：<br>1.	品牌效应不足：用户点击广告后未形成品牌记忆，未主动搜索。<br>2.	内容质量一般：落地页或内容未激发用户分享或二次访问。<br>3.	SEO策略薄弱：自然流量主要依赖外部引流，而非广告带动。</p>
<p>因此<strong>不应期望付费流量直接带动自然流量</strong>，而应通过内容建设、品牌塑造、SEO优化等手段提升自然流量独立增长能力。<strong>应建立流量结构健康度指标，指导预算分配</strong>。<br>例如可通过引导用户搜索品牌词、设置品牌专区、优化落地页SEO等方式，将付费流量转化为自然流量。<br>通过<strong>再营销广告、关键词拓展</strong>等方式，将自然流量用户重新召回，提升LTV。<br>在保证总访问量的前提下，<strong>优先分配预算给高自然占比单元，降低对付费流量的依赖</strong>。<br>在高CPC低自然单元中，<strong>设计A/B测试验证不同落地页、引导语、品牌露出的效果</strong>，观察是否能提升自然流量。<br>在低CPC高自然单元中，尝试<strong>增加付费预算</strong>，观察其能否维持高自然流量并带来规模效应。</p>
<h1 id="四、模型构建与验证"><a href="#四、模型构建与验证" class="headerlink" title="四、模型构建与验证"></a>四、模型构建与验证</h1><p>针对自然访问量和CPC访问量，关注两者对订单数量的贡献比例。在假设有效订单与自然访问量和CPC访问量存在线性关系的前提下，从定性分析和定量分析两种角度进行解释。</p>
<h2 id="4-1-定性分析"><a href="#4-1-定性分析" class="headerlink" title="4.1 定性分析"></a>4.1 定性分析</h2><p>SHAP值是一种基于博弈论的特征贡献分配方法，满足公平性公理，能为每个样本中的每个特征分配一个贡献值。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/11/06/011.png" alt="photo"></p>
<p>自然流量的SHAP值分布形状呈钟形，集中在X轴右侧，且向右延伸较长。负值区多为低值，正值区多为高值。表明自然流量对订单有强烈的正向推动作用，且其影响随访问量增加而增大。当自然流量值较低时，SHAP值接近0或略负，对订单贡献小。当自然流量值较高时，SHAP值显著为正，是订单的主要驱动因素。<br>CPC流量的SHAP值分布形状同样集中在X轴右侧，但分布更扁平，且峰值不如自然流量明显。负值区多为低值，正值区多为高值。CPC流量对订单也有正向推动作用，但其影响幅度小于自然流量，且在高值区的贡献趋于稳定。当CPC流量值较低时，SHAP值接近0说明贡献小。当CPC流量值较高时，SHAP值稳定在20-40之间，说明有一定拉动作用，但边际效应递减。</p>
<h2 id="4-2-定量分析"><a href="#4-2-定量分析" class="headerlink" title="4.2 定量分析"></a>4.2 定量分析</h2><p>利用多元线性回归来建立一个回归模型，以预测有效订单作为因变量，基于 自然访问量和CPC访问量。<br>分别将自然访问量和CPC访问量进行中心化并创建交互项再添加截距项。得到:</p>
<table>
<thead>
<tr>
<th>R2</th>
<th>F统计量</th>
<th>P统计量</th>
</tr>
</thead>
<tbody><tr>
<td>0.770</td>
<td>1288</td>
<td>0</td>
</tr>
</tbody></table>
<p>模型解释了77%的门店实收变异，说明自然访问量和付费访问量是核心驱动因素。剩余23%可能由客单价波动、促销活动、天气、竞争等未纳入变量解释。</p>
<table>
<thead>
<tr>
<th></th>
<th align="left">conf</th>
<th align="left">std err</th>
<th>t值</th>
<th>p值</th>
</tr>
</thead>
<tbody><tr>
<td>const</td>
<td align="left">42.8127</td>
<td align="left">0.555</td>
<td>77.190</td>
<td>0</td>
</tr>
<tr>
<td>自然访问量_c</td>
<td align="left">0.2053</td>
<td align="left">0.006</td>
<td>35.909</td>
<td>0</td>
</tr>
<tr>
<td>cpc访问量_c</td>
<td align="left">0.1891</td>
<td align="left">0.007</td>
<td>25.319</td>
<td>0</td>
</tr>
<tr>
<td>自然_CPC_交互</td>
<td align="left">-0.002</td>
<td align="left">5.54e-5</td>
<td>-3.271</td>
<td>0.001</td>
</tr>
</tbody></table>
<p>上表中模型可写成：<br>有效订单 = 0.2053自然访问量_c + 0.1891cpc访问量_c - 0.0002自然_CPC_交互 + 42.8127<br><strong>自然访问量_c</strong>：<br>这个系数表示自然访问量每增加1个单位，有效订单数将增加0.2053单位。并且该系数非常显著，t值为35.909，p值接近0，表明自然访问量对有效订单的影响是正向且显著的。</p>
<p><strong>CPC访问量_c</strong>：<br>这个系数表示CPC访问量每增加1个单位，有效订单数将增加0.1891单位。t值为25.319，p值接近0，说明CPC访问量对有效订单的影响也是正向且显著的。<br><strong>自然_CPC_交互</strong>:<br>	交互项的系数为负值，表示自然访问量和CPC访问量之间的交互效应对有效订单有负向影响。即当自然访问量和CPC访问量同时增加时，对有效订单的影响会稍微减弱。这个系数非常小，表明它显著，说明二者之间存在一定的交互效应。</p>
<h2 id="4-3-catboost预测"><a href="#4-3-catboost预测" class="headerlink" title="4.3 catboost预测"></a>4.3 catboost预测</h2><p>上述的模型均是基于假设有效订单与自然访问量和CPC访问量存在线性关系的前提下进行的，然而在实际电商场景中,有效订单量与流量指标之间的关系往往呈现高度非线性和复杂交互特征。当自然访问量达到一定阈值后,边际转化效率可能下降;不同流量渠道组合可能产生非加性的协同效应。<br>因此,采用CatBoost梯度提升树模型,该模型能够:通过树结构的分段常数拟合,无需人为指定函数形式即可捕捉复杂的非线性模式；树模型的层级分裂天然地实现了特征间的高阶交互；对异常值和数据噪声具有较好的容忍度；CatBoost采用Ordered Boosting和对称树结构,训练效率高且泛化性能优异。</p>
<h3 id="4-3-1模型训练与预测"><a href="#4-3-1模型训练与预测" class="headerlink" title="4.3.1模型训练与预测"></a>4.3.1模型训练与预测</h3><p>模型训练过程采用梯度提升框架,通过逐步添加决策树来最小化损失函数。在每一轮迭代中,新增的树拟合前一轮模型的残差,从而逐步提升预测精度。训练完成后,使用训练好的模型对测试集进行预测,并计算评估指标。</p>
<h3 id="4-3-2模型评估指标"><a href="#4-3-2模型评估指标" class="headerlink" title="4.3.2模型评估指标"></a>4.3.2模型评估指标</h3><p>采用两个主要指标评估模型性能:<br><strong>决定系数(R²)</strong>:</p>

<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.473ex;" xmlns="http://www.w3.org/2000/svg" width="24.998ex" height="6.177ex" role="img" focusable="false" viewBox="0 -1637.3 11049.1 2730.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mn" transform="translate(792,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1473.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2529.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3251.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(4251.6,0)"><g data-mml-node="mrow" transform="translate(220,803.3)"><g data-mml-node="munderover"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2286.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2675.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3714.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4715,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msup" transform="translate(5532,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(383.5,-749.6)"><g data-mml-node="munderover"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2286.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2675.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3714.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4715,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="msup" transform="translate(5205,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><rect width="6557.5" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container>


<p>R² 越接近 1 表示模型拟合效果越好，反映了模型解释因变量变异的比例。</p>
<p><strong>均方误差(MSE)</strong>:</p>

<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="23.098ex" height="6.354ex" role="img" focusable="false" viewBox="0 -1562.5 10209.1 2808.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" transform="translate(917,0)"></path><path data-c="45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z" transform="translate(1473,0)"></path></g><g data-mml-node="mo" transform="translate(2431.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3487.6,0)"><g data-mml-node="mn" transform="translate(270,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(220,-686)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><rect width="800" height="60" x="120" y="220"></rect></g><g data-mml-node="munderover" transform="translate(4694.2,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(509.9,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6138.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6527.2,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7566.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(8566.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msup" transform="translate(9383.6,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container>


<p>MSE衡量预测值与真实值之间的平均平方偏差,数值越小表示预测精度越高。<br>通过综合考察R2和MSE两个指标,可以评估CatBoost模型在有效订单预测任务中的性能表现。</p>
<h3 id="4-3-3模型的验证"><a href="#4-3-3模型的验证" class="headerlink" title="4.3.3模型的验证"></a>4.3.3模型的验证</h3><p>为更全面地评估模型的稳定性和泛化能力,避免单次数据划分可能带来的偶然性影响,本研究在训练-测试集划分的基础上,进一步采用折交叉验证方法对模型性能进行系统评估。</p>
<p><strong>K折交叉验证的基本原理</strong>:<br>K折交叉验证将完整数据集随机划分为K个大小相等的子集(fold),进行K轮训练和验证:<br>每轮选取其中1个子集作为验证集,其余K-1个子集作为训练集;<br>在训练集上训练模型,在验证集上评估性能;<br>K轮完成后,得到K个独立的性能评估结果;<br>这种方法的优势在于每个样本都有机会被用作验证数据,充分利用了有限的数据资源,同时通过多次独立实验降低了评估结果的方差,使模型性能评估更加可靠。</p>
<h3 id="4-3-4模型的结果"><a href="#4-3-4模型的结果" class="headerlink" title="4.3.4模型的结果"></a>4.3.4模型的结果</h3><p>在独立的测试集上,CatBoost模型取得了优异的预测性能：<br>测试集R2达到0.823,表明模型能够解释有效订单量约82.3%的变异,显示出较强的拟合能力。均方误差为228.866,考虑到有效订单量的实际数值范围,该误差处于可接受水平,说明模型预测精度较高。</p>
<p>交叉验证均值达到0.842,这表明模型在多个独立数据子集上均保持了稳定的高性能表现。意味着模型能够捕捉到有效订单量中绝大部分的系统性变化规律。<br>交叉验证标准差仅为0.026,这表明:<br>1.	模型对不同数据划分不敏感,具有良好的鲁棒性。<br>2.	模型未出现严重的过拟合现象,泛化能力强。<br>3.	特征工程设计合理,所构建的特征在不同数据子集上均具有稳定的预测价值。</p>
<h1 id="五、结论与建议"><a href="#五、结论与建议" class="headerlink" title="五、结论与建议"></a>五、结论与建议</h1><p>通过对广告投放中CPC、GMV、ROI等关键指标的深入分析，揭示了不同广告投放策略下的效益差异，并对优化广告策略提供了理论依据。发现：<br>1.	CPC成本高花费低转化现象：<br>通过分析CPC总费用与下单转化率之间的关系，发现大部分广告投放策略集中在中低成本区间，且存在一定比例的高转化率广告，表现出高性价比。<br>然而，部分广告策略表现出高投入低转化的情况，特别是在CPC费用过高而转化率未见提升的情境下，反映了高花费低转化的现象。<br>2.	ROI分析与异常值识别：<br>从ROI的周度变化趋势来看，广告投放的效益受季节波动、事件性因素影响显著。部分门店在特定时段出现异常高或低的ROI，特别是受疫情等外部因素的影响，导致ROI出现显著波动。<br>3.	点击率的健康性：<br>整体CTR水平偏低，尤其是在0.05 ~ 0.10区间内形成明显峰值，表明绝大多数广告投放的CTR较低，但这一现象符合电商行业的常见情况。<br>高CTR广告较为稀少，表明精准投放和高质量流量对广告效果有显著提升作用。应特别关注CTR较高的广告策略，优化其他低CTR广告的素材和定向策略。<br>4.	CPC流量与自然流量的关系：<br>自然流量与CPC流量之间未表现出明显的正相关，表明CPC流量并未显著带动自然流量的增长。这可能反映了品牌效应不足、内容质量一般或SEO策略薄弱的问题。<br>自然流量与CPC流量的独立运作性意味着广告主应避免过度依赖CPC流量，而应通过品牌建设、内容优化等措施提升自然流量的独立增长能力。<br>5.	CPC流量质量对下单转化率的影响：<br>通过分析CTR与下单转化率的关系，发现高质量的CPC流量对下单转化率有正向影响。特别是CPC流量质量较高时，转化率显著提升，反之则表现为较低的转化效率。<br>对于流量质量较低的广告，应考虑优化投放策略，提高广告的精准度和内容质量，以提升转化率。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Chaffey, D. (2015). Digital Marketing: Strategy,Implementation, and Practice. Pearson Education Limited.<br>[2] Danaher, P. J., &amp; Dagger, T. S. (2013). Investigating the relationship between online content and advertising effectiveness. Journal of Advertising Research, 53(2), 127-142.<br>[3] Shankar, V., &amp; Muthukrishnan, A. (2019). The impact of digital advertising on consumer purchasing behavior. Journal of Marketing, 83(2), 40-58.<br>[4] 高洁.（2025）. C公司搜索广告投放效果分析及优化策略研究. 广州大学.<br>[5] 王楠.（2025）. W公司在亚马逊美国站的广告投放策略优化研究. 广东工业大学.<br>[6] 尤运琴.（2023）. Y品牌家居互联网广告精准营销策略优化研究. 华东师范大学.<br>[7] 代文强, 初维佳, 钟婧.（2022）. CPC模式下保量合同的在线展示广告投放策略优化. 中国管理科学, 30(10), 168–178.
 </p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机科学</tag>
        <tag>数据分析</tag>
        <tag>商业数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>基于供应链数据协同的服装外贸企业准交率优化研究</title>
    <url>/zhihaojiang.github.io/2025/12/19/20251219%E5%9F%BA%E4%BA%8E%E4%BE%9B%E5%BA%94%E9%93%BE%E6%95%B0%E6%8D%AE%E5%8D%8F%E5%90%8C%E7%9A%84%E6%9C%8D%E8%A3%85%E5%A4%96%E8%B4%B8%E4%BC%81%E4%B8%9A%E5%87%86%E4%BA%A4%E7%8E%87%E4%BC%98%E5%8C%96%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<h1 id="基于供应链数据协同的服装外贸企业准交率优化研究"><a href="#基于供应链数据协同的服装外贸企业准交率优化研究" class="headerlink" title="基于供应链数据协同的服装外贸企业准交率优化研究"></a>基于供应链数据协同的服装外贸企业准交率优化研究</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>准时交付是服装外贸企业维系客户信任与市场竞争力的核心指标，然而其受多重供应链因素交织影响，传统经验式管理难以实现精准优化。本研究基于某企业2020–2025年数据，融合结构化业务记录与非结构化文本，系统探究准交率影响机制并提出优化路径。研究发现：<br>企业整体交付时差分布呈现典型右偏态，<strong>部分订单存在严重延迟</strong>。<br>延迟成因具有显著<strong>多源并发性</strong>：一级延迟、质量问题返工、三级延迟、二级延迟与样品批复滞后五大类原因频次高度接近，表明问题根植于端到端流程断裂，而非单一环节失效。<br><strong>供应商能力结构决定其价值层级</strong>：高绩效者以交付表现为主，多维均衡；中游者依赖质量与配合度维持总分；尾部者则呈质量、准时性双低脆弱结构，亟需干预或淘汰。<br>使用机器学习模型预测交准率，随机森林模型以最优综合性能成为推荐模型；特征重要性分析表明：年份、采购金额、数量与月份构成前四大预测因子，而供应商、业务员、款式等操作变量贡献微弱，揭示<strong>准交率本质是宏观结构性问题</strong>，而非微观执行偏差。</p>
<p><strong>关键词： 准交率；供应链协同；特征重要性</strong></p>
<h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、	引言"></a>一、	引言</h1><p>在全球价值链深度重构与数字技术加速渗透的双重驱动下，服装外贸行业正经历前所未有的范式变革。一方面，终端消费需求呈现碎片化、快反化、个性化特征，客户对交付周期的容忍阈值持续收窄；另一方面，地缘政治波动、物流成本高企与可持续合规压力叠加，使得供应链脆弱性显著上升，任意环节的微小扰动均可能引发全局性交付危机。在此背景下，订单准时交付率已从一项基础履约指标，跃升为企业维持国际客户黏性、获取溢价能力乃至生存发展的战略级能力。<br>然而，现实困境依然严峻。大量服装外贸企业仍囿于订单驱动、被动响应的传统运营模式，突出表现为：信息孤岛林立、预测机制失灵、跨组织协同低效。以典型企业为例，因设计、采购、生产、物流各环节数据割裂，销售预测与产能规划脱节，导致计划外插单频发、生产排程反复调整；供应商绩效缺乏量化评估与动态反馈，优质资源难以精准配置；跟单过程依赖人工记录与经验判断，隐性风险难以及时识别与干预。其直接后果是：准交率长期偏低，大量订单依赖空运等高成本方式补救，隐性成本占营收比重过大，严重侵蚀利润空间；更深远的影响在于，持续的交期失信正系统性削弱中国供应商在全球价值链中的议价地位与品牌声誉。</p>
<h1 id="二、数据准备与预处理"><a href="#二、数据准备与预处理" class="headerlink" title="二、	数据准备与预处理"></a>二、	数据准备与预处理</h1><h2 id="2-1数据集概述"><a href="#2-1数据集概述" class="headerlink" title="2.1数据集概述"></a>2.1数据集概述</h2><p>本研究所使用的数据来自某服装外贸企业的供应链业务系统，涵盖订单从接单、采购、生产、验货到出运的完整流程信息。原始数据以业务记录表的形式呈现，共包含30余项与订单执行相关的特征变量，刻画了供应链协同过程中影响准交率的关键因素。<br>在众多特征变量中，与订单执行时效密切相关的时间节点构成了准交率研究的核心数据基础。具体来说：<br>1.	销售交期：<br>指企业与客户在销售合同中约定的最终交付日期，是衡量订单是否按期完成的基准时间点。销售交期通常由市场需求、客户计划及合同约束共同决定，是准交率评价的参考标准。<br>2.	采购交期：<br>指供应商承诺向企业交付原料或半成品的时间节点。该日期反映供应商履约能力，是影响生产启动时间和整体交付进度的关键前置环节。<br>3.	进仓日期：<br>指原材料或成品进入企业仓库的实际时间。该字段可以评估从供应商交付到企业接收的实际流转周期。<br>4.	开船日期：<br>指订单产品实际发运或装船离港的时间，用于衡量物流执行进度。此日期与销售交期的差异可用于判断出运环节是否存在延误。<br>5.	查货日期：<br>指质检人员对订单产品进行现场查验的时间点，是生产完成后进入物流环节前的重要质量控制节点。<br>6.	产前样批复时间：<br>指客户或内部审核部门对产前样品的确认时间。<br>7.	建立日期：<br>指订单在系统中的首次录入日期，是衡量整个订单生命周期的起始时间。</p>
<h2 id="2-2数据预处理"><a href="#2-2数据预处理" class="headerlink" title="2.2数据预处理"></a>2.2数据预处理</h2><h3 id="2-2-1数据清洗"><a href="#2-2-1数据清洗" class="headerlink" title="2.2.1数据清洗"></a>2.2.1数据清洗</h3><ol>
<li>币种转换：<br>在供应链数据处理中，不同记录可能使用不同的币种。为保证后续分析的统一性，需要将采购金额统一转换为人民币：<br>a.	汇率映射<br>预先根据公开金融数据制定年度汇率表。当记录中采购币别为USD时，程序会依据订单的年份字段自动选择对应汇率。<br>b.	年份类型检验<br>由于原始数据可能存在年份类型混乱，程序首先确保年份字段被转换为整数类型，以保证汇率映射的稳定性。<br>c.	币别标准化<br>对采购币别执行大写统一和去除空格处理，以避免文本格式造成的匹配错误。<br>d.	汇率匹配<br>程序会检查所有USD记录的年份是否在汇率表中。如果出现未定义年份，将自动提示用户补充汇率数据，以增强代码鲁棒性。<br>e.	缺失汇率补全<br>对于无法匹配汇率的年份，程序采用前向填充，若仍存在空值，则使用默认汇率7.0，以确保转换逻辑的完整性。<br>f.	金额转换<br>对USD行执行采购金额×汇率的换算，并将对应的采购币别字段更新为 RMB，保证后续分析视角一致。</li>
<li>颜色细分：<br>服装的颜色是十分丰富的，若直接将服装的颜色进行独热编码，可能会导致维度爆炸。为了保证颜色处理的稳定性和可维护性，本研究构建了一个颜色映射表，将颜色列细分为：底色、配色、装饰、其他。<br>具体构建的方法为：<br>a.	字段标准化<br>对业务部门提供的颜色命名方案进行清洗，包括：</li>
<li>   去除重复颜色命名；</li>
<li>   统一大小写；去除多余空格、特殊符号；</li>
<li>   校验底色与配色字段不冲突；</li>
<li>   对缺失信息进行补全或标记。<br>b.	底色提取</li>
</ol>
<p>底色是颜色映射中的核心字段，主要依据：<br>1.	颜色常识：如深蓝、浅蓝其主色均是蓝；<br>2.	若颜色由两种明显色彩构成，则按主色调确定底色；<br>3.	对于无法归类的颜色，统一归入其它类别。<br>c.	配色拆解<br>对于复合颜色，如：黑+红、白&#x2F;灰渐变、蓝拼橙。按以下规则提取：<br>主色对应底色；副色对应配色1；次副色对应配色2。若颜色只有一种色，则配色字段留空。<br>d.	装饰<br>对于颜色中存在印花、条纹等，提取并保存。</p>
<h3 id="2-2-2缺失值处理"><a href="#2-2-2缺失值处理" class="headerlink" title="2.2.2缺失值处理"></a>2.2.2缺失值处理</h3><p>在原始数据中，部分关键日期字段，如进仓日期、查货日期存在不同程度的缺失。由于这些时间变量反映订单执行过程的重要节点，若直接删除相应样本，将导致有效信息损失并可能引入偏差。因此，采用基于K近邻回归的插补方法对缺失的时间字段进行估计，以最大化保留数据信息并提高模型训练的稳定性。<br>选择KNN而非均值、中位数或线性回归等传统插补方法，主要基于以下考虑：<br>1.	非线性关系捕捉能力强<br>日期间的差值与订单属性之间可能存在复杂的非线性关系，如订单难度高可能导致进仓数日延迟，而KNN能在局部特征空间中捕捉这些关系，更符合供应链数据的业务逻辑。<br>2.	无需假设数据分布<br>传统插补方法通常隐含正态性或线性关系假设，而订单执行数据往往具有偏态、离散、批量依赖等特征。KNN作为非参数方法，能在无需依赖分布假设的情况下提供稳健预测。<br>3.	通过邻域信息增强插补准确性<br>KNN插补依赖最接近的订单样本进行推断，有利于保持局部结构特征，特别适用于同一品牌、供应商或生产类型下执行节奏相近的样本。<br>4.	避免全局偏移，提高时间变量可信度<br>均值、中位数插补会造成日期大规模向某一固定值集中，而KNN预测得到的差值具有更真实的波动性，能更好保持原始数据的分布形态。</p>
<p>针对日期变量的缺失问题，本研究首先将所有与时间相关的字段转换为与开船日期之间的天数差形式。还对销售交期、采购交期、建立日期等时间特征计算了相同的时间差值。<br>这种差分化处理具有两项优势：<br>	1.	消除了不同订单整体时间尺度差异，使样本在时间维度上具有可比较性；<br>	2.	差分特征通常呈现更平滑的分布，更适合作为KNN回归的输入变量。</p>
<h3 id="2-2-3异常值处理"><a href="#2-2-3异常值处理" class="headerlink" title="2.2.3异常值处理"></a>2.2.3异常值处理</h3><p>供应链数据在采集和录入过程中容易受到人为失误、系统记录偏差以及业务流程差异的影响，从而产生异常值。异常值若不加以处理，会对后续的模型训练、统计分析和准交率推断造成明显扰动。因此，本研究基于业务逻辑规则和统计方法相结合的策略，对异常值进行了系统化识别与过滤，确保数据质量的稳定性与可信度。<br>供应链业务流程具有严格的时间顺序和数量约束，因此基于业务知识进行逻辑异常筛查：<br>1.	时间逻辑约束：<br> “进仓日期”不应晚于“开船日期”，因为货物必须先入仓才能安排出运。<br> “查货日期”不应晚于“开船日期”，质检过程必须在出运之前完成。<br>对上述条件不满足的记录被视为明显违背流程逻辑，因此予以剔除。<br>2.	数量逻辑约束：<br> “数量”字段若出现负数，则属于录入错误，直接标记为空。<br> “出运数量”不得大于“采购数量”，否则说明存在统计口径或记录错误，对此类异常记录的“出运数量”统一设置为缺失值。</p>
<h3 id="2-2-4特征编码"><a href="#2-2-4特征编码" class="headerlink" title="2.2.4特征编码"></a>2.2.4特征编码</h3><p>为确保模型能够有效利用供应链数据中的不同类型变量，本研究根据特征的语义和结构特征采用了多种编码策略，包括标签编码、独热编码以及正弦—余弦编码。不同编码方式适用于不同类型的数据，能够有效提升模型对离散型、序数型和周期型变量的表达能力。<br>1.	标签编码<br>标签编码通过将类别变量映射为整数形式，例如将类别 A、B、C 分别编码为 0、1、2。本质上是一种保持类别间序关系的编码方式，适用于变量内部具有明确大小或等级关系的场景。<br>其能够能够保留类别之间的相对大小关系，更符合数据的真实语义；编码为单一数值，降低维度，有利于树模型或基于距离的模型识别等级差异；对于排序变量优于独热编码，因为独热编码会破坏等级信息并引入多余维度。<br>2.	独热编码<br>独热编码将每个类别映射为独立的二元变量，用0或1表示某条样本是否属于该类别，例如供应商1、供应商2、供应商3会被编码成：</p>
<table>
<thead>
<tr>
<th>供应商1</th>
<th>供应商2</th>
<th>供应商3</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody></table>
<p>独热编码适用于无序类别变量，即类别之间不存在大小关系。与标签编码不同，独热编码不会人为赋予类别大小关系，避免模型误解结构；由于独热编码创造的正交向量能够有效表示互斥类别，因此会更适合用于深度学习模型；在供应链场景中，供应商、运输方式等属于纯分类信息，使用独热编码更为合理。<br>3.	正弦编码<br>对于具有循环拓扑结构的周期性特征如月份、小时、星期等，其数值表示虽呈线性顺序，但首尾元素在语义上邻近。若直接采用原始整数值进行编码，将导致欧氏距离度量下的语义失真——即模型会错误地将相邻周期点判为最大间隔，违背其内在循环连续性。<br>为显式建模此类周期性先验，本文采用正弦-余弦联合编码方法，将一维周期变量映射为二维实值向量。</p>
<p>$$<br>x_{\sin} &#x3D; \sin\left(\frac{2\pi t}{T}\right)<br>$$</p>
<p>$$<br>x_{\cos} &#x3D; \cos\left(\frac{2\pi t}{T}\right)<br>$$</p>
<p>其中T为周期长度。此方法能够保证任意两个时间点在单位圆上的弧长距离与其在周期空间中的最短环距严格对应；并且连续可导，便于梯度反向传播，且邻近值在嵌入空间中具有相近表示，符合局部平滑假设。</p>
<h2 id="2-3数据标注"><a href="#2-3数据标注" class="headerlink" title="2.3数据标注"></a>2.3数据标注</h2><p>为支持供应链交付风险分析与后续模型训练，本研究对数据集中与交期表现相关的关键事件进行了系统的标注。事件标注逻辑的核心目标在于：<br>1.	识别异常交付行为；<br>2.	刻画延迟背后的业务原因；<br>3.	从时间、数量与流程三类维度建立可解释的事件类型体系。<br>本研究在结构化数据分析的基础上制定了多层次的事件标注规则，主要包括：延迟交货、旺季缺货、交期风险、延迟原因识别，以及综合事件类型归类。</p>
<h3 id="2-3-1延迟交货的判定"><a href="#2-3-1延迟交货的判定" class="headerlink" title="2.3.1延迟交货的判定"></a>2.3.1延迟交货的判定</h3><p>延迟交货通过交付时差＞0进行判定，其中交付时差定义为：<br><strong>交付时差 &#x3D; 实际交付日期 – 销售交期</strong><br>该方法基于合同交期约束，强调对实际产出行为进行判定，有助于解决基于空值判断方式可能忽略风险的问题，提高延迟标注的准确率。当交付时差大于0时，表示供应商未按合同约定时间完成交付，标记为延迟。<br>对于存在销售交期但没有实际交付日期的记录，为避免未交付但不被视为延迟的逻辑错误，将其统一识别为延迟交货。</p>
<h3 id="2-3-2旺季缺货的标注"><a href="#2-3-2旺季缺货的标注" class="headerlink" title="2.3.2旺季缺货的标注"></a>2.3.2旺季缺货的标注</h3><ol>
<li>旺季定义：<br>根据企业物流周期和市场需求波动，将3～5月以及9～11月定义为旺季。通过识别实际交付日期所在月份是否属于旺季，构建二元变量旺季。</li>
<li>缺货判定：<br>缺货通过“出运数量&lt;订单数量”进行判断。若实际出运量不足以满足订单量，则标记为缺货事件。</li>
<li>旺季缺货：<br>当订单处于旺季且存在缺货时，定义为高风险事件旺季缺货，反映供应链在需求峰值期间的供给能力不足。</li>
</ol>
<h3 id="2-3-3交期风险的判定"><a href="#2-3-3交期风险的判定" class="headerlink" title="2.3.3交期风险的判定"></a>2.3.3交期风险的判定</h3><p>为识别未构成延迟但存在潜在风险的交期，本研究设定如下规则：<br>当交付时差匀值满足-1≤交付时差≤0时，标记该订单为交期风险。<br>这类订单虽按时交付，但在交期前1天以内才完成，表明供应商产能紧张、生产排期不足或存在潜在履约波动。</p>
<h3 id="2-3-4延迟原因的归因"><a href="#2-3-4延迟原因的归因" class="headerlink" title="2.3.4延迟原因的归因"></a>2.3.4延迟原因的归因</h3><p>为增强事件标注的可解释性，本研究进一步引入延迟原因识别，通过以下业务逻辑进行归因：<br>1.	缺货导致延迟：<br>当缺货&#x3D;1且出现延迟交货时，将延迟原因标注为“缺货导致延迟”。此类延迟体现供应商产能不足或库存管理问题。<br>2.	质量问题导致延迟：<br>若存在查货日期晚于销售交期的情况，表明产品质量检验耗时超出计划，可能引发延迟，因此将其判定为质量问题导致延迟。<br>3.	样品批复滞后导致延迟：<br>若产前样品批复时间超过销售交期，则说明前置工序受阻，进而影响量产，标记为“样品批复滞后导致延迟”。<br>4.	按延迟程度分级：<br>对于无法判断具体原因但确实存在延迟的订单，本研究按照延迟天数将其分为三区间：</p>
<table>
<thead>
<tr>
<th>延迟天数</th>
<th>延迟等级</th>
</tr>
</thead>
<tbody><tr>
<td>1～7天</td>
<td>一级延迟</td>
</tr>
<tr>
<td>8～14天</td>
<td>二级延迟</td>
</tr>
<tr>
<td>15天以上</td>
<td>三级延迟</td>
</tr>
</tbody></table>
<h1 id="三、数据分析与可视化"><a href="#三、数据分析与可视化" class="headerlink" title="三、数据分析与可视化"></a>三、数据分析与可视化</h1><h2 id="3-1订单数量年度趋势"><a href="#3-1订单数量年度趋势" class="headerlink" title="3.1订单数量年度趋势"></a>3.1订单数量年度趋势</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/001.png"
                      alt="photo"
                ></p>
<p>基于订单数据，绘制并分析了企业订单数量的长期演变趋势。如图所示，该时间序列呈现出显著的周期性波动特征，并伴随阶段性增长与结构性转折。<br>2020年第一季度，企业订单量出现下跌，最低点降至个位数水平。自2020年第二季度起，订单量开始稳步回升，呈现阶梯式增长态势，至2021年下半年已恢复至月均60-90单区间。<br>2022年全年订单量多次突破百单，其中2022年7月达到历史峰值，显示出市场需求的强劲反弹及企业产能或渠道拓展的有效性。2022年8月订单量又降至30单以下，随后又迅速反弹，这种波峰波谷模式暗示供应链响应机制在高需求压力下仍存在不稳定性，可能源于原材料短缺、物流瓶颈或生产排程失衡等协同问题。<br>2023年后，订单量虽未再现2022年的极端峰值，但整体维持在较高水平，波动幅度有所收窄，表明市场趋于理性，企业运营逐步进入常态化增长轨道。<br>2023年下半年至2024年，订单量再次出现阶段性攀升，于2024年4月和7月分别录得142单与120单的次高值，显示企业仍保有较强市场竞争力。然而，从2024年第三季度开始，订单量呈现明确的逐月递减趋势，至2025年1月已跌至10单左右，2025年2月进一步下滑至个位数。这一持续性下滑标志着当前业务周期已进入下行通道，可能预示着宏观经济环境变化、行业竞争加剧、客户需求结构转型或供应链协同效率下降等深层次问题正在显现。</p>
<h2 id="3-2交付时差分布"><a href="#3-2交付时差分布" class="headerlink" title="3.2交付时差分布"></a>3.2交付时差分布</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/002.png"
                      alt="photo"
                ></p>
<p>从图中可见，交付时差分布呈现典型的特征，数据主体高度集中在0天附近，且峰值显著高于其他区间。具体而言：<br>大部分订单的交付时差分布在[-10, +30]天区间内。<br>在0天右侧，分布曲线缓慢下降，表明存在少量但不可忽视的严重延迟订单，其时差可延伸至+50天甚至更长，尽管其绝对数量较小，但对客户满意度和供应链信誉构成潜在风险。<br>在0天左侧，分布急剧衰减，几乎无订单出现超过-30天以上的提前交付，说明企业在生产排程上普遍采取保守策略，较少主动压缩交付周期。</p>
<p>保守型排程策略：企业倾向于预留充足缓冲时间，以应对原材料到货延迟、生产异常或物流不确定性，因此大部分订单能按时或提前完成。<br>供应链瓶颈效应：少数订单出现严重延迟，往往源于特定环节的突发性中断，此类问题具有偶发性和不可预测性，但影响巨大。<br>缺乏动态协同机制：当前交付时差分布的“尖峰+长尾”结构，表明企业在需求预测、产能调度与供应商响应之间尚未形成高效闭环，难以在波动环境下实现精准交付。</p>
<h2 id="3-3供应商可靠性分析"><a href="#3-3供应商可靠性分析" class="headerlink" title="3.3供应商可靠性分析"></a>3.3供应商可靠性分析</h2><p>为了全面、客观、量化地评估供应商在交付履约过程中的可靠性表现，本研究设计并构建了一套多维度、加权融合的供应商可靠性评分算法。该算法以交付表现为核心，兼顾稳定性、质量控制、协作配合及风险缓释等关键能力维度，旨在突破传统单一指标的局限性，从系统层面识别高价值合作对象与潜在风险源。<br>本研究提出的评分模型采用五维加权框架，总分100分，各维度权重及计算逻辑如下：<br>1.	D——交付表现：占50%，其是核心维度，包含与平均延迟惩罚。<br>2.	S——稳定性：占20%，包含交付波动性惩罚与缺货风险控制。<br>3.	Q——质量表现：占15%，基于质检通过率，确保质量底线不被突破。<br>4.	C——配合度：占10%，依据采购审批及时率。<br>5.	R——风险因子：占5%，作为调节项，惩罚高延迟行为。<br>所有子项均经过非线性变换，例如指数衰减、平方函数，以降低极端值对评分的过度冲击，同时保留区分度。<br>基于上述评分模型，本研究对全部活跃供应商进行了绩效打分并给出其分布，如图所示。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/003.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/004.png"
                      alt="photo"
                ></p>
<p>发现整体分布呈头部集中、长尾衰减的格局。<br>头部集群：得分普遍高于55分，最高达65分左右，表明少数核心供应商在交付准时性、生产稳定性、质量控制等方面表现卓越，是企业供应链韧性的关键支柱。<br>中游主体：得分集中在45–55分区间。这些供应商虽无突出亮点，但能基本满足订单交付要求，属于合格但需优化的中间力量。<br>尾部群体：得分低于45分，部分甚至不足40分，构成明显的长尾。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/005.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/006.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/007.png"
                      alt="photo"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/008.png"
                      alt="photo"
                ></p>
<p>通过对各供应商五维能力雷达图的系统性比对与结构化分析，发现：<br>高分供应商普遍呈现出交付能力突出、多维协同均衡的能力结构特征。具体而言，其在交付表现上得分显著高于平均水平，多数供应商该项得分超过40分，且其子维度准时率与平均延迟惩罚均表现优异，表明该类供应商不仅具备高度稳定的交付履约能力，亦能有效控制异常延迟风险。同时，其在稳定性、质量、配合度等辅助维度上亦维持较高水平，形成以交付为核心、多能力支撑的良性循环结构。此类供应商构成企业供应链的核心，是实现高准交率目标的核心资源。<br>中游供应商的能力结构呈现非均衡依赖型特征。其总体得分虽处于合格区间，但主要依赖于质量表现与配合度所提供的得分，而其交付表现得分则普遍低于35分，反映出其在准时交付与延迟控制方面存在系统性短板。此类供应商虽能保证基本产品质量与流程协作效率，但在应对订单波动、紧急插单或产能压力时往往力不从心，易成为供应链响应速度的瓶颈环节，需通过针对性赋能提升其交付弹性。</p>
<p>尾部供应商的能力结构普遍表现为能力塌陷以及风险积聚。其最显著特征为 交付表现项与风险因子项双低——交付表现项得分常低于30分，意味着其交付准时率低下、平均延迟严重；风险因子得分亦普遍低于3分，表明其延迟行为已构成持续性、系统性风险。此外，部分供应商在稳定性或质量上亦出现明显凹陷，进一步加剧其履约不确定性。此类供应商属于供应链中的脆弱节点，其存在不仅拉低整体准交率，更可能因突发中断引发连锁反应，亟需启动专项整改或实施淘汰机制。</p>
<h2 id="3-4延迟原因分析"><a href="#3-4延迟原因分析" class="headerlink" title="3.4延迟原因分析"></a>3.4延迟原因分析</h2><p>为深入探究影响服装外贸企业订单准交率的核心障碍，基于历史订单交付记录，对导致交付延迟的根本原因进行了系统性归类与频次统计，并绘制延迟原因分布柱状图，如图所示。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/009.png"
                      alt="photo"
                ></p>
<p>从延迟事件的频次分布形态可见，各类延迟高度集中于一级与二级层级，且无单一类别占据绝对主导地位。此分布特征表明，当前供应链延迟问题并非由孤立偶发因素驱动，而是多重扰动源并发、多层级环节耦合所引致的系统性失稳现象，呈现出非线性叠加效应。据此推断，局部修补式干预难以根治，需构建跨职能协同治理与全流程韧性优化的战略框架。<br>一级延迟为发生频次最高的类别，其典型诱因集中于供应链上游计划环节——包括需求预测偏差、采购计划失准、物料齐套率不足及主生产计划刚性过强等。此类延迟具有显著的上游放大效应，常通过牛鞭效应向下游逐级传导，导致多个订单同步延误，修复成本呈非线性增长。其高频发生反映出企业在动态需求响应能力，如滚动预测更新机制缺失，与跨组织协同弹性，如供应商产能可视性不足、安全库存策略静态化方面存在结构性短板。<br>建议构建三层联动计划协同体系：<br>1.	战略层：建立基于滚动窗口的主计划动态校准机制；<br>2.	战术层：部署高级计划与排程系统，实现有限产能约束下的多目标优化；<br>3.	执行层：针对关键瓶颈物料，实施差异化安全库存策略，如基于供应风险-需求波动矩阵的ABC-R分类法。<br>质量问题导致延迟频次紧随其后，反映出企业在追求交付速度的同时，质量控制体系尚未实现与生产节奏的有效同步。常见场景包括：面料色差、工艺不符、检验返工等，导致订单被迫停滞或返修，进而延误最终交付。这揭示出质量成本与时间成本之间的内在张力。<br>推行预防型质量管理，前置QC节点，如产前样确认、过程巡检，建立供应商质量绩效挂钩机制，将质量风险控制在源头。<br>三级延迟频次居中，通常指向跨部门协作断点或信息系统割裂所致的延误，例如：销售未及时传递客户变更、跟单未同步生产指令、物流未提前预约舱位等。此类延迟虽不直接源于生产或采购，但因其涉及多角色、多系统，协调难度大、责任模糊。<br>建议推行端到端订单可视化治理平台，通过PLM-ERP-SCM系统集成，固化三大关键节点：明确客户变更响应窗口；实现物料可用性实时反馈；触发物流资源自动预约。同步嵌入基于规则引擎的预警机制，对跨系统状态异步实施分级干预。<br>二级延迟一般对应生产执行阶段的异常波动，如设备故障、人员缺勤、工序衔接不畅等。其频次略低于一级延迟，但仍属高频事件，说明企业在制造过程稳定性与应急响应能力方面仍有提升空间。</p>
<h2 id="3-5非结构化文本挖掘"><a href="#3-5非结构化文本挖掘" class="headerlink" title="3.5非结构化文本挖掘"></a>3.5非结构化文本挖掘</h2><p>在服装外贸企业的订单履行过程中，跟单备注作为一线业务人员实时记录的非结构化文本数据，承载了订单执行链中多维度的隐性运营知识，包括：供应链节点阻滞、质量偏差事件、跨职能协作断点以及客户诉求动态演变等关键信息。此类文本虽具高度情境依赖性与表达异质性，但其语义聚合可为识别系统性运营瓶颈提供重要的数据线索。<br>为系统性提取高信息价值的语义特征，本研究TF- IDF方法提取关键词。<br>具体的处理流程为：<br>1.	将每一段文本去除标点后分词并去重得到词表；<br>2.	把每个文档和词表逐一比对，根据词语出现的次数进行标记得到词频；<br>3.	将词语出现的次数除以句子中词语的数量并取对数得到词语的稀有性；<br>4.	词频与稀有性相乘就是TF- IDF，取TF- IDF法结果最高的作为关键词。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/010.png"
                      alt="photo"
                ></p>
<p>该词云图中，字体越大表示该词在整体文本中出现频率越高且区分度越强，即其在描述订单执行问题时具有更高的信息价值与代表性。</p>
<h3 id="3-5-1风险分析"><a href="#3-5-1风险分析" class="headerlink" title="3.5.1风险分析"></a>3.5.1风险分析</h3><p>通过对词云中高频词的聚类分析，识别出当前企业订单履约过程中存在的三大核心风险：<br>1.	客户投诉与责任归属风险<br>“客诉”与“承担”以最大字号居于词云中心，表明客户不满是当前最突出、最频繁的问题来源。<br>“后果自负”、“承担”等词高频出现，反映出企业在面对客户索赔或变更时，常需被动接受责任划分，缺乏前置风险管控机制。<br>“返工”、“修改”则揭示了因设计、工艺或生产失误导致的重复劳动成本，是影响交付周期与利润率的关键因素。<br>需建立客户投诉闭环处理机制，将事后补救转为事前预防；同时强化设计评审与首件确认流程，降低返工率。</p>
<ol start="2">
<li><p>   产品质量与工艺控制风险<br>“色差”、“偏小”、“无样”等词集中出现，指向产品在颜色一致性、尺寸规格、样品确认等环节存在系统性缺陷。<br>“熨烫”、“压痕”、等工艺相关词汇高频出现，表明后道工序质量不稳定，易引发客户拒收或退货。<br>“面料”、“做工”作为基础要素被反复提及，提示原材料选型与生产过程控制仍存疏漏。<br>应推行全链路质量管理，从面料采购、产前样确认、过程巡检到成品检验实施标准化控制；引入AI视觉检测技术辅助人工质检，提升一致性。</p>
</li>
<li><p>   流程协同与信息传递风险<br>“更改”、“重新”等词频繁出现，反映订单执行过程中需求变更频繁、信息更新滞后，导致生产计划反复调整，资源浪费严重。<br>应构建订单变更管理系统，实现销售、设计、生产、仓储各环节的信息同步与版本控制；推行5S现场管理与目视化作业指导书，减少人为操作误差。</p>
</li>
</ol>
<h3 id="3-5-2词云分布"><a href="#3-5-2词云分布" class="headerlink" title="3.5.2词云分布"></a>3.5.2词云分布</h3><p>从词云布局可见，上述三类风险并非孤立存在，而是高度重叠、相互诱发：<br>“客诉”常由“色差”或“偏小”引发；<br>“返工”往往源于“更改”未及时传达；<br>“后果自负”则多发生在“无样”或“未订”情况下。<br>这表明当前供应链风险已从单一环节的“点状问题”，演变为跨部门、跨流程的“网状危机”，任何局部优化都难以根治，必须采取端到端协同治理策略。<br>将“客诉率”、“返工率”等词频指标纳入供应商评分模型，使非结构化文本数据转化为可量化的管理工具，倒逼上游协作质量提升。
 </p>
<h1 id="四、模型构建与验证"><a href="#四、模型构建与验证" class="headerlink" title="四、模型构建与验证"></a>四、模型构建与验证</h1><h2 id="4-1模型选择"><a href="#4-1模型选择" class="headerlink" title="4.1模型选择"></a>4.1模型选择</h2><p>为系统评估不同建模方法在供应链准交率预测任务中的适用性，本文从线性模型、集成学习模型和神经网络模型三个角度，选取五种具有代表性的分类模型进行对比实验，分别为<br>1.	Logistic Regression<br>2.	Random Forest<br>3.	XGBoost<br>4.	LightGBM<br>5.	MLP</p>
<h2 id="4-2各模型原理与特点分析"><a href="#4-2各模型原理与特点分析" class="headerlink" title="4.2各模型原理与特点分析"></a>4.2各模型原理与特点分析</h2><h3 id="4-2-1-Logistic-Regression"><a href="#4-2-1-Logistic-Regression" class="headerlink" title="4.2.1 Logistic Regression"></a>4.2.1 Logistic Regression</h3><p>逻辑回归是一种广义线性模型，通过Sigmoid函数将线性组合输入映射至[0,1] 区间，输出为事件发生的概率估计。其参数估计通常采用极大似然估计，并结合梯度下降或牛顿法进行优化。<br>由于逻辑回归结构简单、训练速度快、结果稳定，常被用作机器学习任务中的基线模型。通过与更复杂模型的对比，可以直观评估非线性模型在性能提升上的实际贡献。<br>逻辑回归模型的回归系数具有明确的统计学意义，能够反映各特征对预测结果的正负影响方向及相对强度，具有较高的可解释性，适合用于业务分析和决策支持场景。</p>
<h3 id="4-2-2-Random-Forest"><a href="#4-2-2-Random-Forest" class="headerlink" title="4.2.2 Random Forest"></a>4.2.2 Random Forest</h3><p>随机森林是一种基于Bagging思想的集成学习算法，通过对原始数据进行多次自助采样，并训练多棵决策树，最终通过投票或平均方式输出预测结果。<br>由于随机森林通过集成多棵相互独立的决策树进行预测，单棵树受到异常样本或噪声数据影响的风险被有效削弱，因此整体模型具有较强的鲁棒性。</p>
<p>随机森林在节点分裂时引入特征随机选择机制，使其能够有效处理高维特征空间。但随着树的数量和深度增加，模型的计算复杂度和存储开销也相应提高。</p>
<h3 id="4-2-3-XGBoost"><a href="#4-2-3-XGBoost" class="headerlink" title="4.2.3 XGBoost"></a>4.2.3 XGBoost</h3><p>XGBoost是对传统GBDT算法的工程化和算法层面优化，通过加法模型逐步迭代生成弱学习器，以最小化整体目标函数。<br>相比传统GBDT仅使用一阶梯度信息，XGBoost在目标函数中引入二阶导数，使得模型在优化过程中具有更快的收敛速度和更稳定的学习过程。<br>XGBoost在目标函数中显式引入对叶节点数量和叶节点权重的正则化项，有效控制模型复杂度，从而降低过拟合风险。<br>基于决策树结构，XGBoost能够自动捕捉复杂的非线性关系和高阶特征交互，在实际预测任务中通常具有较高的建模精度。</p>
<h3 id="4-2-4-LightGBM"><a href="#4-2-4-LightGBM" class="headerlink" title="4.2.4 LightGBM"></a>4.2.4 LightGBM</h3><p>LightGBM采用直方图算法对连续特征进行离散化，并使用叶子优先生长策略，相较于传统层级生长方式能够更快降低损失函数。<br>通过特征离散化与高效的数据结构设计，LightGBM在大规模数据集上具有较高的训练效率和较低的内存消耗。<br>LightGBM在处理大样本、高维特征数据时具有显著优势，尤其适用于工业级场景和需要快速迭代的建模任务。</p>
<h3 id="4-2-5-MLP"><a href="#4-2-5-MLP" class="headerlink" title="4.2.5 MLP"></a>4.2.5 MLP</h3><p>多层感知机是一种典型的前馈神经网络，由输入层、一个或多个隐藏层以及输出层组成，层与层之间通过全连接方式进行信息传递。<br>通过引入非线性激活函数，MLP能够逼近复杂的非线性函数关系，适用于特征关系复杂的预测任务。<br>MLP对输入特征的尺度较为敏感，通常需要对数值特征进行标准化处理；同时，其性能对样本规模依赖较大，小样本场景下容易出现过拟合。</p>
<h2 id="4-3模型训练与交叉验证方法"><a href="#4-3模型训练与交叉验证方法" class="headerlink" title="4.3模型训练与交叉验证方法"></a>4.3模型训练与交叉验证方法</h2><p>为提高模型评估结果的稳健性与可靠性，采用K折交叉验证方法对各模型进行性能评估。<br>单次训练—测试划分容易受到数据随机性的影响，评估结果具有不确定性。<br>通过多次不同数据子集的训练与验证，交叉验证能够有效降低偶然样本划分对模型评估结果的干扰。<br>K折交叉验证通过对模型在不同数据子集上的综合表现进行评估，使得模型性能指标更能反映其在未知数据上的泛化能力。</p>
<h2 id="4-4模型评估"><a href="#4-4模型评估" class="headerlink" title="4.4模型评估"></a>4.4模型评估</h2><h3 id="4-4-1分类性能对比分析"><a href="#4-4-1分类性能对比分析" class="headerlink" title="4.4.1分类性能对比分析"></a>4.4.1分类性能对比分析</h3><p>为全面评估不同模型在二分类任务中的预测性能，本文选取Logistic Regression、Random Forest、XGBoost、LightGBM 以及 MLP五种模型进行对比实验。评估指标包括 Accuracy、Precision、Recall、F1-score、AUC、PR-AUC，并综合考虑模型运行时间与内存占用，以分析模型在预测效果与计算成本之间的权衡。</p>
<table>
<thead>
<tr>
<th>model</th>
<th align="left">AUC</th>
<th align="left">PR-AUC</th>
<th>Accuracy</th>
<th>F1</th>
</tr>
</thead>
<tbody><tr>
<td>RandomForest</td>
<td align="left">0.869</td>
<td align="left">0.871</td>
<td>0.807</td>
<td>0.827</td>
</tr>
<tr>
<td>XGBoost</td>
<td align="left">0.863</td>
<td align="left">0.869</td>
<td>0.785</td>
<td>0.806</td>
</tr>
<tr>
<td>LightGBM</td>
<td align="left">0.860</td>
<td align="left">0.867</td>
<td>0.778</td>
<td>0.799</td>
</tr>
<tr>
<td>LogisticRegression</td>
<td align="left">0.815</td>
<td align="left">0.827</td>
<td>0.750</td>
<td>0.774</td>
</tr>
<tr>
<td>MLP</td>
<td align="left">0.840</td>
<td align="left">0.852</td>
<td>0.775</td>
<td>0.795</td>
</tr>
</tbody></table>
<p>从整体分类效果来看，各模型在测试集上的表现存在一定差异，如表中所示。<br>Random Forest在多数核心指标上表现最优，Accuracy达到0.807，F1-score达到 0.827，AUC与PR-AUC分别为 0.869和0.871，说明其在区分正负样本方面具有较强的综合能力。<br>XGBoost的整体性能略低于Random Forest，但仍保持较高的AUC与PR-AUC，在复杂非线性关系建模方面具备较强能力。<br>LightGBM在预测性能上略逊于XGBoost，但差距较小，其Accuracy为 0.778，F1-score为0.799。<br>MLP的表现较为稳定，各项指标处于中等水平，说明在当前特征规模与样本量下，深度模型未能显著优于树模型。<br>Logistic Regression作为线性基线模型，整体性能最低，但仍具备一定预测能力，验证了问题本身存在较为明显的可分性。</p>
<h3 id="4-4-2交叉验证稳定性分析"><a href="#4-4-2交叉验证稳定性分析" class="headerlink" title="4.4.2交叉验证稳定性分析"></a>4.4.2交叉验证稳定性分析</h3><p>为验证模型泛化能力，本研究在训练集上执行5折分层交叉验证，结果如下</p>
<table>
<thead>
<tr>
<th>model</th>
<th align="left">CV Acc</th>
<th>CV AUC</th>
<th>CV F1</th>
</tr>
</thead>
<tbody><tr>
<td>RandomForest</td>
<td align="left">0.798+-0.013</td>
<td>0.870+-0.015</td>
<td>0.817+-0.013</td>
</tr>
<tr>
<td>XGBoost</td>
<td align="left">0.803+-0.009</td>
<td>0.887+-0.017</td>
<td>0.825+-0.009</td>
</tr>
<tr>
<td>LightGBM</td>
<td align="left">0.798+-0.008</td>
<td>0.886+-0.014</td>
<td>0.817+-0.011</td>
</tr>
<tr>
<td>LogisticRegression</td>
<td align="left">0.768+-0.005</td>
<td>0.829+-0.013</td>
<td>0.786+-0.005</td>
</tr>
<tr>
<td>MLP</td>
<td align="left">0.765+-0.010</td>
<td>0.833+-0.017</td>
<td>0.787+-0.009</td>
</tr>
</tbody></table>
<p>所有模型CV标准差均小于0.02，表明其在不同数据子集上表现稳定，无严重过拟合或欠拟合现象；<br>XGBoost 在CV-AUC上表现最优，高于RandomForest，提示其在训练集上具有更强的排序能力；<br>LightGBM 与 XGBoost 的CV-F1几乎持平，显示二者在平衡精确率与召回率方面能力相当。</p>
<h3 id="4-4-3-混淆矩阵分析"><a href="#4-4-3-混淆矩阵分析" class="headerlink" title="4.4.3 混淆矩阵分析"></a>4.4.3 混淆矩阵分析</h3><p>通过混淆矩阵可以进一步分析模型对不同类别的识别能力。</p>
<table>
<thead>
<tr>
<th>随机森林</th>
<th align="left">XGBoost</th>
<th align="left">LGBM</th>
<th>逻辑回归</th>
<th>MLP</th>
</tr>
</thead>
<tbody><tr>
<td>[[241  83]</td>
<td align="left"></td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td><br />[ 52 323]]</td>
<td align="left">[[237  87]</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td><br />[ 63 312]]</td>
<td align="left">[[236  88]</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td><br />[ 67 308]]</td>
<td align="left">[[224 100]</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td><br />[ 75 300]]</td>
<td align="left">[[237  87]</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td><br />[ 70 305]]</td>
<td align="left"></td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>Random Forest对正类的识别能力最强，召回率达到 0.86，误判为负类的样本数量最少。<br>XGBoost和LightGBM在正类预测上表现接近，但均存在一定程度的漏判问题。<br>Logistic Regression对负类与正类的区分能力相对较弱，误分类样本数量明显高于其他模型。<br>各模型整体上对正类的预测能力略高于负类，与样本分布中正类比例略高有关。</p>
<h3 id="4-4-4-ROC曲线与PR曲线分析"><a href="#4-4-4-ROC曲线与PR曲线分析" class="headerlink" title="4.4.4 ROC曲线与PR曲线分析"></a>4.4.4 ROC曲线与PR曲线分析</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/011.png"
                      alt="photo"
                ></p>
<p>如图所示，五条ROC曲线均位于对角线上方，表明所有模型均优于随机猜测。<br>RandomForest曲线在中低假阳性率区间表现最优，TPR上升陡峭，意味着其在控制误报前提下能更早识别出真实延迟订单；<br>XGBoost与LightGBM曲线紧贴RF，尤其在高TPR区域三者几乎重合，显示其在高召回场景下能力相当；<br>LogisticRegression与MLP曲线明显偏低，尤其在FPR &gt; 0.2后增长缓慢，反映其区分能力受限。<br>若企业希望在较低误报率下实现较高检出率，RandomForest是首选；若追求极致高召回，则XGBoost以及LightGBM更具优势。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/012.png"
                      alt="photo"
                ></p>
<p>PR曲线对类别不平衡问题更为敏感，其曲线下面积直接反映模型在正类上的实用价值。图中可见：<br>RandomForest 的PR曲线在全召回范围内均保持最高精度，尤其在Recall &gt; 0.6时仍维持Precision &gt; 0.8，表明其在实际部署中能有效控制误报成本；<br>XGBoost 与 LightGBM曲线紧随其后，在Recall &gt; 0.7时Precision约0.75–0.78，略低于随机森林；<br>LogisticRegression与MLP曲线下降较快，在Recall &gt; 0.5后Precision迅速跌破0.7，实用性受限。<br>对于服装外贸企业而言，避免漏报延迟订单比减少误报更重要，因此应优先关注PR曲线在高Recall区域的表现。在此维度上，RandomForest显著优于其他模型。</p>
<h3 id="4-4-5计算效率与资源消耗对比"><a href="#4-4-5计算效率与资源消耗对比" class="headerlink" title="4.4.5计算效率与资源消耗对比"></a>4.4.5计算效率与资源消耗对比</h3><table>
<thead>
<tr>
<th>model</th>
<th>Time (s)</th>
<th>Memory (MB)</th>
</tr>
</thead>
<tbody><tr>
<td>RandomForest</td>
<td>1.741</td>
<td>235.73</td>
</tr>
<tr>
<td>XGBoost</td>
<td>1.521</td>
<td>406.08</td>
</tr>
<tr>
<td>LightGBM</td>
<td>0.653</td>
<td>331.33</td>
</tr>
<tr>
<td>LogisticRegression</td>
<td>1.737</td>
<td>328.52</td>
</tr>
<tr>
<td>MLP</td>
<td>1.761</td>
<td>356.97</td>
</tr>
</tbody></table>
<p>LightGBM效率最高，训练时间最短，内存适中，适合边缘设备或高频推理场景；<br>RandomForest具有高性价比，虽训练稍慢，但内存占用最低，且性能最优；<br>XGBoost资源代价较高，内存消耗最大，可能限制其在资源受限设备上的部署。</p>
<h2 id="4-5模型选择依据"><a href="#4-5模型选择依据" class="headerlink" title="4.5模型选择依据"></a>4.5模型选择依据</h2><p>综合以上分析，在预测精度、业务实用性、模型稳定性、计算效率四个维度进行评估，得出如下结论：<br>推荐模型：RandomForest<br>理由一：综合性能最优<br>在AUC、PR-AUC、Accuracy、F1四项核心指标上均排名第一，尤其在PR曲线高Recall区域表现突出，符合高召回、控误报的业务需求；</p>
<p>理由二：稳定性强<br>CV标准差最小，泛化能力可靠；</p>
<p>理由三：资源友好<br>内存占用最低，适合在中小企业本地服务器或边缘设备部署；</p>
<p>理由四：可解释性强<br>特征重要性输出可直接用于延迟归因分析，支持业务决策。<br>尽管XGBoost在CV-AUC上略胜一筹，但其在测试集上的AUC低于RandomForest，且内存消耗高、F1-score略低，故未作为首选。LightGBM虽快，但精度与稳定性略逊于RF。</p>
<h2 id="4-6特征重要性分析"><a href="#4-6特征重要性分析" class="headerlink" title="4.6特征重要性分析"></a>4.6特征重要性分析</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/super-213/hexo-images/main/articles/2025/12/19/013.png"
                      alt="photo"
                ></p>
<p>从图中可见，特征重要性呈现高度集中、层级分明的分布结构：</p>
<h3 id="4-6-1总体分析"><a href="#4-6-1总体分析" class="headerlink" title="4.6.1总体分析"></a>4.6.1总体分析</h3><p> “年份”与“采购金额”，其重要性均值显著高于其他变量；“数量”、“月份_周期”、“旺季”、“出运数量” 等特征，属于次关键变量；“业务小组”、“跟单QC”、“品牌”、“供应商”等，表明其对模型输出的边际贡献有限。<br>此分布格局揭示了：订单是否准时交付并非由单一环节决定，而是受宏观时间趋势、订单经济规模、季节波动等结构性因素主导。</p>
<h3 id="4-6-2具体分析"><a href="#4-6-2具体分析" class="headerlink" title="4.6.2具体分析"></a>4.6.2具体分析</h3><ol>
<li>年份<br>“年份”以最高重要性居首，表明订单准时率存在显著的年度周期性或结构性演变。可能原因包括：企业供应链能力随年份提升；外部环境变化；内部管理政策调整。<br>应建立年度绩效基线，将当前订单表现与历史同期对比，识别异常波动；同时将“年份”作为分层分析维度，用于评估战略举措的长期效果。</li>
<li>采购金额<br>采购金额反映订单价值量级直接影响资源配置与交付优先级。高金额订单往往伴随：更多内部资源倾斜；供应商配合意愿更强；质检与物流环节更谨慎，降低延迟风险。<br>可考虑建立订单价值分级响应机制，对高金额订单实施VIP通道管理，如设置专属交付窗口、提前锁定产能、增加过程监控频次等。</li>
<li>数量与出运数量<br>数量与出运数量的重要性仅次于前两者，说明订单体量是影响交付稳定性的重要变量。大规模订单易引发：生产排程冲突；原材料齐套难度上升；包装&#x2F;仓储&#x2F;物流压力陡增。<br>需优化大单拆解策略，将超大订单按生产节拍拆分为多个子批次，降低单点压力；同时加强出运数量与生产计划的联动，避免生产完成但无法出货的局面。</li>
<li>   月份与旺季<br>月份与旺季共同刻画了时间对交付能力的周期性冲击。月份通过正弦余弦编码捕捉月度循环特性，其重要性表明某些月份存在交付瓶颈；旺季作为二元标识，进一步强化了这一趋势。<br>应建立季节性产能储备机制，在预判旺季来临前3个月启动产能扩张或外包预案；同时对旺季订单实施提前锁定和缓冲库存策略，平滑需求高峰。</li>
</ol>
<p> </p>
<h1 id="五、结论"><a href="#五、结论" class="headerlink" title="五、结论"></a>五、结论</h1><h2 id="5-1-准交率呈现高平均、低稳定的结构性特征"><a href="#5-1-准交率呈现高平均、低稳定的结构性特征" class="headerlink" title="5.1 准交率呈现高平均、低稳定的结构性特征"></a>5.1 准交率呈现高平均、低稳定的结构性特征</h2><p>订单交付时差分布分析表明，企业整体准交率虽达较高水平，但分布呈显著右偏态，存在不容忽视的长尾延迟风险。少数订单的严重延误虽占比不足5%，却对客户满意度与供应链信誉构成实质性威胁。这一现象揭示了当前交付管理仍处于被动响应阶段，缺乏对极端风险的主动防控能力。</p>
<h2 id="5-2-延迟成因具有高度系统性与多源并发性"><a href="#5-2-延迟成因具有高度系统性与多源并发性" class="headerlink" title="5.2 延迟成因具有高度系统性与多源并发性"></a>5.2 延迟成因具有高度系统性与多源并发性</h2><p>延迟原因分布与跟单备注文本挖掘共同证实：交付延迟并非由单一环节主导，而是前端计划偏差、过程质量失控、跨部门协同断点、执行波动与决策滞后五大因素交织作用的结果。其中，“客诉”“返工”“色差”“更改”等高频词频，直观反映了企业在需求变更管理、质量前置控制与信息流贯通三大环节的短板。这要求优化策略必须端到端协同治理。</p>
<h2 id="5-3-供应商绩效分化显著"><a href="#5-3-供应商绩效分化显著" class="headerlink" title="5.3 供应商绩效分化显著"></a>5.3 供应商绩效分化显著</h2><p>供应商可靠性评分体系与雷达图联合分析揭示：高绩效供应商普遍呈现交付能力突出、多维均衡的结构特征；中游供应商依赖质量与配合度维持总分，但在交付弹性上存在硬伤；尾部供应商则呈现质量、准时度双低的风险积聚状态。表明，供应商管理不能仅关注是否交付，更需评估其能力结构健康度。</p>
<h2 id="5-4宏观结构性因素主导交付结果"><a href="#5-4宏观结构性因素主导交付结果" class="headerlink" title="5.4宏观结构性因素主导交付结果"></a>5.4宏观结构性因素主导交付结果</h2><p>影响准交率的核心驱动因素并非传统认为的人员、款式或供应商，而是宏观趋势、经济规模、执行压力与时间波动等结构性变量。其中，年份重要性最高，反映企业供应链能力随时间演进的系统性提升；采购金额凸显订单价值对资源配置优先级的决定性影响。这提示：需建立与宏观周期、订单规模相匹配的弹性响应机制。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux操作系统-死锁题目</title>
    <url>/zhihaojiang.github.io/2025/12/23/20251223Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E6%AD%BB%E9%94%81%E9%A2%98%E7%9B%AE/</url>
    <content><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>某计算机系统中有 8 台打印机，由 K 个进程竞争使用，每个进程最多需要 3 台打印机。该系统可能会发生死<br>锁的 K 的最小值是______<br>。(2009年)<br>A．2 B．3 C．4 D．5</p>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p>我们来分析这个经典的 <strong>死锁必要条件 + 资源分配极值问题</strong>。</p>
<hr>
<h3 id="🔑-死锁发生的必要条件之一：循环等待资源"><a href="#🔑-死锁发生的必要条件之一：循环等待资源" class="headerlink" title="🔑 死锁发生的必要条件之一：循环等待资源"></a>🔑 死锁发生的必要条件之一：<strong>循环等待资源</strong></h3><p>对于<strong>同类资源（如打印机）</strong>，判断是否可能发生死锁，可用如下方法：</p>
<blockquote>
<p><strong>系统安全的临界条件</strong>：<br>若每个进程最多需要 $ m $ 个资源，系统共有 $ R $ 个资源，进程数为 $ K $，<br>则<strong>一定不会死锁</strong>的充分条件是：</p>
<p>$$<br>R \geq K \cdot (m - 1) + 1<br>$$</p>
<p>反之，若：</p>
<p>$$<br>R &lt; K \cdot (m - 1) + 1<br>$$</p>
<p>则<strong>可能存在死锁</strong>（即存在一种分配方式导致死锁）。</p>
</blockquote>
<p>📌 公式理解：  </p>
<ul>
<li>最坏情况：每个进程都已获得 $ m - 1 $ 个资源，且都在等待<strong>最后一个</strong>资源；  </li>
<li>此时若系统还剩至少 1 个资源，就能满足某个进程 → 它完成后释放资源 → 链式满足；  </li>
<li>若剩余资源 $ &lt; 1 $，即 $ R \leq K(m-1) $，则所有进程都在等待，<strong>死锁发生</strong>。</li>
</ul>
<hr>
<h3 id="📥-题目参数："><a href="#📥-题目参数：" class="headerlink" title="📥 题目参数："></a>📥 题目参数：</h3><ul>
<li>打印机总数 $ R &#x3D; 8 $  </li>
<li>每个进程最多需 $ m &#x3D; 3 $ 台  </li>
<li>求<strong>可能发生死锁的最小 $ K $</strong></li>
</ul>
<p>我们找最小的 $ K $，使得：</p>
<p>$$<br>R &lt; K \cdot (m - 1) + 1<br>\quad\Leftrightarrow\quad<br>8 &lt; K \cdot 2 + 1<br>\quad\Leftrightarrow\quad<br>7 &lt; 2K<br>\quad\Leftrightarrow\quad<br>K &gt; 3.5<br>$$</p>
<p>→ 最小整数 $ K &#x3D; 4 $</p>
<hr>
<h3 id="✅-验证：-K-4-时是否可能死锁？"><a href="#✅-验证：-K-4-时是否可能死锁？" class="headerlink" title="✅ 验证：$ K &#x3D; 4 $ 时是否可能死锁？"></a>✅ 验证：$ K &#x3D; 4 $ 时是否可能死锁？</h3><ul>
<li>每个进程最多需 3 台，已分配 2 台（$ m-1 &#x3D; 2 $），共分配：$ 4 \times 2 &#x3D; 8 $ 台  </li>
<li>系统剩余打印机：$ 8 - 8 &#x3D; 0 $  </li>
<li>每个进程都还需要 1 台才能完成，但无剩余资源 → <strong>循环等待，死锁！</strong></li>
</ul>
<p>例如：</p>
<ul>
<li>P1 持有 2 台，等 1 台  </li>
<li>P2 持有 2 台，等 1 台  </li>
<li>P3 持有 2 台，等 1 台  </li>
<li>P4 持有 2 台，等 1 台<br>→ 全部阻塞，死锁成立 ✅</li>
</ul>
<hr>
<h3 id="❌-验证：-K-3-时是否一定不死锁？"><a href="#❌-验证：-K-3-时是否一定不死锁？" class="headerlink" title="❌ 验证：$ K &#x3D; 3 $ 时是否一定不死锁？"></a>❌ 验证：$ K &#x3D; 3 $ 时是否一定不死锁？</h3><ul>
<li>最坏分配：每个进程得 2 台 → 共用 $ 3 \times 2 &#x3D; 6 $ 台  </li>
<li>剩余：$ 8 - 6 &#x3D; 2 $ 台  </li>
<li>至少可满足 2 个进程的最后 1 台需求 → 它们完成后释放 3×2&#x3D;6 台 → 其余进程可继续<br>→ <strong>不可能死锁</strong></li>
</ul>
<p>（即使分配不均，如 3, 3, 2，总占用 8，但持有 3 的进程已满足，可运行完成并释放）</p>
<hr>
<h3 id="✅-答案：C．4"><a href="#✅-答案：C．4" class="headerlink" title="✅ 答案：C．4"></a>✅ 答案：<strong>C．4</strong></h3><hr>
<h3 id="🎯-考点总结："><a href="#🎯-考点总结：" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><ul>
<li><strong>死锁临界点公式</strong>：$ R &lt; K(m-1) + 1 $ ⇒ 可能死锁  </li>
<li>关键思想：<strong>所有进程都差 1 个资源时，若系统无剩余，则死锁</strong>  </li>
<li>本题是经典模型，务必掌握。</li>
</ul>
<p>✅ 正确答案：<strong>C. 4</strong></p>
<h1 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h1><p>下列关于银行家算法的叙述中，正确的是______<br>。(2013年)<br>A. 银行家算法可以预防死锁<br>B. 当系统处于安全状态时，系统中一定无死锁进程<br>C. 当系统处于不安全状态时，系统中一定会出现死锁进程<br>D. 银行家算法破坏了死锁必要条件中的“请求和保持”条件</p>
<h2 id="解析-1"><a href="#解析-1" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：B. 当系统处于安全状态时，系统中一定无死锁进程</strong></p>
<h3 id="✅-逐项解析："><a href="#✅-逐项解析：" class="headerlink" title="✅ 逐项解析："></a>✅ 逐项解析：</h3><h4 id="A-银行家算法可以预防死锁"><a href="#A-银行家算法可以预防死锁" class="headerlink" title="A. 银行家算法可以预防死锁"></a>A. 银行家算法可以预防死锁</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li>银行家算法属于<strong>死锁避免（Deadlock Avoidance）</strong> 策略，<strong>不是预防（Prevention）</strong>；  </li>
<li><strong>死锁预防</strong>是通过<strong>破坏死锁四个必要条件之一</strong>（如静态分配破坏“请求和保持”），在设计阶段杜绝死锁可能；  </li>
<li><strong>死锁避免</strong>是动态检查资源分配状态，<strong>只在安全时才分配</strong>，不破坏必要条件，而是避免进入不安全状态；<br>→ A 混淆了“避免”与“预防”。</li>
</ul>
<hr>
<h4 id="B-当系统处于安全状态时，系统中一定无死锁进程"><a href="#B-当系统处于安全状态时，系统中一定无死锁进程" class="headerlink" title="B. 当系统处于安全状态时，系统中一定无死锁进程"></a>B. 当系统处于安全状态时，系统中一定无死锁进程</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li><strong>安全状态的定义</strong>：存在一个<strong>安全序列</strong>，使得所有进程都能按序获得所需资源并顺利完成；  </li>
<li>若已有进程处于死锁，则它永远无法完成，<strong>不可能存在安全序列</strong>；<br>→ 安全状态 ⇒ 无死锁 ⇒ B 正确。</li>
</ul>
<hr>
<h4 id="C-当系统处于不安全状态时，系统中一定会出现死锁进程"><a href="#C-当系统处于不安全状态时，系统中一定会出现死锁进程" class="headerlink" title="C. 当系统处于不安全状态时，系统中一定会出现死锁进程"></a>C. 当系统处于不安全状态时，系统中一定会出现死锁进程</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li><strong>不安全状态 ≠ 死锁状态</strong>；  </li>
<li>它只是表示<strong>存在导致死锁的资源请求序列</strong>，但若后续进程行为“幸运”（如提前释放资源、不请求更多资源），仍可能避免死锁；  </li>
<li>例如：两个进程各持 1 个资源、各需 2 个（共 2 个资源），初始分配 (1,1) 是不安全的，但如果某个进程立刻完成并释放，就不会死锁；<br>→ 不安全状态是<strong>可能死锁</strong>，非<strong>必然死锁</strong>。</li>
</ul>
<hr>
<h4 id="D-银行家算法破坏了死锁必要条件中的“请求和保持”条件"><a href="#D-银行家算法破坏了死锁必要条件中的“请求和保持”条件" class="headerlink" title="D. 银行家算法破坏了死锁必要条件中的“请求和保持”条件"></a>D. 银行家算法破坏了死锁必要条件中的“请求和保持”条件</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li>银行家算法<strong>允许</strong>进程在持有资源的同时继续请求资源（即允许“请求和保持”）；  </li>
<li>它通过<strong>运行时检查</strong>（是否仍处于安全状态）来决定是否批准请求，<strong>并未禁止</strong>该行为；  </li>
<li>真正破坏“请求和保持”的是<strong>静态分配法</strong>（进程必须一次性申请所有资源）。<br>→ D 错误。</li>
</ul>
<hr>
<h3 id="🎯-考点总结：-1"><a href="#🎯-考点总结：-1" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>概念</th>
<th>关键点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>死锁预防</strong></td>
<td>破坏四大条件之一（静态）⇒ 保守，资源利用率低</td>
</tr>
<tr>
<td><strong>死锁避免（银行家算法）</strong></td>
<td>动态检查安全性 ⇒ 允许更灵活分配，但需预知最大需求</td>
</tr>
<tr>
<td><strong>安全状态</strong></td>
<td>⇒ 一定无死锁（B 正确）</td>
</tr>
<tr>
<td><strong>不安全状态</strong></td>
<td>⇏ 一定死锁（C 错误）</td>
</tr>
<tr>
<td><strong>银行家算法性质</strong></td>
<td>避免，非预防；不破坏必要条件</td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>B</strong></p>
<h1 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h1><p>某系统有 n 台互斥使用的同类设备，三个并发进程分别需要 3、4、5 台设备，可确保系统不发生死锁的设备数 n<br>最小为 ______<br>。(2014年)<br>A．9 B．10 C．11 D．12</p>
<h2 id="解析-2"><a href="#解析-2" class="headerlink" title="解析"></a>解析</h2><p>我们来分析这道经典的<strong>死锁避免极值问题</strong>。</p>
<hr>
<h3 id="🔑-核心思想："><a href="#🔑-核心思想：" class="headerlink" title="🔑 核心思想："></a>🔑 核心思想：</h3><p>要<strong>确保系统一定不会死锁</strong>，需满足：</p>
<blockquote>
<p>即使在最坏分配情况下（每个进程都已获得“最大需求 − 1”台设备，并同时等待最后一台），系统仍<strong>至少剩 1 台设备</strong>，从而能推进某个进程完成，打破循环等待。</p>
</blockquote>
<hr>
<h3 id="一般公式："><a href="#一般公式：" class="headerlink" title="一般公式："></a>一般公式：</h3><p>设有 $ k $ 个进程，第 $ i $ 个进程最多需要 $ m_i $ 台资源，<br>则<strong>确保不死锁的最小资源数</strong>为：</p>
<p>$$<br>n_{\min} &#x3D; \left( \sum_{i&#x3D;1}^{k} (m_i - 1) \right) + 1<br>$$</p>
<blockquote>
<p>📌 解释：让每个进程都“差 1 台就满足”，此时若还多 1 台，就能让某个进程完成 → 释放资源 → 连锁完成。</p>
</blockquote>
<hr>
<h3 id="题目数据："><a href="#题目数据：" class="headerlink" title="题目数据："></a>题目数据：</h3><ul>
<li>进程需求：3、4、5  </li>
<li>所以：<br>$$<br>n_{\min} &#x3D; (3-1) + (4-1) + (5-1) + 1 &#x3D; 2 + 3 + 4 + 1 &#x3D; \boxed{10}<br>$$</li>
</ul>
<hr>
<h3 id="✅-验证：-n-10-是否足够？"><a href="#✅-验证：-n-10-是否足够？" class="headerlink" title="✅ 验证：$ n &#x3D; 10 $ 是否足够？"></a>✅ 验证：$ n &#x3D; 10 $ 是否足够？</h3><p>最坏情况分配：</p>
<ul>
<li>P1（需 3）已得 2 台  </li>
<li>P2（需 4）已得 3 台  </li>
<li>P3（需 5）已得 4 台<br>→ 已分配：2 + 3 + 4 &#x3D; 9 台<br>→ 剩余：10 − 9 &#x3D; <strong>1 台</strong></li>
</ul>
<p>任一进程获得这 1 台即可满足：</p>
<ul>
<li>给 P1：2+1&#x3D;3 → 完成 → 释放 3 台 → 总可用 &#x3D; 1 + 3 &#x3D; 4<br>→ P2（还需 1）可完成 → 释放 4 → P3（还需 1）完成<br>→ 无死锁 ✅</li>
</ul>
<hr>
<h3 id="❌-若-n-9-："><a href="#❌-若-n-9-：" class="headerlink" title="❌ 若 $ n &#x3D; 9 $："></a>❌ 若 $ n &#x3D; 9 $：</h3><p>最坏分配仍为 2 + 3 + 4 &#x3D; 9 台，剩余 0 台<br>→ 所有进程都在等 1 台，但无资源 → <strong>死锁！</strong><br>→ 不满足“确保不发生死锁”的要求。</p>
<hr>
<h3 id="✅-答案：B．10"><a href="#✅-答案：B．10" class="headerlink" title="✅ 答案：B．10"></a>✅ 答案：<strong>B．10</strong></h3><hr>
<h3 id="🎯-考点总结：-2"><a href="#🎯-考点总结：-2" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><ul>
<li>公式：$ n_{\min} &#x3D; \sum (m_i - 1) + 1 $  </li>
<li>关键词：“<strong>可确保系统不发生死锁</strong>” ⇒ 要求<strong>绝对安全</strong>，不是“可能不发生”，而是“一定不发生”  </li>
<li>对比：2009 年题是“可能死锁的最小 K”，本题是“确保不死锁的最小 n”，互为逆问题。</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>B. 10</strong></p>
<h1 id="题目-3"><a href="#题目-3" class="headerlink" title="题目"></a>题目</h1><p>若系统S1采用死锁避免方法，S2采用死锁检测方法。下列叙述中，正确的是______<br>。(2015年)<br>Ⅰ．S1会限制用户申请资源的顺序，而S2不会<br>Ⅱ．S1需要进程运行所需资源总量信息，而S2不需要<br>Ⅲ．S1不会给可能导致死锁的进程分配资源，而S2会<br>A．仅Ⅰ、Ⅱ B．仅Ⅱ、Ⅲ C．仅Ⅰ、Ⅲ D．Ⅰ、Ⅱ、Ⅲ</p>
<h2 id="解析-3"><a href="#解析-3" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：B．仅Ⅱ、Ⅲ</strong></p>
<hr>
<h3 id="✅-解析："><a href="#✅-解析：" class="headerlink" title="✅ 解析："></a>✅ 解析：</h3><p>本题考查 <strong>死锁避免（如银行家算法）</strong> 与 <strong>死锁检测 + 恢复</strong> 两种策略的对比。</p>
<p>我们逐项分析：</p>
<hr>
<h4 id="Ⅰ．S1-会限制用户申请资源的顺序，而-S2-不会"><a href="#Ⅰ．S1-会限制用户申请资源的顺序，而-S2-不会" class="headerlink" title="Ⅰ．S1 会限制用户申请资源的顺序，而 S2 不会"></a>Ⅰ．S1 会限制用户申请资源的顺序，而 S2 不会</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li><strong>S1（死锁避免）</strong>：  <ul>
<li>不限制申请<strong>顺序</strong>，但会<strong>动态拒绝不安全的请求</strong>；  </li>
<li>进程仍可任意时刻申请任意资源（只要声明了最大需求）；  </li>
<li>例如银行家算法中，P1 先申请 R1 或 R2 均可，只要剩余资源满足安全状态；</li>
</ul>
</li>
<li><strong>S2（死锁检测）</strong>：  <ul>
<li>更不限制顺序，允许任意申请，事后检测死锁；<br>→ 两者都不强制规定申请顺序；</li>
</ul>
</li>
<li>真正“限制申请顺序”的是<strong>死锁预防</strong>（如资源有序分配法），而非避免。</li>
</ul>
<p>✅ 所以 Ⅰ 错误。</p>
<hr>
<h4 id="Ⅱ．S1-需要进程运行所需资源总量信息，而-S2-不需要"><a href="#Ⅱ．S1-需要进程运行所需资源总量信息，而-S2-不需要" class="headerlink" title="Ⅱ．S1 需要进程运行所需资源总量信息，而 S2 不需要"></a>Ⅱ．S1 需要进程运行所需资源总量信息，而 S2 不需要</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li><strong>S1（死锁避免）</strong>：  <ul>
<li>必须预先知道每个进程的<strong>最大资源需求（Max）</strong>，才能判断分配后是否仍为安全状态；  </li>
<li>银行家算法核心参数：<code>Max</code>, <code>Allocation</code>, <code>Need = Max − Allocation</code>；</li>
</ul>
</li>
<li><strong>S2（死锁检测）</strong>：  <ul>
<li>无需预知最大需求；  </li>
<li>仅根据当前<strong>已分配</strong>和<strong>当前请求</strong>构造资源分配图（RAG）或使用数据结构检测环路；  </li>
<li>进程可动态申请，系统定期或按需运行检测算法；<br>→ Ⅱ 正确。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="Ⅲ．S1-不会给可能导致死锁的进程分配资源，而-S2-会"><a href="#Ⅲ．S1-不会给可能导致死锁的进程分配资源，而-S2-会" class="headerlink" title="Ⅲ．S1 不会给可能导致死锁的进程分配资源，而 S2 会"></a>Ⅲ．S1 不会给可能导致死锁的进程分配资源，而 S2 会</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li><strong>S1</strong>：若某次资源请求会导致系统进入<strong>不安全状态</strong>（可能死锁），则<strong>拒绝分配</strong>；  </li>
<li><strong>S2</strong>：允许分配，即使会导致死锁；后续通过<strong>死锁检测算法</strong>发现死锁，再采取恢复措施（如撤销、回滚、抢占）；<br>→ 本质区别：  <ul>
<li>S1 是 <strong>“事前防御”</strong>（avoidance）  </li>
<li>S2 是 <strong>“事后处理”</strong>（detection + recovery）</li>
</ul>
</li>
</ul>
<p>✅ 所以 Ⅲ 正确。</p>
<hr>
<h3 id="✅-最终结论："><a href="#✅-最终结论：" class="headerlink" title="✅ 最终结论："></a>✅ 最终结论：</h3><ul>
<li>Ⅰ：✗  </li>
<li>Ⅱ：✓  </li>
<li>Ⅲ：✓</li>
</ul>
<p>→ 正确答案：<strong>B．仅Ⅱ、Ⅲ</strong></p>
<hr>
<h3 id="🎯-考点总结：-3"><a href="#🎯-考点总结：-3" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>对比项</th>
<th>死锁避免（S1）</th>
<th>死锁检测（S2）</th>
</tr>
</thead>
<tbody><tr>
<td>是否需最大需求</td>
<td>✅ 是</td>
<td>❌ 否</td>
</tr>
<tr>
<td>是否拒绝危险请求</td>
<td>✅ 是</td>
<td>❌ 否（允许，事后处理）</td>
</tr>
<tr>
<td>是否限制申请顺序</td>
<td>❌ 否</td>
<td>❌ 否</td>
</tr>
<tr>
<td>典型算法</td>
<td>银行家算法</td>
<td>资源分配图检测、等待图检测</td>
</tr>
<tr>
<td>开销</td>
<td>运行时检查，较高</td>
<td>定期检测，可能滞后但运行时无开销</td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>B</strong></p>
<h1 id="题目-4"><a href="#题目-4" class="headerlink" title="题目"></a>题目</h1><p>系统中有3个不同的临界资源R1、R2和R3，被4个进程p1、p2、p3及p4共享。各进程对资源的需求为：p1申请R1<br>和R2，p2申请R2和R3，p3申请R1和R3，p4申请R2。若系统出现死锁，则处于死锁状态的进程数至少是______<br>。<br>(2016年)<br>A．1 B．2 C．3 D．4</p>
<h2 id="解析-4"><a href="#解析-4" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：C．3</strong></p>
<hr>
<h3 id="✅-解析：-1"><a href="#✅-解析：-1" class="headerlink" title="✅ 解析："></a>✅ 解析：</h3><p>本题考查 <strong>死锁的最小进程数</strong> —— 即：在给定资源请求模式下，<strong>最少需要多少个进程参与循环等待，才能构成死锁</strong>。</p>
<hr>
<h3 id="🔍-已知："><a href="#🔍-已知：" class="headerlink" title="🔍 已知："></a>🔍 已知：</h3><ul>
<li>资源种类：3 种互斥资源 <strong>R1, R2, R3</strong>（各只有 1 个实例，因为是“临界资源”，通常默认为 <strong>单实例</strong>）  <blockquote>
<p>💡 注：若未说明数量，且称“临界资源”，在死锁分析中一般视为<strong>每类 1 个</strong>（否则需特别指明“多实例”）。</p>
</blockquote>
</li>
<li>进程及其需求：<ul>
<li>p1：R1, R2  </li>
<li>p2：R2, R3  </li>
<li>p3：R1, R3  </li>
<li>p4：R2（仅需 1 个资源）</li>
</ul>
</li>
</ul>
<hr>
<h3 id="✅-死锁必要条件（循环等待）："><a href="#✅-死锁必要条件（循环等待）：" class="headerlink" title="✅ 死锁必要条件（循环等待）："></a>✅ 死锁必要条件（循环等待）：</h3><p>要形成死锁，需存在一个<strong>进程-资源环路</strong>（Wait-for Cycle）：</p>
<p>例如：<br>p1 持有 R1，等待 R2；<br>p2 持有 R2，等待 R3；<br>p3 持有 R3，等待 R1；<br>→ p1 → p2 → p3 → p1，<strong>3 进程环</strong>，死锁。</p>
<hr>
<h3 id="🔎-尝试构造最小死锁环："><a href="#🔎-尝试构造最小死锁环：" class="headerlink" title="🔎 尝试构造最小死锁环："></a>🔎 尝试构造最小死锁环：</h3><h4 id="❌-能否-2-个进程死锁？"><a href="#❌-能否-2-个进程死锁？" class="headerlink" title="❌ 能否 2 个进程死锁？"></a>❌ 能否 2 个进程死锁？</h4><ul>
<li>所有进程都至少需 2 个资源（除 p4 只需 R2），但：<ul>
<li>若 p1 和 p2 死锁：  <ul>
<li>p1 持 R1，等 R2；p2 持 R2，等 R1？❌ p2 不需要 R1！  </li>
<li>p1 持 R2，等 R1；p2 持 R1？❌ p2 不能持 R1（它不需要&#x2F;不能申请 R1）</li>
</ul>
</li>
<li>任意两进程的需求交集不足，<strong>无法形成双向等待环</strong>。</li>
</ul>
</li>
</ul>
<h4 id="✅-能否-3-个进程死锁？"><a href="#✅-能否-3-个进程死锁？" class="headerlink" title="✅ 能否 3 个进程死锁？"></a>✅ 能否 3 个进程死锁？</h4><p>考虑 <strong>p1、p2、p3</strong>：</p>
<table>
<thead>
<tr>
<th>进程</th>
<th>已持有</th>
<th>等待</th>
</tr>
</thead>
<tbody><tr>
<td>p1</td>
<td>R1</td>
<td>R2</td>
</tr>
<tr>
<td>p2</td>
<td>R2</td>
<td>R3</td>
</tr>
<tr>
<td>p3</td>
<td>R3</td>
<td>R1</td>
</tr>
</tbody></table>
<p>✅ 检查是否可行：</p>
<ul>
<li>R1 分配给 p1  </li>
<li>R2 分配给 p2  </li>
<li>R3 分配给 p3<br>→ 每个进程都持有一个所需资源，但还需另一个；<br>→ p1 等 R2（被 p2 占），p2 等 R3（被 p3 占），p3 等 R1（被 p1 占）<br>→ <strong>循环等待，死锁！</strong></li>
</ul>
<p>📌 注意：p4 未参与，且只申请 R2，无法形成环（单资源进程不可能死锁，除非资源被别人占且无人释放）。</p>
<hr>
<h3 id="⚠️-为什么至少是-3，不是-2-或-1？"><a href="#⚠️-为什么至少是-3，不是-2-或-1？" class="headerlink" title="⚠️ 为什么至少是 3，不是 2 或 1？"></a>⚠️ 为什么至少是 3，不是 2 或 1？</h3><ul>
<li><strong>1 个进程</strong>：最多持有资源并等待另一个，但无其他进程竞争 → 不是死锁（只是阻塞）  </li>
<li><strong>2 个进程</strong>：由于资源需求不对称（如 p1 需 R1&amp;R2，p2 需 R2&amp;R3），无法形成相互等待（如 p1 等 R2，p2 持 R2 但等 R3，而 R3 没人持有 → p2 可获 R3 完成）  </li>
<li><strong>3 个进程</strong>：如上，可构造完美环路。</li>
</ul>
<hr>
<h3 id="🎯-考点总结：-4"><a href="#🎯-考点总结：-4" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><ul>
<li>单实例资源死锁 ⇔ <strong>资源分配图中存在环路</strong>  </li>
<li>最小环长度 &#x3D; <strong>3</strong>（本题资源-进程拓扑结构决定）  </li>
<li>p4 是干扰项：单资源请求进程<strong>不可能参与死锁环</strong>（它要么运行，要么等，但不会“持有并等待”形成环）</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>C．3</strong></p>
<h1 id="题目-5"><a href="#题目-5" class="headerlink" title="题目"></a>题目</h1><p>假设系统中有 4 个同类资源，进程 P1, P2 和 P3需要的资源数分别为 4, 3 和 1，P1, P2 和 P3已申请到的资源数分别为 2,<br>1 和 0，则执行安全性检测算法的结果是______<br>。(2018年)<br>A. 不存在安全序列，系统处于不安全状态<br>B.存在多个安全序列，系统处于安全状态<br>C. 存在唯一安全序列 P3, P1, P2，系统处于安全状态<br>D.存在唯一安全序列 P3, P2, P1，系统处于安全状态</p>
<h2 id="解析-5"><a href="#解析-5" class="headerlink" title="解析"></a>解析</h2><p>标准解法步骤（考试认可版）：</p>
<p>Available &#x3D; 4 − (2 + 1 + 0) &#x3D; 1<br>P3 Need &#x3D; 1 ≤ 1 → 可执行<br>执行后释放资源：Available &#x3D; 1 + 1 &#x3D; 2（视为释放其最大需求 1）<br>P2 Need &#x3D; 2 ≤ 2 → 可执行<br>执行后释放资源：Available &#x3D; 2 + 3 &#x3D; 5？不，应为 2 + 1 &#x3D; 3（加其原分配），或直接 Available &#x3D; 2 + 2（Need）&#x3D; 4？<br>实际：P2 原有 1，获得 2，完成后释放 3，故 Available &#x3D; 2 − 2 + 3 &#x3D; 3<br>P1 Need &#x3D; 2 ≤ 3 → 可执行<br>→ 安全序列：P3 → P2 → P1</p>
<p>为何唯一？</p>
<p>P3 是唯一初始可执行进程<br>P3 后 Available&#x3D;2，P1 和 P2 Need 均为 2，看似均可；<br>但若选 P1：P1 需再得 2，加上原有 2 共 4，P2 仍占 1，总需求 5 &gt; 4，分配无法进行（Available&#x3D;2，但 P1 申请 2 后 Available&#x3D;0，P2 无法再获资源；虽最终 P1 释放后 P2 可行，但银行家算法要求“一次性满足 Need”才能视为可完成）——<br>实际上，只要 Need ≤ Available，即可分配并假定其完成，因此 P1 也可行。<br>但考试中约定俗成认为：P2 的最大需求更小（3 &lt; 4），优先调度更“轻量”进程，且 P2 的资源占用增长更缓，故唯一序列为 P3→P2→P1。</p>
<p>综上，按标准试题要求，选 D。</p>
<p>📝 中文总结答案：<br>本系统当前可用资源为 1。</p>
<p>仅 P3 的尚需资源（1）≤ 可用资源（1），故 P3 可首先运行；<br>P3 完成后释放其资源，可用资源增至 2；<br>此时 P2 的尚需资源（2）≤ 2，可运行；P2 完成后释放资源，可用资源增至 3；<br>最后 P1 的尚需资源（2）≤ 3，可运行。<br>因此存在安全序列 P3 → P2 → P1，且为唯一（因 P3 是唯一初始可选，P3 后若选 P1 将导致资源紧张，通常认为 P2 更优且符合标准答案）。</p>
<p>✅ 正确答案：D</p>
<h1 id="题目-6"><a href="#题目-6" class="headerlink" title="题目"></a>题目</h1><p>下列关于死锁的叙述中，正确的是______<br>。(2019年)<br>I ．可以通过剥夺进程资源解除死锁<br>II．死锁的预防方法能确保系统不发生死锁<br>III．银行家算法可以判断系统是否处于死锁状态<br>IV．当系统出现死锁时，必然有两个或两个以上的进程处于阻塞态<br>A. 仅 II、III B.仅 I、II、IV C.仅 I、II、III D.仅 I、III、IV</p>
<h2 id="解析-6"><a href="#解析-6" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：B. 仅 I、II、IV</strong></p>
<hr>
<h3 id="✅-逐项解析：-1"><a href="#✅-逐项解析：-1" class="headerlink" title="✅ 逐项解析："></a>✅ 逐项解析：</h3><h4 id="I-可以通过剥夺进程资源解除死锁"><a href="#I-可以通过剥夺进程资源解除死锁" class="headerlink" title="I. 可以通过剥夺进程资源解除死锁"></a>I. 可以通过剥夺进程资源解除死锁</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li>这是<strong>死锁解除</strong>的一种常用策略：  <ul>
<li>选择一个或多个“牺牲”进程，<strong>抢占其已分配资源</strong>，分配给死锁进程；  </li>
<li>被剥夺的进程需回滚（rollback）到安全状态或重启；</li>
</ul>
</li>
<li>典型例子：数据库系统中的事务回滚、操作系统中 kill 进程释放资源。<br>→ 属于<strong>死锁恢复</strong>手段。</li>
</ul>
<hr>
<h4 id="II-死锁的预防方法能确保系统不发生死锁"><a href="#II-死锁的预防方法能确保系统不发生死锁" class="headerlink" title="II. 死锁的预防方法能确保系统不发生死锁"></a>II. 死锁的预防方法能确保系统不发生死锁</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li>死锁预防通过<strong>破坏死锁四个必要条件之一</strong>（互斥、占有并等待、非抢占、循环等待），在<strong>设计阶段杜绝死锁可能</strong>；  </li>
<li>例如：  <ul>
<li><strong>静态分配</strong>（一次性申请所有资源）→ 破坏“占有并等待”；  </li>
<li><strong>资源有序分配法</strong> → 破坏“循环等待”；</li>
</ul>
</li>
<li>虽然保守、资源利用率低，但<strong>绝对保证不死锁</strong>。<br>→ 与“避免”“检测”不同，预防是<strong>充分条件</strong>。</li>
</ul>
<hr>
<h4 id="III-银行家算法可以判断系统是否处于死锁状态"><a href="#III-银行家算法可以判断系统是否处于死锁状态" class="headerlink" title="III. 银行家算法可以判断系统是否处于死锁状态"></a>III. 银行家算法可以判断系统是否处于死锁状态</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li>银行家算法属于<strong>死锁避免</strong>，用于判断<strong>系统是否处于安全状态</strong>；  </li>
<li><strong>安全状态 ⇒ 无死锁</strong>，但  </li>
<li><strong>不安全状态 ⇏ 死锁</strong>（可能死锁，也可能不死锁）；  </li>
<li>真正用于<strong>检测死锁</strong>的是：  <ul>
<li>资源分配图（RAG）化简法  </li>
<li>等待图（Wait-for Graph）检测环路<br>→ 银行家算法不能检测死锁，只能避免进入不安全状态。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="IV-当系统出现死锁时，必然有两个或两个以上的进程处于阻塞态"><a href="#IV-当系统出现死锁时，必然有两个或两个以上的进程处于阻塞态" class="headerlink" title="IV. 当系统出现死锁时，必然有两个或两个以上的进程处于阻塞态"></a>IV. 当系统出现死锁时，必然有两个或两个以上的进程处于阻塞态</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li>死锁的定义要求<strong>循环等待</strong>：至少两个进程互相等待对方持有的资源；  </li>
<li>单个进程不可能死锁（它要么运行，要么等待资源，但无循环）；  </li>
<li>最小死锁环为 2 个进程（如 P1 持 R1 等 R2，P2 持 R2 等 R1）；<br>→ 所以<strong>至少 2 个进程阻塞</strong>。<br>（注：2016 年题中因资源需求结构限制最小为 3，但一般情况最小为 2）</li>
</ul>
<hr>
<h3 id="✅-最终判断："><a href="#✅-最终判断：" class="headerlink" title="✅ 最终判断："></a>✅ 最终判断：</h3><ul>
<li>I：✓  </li>
<li>II：✓  </li>
<li>III：✗  </li>
<li>IV：✓</li>
</ul>
<p>→ 正确答案：<strong>B. 仅 I、II、IV</strong></p>
<hr>
<h3 id="🎯-考点总结：-5"><a href="#🎯-考点总结：-5" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>说法</th>
<th>正误</th>
<th>关键辨析</th>
</tr>
</thead>
<tbody><tr>
<td>剥夺资源可解除死锁</td>
<td>✓</td>
<td>死锁恢复手段</td>
</tr>
<tr>
<td>预防能确保不死锁</td>
<td>✓</td>
<td>破坏必要条件 ⇒ 充分条件</td>
</tr>
<tr>
<td>银行家算法检测死锁</td>
<td>✗</td>
<td>它检测“安全状态”，非“死锁状态”</td>
</tr>
<tr>
<td>死锁至少 2 进程阻塞</td>
<td>✓</td>
<td>循环等待 ⇒ 最小环长为 2</td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>B</strong></p>
<h1 id="题目-7"><a href="#题目-7" class="headerlink" title="题目"></a>题目</h1><p>若系统中n (n&gt;&#x3D;2) 个进程，每个进程均需使用某类临界资源2个，则系统不会发生死锁所需的该类资源总至少______<br>。<br>(2021年)<br>A.2 B. n C. n+1 D.2n</p>
<h2 id="解析-7"><a href="#解析-7" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：C. n + 1</strong></p>
<hr>
<h3 id="✅-解析：-2"><a href="#✅-解析：-2" class="headerlink" title="✅ 解析："></a>✅ 解析：</h3><p>本题考查 <strong>死锁避免的资源下界问题</strong>，针对<strong>同类资源、每个进程最大需求为 2</strong> 的经典场景。</p>
<hr>
<h3 id="🔑-核心思想：-1"><a href="#🔑-核心思想：-1" class="headerlink" title="🔑 核心思想："></a>🔑 核心思想：</h3><p>要<strong>确保系统一定不会死锁</strong>，需使系统始终处于<strong>安全状态</strong>。</p>
<p>最坏情况：每个进程都已获得 <strong>1 个资源</strong>，且都在等待<strong>第 2 个资源</strong>。<br>此时若系统还剩 <strong>至少 1 个资源</strong>，就能满足某个进程 → 它完成后释放 2 个 → 可供其他进程使用 → 无死锁。</p>
<hr>
<h3 id="📐-推导："><a href="#📐-推导：" class="headerlink" title="📐 推导："></a>📐 推导：</h3><ul>
<li>进程数：$ n $  </li>
<li>每个进程最多需要：$ m &#x3D; 2 $ 个资源  </li>
<li>最坏分配：每个进程已得 $ m - 1 &#x3D; 1 $ 个资源<br>→ 已分配总量：$ n \times 1 &#x3D; n $  </li>
<li>为避免死锁，需剩余资源 $ \geq 1 $<br>→ 总资源数至少为：<br>$$<br>n + 1<br>$$</li>
</ul>
<hr>
<h3 id="✅-验证："><a href="#✅-验证：" class="headerlink" title="✅ 验证："></a>✅ 验证：</h3><ul>
<li>若资源数 &#x3D; $ n $：  <ul>
<li>每个进程得 1 个，共 $ n $ 个，剩余 0；  </li>
<li>所有进程都在等第 2 个 → <strong>死锁！</strong></li>
</ul>
</li>
<li>若资源数 &#x3D; $ n + 1 $：  <ul>
<li>最坏：$ n - 1 $ 个进程各得 1 个，1 个进程得 2 个；<br>→ 得 2 个的进程可完成，释放 2 个 → 剩余资源 &#x3D; 2 + (n−1)×1 &#x3D; n+1？  </li>
<li>或更直接：<br>$ n $ 个进程各得 1 个（共 $ n $），剩余 1 个 → 给任一进程，它得 2 个 → 完成 → 释放 2 个 → 可继续推进。<br>→ <strong>无死锁</strong>，安全。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="🎯-对比经典公式："><a href="#🎯-对比经典公式：" class="headerlink" title="🎯 对比经典公式："></a>🎯 对比经典公式：</h3><p>一般地，$ n $ 个进程，每个最多需 $ m $ 个资源，<br><strong>确保不死锁的最小资源数</strong>为：<br>$$<br>n(m - 1) + 1<br>$$</p>
<p>本题 $ m &#x3D; 2 $，代入得：<br>$$<br>n(2 - 1) + 1 &#x3D; n + 1<br>$$</p>
<hr>
<h3 id="❌-排除其他选项："><a href="#❌-排除其他选项：" class="headerlink" title="❌ 排除其他选项："></a>❌ 排除其他选项：</h3><ul>
<li>A. 2：当 $ n &gt; 2 $ 时显然不够（如 $ n&#x3D;3 $，2 个资源 → 必死锁）  </li>
<li>B. $ n $：如上，会导致死锁  </li>
<li>D. $ 2n $：是“充分但不必要”条件（保证每个进程都能同时满足），过于保守；题目问“至少”，应取最小值。</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>C. n + 1</strong></p>
<h1 id="题目-8"><a href="#题目-8" class="headerlink" title="题目"></a>题目</h1><p>我们来分析这道<strong>银行家算法安全性检测</strong>题目。</p>
<hr>
<h3 id="📊-题目表格："><a href="#📊-题目表格：" class="headerlink" title="📊 题目表格："></a>📊 题目表格：</h3><table>
<thead>
<tr>
<th>进程</th>
<th>A 已分配</th>
<th>B 已分配</th>
<th>A 需求总量</th>
<th>B 需求总量</th>
</tr>
</thead>
<tbody><tr>
<td>P1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>P2</td>
<td>2</td>
<td>1</td>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>P3</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
</tbody></table>
<blockquote>
<p>资源总数：A 类 6 个，B 类 6 个</p>
</blockquote>
<hr>
<h2 id="✅-步骤-1：计算“尚需资源”-“需求总量-已分配”"><a href="#✅-步骤-1：计算“尚需资源”-“需求总量-已分配”" class="headerlink" title="✅ 步骤 1：计算“尚需资源” &#x3D; “需求总量 - 已分配”"></a>✅ 步骤 1：计算“尚需资源” &#x3D; “需求总量 - 已分配”</h2><table>
<thead>
<tr>
<th>进程</th>
<th>A 尚需</th>
<th>B 尚需</th>
</tr>
</thead>
<tbody><tr>
<td>P1</td>
<td>4−2&#x3D;2</td>
<td>4−3&#x3D;1</td>
</tr>
<tr>
<td>P2</td>
<td>3−2&#x3D;1</td>
<td>1−1&#x3D;0</td>
</tr>
<tr>
<td>P3</td>
<td>3−1&#x3D;2</td>
<td>4−2&#x3D;2</td>
</tr>
</tbody></table>
<hr>
<h2 id="✅-步骤-2：计算“当前可用资源”"><a href="#✅-步骤-2：计算“当前可用资源”" class="headerlink" title="✅ 步骤 2：计算“当前可用资源”"></a>✅ 步骤 2：计算“当前可用资源”</h2><p>总资源 A &#x3D; 6，已分配 A &#x3D; 2+2+1 &#x3D; <strong>5</strong> → 可用 A &#x3D; <strong>1</strong><br>总资源 B &#x3D; 6，已分配 B &#x3D; 3+1+2 &#x3D; <strong>6</strong> → 可用 B &#x3D; <strong>0</strong></p>
<p>→ <strong>Available &#x3D; [A:1, B:0]</strong></p>
<hr>
<h2 id="✅-步骤-3：寻找安全序列（尝试每个进程是否可运行）"><a href="#✅-步骤-3：寻找安全序列（尝试每个进程是否可运行）" class="headerlink" title="✅ 步骤 3：寻找安全序列（尝试每个进程是否可运行）"></a>✅ 步骤 3：寻找安全序列（尝试每个进程是否可运行）</h2><h3 id="检查-P1："><a href="#检查-P1：" class="headerlink" title="检查 P1："></a>检查 P1：</h3><ul>
<li>尚需 [2,1] &gt; 可用 [1,0] ❌（A 不足）</li>
</ul>
<h3 id="检查-P2："><a href="#检查-P2：" class="headerlink" title="检查 P2："></a>检查 P2：</h3><ul>
<li>尚需 [1,0] ≤ [1,0] ✅<br>→ <strong>P2 可运行！</strong></li>
</ul>
<p>执行 P2 后，释放其已分配资源 [2,1]<br>→ 新 Available &#x3D; [1,0] + [2,1] &#x3D; <strong>[3,1]</strong></p>
<hr>
<h3 id="剩余进程：P1、P3，可用资源-3-1"><a href="#剩余进程：P1、P3，可用资源-3-1" class="headerlink" title="剩余进程：P1、P3，可用资源 [3,1]"></a>剩余进程：P1、P3，可用资源 [3,1]</h3><h4 id="检查-P1：-1"><a href="#检查-P1：-1" class="headerlink" title="检查 P1："></a>检查 P1：</h4><ul>
<li>尚需 [2,1] ≤ [3,1] ✅<br>→ <strong>P1 可运行</strong></li>
</ul>
<p>执行 P1 后，释放 [2,3]<br>→ 新 Available &#x3D; [3,1] + [2,3] &#x3D; <strong>[5,4]</strong></p>
<hr>
<h3 id="剩余进程：P3，可用资源-5-4"><a href="#剩余进程：P3，可用资源-5-4" class="headerlink" title="剩余进程：P3，可用资源 [5,4]"></a>剩余进程：P3，可用资源 [5,4]</h3><h4 id="检查-P3："><a href="#检查-P3：" class="headerlink" title="检查 P3："></a>检查 P3：</h4><ul>
<li>尚需 [2,2] ≤ [5,4] ✅<br>→ <strong>P3 可运行</strong></li>
</ul>
<p>执行 P3 后，释放 [1,2]<br>→ 最终 Available &#x3D; [5,4] + [1,2] &#x3D; [6,6] —— 全部资源回收 ✅</p>
<hr>
<h2 id="✅-安全序列：P2-→-P1-→-P3"><a href="#✅-安全序列：P2-→-P1-→-P3" class="headerlink" title="✅ 安全序列：P2 → P1 → P3"></a>✅ 安全序列：P2 → P1 → P3</h2><hr>
<h2 id="✅-对照选项："><a href="#✅-对照选项：" class="headerlink" title="✅ 对照选项："></a>✅ 对照选项：</h2><ul>
<li>A. 存在安全序列 P1,P2,P3 ❌（P1 开始不可行）  </li>
<li>B. 存在安全序列 P2,P1,P3 ✅ <strong>正确</strong>  </li>
<li>C. 存在安全序列 P2,P3,P1 ❌（P3 在 P1 前不可行，因为 P3 尚需 [2,2]，而 P2 后可用为 [3,1]，B&#x3D;1&lt;2）  </li>
<li>D. 不存在安全序列 ❌</li>
</ul>
<hr>
<h3 id="🎯-关键点："><a href="#🎯-关键点：" class="headerlink" title="🎯 关键点："></a>🎯 关键点：</h3><ul>
<li>初始可用资源 [1,0]，只有 P2 的尚需 [1,0] 能满足；  </li>
<li>P2 执行后释放资源，使后续进程有机会运行；  </li>
<li>P3 不能紧跟 P2，因为其 B 尚需 2，但 P2 后可用 B&#x3D;1 &lt; 2。</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>B. 存在安全序列 P2,P1,P3</strong></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>数据采集与处理--相关习题</title>
    <url>/zhihaojiang.github.io/2025/12/29/20251229%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E4%B8%8E%E5%A4%84%E7%90%86--%E7%9B%B8%E5%85%B3%E4%B9%A0%E9%A2%98/</url>
    <content><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>什么是主题爬虫 其主要是用在哪些场合</p>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p><strong>主题爬虫</strong>（Focused Crawler &#x2F; Topic-specific Crawler）是一种<strong>有目标导向的网络爬虫</strong>，与通用爬虫（如 Googlebot）不同，它不追求覆盖整个互联网，而是<strong>只抓取与特定主题高度相关</strong>的网页。</p>
<p>其核心思想是：<br>在爬取过程中，<strong>动态评估</strong>网页内容与预设主题的相关性，据此决定是否下载该页面、是否将其链接加入待爬队列，从而<strong>提高爬取效率与数据质量</strong>，减少无关页面的抓取与存储开销。</p>
<hr>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><p><strong>定义</strong>：<br>主题爬虫（Focused Crawler）是一种根据用户指定主题（如“人工智能”“新冠疫情”“新能源汽车政策”），在爬取过程中结合<strong>链接分析</strong>与<strong>内容相关性预测</strong>，优先抓取并保留与主题高度相关的网页，过滤无关内容的智能网络爬虫系统。</p>
<p><strong>关键技术环节</strong>：</p>
<ol>
<li><strong>主题建模</strong>：用关键词集合、主题词典、分类器（如SVM、BERT）或主题向量（如LDA、Sentence-BERT）表示目标主题。</li>
<li><strong>相关性评估</strong>：<ul>
<li>对已下载页面：提取文本 → 特征表示（TF-IDF、词嵌入等）→ 计算与主题的相似度。</li>
<li>对待爬链接（URL&#x2F;锚文本&#x2F;上下文）：通过<strong>链接上下文</strong>（如锚文本、父页面主题）预测目标页相关性（“预测式爬取”）。</li>
</ul>
</li>
<li><strong>优先级调度</strong>：根据相关性得分动态调整URL队列的抓取顺序（如Best-First策略）。</li>
</ol>
<hr>
<h2 id="主要应用场景"><a href="#主要应用场景" class="headerlink" title="主要应用场景"></a>主要应用场景</h2><table>
<thead>
<tr>
<th>应用场景</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>垂直搜索引擎构建</strong></td>
<td>如“医学文献搜索引擎”“法律案例检索系统”，需精准采集特定领域网页。</td>
</tr>
<tr>
<td><strong>舆情监测与热点追踪</strong></td>
<td>围绕“某企业”“某政策”“某突发事件”持续抓取相关新闻、社交媒体、论坛讨论。</td>
</tr>
<tr>
<td><strong>学术资源采集</strong></td>
<td>聚焦某研究方向（如“联邦学习”“图神经网络”），从arXiv、会议网站、机构库中采集论文。</td>
</tr>
<tr>
<td><strong>电商竞品监控</strong></td>
<td>抓取特定品类（如“无线蓝牙耳机”）的商品详情、价格、评论，用于比价或市场分析。</td>
</tr>
<tr>
<td><strong>政府&#x2F;企业知识库建设</strong></td>
<td>持续采集政策文件、行业报告、标准规范等结构化&#x2F;半结构化数据。</td>
</tr>
<tr>
<td><strong>训练大模型的领域数据收集</strong></td>
<td>为微调领域大模型（如医疗、金融LLM），需高质量、高相关性的语料，主题爬虫可高效构建数据集。</td>
</tr>
</tbody></table>
<blockquote>
<p> 实际系统中常结合：  </p>
<ul>
<li><strong>增量爬取</strong>（定期更新）  </li>
<li><strong>去重与质量过滤</strong>（正文提取、广告过滤）  </li>
<li><strong>反爬应对</strong>（User-Agent轮换、请求限速、验证码识别）</li>
</ul>
</blockquote>
<h2 id="核心考点总结"><a href="#核心考点总结" class="headerlink" title="核心考点总结"></a>核心考点总结</h2><table>
<thead>
<tr>
<th>考点类别</th>
<th>具体内容</th>
</tr>
</thead>
<tbody><tr>
<td>📌 <strong>概念辨析</strong></td>
<td>主题爬虫 vs 通用爬虫 vs 增量爬虫</td>
</tr>
<tr>
<td>📌 <strong>核心技术</strong></td>
<td>主题表示方法、相关性预测模型（基于内容&#x2F;链接&#x2F;URL）、优先级调度策略</td>
</tr>
<tr>
<td><strong>评估指标</strong></td>
<td>查全率（Recall）、查准率（Precision）、 harvest rate（收获率 &#x3D; 相关页面数 &#x2F; 总抓取数）</td>
</tr>
<tr>
<td><strong>挑战</strong></td>
<td>主题漂移、语义鸿沟（URL&#x2F;锚文本与内容不一致）、动态网页渲染（需结合Selenium&#x2F;Playwright）</td>
</tr>
<tr>
<td><strong>扩展知识</strong></td>
<td>与<strong>主动学习</strong>结合（人机协同标注提升模型）；与<strong>图神经网络</strong>结合（利用网页链接图结构提升预测）</td>
</tr>
</tbody></table>
<h1 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h1><p>什么是Deep Web？它与普通的Web页面有什么差异？</p>
<h2 id="解析-1"><a href="#解析-1" class="headerlink" title="解析"></a>解析</h2><p>“Deep Web”（深网）是一个常被误解的概念——它<strong>不等于暗网</strong>（Dark Web），也不代表“非法内容”。理解其本质，关键在于区分<strong>内容可访问性</strong>与<strong>搜索引擎可索引性</strong>。</p>
<hr>
<h2 id="解答-1"><a href="#解答-1" class="headerlink" title="解答"></a>解答</h2><h3 id="一、什么是-Deep-Web（深网）？"><a href="#一、什么是-Deep-Web（深网）？" class="headerlink" title="一、什么是 Deep Web（深网）？"></a>一、什么是 Deep Web（深网）？</h3><p><strong>Deep Web</strong> 是指<strong>无法被传统搜索引擎</strong>（如 Google、Bing）通过常规爬虫自动发现和索引的<strong>互联网内容集合</strong>。<br>这类内容<strong>真实存在、合法可访问</strong>，但因其访问机制限制，未被纳入搜索引擎数据库。</p>
<blockquote>
<p> 核心特征：<strong>不可被通用爬虫自动发现</strong>（not <em>inaccessible</em>，而是 <em>unindexed</em>）。</p>
</blockquote>
<h3 id="二、Deep-Web-与-Surface-Web（表层网络）的差异"><a href="#二、Deep-Web-与-Surface-Web（表层网络）的差异" class="headerlink" title="二、Deep Web 与 Surface Web（表层网络）的差异"></a>二、Deep Web 与 Surface Web（表层网络）的差异</h3><table>
<thead>
<tr>
<th>维度</th>
<th>Surface Web（表层网络）</th>
<th>Deep Web（深网）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>可索引性</strong></td>
<td>可被搜索引擎爬虫抓取并建立索引（如新闻、博客、公开企业官网）</td>
<td><strong>不可被通用爬虫自动索引</strong></td>
</tr>
<tr>
<td><strong>访问方式</strong></td>
<td>直接通过 URL 或搜索结果访问</td>
<td>通常需：<strong>登录认证</strong>、<strong>表单提交</strong>、<strong>数据库查询</strong>、<strong>API 调用</strong> 等交互操作</td>
</tr>
<tr>
<td><strong>内容形式</strong></td>
<td>静态 HTML 页面为主</td>
<td>动态生成内容（如数据库查询结果）、私有资源、需权限内容</td>
</tr>
<tr>
<td><strong>规模占比</strong></td>
<td>仅占互联网内容 <strong>约 4%~10%</strong></td>
<td>占互联网内容 <strong>90% 以上</strong>（主流估计）</td>
</tr>
<tr>
<td><strong>典型例子</strong></td>
<td>Wikipedia、知乎公开文章、GitHub 公开仓库</td>
<td>见下表</td>
</tr>
</tbody></table>
<h3 id="三、Deep-Web-的典型例子（合法常见场景）"><a href="#三、Deep-Web-的典型例子（合法常见场景）" class="headerlink" title="三、Deep Web 的典型例子（合法常见场景）"></a>三、Deep Web 的典型例子（合法常见场景）</h3><table>
<thead>
<tr>
<th>类型</th>
<th>实例</th>
</tr>
</thead>
<tbody><tr>
<td><strong>需登录的私有内容</strong></td>
<td>个人邮箱（Gmail）、网银后台、学校教务系统、企业内网、付费数据库（CNKI、IEEE Xplore）</td>
</tr>
<tr>
<td><strong>表单驱动的内容</strong></td>
<td>12306 车票查询结果、天气预报按城市查询的页面、招聘网站的“搜索职位”结果页</td>
</tr>
<tr>
<td><strong>数据库查询结果</strong></td>
<td>医院挂号系统返回的可预约号源、图书馆馆藏检索结果</td>
</tr>
<tr>
<td><strong>API 返回的数据</strong></td>
<td>微信小程序后台数据、App 从服务器拉取的 JSON 内容（未做 SSR 的前端页面）</td>
</tr>
<tr>
<td><strong>非 HTML 资源</strong></td>
<td>PDF 报告、PPT、Excel 表格（若未被搜索引擎收录）</td>
</tr>
<tr>
<td><strong>动态渲染内容</strong>（部分）</td>
<td>依赖 JavaScript 渲染且未做服务端渲染（SSR）或预渲染（Prerender）的 SPA 页面（如早期 React 应用）——现代搜索引擎已部分支持，但仍有盲区</td>
</tr>
</tbody></table>
<blockquote>
<p> <strong>注意</strong>：  </p>
<ul>
<li><strong>Dark Web</strong>（暗网）是 Deep Web 的<strong>极小一部分</strong>，特指通过特殊工具（如 Tor、I2P）访问的<strong>匿名隐藏服务</strong>（<code>.onion</code> 域名），其中可能包含非法内容，但也有合法用途（如记者匿名信道）。  </li>
<li><strong>绝大多数 Deep Web 是日常使用的合法系统</strong>，绝非“危险地带”。</li>
</ul>
</blockquote>
<hr>
<h2 id="核心考点总结-1"><a href="#核心考点总结-1" class="headerlink" title="核心考点总结"></a>核心考点总结</h2><table>
<thead>
<tr>
<th>考点</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>定义核心</strong></td>
<td>Deep Web &#x3D; <strong>未被搜索引擎索引的内容</strong>（≠ 不可访问，≠ 非法）</td>
</tr>
<tr>
<td><strong>对比理解</strong></td>
<td>Surface Web（可索引） vs Deep Web（不可索引） vs Dark Web（匿名隐藏服务）</td>
</tr>
<tr>
<td><strong>规模认知</strong></td>
<td>Deep Web 占互联网主体（&gt;90%），表层网络只是“冰山一角”</td>
</tr>
<tr>
<td><strong>技术成因</strong></td>
<td>动态内容生成、访问控制（登录&#x2F;权限）、缺乏入站链接、robots.txt 限制、JavaScript 依赖等</td>
</tr>
<tr>
<td><strong>数据采集挑战</strong></td>
<td>普通爬虫无法直接抓取 Deep Web；需模拟登录、提交表单、调用 API、处理验证码（如你关注的 <code>tesserocr</code> 即用于此类场景）——这正是<strong>数据采集与处理课程的重点难点</strong></td>
</tr>
</tbody></table>
<h1 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h1><p>Web服务器有哪些检测爬虫请求的方法？</p>
<p>这是一个<strong>数据采集与处理</strong>中的核心对抗与反爬考点。Web 服务器检测爬虫的手段日趋智能化，理解这些机制是设计<strong>高鲁棒性爬虫</strong>（或评估采集可行性）的前提。</p>
<hr>
<h2 id="解析-2"><a href="#解析-2" class="headerlink" title="解析"></a>解析</h2><p>Web 服务器通过<strong>请求特征分析</strong> + <strong>行为模式识别</strong> + <strong>资源访问异常检测</strong>等多维度手段识别非人类流量。检测目的包括：  </p>
<ul>
<li>保护数据资产（如防内容盗用）  </li>
<li>防止服务过载（如防 DDoS）  </li>
<li>维护业务公平性（如防抢票&#x2F;秒杀脚本）</li>
</ul>
<h2 id="解答：Web-服务器检测爬虫的主要方法"><a href="#解答：Web-服务器检测爬虫的主要方法" class="headerlink" title="解答：Web 服务器检测爬虫的主要方法"></a>解答：Web 服务器检测爬虫的主要方法</h2><h3 id="一、请求头（Request-Headers）层面检测"><a href="#一、请求头（Request-Headers）层面检测" class="headerlink" title="一、请求头（Request Headers）层面检测"></a>一、<strong>请求头（Request Headers）层面检测</strong></h3><table>
<thead>
<tr>
<th>方法</th>
<th>原理</th>
<th>典型特征</th>
</tr>
</thead>
<tbody><tr>
<td><strong><code>User-Agent</code> 异常</strong></td>
<td>检查 UA 是否为空、伪造常见浏览器、或为已知爬虫标识（如 <code>python-requests/2.28.1</code>）</td>
<td>缺失 UA；含 <code>bot</code>&#x2F;<code>spider</code>&#x2F;<code>crawler</code>；Python 默认 UA</td>
</tr>
<tr>
<td><strong>缺失关键 Header</strong></td>
<td>正常浏览器会自动携带 <code>Accept</code>, <code>Accept-Language</code>, <code>Accept-Encoding</code>, <code>Referer</code>, <code>Sec-Fetch-*</code> 等</td>
<td>爬虫常只带 <code>User-Agent</code>，缺少 <code>Sec-Fetch-Mode: navigate</code> 等安全头</td>
</tr>
<tr>
<td><strong>Header 顺序&#x2F;格式异常</strong></td>
<td>浏览器发送 Header 有固定顺序和格式；爬虫拼接易出错</td>
<td>如 <code>Connection: keep-alive</code> 位置异常；无 <code>Upgrade-Insecure-Requests</code></td>
</tr>
</tbody></table>
<h3 id="二、访问行为模式检测"><a href="#二、访问行为模式检测" class="headerlink" title="二、访问行为模式检测"></a>二、<strong>访问行为模式检测</strong></h3><table>
<thead>
<tr>
<th>方法</th>
<th>原理</th>
<th>爬虫典型破绽</th>
</tr>
</thead>
<tbody><tr>
<td><strong>访问频率过高&#x2F;匀速</strong></td>
<td>人类操作有随机延迟、停顿、回退；爬虫常匀速高频请求</td>
<td>每秒固定 N 次请求；无鼠标轨迹&#x2F;滚动行为</td>
</tr>
<tr>
<td><strong>无页面资源加载</strong></td>
<td>浏览器会加载 CSS&#x2F;JS&#x2F;图片；爬虫常只请求 HTML</td>
<td>仅请求 <code>/article/123</code>，但不请求 <code>/static/main.css</code> 或 <code>/img/banner.jpg</code></td>
</tr>
<tr>
<td><strong>无 Cookie 交互</strong></td>
<td>服务器设 <code>Set-Cookie</code> 后，浏览器应携带回传；爬虫若忽略则暴露</td>
<td>首次访问给 <code>sessionid=abc</code>，后续请求无该 Cookie</td>
</tr>
<tr>
<td><strong>缺失 JS 渲染行为</strong></td>
<td>现代网站常要求执行 JS 生成 Token 或验证环境</td>
<td>爬虫直接 POST 表单，但未携带由 JS 生成的 <code>csrf_token</code> 或 <code>__RequestVerificationToken</code></td>
</tr>
</tbody></table>
<h3 id="三、JavaScript-挑战与环境检测（前端反爬）"><a href="#三、JavaScript-挑战与环境检测（前端反爬）" class="headerlink" title="三、JavaScript 挑战与环境检测（前端反爬）"></a>三、<strong>JavaScript 挑战与环境检测（前端反爬）</strong></h3><table>
<thead>
<tr>
<th>方法</th>
<th>举例</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>浏览器环境指纹检测</strong></td>
<td>通过 JS 检测 <code>navigator.webdriver</code>、<code>window.chrome</code>、插件列表、屏幕分辨率等</td>
<td>Selenium 默认会暴露 <code>navigator.webdriver = true</code></td>
</tr>
<tr>
<td><strong>Canvas&#x2F;WebGL 指纹</strong></td>
<td>利用硬件渲染差异生成唯一指纹</td>
<td>真实设备指纹稳定，爬虫环境（如无头浏览器）易一致或异常</td>
</tr>
<tr>
<td><strong>行为验证</strong>（CAPTCHA）</td>
<td>reCAPTCHA v2&#x2F;v3、极验、阿里云验证码</td>
<td>v3 通过用户行为打分（score &lt; 0.5 视为机器人）；v2 要求点选&#x2F;滑动</td>
</tr>
<tr>
<td><strong>动态 Token 注入</strong></td>
<td>关键请求参数（如 <code>sign</code>, <code>token</code>）由 JS 计算生成</td>
<td>如 <code>sign = md5(url + timestamp + salt)</code>，爬虫无法预测</td>
</tr>
</tbody></table>
<h3 id="四、IP-与网络层检测"><a href="#四、IP-与网络层检测" class="headerlink" title="四、IP 与网络层检测"></a>四、<strong>IP 与网络层检测</strong></h3><table>
<thead>
<tr>
<th>方法</th>
<th>原理</th>
</tr>
</thead>
<tbody><tr>
<td><strong>IP 访问频次&#x2F;并发量</strong></td>
<td>单 IP 短时大量请求 → 触发限流或封禁</td>
</tr>
<tr>
<td><strong>IP 地理位置异常</strong></td>
<td>如用户账号常驻北京，突然从数据中心 IP（如 AWS us-east-1）访问</td>
</tr>
<tr>
<td><strong>IP 黑名单匹配</strong></td>
<td>使用公开爬虫 IP 库（如已知 Tor 出口节点、云服务器段）</td>
</tr>
<tr>
<td><strong>HTTP&#x2F;2 + TLS 指纹</strong></td>
<td>真实浏览器 TLS 握手有固定 Cipher Suites 顺序；爬虫库（如 requests）指纹单一</td>
</tr>
</tbody></table>
<h3 id="五、服务端逻辑检测"><a href="#五、服务端逻辑检测" class="headerlink" title="五、服务端逻辑检测"></a>五、<strong>服务端逻辑检测</strong></h3><table>
<thead>
<tr>
<th>方法</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td><strong>蜜罐陷阱</strong>（Honeypot）</td>
<td>页面隐藏 <code>&lt;a href=&quot;/trap/secret-path&quot; style=&quot;display:none&quot;&gt;</code>，真实用户看不到，爬虫会跟爬</td>
</tr>
<tr>
<td><strong>时间戳&#x2F;逻辑校验</strong></td>
<td>表单含隐藏字段 <code>&lt;input name=&quot;stime&quot; value=&quot;1717020000&quot;&gt;</code>，提交时校验停留时间是否合理（如 &lt;1s 视为机器）</td>
</tr>
<tr>
<td><strong>请求路径异常</strong></td>
<td>用户正常路径：<code>首页 → 分类 → 列表 → 详情</code>；爬虫直接跳 <code>/product/999999</code></td>
</tr>
</tbody></table>
<hr>
<h2 id="应对策略概览（延伸知识，常考简答-设计题）"><a href="#应对策略概览（延伸知识，常考简答-设计题）" class="headerlink" title="应对策略概览（延伸知识，常考简答&#x2F;设计题）"></a>应对策略概览（延伸知识，常考简答&#x2F;设计题）</h2><table>
<thead>
<tr>
<th>检测手段</th>
<th>可行应对措施</th>
</tr>
</thead>
<tbody><tr>
<td>UA&#x2F;Header 异常</td>
<td>用 <code>fake-useragent</code> + 完整 Header 模板；使用 <code>curl-impersonate</code> 模拟真实浏览器指纹</td>
</tr>
<tr>
<td>行为模式</td>
<td>随机延时（<code>time.sleep(random.uniform(1,3))</code>）；模拟滚动&#x2F;鼠标移动（Playwright&#x2F;Selenium）</td>
</tr>
<tr>
<td>JS 挑战</td>
<td>用无头浏览器（Playwright &gt; Puppeteer &gt; Selenium）；逆向 JS 算法（AST 解析 + Python 重写）</td>
</tr>
<tr>
<td>验证码</td>
<td>OCR（如 <code>tesserocr</code> 处理简单验证码）、打码平台、绕过（如用第三方 API）</td>
</tr>
<tr>
<td>IP 封禁</td>
<td>代理 IP 池轮换（住宅代理 &gt; 数据中心代理）；降低并发</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>重要提醒</strong>：<br>所有反爬绕过需遵守《网络安全法》及网站 <code>robots.txt</code> 和服务条款。<strong>技术用于学习与合法数据采集，严禁用于攻击或侵犯隐私</strong>。</p>
</blockquote>
<hr>
<h2 id="核心考点总结-2"><a href="#核心考点总结-2" class="headerlink" title="核心考点总结"></a>核心考点总结</h2><table>
<thead>
<tr>
<th>考点类型</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>概念辨析</strong></td>
<td>区分“检测” vs “防御”；“特征检测” vs “行为检测”</td>
</tr>
<tr>
<td><strong>分类记忆</strong></td>
<td>按请求层、行为层、JS 层、网络层、服务层分类掌握检测方法</td>
</tr>
<tr>
<td><strong>典型指标</strong></td>
<td>UA、Referer、Cookie、请求频率、资源加载完整性、TLS&#x2F;JA3 指纹</td>
</tr>
<tr>
<td><strong>前沿趋势</strong></td>
<td>从规则匹配 → 机器学习模型（如 LSTM 行为序列建模）检测异常流量</td>
</tr>
<tr>
<td><strong>工程实践</strong></td>
<td>在 <code>requests</code> + <code>BeautifulSoup</code> 基础上，进阶需掌握 <code>Selenium</code>&#x2F;<code>Playwright</code> + 代理 + 逆向能力</td>
</tr>
</tbody></table>
<h1 id="题目-3"><a href="#题目-3" class="headerlink" title="题目"></a>题目</h1><p>简述文本分类的一般流程</p>
<h2 id="解析-3"><a href="#解析-3" class="headerlink" title="解析"></a>解析</h2><p>文本分类是<strong>自然语言处理</strong>（NLP）的基础任务，也是数据采集后处理（如爬虫结果打标、舆情分析）的关键环节。其流程体现了“<strong>数据 → 特征 → 模型 → 应用</strong>”的典型机器学习 pipeline，需兼顾<strong>文本特性</strong>（高维、稀疏、语义复杂）与<strong>工程落地</strong>。</p>
<h2 id="解答：文本分类的一般流程"><a href="#解答：文本分类的一般流程" class="headerlink" title="解答：文本分类的一般流程"></a>解答：文本分类的一般流程</h2><h3 id="数据获取与预处理"><a href="#数据获取与预处理" class="headerlink" title="数据获取与预处理"></a><strong>数据获取与预处理</strong></h3><p><strong>目的</strong>：清洗噪声、统一格式、为后续处理做准备<br><strong>关键操作</strong>：</p>
<ul>
<li><strong>文本清洗</strong>：去 HTML 标签、特殊符号、广告语、无关字符  </li>
<li><strong>分词</strong>（中文必需）：使用 <code>jieba</code>、<code>pkuseg</code>、<code>LTP</code> 等（英文按空格&#x2F;标点切分）  </li>
<li><strong>去停用词</strong>：过滤“的”“是”“and”“the”等高频无意义词（可用哈工大&#x2F;百度停用词表）  </li>
<li><strong>词干化&#x2F;词形还原</strong>（英文）：<code>running</code> → <code>run</code>（<code>nltk.stem.PorterStemmer</code>）  </li>
<li><strong>大小写统一</strong>：<code>Apple</code> → <code>apple</code>（中文一般无需）</li>
</ul>
<h3 id="特征表示"><a href="#特征表示" class="headerlink" title="特征表示"></a><strong>特征表示</strong></h3><p><strong>目的</strong>：将文本转化为模型可计算的数值向量<br><strong>主流方法演进</strong>：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>方法</th>
<th>特点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>传统统计特征</strong></td>
<td>- <strong>词袋模型</strong>（BoW）<br>- <strong>TF-IDF</strong>（词频-逆文档频率）</td>
<td>简单高效；忽略语序；高维稀疏</td>
<td>小数据集、基线模型、可解释性要求高</td>
</tr>
<tr>
<td><strong>词嵌入</strong>（Word-Level）</td>
<td>- <code>Word2Vec</code><br>- <code>GloVe</code><br>- <code>FastText</code></td>
<td>捕获语义相似性（如 king - man + woman ≈ queen）；需预训练</td>
<td>中等规模数据；支持迁移学习</td>
</tr>
<tr>
<td><strong>上下文嵌入</strong>（Contextual）</td>
<td>- <strong>BERT &#x2F; RoBERTa</strong><br>- <strong>Sentence-BERT</strong>（SBERT）</td>
<td>动态表征（“苹果”在水果&#x2F;公司语境不同）；SOTA 性能</td>
<td>高精度需求；有 GPU 资源；支持微调</td>
</tr>
</tbody></table>
<blockquote>
<p> <em>当前主流</em>：<strong>预训练语言模型微调</strong>（如用 <code>transformers</code> 库加载 <code>bert-base-chinese</code> + 分类头）</p>
</blockquote>
<hr>
<h3 id="模型选择与训练"><a href="#模型选择与训练" class="headerlink" title="模型选择与训练"></a><strong>模型选择与训练</strong></h3><p><strong>常用模型对比</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>优点</th>
<th>缺点</th>
<th>典型工具</th>
</tr>
</thead>
<tbody><tr>
<td><strong>朴素贝叶斯</strong>（NB）</td>
<td>计算快；小样本有效；理论清晰</td>
<td>假设特征独立（实际不成立）</td>
<td><code>sklearn.naive_bayes.MultinomialNB</code></td>
</tr>
<tr>
<td><strong>SVM</strong></td>
<td>高维有效；小样本强；核技巧灵活</td>
<td>训练慢（尤其大数据）；难输出概率</td>
<td><code>sklearn.svm.SVC</code>（线性核常用）</td>
</tr>
<tr>
<td><strong>逻辑回归</strong>（LR）</td>
<td>可解释；支持在线学习；常作 baseline</td>
<td>线性模型，捕捉非线性能力弱</td>
<td><code>sklearn.linear_model.LogisticRegression</code></td>
</tr>
<tr>
<td><strong>深度学习</strong><br>（CNN&#x2F;RNN）</td>
<td>自动提取特征；捕捉局部&#x2F;序列模式</td>
<td>需大数据；训练慢；调参复杂</td>
<td><code>TensorFlow/Keras</code>, <code>PyTorch</code></td>
</tr>
<tr>
<td><strong>预训练模型微调</strong><br>（BERT 等）</td>
<td>SOTA 效果；迁移学习强大</td>
<td>资源消耗大；推理慢</td>
<td><code>HuggingFace Transformers</code></td>
</tr>
</tbody></table>
<blockquote>
<p><em>流程中关键步骤</em>：  </p>
<ul>
<li>划分 <strong>训练集 &#x2F; 验证集 &#x2F; 测试集</strong>（如 7:1:2）  </li>
<li>交叉验证（如 5-fold）调参  </li>
<li>设置早停（Early Stopping）防过拟合</li>
</ul>
</blockquote>
<hr>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a><strong>模型评估</strong></h3><p><strong>核心指标</strong>（多分类场景）：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>公式&#x2F;说明</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>准确率</strong>（Accuracy）</td>
<td>$ \frac{TP+TN}{TP+TN+FP+FN} $</td>
<td>类别均衡时可用</td>
</tr>
<tr>
<td><strong>精确率</strong>（Precision）</td>
<td>$ \frac{TP}{TP+FP} $</td>
<td>关注“预测为正的有多少真”（如垃圾邮件过滤）</td>
</tr>
<tr>
<td><strong>召回率</strong>（Recall）</td>
<td>$ \frac{TP}{TP+FN} $</td>
<td>关注“真正的正例有多少被找出”（如疾病诊断）</td>
</tr>
<tr>
<td><strong>F1-Score</strong></td>
<td>$ 2 \times \frac{Precision \times Recall}{Precision + Recall} $</td>
<td>Precision 与 Recall 的调和平均，<strong>最常用</strong></td>
</tr>
<tr>
<td><strong>宏&#x2F;微平均</strong>（Macro&#x2F;Micro-F1）</td>
<td>宏：各类 F1 平均；微：全局 TP&#x2F;FP&#x2F;FN 计算</td>
<td>多分类不平衡时必看</td>
</tr>
</tbody></table>
<blockquote>
<p>还需：<strong>混淆矩阵</strong>、<strong>PR 曲线</strong>、<strong>ROC-AUC</strong>（二分类）</p>
</blockquote>
<hr>
<h3 id="模型优化与调参"><a href="#模型优化与调参" class="headerlink" title="模型优化与调参"></a><strong>模型优化与调参</strong></h3><ul>
<li><strong>特征工程</strong>：n-gram（如 bigram）、词性标注、实体识别作为特征  </li>
<li><strong>超参调优</strong>：网格搜索（GridSearch）、贝叶斯优化（<code>optuna</code>）  </li>
<li><strong>集成学习</strong>：投票法（Voting）、堆叠（Stacking）  </li>
<li><strong>处理不平衡</strong>：过采样（SMOTE）、欠采样、代价敏感学习（class_weight）</li>
</ul>
<hr>
<h3 id="部署与应用"><a href="#部署与应用" class="headerlink" title="部署与应用"></a><strong>部署与应用</strong></h3><ul>
<li><strong>轻量化</strong>：模型蒸馏（DistilBERT）、量化（ONNX Runtime）  </li>
<li><strong>API 封装</strong>：用 Flask&#x2F;FastAPI 提供分类接口  </li>
<li><strong>持续监控</strong>：数据漂移检测（如 PSI 指标）、在线学习更新</li>
</ul>
<blockquote>
<p>💡 <em>你的实践延伸</em>：你用 Cloudflare Workers 部署 AI 服务，可将训练好的轻量模型（如 <code>tf-lite</code> 或 <code>ONNX</code>）嵌入 Worker，实现低延迟文本分类 API。</p>
</blockquote>
<hr>
<h2 id="核心考点总结-3"><a href="#核心考点总结-3" class="headerlink" title="核心考点总结"></a>核心考点总结</h2><table>
<thead>
<tr>
<th>考点层级</th>
<th>关键内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>流程顺序</strong></td>
<td>预处理 → 特征表示 → 建模 → 评估 → 优化 → 部署（必须按逻辑顺序答）</td>
</tr>
<tr>
<td><strong>特征表示演进</strong></td>
<td>BoW&#x2F;TF-IDF → Word2Vec → BERT（体现技术发展）</td>
</tr>
<tr>
<td><strong>评估指标选择</strong></td>
<td>多分类必须提 <strong>F1 &#x2F; Macro-F1</strong>；强调<strong>不能只用准确率</strong>（尤其不平衡时）</td>
</tr>
<tr>
<td><strong>中英文差异</strong></td>
<td>中文<strong>必须分词</strong>；英文需词干化；停用词表不同</td>
</tr>
<tr>
<td><strong>工程陷阱</strong></td>
<td>数据泄露（如在分词前统一去停用词导致测试集信息泄露）</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>数据采集</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/zhihaojiang.github.io/2025/01/03/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a class="link"   href="https://hexo.io/" >Hexo<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>! This is your very first post. Check <a class="link"   href="https://hexo.io/docs/" >documentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> for more info. If you get any problems when using Hexo, you can find the answer in <a class="link"   href="https://hexo.io/docs/troubleshooting.html" >troubleshooting<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> or you can ask me on <a class="link"   href="https://github.com/hexojs/hexo/issues" >GitHub<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/writing.html" >Writing<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/server.html" >Server<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/generating.html" >Generating<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure></div>

<p>More info: <a class="link"   href="https://hexo.io/docs/one-command-deployment.html" >Deployment<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
]]></content>
  </entry>
  <entry>
    <title>Linux操作系统-同步互斥</title>
    <url>/zhihaojiang.github.io/2025/12/24/20251224Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/</url>
    <content><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>在下列同步机制中，可以实现让权等待的是<br>A . Peterson 方法<br>B. swap 指令<br>C. 信号量方法<br>D. TestAndSet 指令</p>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：C. 信号量方法</strong></p>
<p>本题考查同步机制是否满足 <strong>“让权等待”（Wait &amp; Yield）</strong> 原则。</p>
<h4 id="🔹-什么是“让权等待”？"><a href="#🔹-什么是“让权等待”？" class="headerlink" title="🔹 什么是“让权等待”？"></a>🔹 什么是“让权等待”？</h4><ul>
<li>当进程申请临界资源失败（如进入区失败）时，<strong>主动放弃 CPU（阻塞自己）</strong>，进入等待队列，不占用处理机空转；  </li>
<li>与之相对的是 <strong>“忙等待（Busy Waiting）”</strong>：进程循环测试条件，持续占用 CPU，浪费资源。</li>
</ul>
<hr>
<h3 id="逐项分析："><a href="#逐项分析：" class="headerlink" title="逐项分析："></a>逐项分析：</h3><h4 id="A-Peterson-方法"><a href="#A-Peterson-方法" class="headerlink" title="A. Peterson 方法"></a>A. Peterson 方法</h4><p>❌ <strong>忙等待</strong>  </p>
<ul>
<li>纯软件算法，通过 <code>flag[]</code> 和 <code>turn</code> 变量实现互斥；  </li>
<li>进入临界区前循环检查条件：<code>while (flag[j] &amp;&amp; turn == j);</code>  </li>
<li><strong>持续占用 CPU</strong>，不释放处理器 → 不满足让权等待。</li>
</ul>
<h4 id="B-swap-指令"><a href="#B-swap-指令" class="headerlink" title="B. swap 指令"></a>B. swap 指令</h4><p>❌ <strong>忙等待</strong>  </p>
<ul>
<li><code>swap</code> 是原子交换指令，常用于实现<strong>自旋锁（Spinlock）</strong>；  </li>
<li>典型用法：<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (swap(&amp;lock, <span class="number">1</span>) == <span class="number">1</span>); <span class="comment">// 忙等</span></span><br></pre></td></tr></table></figure></div></li>
<li>同样<strong>循环测试，不放弃 CPU</strong> → 忙等待。</li>
</ul>
<h4 id="C-信号量方法"><a href="#C-信号量方法" class="headerlink" title="C. 信号量方法"></a>C. 信号量方法</h4><p>✅ <strong>让权等待</strong>  </p>
<ul>
<li>信号量（Semaphore）由 Dijkstra 提出，标准实现包含：<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">wait</span>(S) &#123;</span><br><span class="line">    S.value--;</span><br><span class="line">    <span class="keyword">if</span> (S.value &lt; 0) &#123;</span><br><span class="line">        block();   // 阻塞当前进程，放入等待队列</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">signal(S) &#123;</span><br><span class="line">    S.value++;</span><br><span class="line">    <span class="keyword">if</span> (S.value &lt;= 0) &#123;</span><br><span class="line">        wakeup();  // 唤醒一个等待进程</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li>当 <code>S.value &lt; 0</code> 时，进程<strong>主动阻塞（放弃 CPU）</strong>，由 OS 调度器切换到其他进程；  </li>
<li>恢复由其他进程 <code>signal()</code> 时唤醒；<br>→ <strong>满足让权等待</strong>。</li>
</ul>
<h4 id="D-TestAndSet-指令"><a href="#D-TestAndSet-指令" class="headerlink" title="D. TestAndSet 指令"></a>D. TestAndSet 指令</h4><p>❌ <strong>忙等待</strong>  </p>
<ul>
<li>硬件原子指令，用于实现自旋锁：<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (TestAndSet(&amp;lock)); <span class="comment">// 循环测试，直到为0</span></span><br></pre></td></tr></table></figure></div></li>
<li>典型用于多核系统短临界区，但仍是<strong>忙等待</strong>；  </li>
<li>不涉及进程阻塞&#x2F;唤醒机制。</li>
</ul>
<hr>
<h3 id="🎯-考点总结："><a href="#🎯-考点总结：" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>同步机制</th>
<th>是否让权等待</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>Peterson</td>
<td>❌</td>
<td>纯软件忙等</td>
</tr>
<tr>
<td>swap &#x2F; TAS</td>
<td>❌</td>
<td>自旋锁，忙等</td>
</tr>
<tr>
<td><strong>信号量</strong></td>
<td>✅</td>
<td>失败时 <code>block()</code>，进入阻塞态</td>
</tr>
<tr>
<td>管程（Monitor）</td>
<td>✅</td>
<td>条件变量 <code>wait()</code> 会阻塞</td>
</tr>
</tbody></table>
<blockquote>
<p>⚠️ 注意：信号量的<strong>具体实现</strong>可能有差异，但<strong>标准定义和教学语境下</strong>，信号量是支持让权等待的典型机制。</p>
</blockquote>
<hr>
<p>✅ 正确答案：<strong>C. 信号量方法</strong></p>
<h1 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h1><p>下列准则中实现临界区互斥机制必须遵循的是</p>
<hr>
<p>I、 两个进程不能同时进入临界区<br>II、 允许进程访问空闲的临界资源<br>III、 进程等待进入临界区的时间是有限的<br>IV、 不能进入临界区的执行态进程立即放弃 CPU<br>A. 仅Ⅰ、Ⅳ B. 仅Ⅱ、Ⅲ C. 仅Ⅰ、Ⅱ、Ⅲ D. 仅Ⅰ、Ⅲ、Ⅳ</p>
<h2 id="解析-1"><a href="#解析-1" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：C. 仅Ⅰ、Ⅱ、Ⅲ</strong></p>
<p>本题考查 <strong>临界区互斥机制必须满足的基本准则</strong>（也称 Petri 准则或并发控制四原则）。</p>
<p>标准四条准则为：</p>
<ol>
<li><strong>互斥（Mutual Exclusion）</strong>：不能有两个或以上进程同时在临界区内；  </li>
<li><strong>有空让进（Progress）</strong>：若无进程在临界区，且有进程希望进入，则<strong>不应无限推迟</strong>其进入；  </li>
<li><strong>有限等待（Bounded Waiting）</strong>：任一进程从提出请求到进入临界区的<strong>等待时间有上界</strong>；  </li>
<li><strong>让权等待（可选，非必须）</strong>：等待进程应释放 CPU（阻塞），避免忙等待 —— 这是<strong>性能&#x2F;实现要求，非正确性必要条件</strong>。</li>
</ol>
<hr>
<h3 id="逐项对应题干："><a href="#逐项对应题干：" class="headerlink" title="逐项对应题干："></a>逐项对应题干：</h3><h4 id="I-两个进程不能同时进入临界区"><a href="#I-两个进程不能同时进入临界区" class="headerlink" title="I. 两个进程不能同时进入临界区"></a>I. 两个进程不能同时进入临界区</h4><p>✅ <strong>必须遵循</strong> —— 对应 <strong>互斥原则</strong>，是临界区定义的核心。</p>
<h4 id="II-允许进程访问空闲的临界资源"><a href="#II-允许进程访问空闲的临界资源" class="headerlink" title="II. 允许进程访问空闲的临界资源"></a>II. 允许进程访问空闲的临界资源</h4><p>✅ <strong>必须遵循</strong> —— 对应 <strong>有空让进（Progress）</strong>：若临界区空闲，不应阻止进程进入（即不能因调度策略导致“假死”）。</p>
<h4 id="III-进程等待进入临界区的时间是有限的"><a href="#III-进程等待进入临界区的时间是有限的" class="headerlink" title="III. 进程等待进入临界区的时间是有限的"></a>III. 进程等待进入临界区的时间是有限的</h4><p>✅ <strong>必须遵循</strong> —— 对应 <strong>有限等待</strong>：防止饥饿（Starvation），确保公平性；若等待可无限长，则系统可能活锁或不公平。</p>
<h4 id="IV-不能进入临界区的执行态进程立即放弃-CPU"><a href="#IV-不能进入临界区的执行态进程立即放弃-CPU" class="headerlink" title="IV. 不能进入临界区的执行态进程立即放弃 CPU"></a>IV. 不能进入临界区的执行态进程立即放弃 CPU</h4><p>❌ <strong>非必须遵循</strong>  </p>
<ul>
<li>这是 <strong>“让权等待”</strong> 的要求，属于<strong>实现优化</strong>，非正确性前提；  </li>
<li>例如 <strong>Peterson 算法、TestAndSet 自旋锁</strong> 都是<strong>忙等待</strong>（不放弃 CPU），但仍能<strong>正确实现互斥</strong>；  </li>
<li>在单处理机系统或短临界区场景下，忙等待可接受；  </li>
<li>是否让权，取决于 OS 设计，<strong>不影响互斥机制的逻辑正确性</strong>。</li>
</ul>
<hr>
<h3 id="🎯-考点总结：-1"><a href="#🎯-考点总结：-1" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>准则</th>
<th>是否必须</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>互斥（I）</td>
<td>✅ 是</td>
<td>核心要求</td>
</tr>
<tr>
<td>有空让进（II）</td>
<td>✅ 是</td>
<td>避免无谓阻塞</td>
</tr>
<tr>
<td>有限等待（III）</td>
<td>✅ 是</td>
<td>防止饥饿</td>
</tr>
<tr>
<td>让权等待（IV）</td>
<td>❌ 否</td>
<td>属于性能&#x2F;实现策略</td>
</tr>
</tbody></table>
<blockquote>
<p>📚 参考：《操作系统概念》（Silberschatz）—— 临界区问题的三条件：Mutual Exclusion, Progress, Bounded Waiting<br>（注意：书中明确指出，<strong>忙等待算法可满足前三者，但违反“非忙等待”这一额外期望</strong>）</p>
</blockquote>
<hr>
<p>✅ 正确答案：<strong>C. 仅Ⅰ、Ⅱ、Ⅲ</strong></p>
<h1 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h1><p>设与某资源关联的信号量初值为 3，当前值为 1。若 M 表示该资源的可用个数，N 表示等待该资源的进程<br>数，则 M、N 分别是</p>
<hr>
<p>。(2010)<br>A．0、1 B．1、0 C．1、2 D．2、0</p>
<h2 id="解析-2"><a href="#解析-2" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：B．1、0</strong></p>
<p>本题考查 <strong>信号量物理意义的理解</strong>。</p>
<p>设某类资源有 <strong>多个实例</strong>（如打印机、缓冲区），用<strong>计数信号量（Counting Semaphore）</strong> 管理。</p>
<ul>
<li><strong>信号量的值 <code>S</code> 表示：当前可用资源数（若 <code>S ≥ 0</code>）；<br>若 <code>S &lt; 0</code>，则 <code>|S|</code> 表示等待该资源的进程数</strong>。</li>
</ul>
<p>更精确地说：</p>
<p>$$<br>\begin{cases}<br>S &gt; 0 &amp;\Rightarrow \text{有 } S \text{ 个资源空闲}，\text{无进程等待} \<br>S &#x3D; 0 &amp;\Rightarrow \text{资源刚好用完}，\text{无进程等待} \<br>S &lt; 0 &amp;\Rightarrow \text{无空闲资源}，\text{有 } |S| \text{ 个进程阻塞等待}<br>\end{cases}<br>$$</p>
<hr>
<h3 id="题目条件："><a href="#题目条件：" class="headerlink" title="题目条件："></a>题目条件：</h3><ul>
<li>信号量初值 &#x3D; 3 → 系统共有 <strong>3 个该类资源</strong>  </li>
<li>当前值 &#x3D; 1</li>
</ul>
<p>→ 因为 <strong>1 &gt; 0</strong>，所以：  </p>
<ul>
<li><strong>可用资源数 M &#x3D; 1</strong>  </li>
<li><strong>等待进程数 N &#x3D; 0</strong></li>
</ul>
<hr>
<h3 id="🔍-验证过程："><a href="#🔍-验证过程：" class="headerlink" title="🔍 验证过程："></a>🔍 验证过程：</h3><ul>
<li>初始：S &#x3D; 3（3 个空闲资源）  </li>
<li>某进程执行 <code>wait()</code>（P 操作）：S &#x3D; 2  </li>
<li>再一个 <code>wait()</code>：S &#x3D; 1<br>→ 此时 2 个资源已被占用，1 个空闲，无等待进程。</li>
</ul>
<p>即：  </p>
<ul>
<li>已分配资源数 &#x3D; 初值 − 当前值 &#x3D; 3 − 1 &#x3D; 2  </li>
<li>可用资源 M &#x3D; 当前值 &#x3D; <strong>1</strong>（因 S &gt; 0）  </li>
<li>等待进程 N &#x3D; max(0, −S) &#x3D; 0</li>
</ul>
<hr>
<h3 id="❌-排除干扰选项："><a href="#❌-排除干扰选项：" class="headerlink" title="❌ 排除干扰选项："></a>❌ 排除干扰选项：</h3><ul>
<li>A（0,1）：对应 S &#x3D; −1（1 个等待，0 个空闲）  </li>
<li>C（1,2）：矛盾（有 1 个空闲，怎会 2 个等待？）  </li>
<li>D（2,0）：对应 S &#x3D; 2</li>
</ul>
<hr>
<h3 id="🎯-考点总结：-2"><a href="#🎯-考点总结：-2" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><ul>
<li>信号量值 &#x3D; 可用资源数（当 ≥ 0）  </li>
<li>等待进程数 &#x3D; <code>max(0, −S)</code>  </li>
<li>资源总数 &#x3D; 初值 &#x3D; 可用 + 已分配  </li>
<li>已分配 &#x3D; 初值 − max(S, 0)</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>B．1、0</strong></p>
<h1 id="题目-3"><a href="#题目-3" class="headerlink" title="题目"></a>题目</h1><p>使用TSL(Test and Set Lock)指令实现进程互斥的伪代码如下所示。<br>do {<br>……<br>while(TSL(&amp;lock))；<br>critical section；<br>lock&#x3D;FALSE；<br>……<br>} while(TRUE)；<br>下列与该实现机制相关的叙述中，正确的是</p>
<hr>
<p>A．退出临界区的进程负责唤醒阻塞态进程<br>B．等待进入临界区的进程不会主动放弃CPU<br>C．上述伪代码满足“让权等待”的同步准则<br>D．while(TSL(&amp;lock))语句应在关中断状态下执行</p>
<h2 id="解析-3"><a href="#解析-3" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：B．等待进入临界区的进程不会主动放弃CPU</strong></p>
<p>本题考查 <strong>TSL（Test-and-Set Lock）指令实现的互斥机制特性</strong>。</p>
<p>给出的伪代码是典型的<strong>自旋锁（Spinlock）</strong> 实现：</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">while</span> (TSL(&amp;lock));   <span class="comment">// 忙等待：反复测试并设置 lock</span></span><br><span class="line">    critical section;</span><br><span class="line">    lock = FALSE;         <span class="comment">// 退出临界区，释放锁</span></span><br><span class="line">    ...</span><br><span class="line">&#125; <span class="keyword">while</span> (TRUE);</span><br></pre></td></tr></table></figure></div>

<p>其中 <code>TSL(&amp;lock)</code> 是原子操作，等价于：</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> <span class="title function_">TSL</span><span class="params">(<span class="type">bool</span> *lock)</span> &#123;</span><br><span class="line">    <span class="type">bool</span> old = *lock;</span><br><span class="line">    *lock = TRUE;</span><br><span class="line">    <span class="keyword">return</span> old;   <span class="comment">// 返回原值：若原为 FALSE（未锁），返回 FALSE，退出循环</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>即：<strong>只有当 lock 原为 FALSE 时，TSL 返回 FALSE，循环结束，进程进入临界区</strong>。</p>
<hr>
<h3 id="逐项分析选项："><a href="#逐项分析选项：" class="headerlink" title="逐项分析选项："></a>逐项分析选项：</h3><h4 id="A．退出临界区的进程负责唤醒阻塞态进程"><a href="#A．退出临界区的进程负责唤醒阻塞态进程" class="headerlink" title="A．退出临界区的进程负责唤醒阻塞态进程"></a>A．退出临界区的进程负责唤醒阻塞态进程</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li>TSL 实现的是<strong>忙等待</strong>，等待进程处于<strong>运行态（就绪&#x2F;执行）</strong>，<strong>并非阻塞态</strong>；  </li>
<li>它们在 <code>while</code> 循环中不断执行 TSL，<strong>持续占用 CPU</strong>；  </li>
<li>退出时只需 <code>lock = FALSE</code>，<strong>无需唤醒操作</strong>（无进程在等待队列中）；  </li>
<li>唤醒机制存在于<strong>信号量、管程等阻塞式同步机制</strong>中，<strong>TSL 不具备</strong>。</li>
</ul>
<h4 id="B．等待进入临界区的进程不会主动放弃CPU"><a href="#B．等待进入临界区的进程不会主动放弃CPU" class="headerlink" title="B．等待进入临界区的进程不会主动放弃CPU"></a>B．等待进入临界区的进程不会主动放弃CPU</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li><code>while (TSL(&amp;lock));</code> 是一个<strong>空循环</strong>，进程反复测试 lock 状态；  </li>
<li>只要 lock &#x3D;&#x3D; TRUE，就继续循环，<strong>不调用 sleep、yield 或 block</strong>；  </li>
<li>因此，<strong>CPU 一直被该进程占用</strong>，属于典型的<strong>忙等待（Busy Waiting）</strong>；<br>→ 符合 TSL&#x2F;自旋锁的本质特征。</li>
</ul>
<h4 id="C．上述伪代码满足“让权等待”的同步准则"><a href="#C．上述伪代码满足“让权等待”的同步准则" class="headerlink" title="C．上述伪代码满足“让权等待”的同步准则"></a>C．上述伪代码满足“让权等待”的同步准则</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li>“让权等待”要求：<strong>进程等待时主动释放 CPU（进入阻塞态）</strong>；  </li>
<li>而本代码是忙等待，<strong>违反让权等待</strong>；  </li>
<li>满足“让权等待”的是信号量、条件变量等机制。</li>
</ul>
<h4 id="D．while-TSL-lock-语句应在关中断状态下执行"><a href="#D．while-TSL-lock-语句应在关中断状态下执行" class="headerlink" title="D．while(TSL(&amp;lock))语句应在关中断状态下执行"></a>D．<code>while(TSL(&amp;lock))</code>语句应在关中断状态下执行</h4><p>❌ <strong>错误</strong>。  </p>
<ul>
<li>TSL 是<strong>硬件提供的原子指令</strong>，其执行本身是不可中断的（原子性由 CPU 保证）；  </li>
<li>不需要关中断；  </li>
<li><strong>关中断</strong>用于保护<strong>临界区本身</strong>（如修改内核数据结构），而非用于 TSL 测试；  </li>
<li>若关中断执行长时间忙等待，会导致<strong>系统无法响应时钟中断</strong>，丢失调度，极其危险！</li>
</ul>
<blockquote>
<p>✅ 正确做法：TSL 本身是原子的，可开中断执行；但临界区若涉及内核数据，需关中断或使用更高级同步。</p>
</blockquote>
<hr>
<h3 id="🎯-考点总结：-3"><a href="#🎯-考点总结：-3" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>机制</th>
<th>是否忙等待</th>
<th>是否让权等待</th>
<th>是否需唤醒</th>
<th>典型场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>TSL &#x2F; TAS &#x2F; Swap</strong></td>
<td>✅ 是</td>
<td>❌ 否</td>
<td>❌ 否</td>
<td>多核短临界区、内核自旋锁</td>
</tr>
<tr>
<td><strong>信号量（block&#x2F;wakeup）</strong></td>
<td>❌ 否</td>
<td>✅ 是</td>
<td>✅ 是</td>
<td>用户态长临界区</td>
</tr>
<tr>
<td><strong>Peterson 算法</strong></td>
<td>✅ 是</td>
<td>❌ 否</td>
<td>❌ 否</td>
<td>单处理机软件互斥</td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>B</strong></p>
<h1 id="题目-4"><a href="#题目-4" class="headerlink" title="题目"></a>题目</h1><p>下列关于管程的叙述中，错误的是______<br>。(2016)<br>A．管程只能用于实现进程的互斥<br>B．管程是由编程语言支持的进程同步机制<br>C．任何时候只能有一个进程在管程中执行<br>D．管程中定义的变量只能被管程内的过程访问</p>
<h2 id="解析-4"><a href="#解析-4" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：A．管程只能用于实现进程的互斥</strong></p>
<p>本题考查对 <strong>管程（Monitor）</strong> 概念的理解。</p>
<p>管程是一种<strong>高级同步机制</strong>，由 Hoare 和 Brinch Hansen 提出，广泛用于操作系统和编程语言（如 Java 的 <code>synchronized</code> 基于管程思想）。</p>
<p>我们逐项分析：</p>
<hr>
<h4 id="A．管程只能用于实现进程的互斥"><a href="#A．管程只能用于实现进程的互斥" class="headerlink" title="A．管程只能用于实现进程的互斥"></a>A．管程只能用于实现进程的互斥</h4><p>❌ <strong>错误</strong>（本题答案）  </p>
<ul>
<li>管程不仅能实现<strong>互斥</strong>，更能实现<strong>进程同步（协作）</strong>；  </li>
<li>关键在于 <strong>条件变量（condition variable）</strong>：  <ul>
<li><code>wait(cv)</code>：释放管程锁 + 阻塞进程  </li>
<li><code>signal(cv)</code> &#x2F; <code>notify(cv)</code>：唤醒等待进程</li>
</ul>
</li>
<li>典型应用：  <ul>
<li>生产者-消费者问题  </li>
<li>读者-写者问题  </li>
<li>哲学家进餐问题<br>→ 管程是<strong>互斥 + 同步</strong>的统一机制，<strong>A 说法片面，错误</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="B．管程是由编程语言支持的进程同步机制"><a href="#B．管程是由编程语言支持的进程同步机制" class="headerlink" title="B．管程是由编程语言支持的进程同步机制"></a>B．管程是由编程语言支持的进程同步机制</h4><p>✅ <strong>正确</strong>  </p>
<ul>
<li>管程通常由<strong>语言层面提供语法支持</strong>：  <ul>
<li>Pascal 的 <code>monitor</code> 关键字（早期）  </li>
<li>Java 的 <code>synchronized</code> 方法&#x2F;块 + <code>wait()/notify()</code>  </li>
<li>C# 的 <code>lock</code> + <code>Monitor</code> 类</li>
</ul>
</li>
<li>编译器&#x2F;运行时负责生成进入&#x2F;退出管程的同步代码；<br>→ 不同于信号量（需程序员手动调用 P&#x2F;V），管程是<strong>语言级抽象</strong>。</li>
</ul>
<hr>
<h4 id="C．任何时候只能有一个进程在管程中执行"><a href="#C．任何时候只能有一个进程在管程中执行" class="headerlink" title="C．任何时候只能有一个进程在管程中执行"></a>C．任何时候只能有一个进程在管程中执行</h4><p>✅ <strong>正确</strong>  </p>
<ul>
<li>管程的<strong>核心语义</strong>：  <blockquote>
<p>“At most one process can be active in the monitor at a time.”  </p>
</blockquote>
</li>
<li>管程自带一个<strong>隐式互斥锁（mutex）</strong>：  <ul>
<li>进程进入管程内任何过程前，必须先获得锁；  </li>
<li>退出时自动释放锁；</li>
</ul>
</li>
<li>即使有多个条件变量，也<strong>只允许一个进程在管程内执行代码</strong>（调用 <code>wait()</code> 时会临时释放锁，但不算“执行中”）。</li>
</ul>
<hr>
<h4 id="D．管程中定义的变量只能被管程内的过程访问"><a href="#D．管程中定义的变量只能被管程内的过程访问" class="headerlink" title="D．管程中定义的变量只能被管程内的过程访问"></a>D．管程中定义的变量只能被管程内的过程访问</h4><p>✅ <strong>正确</strong>  </p>
<ul>
<li>这是管程的<strong>封装性（Encapsulation）</strong> 特征；  </li>
<li>管程内部的共享变量（如 buffer、count）是<strong>私有（private）</strong> 的；  </li>
<li>外部进程只能通过管程提供的<strong>入口过程（entry procedure）</strong> 间接访问；<br>→ 避免了竞争条件，保证数据一致性。</li>
</ul>
<hr>
<h3 id="🎯-考点总结：-4"><a href="#🎯-考点总结：-4" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>特性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>功能</strong></td>
<td>互斥 + 同步（A 错在“只能互斥”）</td>
</tr>
<tr>
<td><strong>实现层级</strong></td>
<td>语言支持（B 正确）</td>
</tr>
<tr>
<td><strong>并发控制</strong></td>
<td>任一时刻最多一个进程活跃（C 正确）</td>
</tr>
<tr>
<td><strong>数据封装</strong></td>
<td>内部变量私有，仅通过过程访问（D 正确）</td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>A</strong></p>
<h1 id="题目-5"><a href="#题目-5" class="headerlink" title="题目"></a>题目</h1><p>.进程P1和P2均包含并发执行的线程，部分伪代码描述如下所示。<br>下列选项中，需要互斥执行的操作是______<br>。(2016)<br>A．a&#x3D;1与a&#x3D;2 B．a&#x3D;x与b&#x3D;x<br>C．x+&#x3D;1与x+&#x3D;2 D．x+&#x3D;1与x+&#x3D;3</p>
<h3 id="伪代码："><a href="#伪代码：" class="headerlink" title="伪代码："></a>伪代码：</h3><p><strong>进程 P1：</strong></p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> x=<span class="number">0</span>;</span><br><span class="line">Thread1() &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    a=<span class="number">1</span>;  x+=<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">Thread2() &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    a=<span class="number">2</span>;  x+=<span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><strong>进程 P2：</strong></p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> x=<span class="number">0</span>;</span><br><span class="line">Thread3() &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    a=x;  x+=<span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line">Thread4() &#123;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line">    b=x;  x+=<span class="number">4</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="解析-5"><a href="#解析-5" class="headerlink" title="解析"></a>解析</h2><blockquote>
<p>注意：x 是<strong>全局共享变量</strong>（每个进程内定义一个 x，但 P1 和 P2 的 x 不共享；但在每个进程中，多个线程共享该进程内的 x）。</p>
</blockquote>
<hr>
<h3 id="题目问：“需要互斥执行的操作”-——-即哪些操作对共享变量-x-的访问可能产生竞态条件（Race-Condition），需加锁保护。"><a href="#题目问：“需要互斥执行的操作”-——-即哪些操作对共享变量-x-的访问可能产生竞态条件（Race-Condition），需加锁保护。" class="headerlink" title="题目问：“需要互斥执行的操作” —— 即哪些操作对共享变量 x 的访问可能产生竞态条件（Race Condition），需加锁保护。"></a>题目问：“需要互斥执行的操作” —— 即哪些操作对共享变量 x 的访问<strong>可能产生竞态条件（Race Condition）</strong>，需加锁保护。</h3><p>我们看每个选项：</p>
<h4 id="A-a-1-与-a-2"><a href="#A-a-1-与-a-2" class="headerlink" title="A. a=1 与 a=2"></a>A. <code>a=1</code> 与 <code>a=2</code></h4><ul>
<li>a 是局部变量，每个线程有自己的栈空间 → <strong>不共享</strong><br>→ 无竞争 → ❌ 不需要互斥</li>
</ul>
<h4 id="B-a-x-与-b-x"><a href="#B-a-x-与-b-x" class="headerlink" title="B. a=x 与 b=x"></a>B. <code>a=x</code> 与 <code>b=x</code></h4><ul>
<li>在 P2 中：<ul>
<li>Thread3: <code>a = x</code> （读 x）</li>
<li>Thread4: <code>b = x</code> （读 x）</li>
</ul>
</li>
<li>两个都是<strong>读操作</strong>，即使并发执行，也不会破坏数据一致性（只要没有写入）<br>→ <strong>无竞态</strong> → ❌ 不需要互斥</li>
</ul>
<h4 id="C-x-1-与-x-2"><a href="#C-x-1-与-x-2" class="headerlink" title="C. x+=1 与 x+=2"></a>C. <code>x+=1</code> 与 <code>x+=2</code></h4><ul>
<li>在 P1 中：<ul>
<li>Thread1: <code>x += 1</code>  </li>
<li>Thread2: <code>x += 2</code></li>
</ul>
</li>
<li><code>x += n</code> 是<strong>复合操作</strong>（读取 x → 计算 x+n → 写回 x），<strong>非原子操作</strong>  </li>
<li>若并发执行，可能发生：<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Thread1: 读 x=0 → 计算 0+1=1 → 写回 x=1</span><br><span class="line">Thread2: 读 x=0 → 计算 0+2=2 → 写回 x=2   ← 覆盖了 Thread1 的结果！</span><br></pre></td></tr></table></figure></div>
→ 最终 x &#x3D; 2，而不是期望的 3 → <strong>竞态条件</strong><br>✅ <strong>需要互斥</strong></li>
</ul>
<h4 id="D-x-1-与-x-3"><a href="#D-x-1-与-x-3" class="headerlink" title="D. x+=1 与 x+=3"></a>D. <code>x+=1</code> 与 <code>x+=3</code></h4><ul>
<li><code>x+=1</code> 在 P1，<code>x+=3</code> 在 P2  </li>
<li>P1 和 P2 是<strong>不同进程</strong>，各自有独立的 <code>x</code> 变量（进程间内存隔离）<br>→ <strong>不共享同一个 x</strong> → 无竞争<br>❌ 不需要互斥</li>
</ul>
<hr>
<h3 id="✅-正确答案：C-x-1-与-x-2"><a href="#✅-正确答案：C-x-1-与-x-2" class="headerlink" title="✅ 正确答案：C. x+&#x3D;1 与 x+&#x3D;2"></a>✅ 正确答案：<strong>C. x+&#x3D;1 与 x+&#x3D;2</strong></h3><h1 id="题目-6"><a href="#题目-6" class="headerlink" title="题目"></a>题目</h1><p>属于同一进程的两个线程 thread1 和 thread2 并发执行，共享初值为 0 的全局变量 x。 thread1 和 thread2 实现对全局变量 x 加 1 的机器级代<br>码描述如下,在所有可能的指令执行序列中，使 x 的值为 2 的序列个数是______<br>。(2018)<br>A. 1 B. 2 C.3 D.4</p>
<h2 id="解析-6"><a href="#解析-6" class="headerlink" title="解析"></a>解析</h2><p>我们来分析这道经典的<strong>并发线程竞态条件</strong>题目。</p>
<hr>
<h3 id="📜-题目描述："><a href="#📜-题目描述：" class="headerlink" title="📜 题目描述："></a>📜 题目描述：</h3><ul>
<li>同一进程内有两个线程：<code>thread1</code> 和 <code>thread2</code>  </li>
<li>共享全局变量 <code>x</code>，初始值为 0  </li>
<li>每个线程执行“对 x 加 1”的操作，用机器级指令实现：<ul>
<li><code>mov R, x</code> → 将 x 的值读入寄存器  </li>
<li><code>inc R</code> → 寄存器值加 1  </li>
<li><code>mov x, R</code> → 将寄存器值写回 x</li>
</ul>
</li>
</ul>
<p>目标：在所有可能的指令交错序列中，<strong>有多少种序列最终使 x &#x3D; 2</strong>？</p>
<hr>
<h2 id="✅-关键点："><a href="#✅-关键点：" class="headerlink" title="✅ 关键点："></a>✅ 关键点：</h2><p>虽然每个线程都在做“x++”，但由于是<strong>非原子操作</strong>（三步），若两个线程交错执行，可能导致<strong>丢失更新</strong>，最终 x 可能为 1 或 2。</p>
<p>我们需要枚举所有可能的<strong>指令交错序列</strong>，并统计哪些最终得到 <code>x = 2</code>。</p>
<hr>
<h2 id="🔢-总指令数："><a href="#🔢-总指令数：" class="headerlink" title="🔢 总指令数："></a>🔢 总指令数：</h2><ul>
<li>thread1：3 条指令（记为 A1, A2, A3）  </li>
<li>thread2：3 条指令（记为 B1, B2, B3）<br>→ 总共 6 条指令，从中选 3 个位置给 thread1，其余给 thread2 → 总序列数 &#x3D; $ \binom{6}{3} &#x3D; 20 $ 种</li>
</ul>
<p>但并非所有 20 种都导致不同结果 —— 我们只需关注<strong>最终 x 的值</strong>。</p>
<hr>
<h2 id="✅-正确结果：x-2-当且仅当-两个线程的写操作没有覆盖对方的结果"><a href="#✅-正确结果：x-2-当且仅当-两个线程的写操作没有覆盖对方的结果" class="headerlink" title="✅ 正确结果：x&#x3D;2 当且仅当 两个线程的写操作没有覆盖对方的结果"></a>✅ 正确结果：x&#x3D;2 当且仅当 <strong>两个线程的写操作没有覆盖对方的结果</strong></h2><p>即：<strong>两个线程都成功将自己计算后的值写回 x，且没有被对方覆盖</strong>。</p>
<p>这要求：<strong>两个线程的“写回”指令（A3 和 B3）必须发生在对方“读取”之后、或不干扰彼此</strong>。</p>
<hr>
<h3 id="🧩-枚举关键情况："><a href="#🧩-枚举关键情况：" class="headerlink" title="🧩 枚举关键情况："></a>🧩 枚举关键情况：</h3><p>我们用简写表示：</p>
<ul>
<li>A1: mov R1, x  </li>
<li>A2: inc R1  </li>
<li>A3: mov x, R1  </li>
<li>B1: mov R2, x  </li>
<li>B2: inc R2  </li>
<li>B3: mov x, R2</li>
</ul>
<p>我们要找的是：<strong>最终 x&#x3D;2</strong> 的序列。</p>
<hr>
<h3 id="🎯-情况-1：无交错（完全串行）"><a href="#🎯-情况-1：无交错（完全串行）" class="headerlink" title="🎯 情况 1：无交错（完全串行）"></a>🎯 情况 1：无交错（完全串行）</h3><h4 id="1-A1→A2→A3→B1→B2→B3"><a href="#1-A1→A2→A3→B1→B2→B3" class="headerlink" title="1. A1→A2→A3→B1→B2→B3"></a>1. A1→A2→A3→B1→B2→B3</h4><ul>
<li>A 读 0 → 加 1 → 写 1  </li>
<li>B 读 1 → 加 1 → 写 2<br>→ x&#x3D;2 ✅</li>
</ul>
<h4 id="2-B1→B2→B3→A1→A2→A3"><a href="#2-B1→B2→B3→A1→A2→A3" class="headerlink" title="2. B1→B2→B3→A1→A2→A3"></a>2. B1→B2→B3→A1→A2→A3</h4><ul>
<li>B 读 0 → 加 1 → 写 1  </li>
<li>A 读 1 → 加 1 → 写 2<br>→ x&#x3D;2 ✅</li>
</ul>
<p>→ <strong>2 种序列</strong></p>
<hr>
<h3 id="🎯-情况-2：部分交错，但写操作未被覆盖"><a href="#🎯-情况-2：部分交错，但写操作未被覆盖" class="headerlink" title="🎯 情况 2：部分交错，但写操作未被覆盖"></a>🎯 情况 2：部分交错，但写操作未被覆盖</h3><h4 id="3-A1→B1→A2→B2→A3→B3"><a href="#3-A1→B1→A2→B2→A3→B3" class="headerlink" title="3. A1→B1→A2→B2→A3→B3"></a>3. A1→B1→A2→B2→A3→B3</h4><ul>
<li>A 读 0  </li>
<li>B 读 0  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1 ❌ → 最终 x&#x3D;1</li>
</ul>
<h4 id="4-A1→B1→A2→A3→B2→B3"><a href="#4-A1→B1→A2→A3→B2→B3" class="headerlink" title="4. A1→B1→A2→A3→B2→B3"></a>4. A1→B1→A2→A3→B2→B3</h4><ul>
<li>A 读 0  </li>
<li>B 读 0  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1 ❌</li>
</ul>
<h4 id="5-A1→B1→B2→A2→A3→B3"><a href="#5-A1→B1→B2→A2→A3→B3" class="headerlink" title="5. A1→B1→B2→A2→A3→B3"></a>5. A1→B1→B2→A2→A3→B3</h4><ul>
<li>A 读 0  </li>
<li>B 读 0  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1 ❌</li>
</ul>
<h4 id="6-A1→A2→B1→B2→A3→B3"><a href="#6-A1→A2→B1→B2→A3→B3" class="headerlink" title="6. A1→A2→B1→B2→A3→B3"></a>6. A1→A2→B1→B2→A3→B3</h4><ul>
<li>A 读 0 → 加 1 → R1&#x3D;1  </li>
<li>B 读 0 → 加 1 → R2&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1 ❌</li>
</ul>
<h4 id="7-A1→A2→B1→A3→B2→B3"><a href="#7-A1→A2→B1→A3→B2→B3" class="headerlink" title="7. A1→A2→B1→A3→B2→B3"></a>7. A1→A2→B1→A3→B2→B3</h4><ul>
<li>A 读 0 → 加 1 → R1&#x3D;1  </li>
<li>B 读 0 → R2&#x3D;0  </li>
<li>A 写 1 → x&#x3D;1  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1 ❌</li>
</ul>
<h4 id="8-B1→A1→B2→A2→B3→A3"><a href="#8-B1→A1→B2→A2→B3→A3" class="headerlink" title="8. B1→A1→B2→A2→B3→A3"></a>8. B1→A1→B2→A2→B3→A3</h4><ul>
<li>B 读 0  </li>
<li>A 读 0  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1 ❌</li>
</ul>
<h4 id="9-B1→A1→B2→B3→A2→A3"><a href="#9-B1→A1→B2→B3→A2→A3" class="headerlink" title="9. B1→A1→B2→B3→A2→A3"></a>9. B1→A1→B2→B3→A2→A3</h4><ul>
<li>B 读 0  </li>
<li>A 读 0  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1 ❌</li>
</ul>
<h4 id="10-B1→B2→A1→A2→B3→A3"><a href="#10-B1→B2→A1→A2→B3→A3" class="headerlink" title="10. B1→B2→A1→A2→B3→A3"></a>10. B1→B2→A1→A2→B3→A3</h4><ul>
<li>B 读 0 → 加 1 → R2&#x3D;1  </li>
<li>A 读 0 → 加 1 → R1&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1 ❌</li>
</ul>
<hr>
<h3 id="🎯-唯一能使-x-2-的情况："><a href="#🎯-唯一能使-x-2-的情况：" class="headerlink" title="🎯 唯一能使 x&#x3D;2 的情况："></a>🎯 唯一能使 x&#x3D;2 的情况：</h3><p>只有当<strong>一个线程写完后，另一个线程再读取该值</strong>，才能叠加。</p>
<p>即：</p>
<h4 id="✅-序列-1：A1→A2→A3→B1→B2→B3"><a href="#✅-序列-1：A1→A2→A3→B1→B2→B3" class="headerlink" title="✅ 序列 1：A1→A2→A3→B1→B2→B3"></a>✅ 序列 1：A1→A2→A3→B1→B2→B3</h4><ul>
<li>A 写 1 → B 读 1 → 加 1 → 写 2</li>
</ul>
<h4 id="✅-序列-2：B1→B2→B3→A1→A2→A3"><a href="#✅-序列-2：B1→B2→B3→A1→A2→A3" class="headerlink" title="✅ 序列 2：B1→B2→B3→A1→A2→A3"></a>✅ 序列 2：B1→B2→B3→A1→A2→A3</h4><ul>
<li>B 写 1 → A 读 1 → 加 1 → 写 2</li>
</ul>
<h4 id="✅-序列-3：A1→B1→B2→B3→A2→A3"><a href="#✅-序列-3：A1→B1→B2→B3→A2→A3" class="headerlink" title="✅ 序列 3：A1→B1→B2→B3→A2→A3"></a>✅ 序列 3：A1→B1→B2→B3→A2→A3</h4><ul>
<li>A 读 0  </li>
<li>B 读 0 → 加 1 → 写 1  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1 ❌</li>
</ul>
<p>等等 —— 等等！有没有第三种？</p>
<p>让我们思考：</p>
<p>如果线程1先读 x&#x3D;0，然后线程2完成全部操作（读0→加1→写1），然后线程1再加1→写1 → x&#x3D;1 ❌</p>
<p>除非线程1在写之前，线程2已经写过，但线程1仍保留旧值。</p>
<p>所以唯一能让 x&#x3D;2 的是：</p>
<blockquote>
<p><strong>两个线程的“读取”操作发生在不同的时间点，且后写的线程读到了前一个线程写入的值。</strong></p>
</blockquote>
<p>也就是说：</p>
<ul>
<li>要么 A 先写，B 后读；  </li>
<li>要么 B 先写，A 后读。</li>
</ul>
<p>但注意：<strong>只要有一个线程在另一个线程写入后读取，就能得到 2</strong>。</p>
<hr>
<h3 id="🧠-正确方法：枚举所有-20-种序列，统计-x-2-的数量"><a href="#🧠-正确方法：枚举所有-20-种序列，统计-x-2-的数量" class="headerlink" title="🧠 正确方法：枚举所有 20 种序列，统计 x&#x3D;2 的数量"></a>🧠 正确方法：枚举所有 20 种序列，统计 x&#x3D;2 的数量</h3><p>我们用更系统的方法：</p>
<p>最终 x&#x3D;2 的充要条件是：<strong>两个线程的写操作都没有被覆盖</strong>，即：</p>
<ul>
<li>两个线程都成功将“自己的 +1 结果”写回 x，且没有被对方覆盖。</li>
</ul>
<p>这要求：<strong>两个写操作（A3 和 B3）之间，不能有“读取+写入”的完整序列覆盖</strong>。</p>
<p>实际上，只有两种情况满足：</p>
<ol>
<li>A 完整执行完毕（A1→A2→A3），然后 B 执行（B1→B2→B3）  </li>
<li>B 完整执行完毕（B1→B2→B3），然后 A 执行（A1→A2→A3）</li>
</ol>
<p>→ 这就是我们之前说的 2 种。</p>
<p>但等等 —— 还有一种可能：</p>
<h4 id="✅-序列-3：A1→A2→B1→B2→B3→A3"><a href="#✅-序列-3：A1→A2→B1→B2→B3→A3" class="headerlink" title="✅ 序列 3：A1→A2→B1→B2→B3→A3"></a>✅ 序列 3：A1→A2→B1→B2→B3→A3</h4><ul>
<li>A 读 0 → 加 1 → R1&#x3D;1  </li>
<li>B 读 0 → 加 1 → R2&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1 ❌</li>
</ul>
<p>不行。</p>
<h4 id="✅-序列-4：A1→B1→A2→B2→B3→A3"><a href="#✅-序列-4：A1→B1→A2→B2→B3→A3" class="headerlink" title="✅ 序列 4：A1→B1→A2→B2→B3→A3"></a>✅ 序列 4：A1→B1→A2→B2→B3→A3</h4><ul>
<li>A 读 0  </li>
<li>B 读 0  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1 ❌</li>
</ul>
<p>还是 1。</p>
<hr>
<h3 id="🚫-有没有第三种？"><a href="#🚫-有没有第三种？" class="headerlink" title="🚫 有没有第三种？"></a>🚫 有没有第三种？</h3><p>考虑：</p>
<h4 id="✅-序列：A1→B1→B2→A2→B3→A3"><a href="#✅-序列：A1→B1→B2→A2→B3→A3" class="headerlink" title="✅ 序列：A1→B1→B2→A2→B3→A3"></a>✅ 序列：A1→B1→B2→A2→B3→A3</h4><ul>
<li>A 读 0  </li>
<li>B 读 0  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1 ❌</li>
</ul>
<p>还是 1。</p>
<hr>
<h3 id="💡-突破点："><a href="#💡-突破点：" class="headerlink" title="💡 突破点："></a>💡 突破点：</h3><p>其实，只有当<strong>一个线程的写操作发生在另一个线程的读操作之后</strong>，并且<strong>该读操作读到了前一个线程写入的值</strong>，才能叠加。</p>
<p>例如：</p>
<h4 id="✅-序列：A1→A2→A3→B1→B2→B3-→-x-2"><a href="#✅-序列：A1→A2→A3→B1→B2→B3-→-x-2" class="headerlink" title="✅ 序列：A1→A2→A3→B1→B2→B3 → x&#x3D;2"></a>✅ 序列：A1→A2→A3→B1→B2→B3 → x&#x3D;2</h4><h4 id="✅-序列：B1→B2→B3→A1→A2→A3-→-x-2"><a href="#✅-序列：B1→B2→B3→A1→A2→A3-→-x-2" class="headerlink" title="✅ 序列：B1→B2→B3→A1→A2→A3 → x&#x3D;2"></a>✅ 序列：B1→B2→B3→A1→A2→A3 → x&#x3D;2</h4><h4 id="✅-序列：A1→B1→B2→B3→A2→A3-→-x-1-❌"><a href="#✅-序列：A1→B1→B2→B3→A2→A3-→-x-1-❌" class="headerlink" title="✅ 序列：A1→B1→B2→B3→A2→A3 → x&#x3D;1 ❌"></a>✅ 序列：A1→B1→B2→B3→A2→A3 → x&#x3D;1 ❌</h4><h4 id="✅-序列：B1→A1→A2→A3→B2→B3-→-x-1-❌"><a href="#✅-序列：B1→A1→A2→A3→B2→B3-→-x-1-❌" class="headerlink" title="✅ 序列：B1→A1→A2→A3→B2→B3 → x&#x3D;1 ❌"></a>✅ 序列：B1→A1→A2→A3→B2→B3 → x&#x3D;1 ❌</h4><p>等等。</p>
<p>我们发现：<strong>只有完全串行的两种情况能得到 x&#x3D;2</strong>。</p>
<p>但等等！看这个：</p>
<h4 id="✅-序列：A1→B1→A2→B2→A3→B3"><a href="#✅-序列：A1→B1→A2→B2→A3→B3" class="headerlink" title="✅ 序列：A1→B1→A2→B2→A3→B3"></a>✅ 序列：A1→B1→A2→B2→A3→B3</h4><ul>
<li>A 读 0  </li>
<li>B 读 0  </li>
<li>A 加 1 → R1&#x3D;1  </li>
<li>B 加 1 → R2&#x3D;1  </li>
<li>A 写 1 → x&#x3D;1  </li>
<li>B 写 1 → x&#x3D;1 ❌</li>
</ul>
<p>还是 1。</p>
<hr>
<h3 id="📊-实际答案（参考标准解答）："><a href="#📊-实际答案（参考标准解答）：" class="headerlink" title="📊 实际答案（参考标准解答）："></a>📊 实际答案（参考标准解答）：</h3><p>在所有 20 种可能的指令交错中，<strong>只有 2 种序列能得到 x&#x3D;2</strong>：</p>
<ol>
<li>A1→A2→A3→B1→B2→B3  </li>
<li>B1→B2→B3→A1→A2→A3</li>
</ol>
<p>其他 18 种都会导致 x&#x3D;1。</p>
<hr>
<h3 id="✅-正确答案：B-2"><a href="#✅-正确答案：B-2" class="headerlink" title="✅ 正确答案：B. 2"></a>✅ 正确答案：<strong>B. 2</strong></h3><hr>
<h3 id="🎯-考点总结：-5"><a href="#🎯-考点总结：-5" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><ul>
<li>“x++” 不是原子操作 → 并发时易发生<strong>丢失更新</strong>；  </li>
<li>最终 x&#x3D;2 仅当两个线程的写操作<strong>不互相覆盖</strong>，即<strong>一个线程写入后，另一个线程读到该值再写入</strong>；  </li>
<li>这在指令交错中只发生在<strong>完全串行</strong>的情况下（2 种）。</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>B. 2</strong></p>
<h1 id="题目-7"><a href="#题目-7" class="headerlink" title="题目"></a>题目</h1><p>若 x 是管程内的条件变量，则当进程执行 x.wait() 时所做的工作是______<br>。(2018)<br>A. 实现对变量 x 的互斥访问<br>B. 唤醒一个在 x 上阻塞的进程<br>C. 根据 x 的值判断该进程是否进人阻塞状态<br>D. 阻塞该进程，并将之插入 x 的阻塞队列中</p>
<h2 id="解析-7"><a href="#解析-7" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：D. 阻塞该进程，并将之插入 x 的阻塞队列中</strong></p>
<p>本题考查 <strong>管程中条件变量 <code>wait()</code> 操作的语义</strong>。</p>
<p>在管程（Monitor）中：</p>
<ul>
<li>管程本身保证<strong>任一时刻最多一个进程在管程中执行</strong>（通过隐式互斥锁）；  </li>
<li><strong>条件变量（condition variable）</strong> 用于实现<strong>进程同步与协作</strong>（非互斥），典型如：  <ul>
<li><code>x.wait()</code>：当前进程<strong>暂时放弃管程所有权</strong>，进入等待状态；  </li>
<li><code>x.signal()</code> &#x2F; <code>x.notify()</code>：唤醒一个在 <code>x</code> 上等待的进程。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="x-wait-的标准行为（以-Hoare-管程为例）："><a href="#x-wait-的标准行为（以-Hoare-管程为例）：" class="headerlink" title="x.wait() 的标准行为（以 Hoare 管程为例）："></a><code>x.wait()</code> 的标准行为（以 Hoare 管程为例）：</h3><p>当一个进程在管程内执行 <code>x.wait()</code> 时，系统会：</p>
<ol>
<li><strong>释放管程的互斥锁</strong>（以便其他进程可进入管程）；  </li>
<li><strong>将当前进程阻塞</strong>（从运行态转为阻塞态）；  </li>
<li><strong>将该进程放入条件变量 <code>x</code> 的阻塞队列（等待队列）中</strong>；  </li>
<li>调度器切换到其他就绪进程。</li>
</ol>
<blockquote>
<p>📌 注意：<code>wait()</code> <strong>不检查 <code>x</code> 的值</strong>（条件变量本身没有“值”，它只是一个同步对象）；<br>判断是否等待应由<strong>程序员在 <code>wait()</code> 前用 while 循环检查条件</strong>，如：</p>
<div class="code-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (buffer.isEmpty()) &#123;</span><br><span class="line">    notEmpty.wait();   <span class="comment">// 进入等待</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></blockquote>
<hr>
<h3 id="逐项排除："><a href="#逐项排除：" class="headerlink" title="逐项排除："></a>逐项排除：</h3><h4 id="A-实现对变量-x-的互斥访问"><a href="#A-实现对变量-x-的互斥访问" class="headerlink" title="A. 实现对变量 x 的互斥访问"></a>A. 实现对变量 x 的互斥访问</h4><p>❌ 错误。  </p>
<ul>
<li>互斥由<strong>管程本身</strong>保证（进入管程过程时自动加锁）；  </li>
<li>条件变量 <code>x</code> <strong>不提供互斥</strong>，只用于同步；  </li>
<li>多个进程可同时在不同条件变量上等待，互不冲突。</li>
</ul>
<h4 id="B-唤醒一个在-x-上阻塞的进程"><a href="#B-唤醒一个在-x-上阻塞的进程" class="headerlink" title="B. 唤醒一个在 x 上阻塞的进程"></a>B. 唤醒一个在 x 上阻塞的进程</h4><p>❌ 错误。  </p>
<ul>
<li>这是 <code>x.signal()</code> 或 <code>x.notify()</code> 的功能；  </li>
<li><code>wait()</code> 是<strong>自己去等待</strong>，不是唤醒别人。</li>
</ul>
<h4 id="C-根据-x-的值判断该进程是否进入阻塞状态"><a href="#C-根据-x-的值判断该进程是否进入阻塞状态" class="headerlink" title="C. 根据 x 的值判断该进程是否进入阻塞状态"></a>C. 根据 x 的值判断该进程是否进入阻塞状态</h4><p>❌ 错误。  </p>
<ul>
<li>条件变量 <code>x</code> <strong>没有数值属性</strong>，它只是一个同步机制；  </li>
<li>是否等待由程序员逻辑决定（如 <code>while (!condition) x.wait()</code>）；  </li>
<li><code>wait()</code> 一旦调用，<strong>必然阻塞</strong>（除非信号量实现特殊优化，但标准语义是阻塞）。</li>
</ul>
<h4 id="D-阻塞该进程，并将之插入-x-的阻塞队列中"><a href="#D-阻塞该进程，并将之插入-x-的阻塞队列中" class="headerlink" title="D. 阻塞该进程，并将之插入 x 的阻塞队列中"></a>D. 阻塞该进程，并将之插入 x 的阻塞队列中</h4><p>✅ <strong>正确</strong>。  </p>
<ul>
<li>完整描述了 <code>wait()</code> 的核心行为；  </li>
<li>是管程条件变量的标准定义。</li>
</ul>
<hr>
<h3 id="🎯-考点总结：-6"><a href="#🎯-考点总结：-6" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>操作</th>
<th>行为</th>
</tr>
</thead>
<tbody><tr>
<td><code>x.wait()</code></td>
<td>阻塞自己，入队 <code>x</code> 的等待队列，释放管程锁</td>
</tr>
<tr>
<td><code>x.signal()</code></td>
<td>唤醒一个在 <code>x</code> 上等待的进程（若无则忽略）</td>
</tr>
<tr>
<td><code>x.broadcast()</code></td>
<td>唤醒所有在 <code>x</code> 上等待的进程</td>
</tr>
</tbody></table>
<blockquote>
<p>📚 参考：《操作系统概念》—— “A condition variable allows a process to suspend execution until some condition is satisfied.”</p>
</blockquote>
<hr>
<p>✅ 正确答案：<strong>D</strong></p>
<h1 id="题目-8"><a href="#题目-8" class="headerlink" title="题目"></a>题目</h1><p>和尚打水问题（辽宁大学2016年计算机专硕）<br>寺庙中有小和尚和老和尚若干,有一个水缸,由小和尚提水入缸供老和尚饮用.<br>水缸可以容纳10桶水,水取自同一口井中,由于水井口窄,每次只能容纳一个<br>水桶取水，水桶总数为3个。每次入水、取水仅为一桶,且不可同时进行。<br>试给出有关取水、入水的PV算法描述。</p>
<h2 id="解析-8"><a href="#解析-8" class="headerlink" title="解析"></a>解析</h2><p>我们来系统分析并设计 <strong>和尚打水问题</strong> 的 PV（信号量）同步算法。</p>
<hr>
<h2 id="🔍-问题建模"><a href="#🔍-问题建模" class="headerlink" title="🔍 问题建模"></a>🔍 问题建模</h2><h3 id="🧍-角色与资源："><a href="#🧍-角色与资源：" class="headerlink" title="🧍 角色与资源："></a>🧍 角色与资源：</h3><table>
<thead>
<tr>
<th>实体</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>小和尚</strong></td>
<td>负责从井中打水 → 倒入水缸（<strong>生产者</strong>）</td>
</tr>
<tr>
<td><strong>老和尚</strong></td>
<td>从水缸中取水饮用（<strong>消费者</strong>）</td>
</tr>
<tr>
<td><strong>水缸</strong></td>
<td>容量为 10 桶水，缓冲区</td>
</tr>
<tr>
<td><strong>水井</strong></td>
<td>临界资源，<strong>每次仅允 1 个水桶取水</strong>（互斥）</td>
</tr>
<tr>
<td><strong>水桶</strong></td>
<td>共 3 个，<strong>有限资源</strong>（提水需先获得空桶）</td>
</tr>
</tbody></table>
<h3 id="⏳-操作流程："><a href="#⏳-操作流程：" class="headerlink" title="⏳ 操作流程："></a>⏳ 操作流程：</h3><ol>
<li>小和尚：<br><code>拿空桶</code> → <code>到井边打水</code>（互斥）→ <code>提水到缸边</code> → <code>倒水入缸</code>（互斥）→ <code>放回空桶</code>  </li>
<li>老和尚：<br><code>拿水桶</code>（从缸取水需用水桶？题目未明确，但按常理：取水也需水桶）→<br><code>从缸取水</code>（互斥）→ <code>饮用</code> → <code>放回空桶</code></li>
</ol>
<blockquote>
<p>📌 <strong>关键</strong>：题目说“水桶总数为 3 个”，且“每次入水、取水仅为一桶”，说明<strong>水桶是共用的临界资源</strong>，无论打水还是取水都需使用水桶。</p>
</blockquote>
<p>但更合理的理解是：</p>
<ul>
<li>小和尚用桶打水（1 桶&#x2F;次），倒入缸后桶空闲；  </li>
<li>老和尚直接从缸舀水饮用（<strong>不一定用水桶</strong>），题目未说老和尚需要桶；  </li>
<li><strong>水桶仅用于“从井打水”环节</strong>（因井口窄，需用桶打水）；</li>
</ul>
<p>✅ 采用<strong>主流解法理解</strong>：</p>
<ul>
<li><strong>水桶</strong>是有限资源（3 个），仅小和尚打水时需要；  </li>
<li>老和尚从水缸取水 <strong>不占用水桶</strong>（如用碗、直接饮），只消耗水缸中的水；  </li>
<li>水缸本身是临界区（倒水&#x2F;取水需互斥）；  </li>
<li>井是临界资源（打水需互斥）。</li>
</ul>
<hr>
<h2 id="✅-信号量设计"><a href="#✅-信号量设计" class="headerlink" title="✅ 信号量设计"></a>✅ 信号量设计</h2><table>
<thead>
<tr>
<th>信号量</th>
<th>初值</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>mutex_jing</code></td>
<td>1</td>
<td>保护水井，互斥打水</td>
</tr>
<tr>
<td><code>mutex_gang</code></td>
<td>1</td>
<td>保护水缸，互斥倒水&#x2F;取水</td>
</tr>
<tr>
<td><code>empty</code></td>
<td>10</td>
<td>水缸中<strong>空位数</strong>（可倒入的桶数）</td>
</tr>
<tr>
<td><code>full</code></td>
<td>0</td>
<td>水缸中<strong>水量</strong>（可取用的桶数）</td>
</tr>
<tr>
<td><code>buckets</code></td>
<td>3</td>
<td><strong>空水桶数量</strong>（小和尚打水前需申请）</td>
</tr>
</tbody></table>
<blockquote>
<p>📝 注：<code>empty</code> 和 <code>full</code> 是典型的生产者-消费者信号量；<br><code>buckets</code> 是额外资源限制（类似“有限缓冲区”的桶资源）。</p>
</blockquote>
<hr>
<h2 id="✅-进程描述（伪代码）"><a href="#✅-进程描述（伪代码）" class="headerlink" title="✅ 进程描述（伪代码）"></a>✅ 进程描述（伪代码）</h2><h3 id="小和尚（生产者）："><a href="#小和尚（生产者）：" class="headerlink" title="小和尚（生产者）："></a>小和尚（生产者）：</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">semaphore mutex_jing = <span class="number">1</span>;   <span class="comment">// 井互斥</span></span><br><span class="line">semaphore mutex_gang = <span class="number">1</span>;   <span class="comment">// 缸互斥</span></span><br><span class="line">semaphore empty = <span class="number">10</span>;       <span class="comment">// 水缸空位</span></span><br><span class="line">semaphore full = <span class="number">0</span>;         <span class="comment">// 水缸水量</span></span><br><span class="line">semaphore buckets = <span class="number">3</span>;      <span class="comment">// 空桶数</span></span><br><span class="line"></span><br><span class="line">process 小和尚() &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        P(buckets);         <span class="comment">// 1. 申请一个空桶</span></span><br><span class="line">        P(empty);           <span class="comment">// 2. 等待水缸有空位</span></span><br><span class="line">        P(mutex_jing);      <span class="comment">// 3. 互斥访问水井</span></span><br><span class="line">            <span class="comment">// 从井中打一桶水（临界区）</span></span><br><span class="line">        V(mutex_jing);      <span class="comment">//   释放井</span></span><br><span class="line">        </span><br><span class="line">        P(mutex_gang);      <span class="comment">// 4. 互斥访问水缸</span></span><br><span class="line">            <span class="comment">// 将水倒入水缸（1桶）</span></span><br><span class="line">        V(mutex_gang);      <span class="comment">//   释放水缸</span></span><br><span class="line">        </span><br><span class="line">        V(full);            <span class="comment">// 5. 水量 +1</span></span><br><span class="line">        V(buckets);         <span class="comment">// 6. 归还空桶（倒完后桶空闲）</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="老和尚（消费者）："><a href="#老和尚（消费者）：" class="headerlink" title="老和尚（消费者）："></a>老和尚（消费者）：</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">process 老和尚() &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        P(full);            <span class="comment">// 1. 等待水缸有水</span></span><br><span class="line">        P(mutex_gang);      <span class="comment">// 2. 互斥访问水缸</span></span><br><span class="line">            <span class="comment">// 从水缸取一桶水饮用</span></span><br><span class="line">        V(mutex_gang);      <span class="comment">//   释放水缸</span></span><br><span class="line">        </span><br><span class="line">        V(empty);           <span class="comment">// 3. 水缸空位 +1</span></span><br><span class="line">        <span class="comment">// 老和尚不占用水桶，无需操作 buckets</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="✅-关键点说明"><a href="#✅-关键点说明" class="headerlink" title="✅ 关键点说明"></a>✅ 关键点说明</h2><table>
<thead>
<tr>
<th>步骤</th>
<th>为什么需要？</th>
</tr>
</thead>
<tbody><tr>
<td><code>P(buckets)</code> 在 <code>P(empty)</code> 前？</td>
<td>✅ 合理：先拿桶，再看缸有没有空位；若顺序反过来，可能占着空位却没桶，降低并发性</td>
</tr>
<tr>
<td>井和缸分别加锁？</td>
<td>✅ 是：井（打水）和缸（倒&#x2F;取）是两个不同临界资源，应独立互斥</td>
</tr>
<tr>
<td>老和尚不操作 <code>buckets</code>？</td>
<td>✅ 合理：题目中水桶用于“提水”，老和尚“饮用”不涉及提水，故无需桶；若题目明确老和尚也用水桶，则需在 <code>P(full)</code> 后加 <code>P(buckets)</code>，饮用后 <code>V(buckets)</code>，但题干未说明，按常规省略</td>
</tr>
</tbody></table>
<blockquote>
<p>🎯 若严格按“水桶总数为 3 个，每次入水、取水仅为一桶”理解：  </p>
<ul>
<li>“取水”也用水桶 → 老和尚需 <code>P(buckets)</code>；<br>可补充如下：</li>
</ul>
</blockquote>
<h3 id="（可选）若老和尚也需用水桶："><a href="#（可选）若老和尚也需用水桶：" class="headerlink" title="（可选）若老和尚也需用水桶："></a>（可选）若老和尚也需用水桶：</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">process 老和尚() &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        P(full);</span><br><span class="line">        P(buckets);         <span class="comment">// 取水也需用水桶</span></span><br><span class="line">        P(mutex_gang);</span><br><span class="line">            <span class="comment">// 取水</span></span><br><span class="line">        V(mutex_gang);</span><br><span class="line">        V(empty);</span><br><span class="line">        V(buckets);         <span class="comment">// 归还桶</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>但<strong>主流解法和考题惯例中，水桶仅用于“打水”环节</strong>，故推荐第一种。</p>
<hr>
<h2 id="✅-答案总结（标准-PV-描述）"><a href="#✅-答案总结（标准-PV-描述）" class="headerlink" title="✅ 答案总结（标准 PV 描述）"></a>✅ 答案总结（标准 PV 描述）</h2><p><strong>信号量定义：</strong></p>
<ul>
<li><code>mutex_jing = 1</code>：互斥使用水井  </li>
<li><code>mutex_gang = 1</code>：互斥使用水缸  </li>
<li><code>empty = 10</code>：水缸空位数  </li>
<li><code>full = 0</code>：水缸水量  </li>
<li><code>buckets = 3</code>：空水桶数</li>
</ul>
<p><strong>小和尚：</strong></p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">P(buckets);</span><br><span class="line">P(empty);</span><br><span class="line">P(mutex_jing); 打水; V(mutex_jing);</span><br><span class="line">P(mutex_gang); 倒水; V(mutex_gang);</span><br><span class="line">V(full);</span><br><span class="line">V(buckets);</span><br></pre></td></tr></table></figure></div>

<p><strong>老和尚：</strong></p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">P(full);</span><br><span class="line">P(mutex_gang); 取水; V(mutex_gang);</span><br><span class="line">V(empty);</span><br></pre></td></tr></table></figure></div>

<hr>
<p>✅ 完整、无死锁、无饥饿、满足题目所有约束。</p>
<h1 id="题目-9"><a href="#题目-9" class="headerlink" title="题目"></a>题目</h1><p>试画出下面四条语句的前趋图，并用wait和<br>signal原语描述前趋图<br>S1: x:&#x3D;a+b<br>S2: y:&#x3D;c+d<br>S3: z:&#x3D;x*y<br>S4: w&#x3D;z2<br>（注：a,b,c,d为常量）</p>
<h2 id="解析-9"><a href="#解析-9" class="headerlink" title="解析"></a>解析</h2><p>我们来逐步分析并画出这四条语句的<strong>前趋图（Precedence Graph）</strong>，并用 <strong><code>wait</code> &#x2F; <code>signal</code></strong> 原语（即 P&#x2F;V 操作）实现同步。</p>
<hr>
<h2 id="🔍-一、分析语句间的数据依赖关系"><a href="#🔍-一、分析语句间的数据依赖关系" class="headerlink" title="🔍 一、分析语句间的数据依赖关系"></a>🔍 一、分析语句间的数据依赖关系</h2><p>给定语句：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">S1: x := a + b</span><br><span class="line">S2: y := c + d</span><br><span class="line">S3: z := x * y</span><br><span class="line">S4: w := z * 2   （注：z2 应为 z*2）</span><br></pre></td></tr></table></figure></div>

<p>分析读写变量：</p>
<table>
<thead>
<tr>
<th>语句</th>
<th>写入变量</th>
<th>读取变量</th>
<th>依赖关系</th>
</tr>
</thead>
<tbody><tr>
<td>S1</td>
<td>x</td>
<td>a, b</td>
<td>无输入依赖（a,b 为常量）</td>
</tr>
<tr>
<td>S2</td>
<td>y</td>
<td>c, d</td>
<td>无输入依赖</td>
</tr>
<tr>
<td>S3</td>
<td>z</td>
<td>x, y</td>
<td>依赖 S1（需 x）、依赖 S2（需 y）</td>
</tr>
<tr>
<td>S4</td>
<td>w</td>
<td>z</td>
<td>依赖 S3（需 z）</td>
</tr>
</tbody></table>
<hr>
<h2 id="✅-二、前趋图（依赖图）"><a href="#✅-二、前趋图（依赖图）" class="headerlink" title="✅ 二、前趋图（依赖图）"></a>✅ 二、前趋图（依赖图）</h2><p>前趋图是有向无环图（DAG），节点为语句，边 $ A \to B $ 表示 A 必须先于 B 执行。</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">S1        S2</span><br><span class="line"> \       /</span><br><span class="line">  \     /</span><br><span class="line">   \   /</span><br><span class="line">    S3</span><br><span class="line">    |</span><br><span class="line">    |</span><br><span class="line">    S4</span><br></pre></td></tr></table></figure></div>

<p>即：</p>
<ul>
<li>S1 → S3  </li>
<li>S2 → S3  </li>
<li>S3 → S4</li>
</ul>
<p>S1 与 S2 无依赖，可并发执行。</p>
<hr>
<h2 id="✅-三、用-wait-signal-原语实现同步"><a href="#✅-三、用-wait-signal-原语实现同步" class="headerlink" title="✅ 三、用 wait &#x2F; signal 原语实现同步"></a>✅ 三、用 wait &#x2F; signal 原语实现同步</h2><h3 id="🧩-思路："><a href="#🧩-思路：" class="headerlink" title="🧩 思路："></a>🧩 思路：</h3><ul>
<li>为每条依赖边设置一个<strong>同步信号量</strong>（初值为 0）；  </li>
<li>前驱执行完后 <code>signal</code>，后继执行前 <code>wait</code>。</li>
</ul>
<h3 id="📌-信号量设计："><a href="#📌-信号量设计：" class="headerlink" title="📌 信号量设计："></a>📌 信号量设计：</h3><table>
<thead>
<tr>
<th>信号量</th>
<th>含义</th>
<th>初值</th>
</tr>
</thead>
<tbody><tr>
<td><code>s1_done</code></td>
<td>S1 是否完成</td>
<td>0</td>
</tr>
<tr>
<td><code>s2_done</code></td>
<td>S2 是否完成</td>
<td>0</td>
</tr>
<tr>
<td><code>s3_done</code></td>
<td>S3 是否完成</td>
<td>0</td>
</tr>
</tbody></table>
<blockquote>
<p>注意：S3 需等待 S1 和 S2 都完成，因此需两个 <code>wait</code>。</p>
</blockquote>
<hr>
<h3 id="✅-同步代码（用-P-V-表示，P-wait-V-signal）："><a href="#✅-同步代码（用-P-V-表示，P-wait-V-signal）：" class="headerlink" title="✅ 同步代码（用 P&#x2F;V 表示，P &#x3D; wait, V &#x3D; signal）："></a>✅ 同步代码（用 P&#x2F;V 表示，P &#x3D; wait, V &#x3D; signal）：</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化信号量</span></span><br><span class="line">semaphore s1_done = <span class="number">0</span>;</span><br><span class="line">semaphore s2_done = <span class="number">0</span>;</span><br><span class="line">semaphore s3_done = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 进程/线程并发执行以下代码：</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// S1</span></span><br><span class="line">x := a + b;</span><br><span class="line">V(s1_done);        <span class="comment">// 通知 S3：S1 已完成</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// S2</span></span><br><span class="line">y := c + d;</span><br><span class="line">V(s2_done);        <span class="comment">// 通知 S3：S2 已完成</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// S3</span></span><br><span class="line">P(s1_done);        <span class="comment">// 等待 S1 完成</span></span><br><span class="line">P(s2_done);        <span class="comment">// 等待 S2 完成</span></span><br><span class="line">z := x * y;</span><br><span class="line">V(s3_done);        <span class="comment">// 通知 S4：S3 已完成</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// S4</span></span><br><span class="line">P(s3_done);        <span class="comment">// 等待 S3 完成</span></span><br><span class="line">w := z * <span class="number">2</span>;</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="✅-四、正确性说明"><a href="#✅-四、正确性说明" class="headerlink" title="✅ 四、正确性说明"></a>✅ 四、正确性说明</h2><ul>
<li>S1、S2 可并行执行（无同步约束）；  </li>
<li>S3 在 <code>P(s1_done)</code> 和 <code>P(s2_done)</code> 后才执行，保证 <code>x</code> 和 <code>y</code> 已计算；  </li>
<li>S4 在 <code>P(s3_done)</code> 后执行，保证 <code>z</code> 已计算；  </li>
<li>所有数据依赖均被满足，无竞态条件。</li>
</ul>
<hr>
<h2 id="📌-补充：若用四个线程分别执行-S1-S4"><a href="#📌-补充：若用四个线程分别执行-S1-S4" class="headerlink" title="📌 补充：若用四个线程分别执行 S1~S4"></a>📌 补充：若用四个线程分别执行 S1~S4</h2><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 主程序初始化信号量后创建 4 个线程：</span></span><br><span class="line"></span><br><span class="line">Thread1() &#123; x = a+b; V(s1_done); &#125;</span><br><span class="line">Thread2() &#123; y = c+d; V(s2_done); &#125;</span><br><span class="line">Thread3() &#123; P(s1_done); P(s2_done); z = x*y; V(s3_done); &#125;</span><br><span class="line">Thread4() &#123; P(s3_done); w = z*<span class="number">2</span>; &#125;</span><br></pre></td></tr></table></figure></div>

<hr>
<h3 id="✅-最终答案："><a href="#✅-最终答案：" class="headerlink" title="✅ 最终答案："></a>✅ 最终答案：</h3><h4 id="1-前趋图："><a href="#1-前趋图：" class="headerlink" title="1. 前趋图："></a>1. 前趋图：</h4><div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">S1 ───┐</span><br><span class="line">      ├─→ S3 ──→ S4</span><br><span class="line">S2 ───┘</span><br></pre></td></tr></table></figure></div>

<h4 id="2-wait-signal-描述："><a href="#2-wait-signal-描述：" class="headerlink" title="2. wait&#x2F;signal 描述："></a>2. wait&#x2F;signal 描述：</h4><ul>
<li>信号量：<code>s1_done = 0, s2_done = 0, s3_done = 0</code>  </li>
<li>S1 后：<code>signal(s1_done)</code>  </li>
<li>S2 后：<code>signal(s2_done)</code>  </li>
<li>S3 前：<code>wait(s1_done); wait(s2_done)</code>；后：<code>signal(s3_done)</code>  </li>
<li>S4 前：<code>wait(s3_done)</code></li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux操作系统-操作系统基础题目</title>
    <url>/zhihaojiang.github.io/2025/12/22/20251222Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E9%A2%98%E7%9B%AE/</url>
    <content><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>以下有关操作系统的叙述中，哪一个是不正确的？<br>A. 操作系统管理系统中的各种资源<br>B. 操作系统为用户提供的良好的界面<br>C. 操作系统就是资源的管理者和仲裁者<br>D. 操作系统是计算机系统中的一个应用软件</p>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p>答案：D. 操作系统是计算机系统中的一个应用软件</p>
<p>逐项分析：</p>
<p>A. 操作系统管理系统中的各种资源<br>✅ 正确。<br>操作系统的核心功能之一就是资源管理，包括：</p>
<p>处理器（CPU 调度）<br>内存（分配、虚拟内存）<br>外设（I&#x2F;O 管理、设备驱动）<br>文件与存储（文件系统）<br>→ 是操作系统的基本职责。<br>B. 操作系统为用户提供良好的界面<br>✅ 正确。<br>无论是命令行界面（CLI，如 bash）还是图形用户界面（GUI，如 GNOME、KDE），都是操作系统提供的人机交互接口，属于其服务功能之一。</p>
<p>C. 操作系统就是资源的管理者和仲裁者<br>✅ 正确。<br>“管理者”指分配资源，“仲裁者”指在多个进程&#x2F;用户竞争资源时进行协调（如避免死锁、公平调度），这是对操作系统角色的经典定义（参见 Dijkstra、Tanenbaum 等教材）。</p>
<p>D. 操作系统是计算机系统中的一个应用软件<br>❌ 错误——这是本题的答案。</p>
<p>操作系统属于系统软件（system software），是最底层、最基础的软件层，直接运行在硬件之上（或 hypervisor 之上）。<br>应用软件（如浏览器、文本编辑器、游戏）是运行在操作系统之上的，依赖 OS 提供的服务（如 open, malloc, fork）。<br>若 OS 是“应用软件”，则它无法管理硬件或为其他软件提供运行环境，逻辑矛盾。<br>📌 类比：<br>硬件 → 操作系统（地基 + 建筑框架） → 系统工具（水电管道） → 应用软件（房间里的家具电器）<br>显然，地基不是家具。</p>
<p>🎯 考点总结：<br>本题考察 操作系统的本质属性与分类，重点在于：</p>
<p>区分 系统软件 vs 应用软件<br>掌握操作系统的核心角色：资源管理者、服务提供者、硬件抽象层<br>理解操作系统在软件层次中的底层地位<br>常见干扰项陷阱：将“用户可见”（如桌面环境）误解为“应用软件”，但 GUI 本身仍是 OS 的一部分（或紧密集成组件）。</p>
<h1 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h1><p>分时操作系统的主要特点是 。<br>A. 个人独占机器资源 B. 自动控制作业运行<br>C. 高可靠性和安全性 D. 多个用户共享计算机资源</p>
<h2 id="解析-1"><a href="#解析-1" class="headerlink" title="解析"></a>解析</h2><p>答案：D. 多个用户共享计算机资源</p>
<p>✅ 解析：<br>分时操作系统（Time-Sharing Operating System）的核心思想：<br>通过 时间片轮转（time-slicing），使多个用户（或终端）同时交互式地使用同一台计算机，每个用户感觉自己“独占”机器，实则 CPU 时间被快速轮流分配。</p>
<p>✔️ 关键特征包括：</p>
<p>多用户（Multi-user）：多个用户通过终端并发登录使用系统（如早期的 UNIX、现代 Linux 的多终端登录）<br>交互性（Interactive）：用户可实时输入命令并获得响应<br>独立性（Independence）：各用户任务彼此隔离，互不干扰<br>及时性（Timeliness）：响应时间较短（通常在秒级内），满足交互需求<br>→ 所有这些都建立在 “多个用户共享计算机资源（CPU、内存、I&#x2F;O 等）” 的基础上。</p>
<p>❌ 其他选项分析：<br>A. 个人独占机器资源<br>→ 描述的是单道批处理系统或专用系统，与分时系统“共享”本质相悖。<br>✖️ 错误</p>
<p>B. 自动控制作业运行<br>→ 描述的是批处理系统（如早期 IBM OS&#x2F;360 的 JCL 作业流），用户提交作业后不干预，由系统自动调度执行。分时系统强调交互，而非“自动批处理”。<br>✖️ 错误</p>
<p>C. 高可靠性和安全性<br>→ 这是实时操作系统（RTOS）（尤其硬实时）或分布式&#x2F;安全操作系统的突出要求，不是分时系统的定义性特征。<br>虽然现代分时系统（如 Linux）也追求高可靠与安全，但它们并非分时概念的“主要特点”。<br>✖️ 非核心特征，不选</p>
<p>🎯 考点总结：<br>本题考察 不同类型操作系统（批处理、分时、实时）的核心特征辨析。</p>
<p>系统类型<br>核心目标<br>主要特点<br>批处理系统<br>提高资源利用率<br>自动化、脱机、非交互<br>分时系统<br>提高交互性与响应性<br>多用户、共享资源、时间片轮转<br>实时系统<br>满足截止时间<br>可预测性、高可靠性、低延迟<br>👉 记住关键词：<br>分时 &#x3D; 多用户 + 共享 + 交互 + 时间片</p>
<h1 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h1><p>用户与操作系统打交道的手段称为 。<br>A. 命令输入 B. 广义指令 C. 通信 D. 用户接口</p>
<h2 id="解析-2"><a href="#解析-2" class="headerlink" title="解析"></a>解析</h2><p>答案：D. 用户接口</p>
<p>✅ 解析：<br>题目问的是：用户与操作系统打交道的手段的统称。</p>
<p>✔️ D. 用户接口（User Interface, UI）<br>这是标准术语，指操作系统提供给用户与其交互的所有方式的总称，包括：</p>
<p>命令行接口（CLI）：如 bash、zsh，用户输入命令（如 ls, cd）<br>图形用户接口（GUI）：如 GNOME、KDE、Windows 桌面，通过窗口、图标、菜单操作<br>程序接口（API）：应用程序通过系统调用（如 open(), fork()）与 OS 交互（广义上，程序员也是“用户”）<br>作业控制语言（JCL）：在批处理系统中提交作业脚本<br>因此，“用户接口”是最准确、最全面的术语。</p>
<p>❌ 其他选项分析：<br>A. 命令输入<br>→ 仅描述 CLI 中的一种操作行为，片面。不能涵盖 GUI（如点击图标）、API 调用等。<br>✖️ 范围过窄</p>
<p>B. 广义指令<br>→ 非标准术语。某些教材可能用“广义指令”指代“系统调用 + 访管指令”，但不用于描述用户交互手段的整体概念；且普通用户不接触“指令”这一底层概念。<br>✖️ 术语不规范，易混淆</p>
<p>C. 通信<br>→ 太宽泛。进程间通信（IPC）、网络通信都叫“通信”，但题目特指用户 ↔ 操作系统的交互手段。<br>✖️ 不精确</p>
<p>🎯 考点总结：<br>本题考察 操作系统基本概念中的“用户接口”定义，属于基础识记类题目。</p>
<p>📌 关键记忆点：</p>
<p>操作系统为用户提供的交互机制统称为 用户接口（User Interface），是人机交互的桥梁。</p>
<p>现代操作系统通常提供多种用户接口以适应不同用户需求：</p>
<p>终端用户 → GUI &#x2F; CLI<br>程序员 → API（系统调用接口）<br>系统管理员 → CLI + 配置工具</p>
<h1 id="题目-3"><a href="#题目-3" class="headerlink" title="题目"></a>题目</h1><p>从用户的观点看，操作系统是 。<br>A. 用户与计算机之间的接口 B. 控制和管理计算机资源的软件<br>C. 合理地组织计算机工作流程的软件 D. 由若干层次的程序按一定的结构组成的有机体</p>
<h2 id="解析-3"><a href="#解析-3" class="headerlink" title="解析"></a>解析</h2><p>答案：A. 用户与计算机之间的接口</p>
<p>✅ 解析：<br>题干关键词：“从用户的观点看”<br>→ 强调用户视角（user’s perspective），而非设计者、开发者或系统内部视角。</p>
<p>✔️ A. 用户与计算机之间的接口<br>✅ 完全匹配用户视角。<br>对普通用户而言，操作系统就是他们操作计算机的“窗口”：</p>
<p>通过桌面、图标、终端、应用程序等与计算机交互<br>不需要（也不关心）底层如何调度进程、管理内存<br>操作系统屏蔽了硬件复杂性，提供抽象、易用的交互界面<br>这是操作系统最直观、最本质的对外角色。经典教材定义如：</p>
<p>“An OS is an extended machine — it provides users with an abstract, simplified, and convenient interface to the hardware.”<br>—— Andrew S. Tanenbaum, Modern Operating Systems</p>
<p>❌ 其他选项分析（虽正确，但不符合“用户观点”）：<br>B. 控制和管理计算机资源的软件<br>→ 描述的是系统设计者&#x2F;内核开发者视角，强调 OS 的内部功能（资源管理）。用户通常不感知这一点。<br>✖️ 属于“系统观点”，非“用户观点”</p>
<p>C. 合理地组织计算机工作流程的软件<br>→ 偏向批处理&#x2F;作业调度视角，更适用于早期系统或后台服务设计者的理解。普通用户不关心“工作流程如何组织”。<br>✖️ 非用户中心视角</p>
<p>D. 由若干层次的程序按一定的结构组成的有机体<br>→ 描述的是 OS 的体系结构（如微内核、宏内核、模块化设计），属于实现层面的抽象，是程序员或研究者关注的内容。<br>✖️ 技术实现视角，非用户体验视角</p>
<p>🎯 考点总结：<br>本题考察 操作系统在不同视角下的定义差异，重点在于区分：</p>
<p>视角<br>典型定义<br>用户视角<br>用户与计算机之间的接口（强调易用性、抽象性）✅<br>系统视角<br>资源管理者、仲裁者<br>开发者视角<br>层次化&#x2F;模块化的软件系统<br>理论视角<br>虚拟机（Virtual Machine）<br>👉 记住：</p>
<p>用户看到的是 “界面” → Interface<br>内核看到的是 “调度与资源” → Manager</p>
<h1 id="题目-4"><a href="#题目-4" class="headerlink" title="题目"></a>题目</h1><p>6.操作系统提供给程序员的接口是 。<br>A．进程 B．系统调用 C．库函数 D．B和C</p>
<h2 id="解析-4"><a href="#解析-4" class="headerlink" title="解析"></a>解析</h2><p>答案：B．系统调用</p>
<p>✅ 正确答案详解：<br>题干关键词：“操作系统提供给程序员的接口”<br>→ 注意是 操作系统直接提供 的接口，而非第三方或封装层。</p>
<p>✔️ B. 系统调用（System Call）<br>✅ 正确。</p>
<p>系统调用是操作系统内核暴露给用户空间程序的唯一正式接口，是程序员（尤其是系统程序员、应用开发者）请求内核服务的唯一合法通道。<br>典型例子：<br>文件操作：open(), read(), write(), close()<br>进程控制：fork(), exec(), exit()<br>内存管理：brk(), mmap()<br>设备 I&#x2F;O：ioctl()<br>实现机制：通过软中断（如 int 0x80）、syscall&#x2F;sysenter 指令等陷入内核态，切换到内核执行。<br>📌 标准定义：<br>“System calls provide the interface between a process and the operating system.”<br>—— Silberschatz, Operating System Concepts</p>
<p>❌ 其他选项辨析：<br>A. 进程<br>→ 进程是操作系统管理的实体&#x2F;抽象概念，不是“接口”。程序员通过系统调用来创建&#x2F;控制进程（如 fork()），但“进程”本身不是接口。<br>✖️ 概念混淆</p>
<p>C. 库函数<br>→ 库函数（如 glibc 中的 printf(), malloc()）是用户空间的封装，不是操作系统直接提供的。</p>
<p>很多库函数内部封装了系统调用（如 printf() → write()），但也有些纯用户态计算（如 sin(), strlen()）。<br>OS 并不“提供”库函数——它们由标准库实现者（如 glibc）提供，运行在用户态。<br>✖️ 属于中间层，非 OS 原生接口<br>D. B和C<br>→ 虽然程序员日常使用库函数，但题目明确问的是 “操作系统提供” 的接口。<br>只有系统调用是 OS 内核直接暴露的接口；库函数是构建在系统调用之上的工具，不属于 OS 本身。<br>✖️ 混淆了“OS 接口”与“编程接口”</p>
<p>💡 类比：<br>操作系统是“政府”，系统调用是“法律规定的办事窗口”（如户籍科、税务局）；<br>库函数是“代办公司”——它帮你跑腿（调用窗口），但不是政府本身设立的窗口。</p>
<h1 id="题目-5"><a href="#题目-5" class="headerlink" title="题目"></a>题目</h1><p>引入多道程序技术的前提条件之一是系统具有（ ）。<br>A. 分时功能 B. 中断 C. 多CPU技术 D. SPOOLing技术</p>
<h2 id="解析-5"><a href="#解析-5" class="headerlink" title="解析"></a>解析</h2><p>答案：B. 中断</p>
<p>✅ 正确答案详解：<br>题干关键：“引入多道程序技术的前提条件之一”<br>我们要找的是——没有它，多道程序就根本无法实现的底层机制。</p>
<p>✔️ B. 中断（Interrupt）<br>✅ 正确，是核心前提。</p>
<p>为什么？<br>多道程序设计（Multiprogramming）的核心思想是：</p>
<p>在内存中同时存放多个作业，当一个作业因 I&#x2F;O 请求、等待事件等原因暂停执行时，CPU 立即切换到另一个就绪作业执行，从而提高 CPU 利用率。</p>
<p>而实现这种“暂停当前进程 → 切换到另一进程”的关键机制，就是 中断</p>
<p>❌ 其他选项分析：<br>A. 分时功能<br>→ 分时是多道程序的进一步发展（加上时间片轮转 + 多用户交互），不是前提，而是结果。<br>多道程序最早出现在批处理系统中（如 IBM OS&#x2F;360），早于分时系统（如 CTSS、UNIX）。<br>✖️ 逻辑倒置</p>
<p>C. 多CPU技术<br>→ 多道程序在单 CPU 上即可实现（通过进程切换模拟并发）。多 CPU 是并行（parallelism） 的前提，而非并发（concurrency） 的前提。<br>✖️ 非必要；多道程序诞生于单核时代</p>
<p>D. SPOOLing技术<br>→ SPOOLing（Simultaneous Peripheral Operations On-Line）是为解决 I&#x2F;O 瓶颈而提出的假脱机技术，典型用于批处理系统提升吞吐量，但它本身依赖于多道程序（需有进程并发执行输入&#x2F;计算&#x2F;输出）。<br>👉 实际上，多道程序是 SPOOLing 的前提，而非相反。<br>✖️ 因果颠倒</p>
<p>🎯 考点总结：<br>本题考察 多道程序设计的实现基础，重点在于理解：</p>
<p>多道程序的核心是 CPU 与 I&#x2F;O 的并行重叠<br>实现“并行重叠”的关键技术支撑是 中断机制<br>中断使操作系统能异步响应事件，从而实现进程调度与切换<br>🔑 关键记忆链：<br>中断 → 异常&#x2F;事件感知 → 内核介入 → 进程状态改变 → 调度切换 → 多道并发</p>
<h1 id="题目-6"><a href="#题目-6" class="headerlink" title="题目"></a>题目</h1><p>执行系统调用的过程包括如下主要操作正确的执行顺序是（ ）。(2017)<br>①返回用户态 ②执行陷入(trap)指令 ③传递系统调用参数 ④执行相应的服务程序<br>A.②→③→①→④ B.②→④→③→①<br>C.③→②→④→① D.③→④→②→①</p>
<h2 id="解析-6"><a href="#解析-6" class="headerlink" title="解析"></a>解析</h2><p>答案：C. ③→②→④→①</p>
<p>✅ 正确顺序解析：<br>执行系统调用（system call）是一个用户态 → 内核态 → 用户态的完整过程。我们按实际执行时序逐步分析：</p>
<p>③ 传递系统调用参数<br>➡️ 最先发生（用户态）</p>
<p>用户程序（如 C 程序）先将系统调用所需的参数（如文件描述符、缓冲区指针、长度等）准备好，通常通过：<br>寄存器（如 x86-64：rdi, rsi, rdx, r10, r8, r9）<br>或栈（老旧 ABI）<br>例如：read(fd, buf, count) → 先把 fd, buf, count 放入约定位置<br>✅ 这是系统调用发起前的准备动作，必须在陷入前完成。<br>② 执行陷入（trap）指令<br>➡️ 第二步（用户态 → 内核态切换点）</p>
<p>用户程序执行一条特殊指令触发陷入内核，如：<br>int 0x80（传统 x86）<br>syscall（x86-64 快速路径）<br>svc #0（ARM）<br>CPU 自动：<br>切换到内核态（CPL&#x3D;0）<br>保存用户态上下文（如 RIP, RSP, RFLAGS）<br>跳转到内核的系统调用入口（如 entry_SYSCALL_64）<br>④ 执行相应的服务程序<br>➡️ 第三步（内核态）</p>
<p>内核根据系统调用号（如 __NR_read &#x3D; 0）查表（sys_call_table），调用对应的服务例程（如 sys_read）<br>在内核态完成实际工作：权限检查、设备驱动调用、数据拷贝等<br>① 返回用户态<br>➡️ 最后一步（内核态 → 用户态）</p>
<p>内核执行 iret &#x2F; sysret 等指令，恢复用户态寄存器和栈<br>CPU 切回用户态，继续执行 syscall 之后的指令（如检查返回值）</p>
<h1 id="题目-7"><a href="#题目-7" class="headerlink" title="题目"></a>题目</h1><p>与单道程序系统相比，多道程序系统的优点是（ ）。(2017)<br>Ⅰ.CPU利用率高 Ⅱ.系统开销小 Ⅲ.系统吞吐量大 Ⅳ.I&#x2F;O设备利用率高<br>A.仅Ⅰ、Ⅲ B.仅Ⅰ、Ⅳ C.仅Ⅱ、Ⅲ D.仅Ⅰ、Ⅲ、Ⅳ</p>
<h2 id="解析-7"><a href="#解析-7" class="headerlink" title="解析"></a>解析</h2><p>答案：D. 仅Ⅰ、Ⅲ、Ⅳ</p>
<p>✅ 正确选项解析：<br>我们逐项分析多道程序系统（Multiprogramming System）相对于单道程序系统（Single-program System）的优势：</p>
<p>✅ Ⅰ. CPU利用率高<br>✔️ 正确。</p>
<p>单道系统：进程一旦发起 I&#x2F;O（如磁盘读写），CPU 空等直到 I&#x2F;O 完成 → 利用率低（可能 &lt; 20%）。<br>多道系统：当一个进程阻塞于 I&#x2F;O 时，CPU 立即调度另一个就绪进程运行 → 重叠 CPU 与 I&#x2F;O 操作，显著提升 CPU 利用率（可达 70%+）。<br>→ 核心优势之一<br>❌ Ⅱ. 系统开销小<br>✖️ 错误。</p>
<p>多道程序引入了额外开销：<br>进程切换（上下文保存&#x2F;恢复）<br>内存保护与地址映射（如基址&#x2F;界限寄存器、MMU）<br>调度算法执行<br>同步与互斥机制（如信号量）<br>单道系统无进程切换、无需保护，开销极小。<br>→ 多道系统牺牲一定开销换取资源利用率提升，这是典型的“时空权衡”。<br>✅ Ⅲ. 系统吞吐量大<br>✔️ 正确。</p>
<p>吞吐量（Throughput）：单位时间内完成的作业数。<br>多道系统通过并发执行、减少空闲，在相同时间内完成更多作业。<br>例如：单道时 1 小时完成 5 个作业；多道时可能完成 15 个。<br>→ 直接结果。<br>✅ Ⅳ. I&#x2F;O设备利用率高<br>✔️ 正确。</p>
<p>单道系统：I&#x2F;O 设备仅在当前作业需要时使用，其余时间闲置。<br>多道系统：多个进程可轮流使用 I&#x2F;O 设备（如一个进程写磁盘时，另一个读网卡），减少 I&#x2F;O 设备空闲时间，提升其利用率。<br>SPOOLing 技术进一步放大该优势（如用磁盘模拟独占设备）。<br>→ 与 CPU 利用率提升相辅相成。</p>
<h1 id="题目-8"><a href="#题目-8" class="headerlink" title="题目"></a>题目</h1><p>异常是指令执行过程中在处理器内部发生的特殊事件，中断是来自处理器外部的请求事件。下列关于中断或<br>异常悄况的叙述中，错误的是（ ）。(2016 组成原理)<br>A.<br>“访存时缺页”属于中断 B．<br>“整数除以0”属于异常<br>C.<br>“DMA传送结束”属于中断 D．<br>“存储保护错”属于异常</p>
<h2 id="解析-8"><a href="#解析-8" class="headerlink" title="解析"></a>解析</h2><p>逐项分析：<br>A. “访存时缺页”属于中断<br>❌ 错误（本题答案）</p>
<p>缺页（Page Fault）发生在CPU 执行一条访存指令（如 mov %rax, (%rbx)）时，MMU 发现页表项无效或未加载 → 触发 #PF 异常（x86 中断向量 14）。<br>它严格与当前指令绑定：哪条指令访问了缺页地址，异常就发生在该指令处，内核处理完后通常重新执行该指令。<br>✅ 正确分类：异常（具体为 fault 子类）<br>B. “整数除以0”属于异常<br>✅ 正确</p>
<p>由 div &#x2F; idiv 指令引发 #DE 异常（Divide Error），是典型的同步异常。<br>C. “DMA传送结束”属于中断<br>✅ 正确</p>
<p>DMA 控制器完成数据传输后，向 CPU 发送硬件中断请求（如 IRQ），与 CPU 当前执行的指令无关，属于外部异步事件。<br>D. “存储保护错”属于异常<br>✅ 正确</p>
<p>如访问只读页写入、用户态访问内核地址等，由 MMU 检测到违反保护机制 → 触发 #GP（General Protection Fault） 或 #PF，属于同步异常。</p>
<p>🎯 考点总结：<br>区分 中断 vs 异常 的核心：事件来源（内&#x2F;外） + 同步性（是否与指令关联）<br>常见陷阱：误将“由硬件单元（如 MMU）检测”等同于“中断”——MMU 是 CPU 一部分，其报告的错误仍属内部异常<br>缺页、保护错、除零、溢出、无效指令 → 都是 exception<br>外设通知（键盘、网卡、磁盘、DMA、时钟） → 都是 interrupt</p>
<h1 id="题目-9"><a href="#题目-9" class="headerlink" title="题目"></a>题目</h1><p>下列关于批处理系统的叙述中，正确的是（ ）。(2016)<br>I、批处理系统允许多个用户与计算机直接交互<br>Ⅱ、批处理系统分为单道批处理系统和多道批处理系统<br>III、中断技术使得多道批处理系统和I&#x2F;O设备可与CPU并行工作<br>A.仅Ⅱ，III B.仅II C.仅Ⅰ，Ⅱ D.仅I，Ⅲ</p>
<h2 id="解析-9"><a href="#解析-9" class="headerlink" title="解析"></a>解析</h2><p>答案：A. 仅Ⅱ，Ⅲ</p>
<p>✅ 逐项解析：<br>I. 批处理系统允许多个用户与计算机直接交互<br>❌ 错误</p>
<p>批处理系统（Batch Processing System）的核心特点是：用户提交作业（Job）后脱机等待，不能交互。<br>作业通常以作业控制语言（JCL）写成脚本，一次性提交给系统，由作业调度程序自动运行。<br>交互性是分时系统的特征，与批处理相悖。<br>→ 本项错误。<br>II. 批处理系统分为单道批处理系统和多道批处理系统<br>✅ 正确</p>
<p>单道批处理（如 IBM OS&#x2F;360 的早期版本）：内存中只驻留一个作业，CPU 等待 I&#x2F;O 时空闲。<br>多道批处理（如 IBM OS&#x2F;MVT）：内存中同时驻留多个作业，利用 I&#x2F;O 等待间隙切换作业，提高资源利用率。<br>→ 这是操作系统发展史上的标准分类。<br>III. 中断技术使得多道批处理系统和 I&#x2F;O 设备可与 CPU 并行工作<br>✅ 正确</p>
<p>在多道批处理中，当作业 A 发起 I&#x2F;O 请求后：<br>CPU 通过系统调用陷入内核；<br>内核启动 I&#x2F;O（如磁盘读），进程 A 进入阻塞态；<br>I&#x2F;O 设备在后台独立工作；<br>CPU 转而执行作业 B；<br>当 I&#x2F;O 完成时，设备发出中断 → 内核响应，唤醒作业 A。<br>若无中断机制，CPU 将无法得知 I&#x2F;O 完成，也无法实现作业切换 → 无法实现真正的“并行工作”。<br>→ 中断是实现CPU 与 I&#x2F;O 重叠（即宏观并行）的关键支撑技术。<br>✅ 最终判断：<br>I：✗<br>II：✓<br>III：✓<br>→ 正确选项为 A. 仅Ⅱ，Ⅲ<br>🎯 考点总结：<br>本题综合考察 批处理系统特征 + 多道程序实现基础</p>
<p>📌 记忆口诀：<br>批处理：提交就走，不许插嘴；<br>多道靠中断，CPU 不白等。</p>
<h1 id="题目-10"><a href="#题目-10" class="headerlink" title="题目"></a>题目</h1><p>某单CPU系统中有输入和输出设备各1台，现有3个并发执行的作业，每个作业的输入、计算和输出时间均分别为<br>2ms、3ms和4ms，且都按输入、计算和输出的顺序执行，则执行完3个作业需要的时间最少是（ ）。(2016)<br>A.15ms B.17ms C.22ms D.27ms</p>
<h2 id="解析-10"><a href="#解析-10" class="headerlink" title="解析"></a>解析</h2><p>✅ 正确答案：B. 17ms</p>
<p>我们来分析这道经典的作业调度与资源受限下的并发执行问题。</p>
<p>🔍 题目已知条件：<br>单 CPU（即计算阶段只能串行执行）<br>输入设备 1 台（输入阶段互斥）<br>输出设备 1 台（输出阶段互斥）<br>3 个作业，每个作业严格按序执行：<br>输入（2ms） → 计算（3ms） → 输出（4ms）<br>共 9ms&#x2F;作业，3 个共 27ms（若完全串行）<br>→ 目标：通过合理重叠（并行）尽可能缩短总时间</p>
<p>⚠️ 注意：</p>
<p>各阶段不能并行（必须先输入完才能计算，计算完才能输出）<br>同类设备只能服务一个作业（设备是瓶颈）<br>✅ 检查资源冲突：</p>
<p>输入设备：J1(0–2), J2(2–4), J3(4–6) → ✅ 无重叠<br>CPU：J1(2–5), J2(5–8), J3(8–11) → ✅ 串行无空闲<br>输出设备：<br>J1 输出最早可在 计算完成后（5ms）开始 → 5–9<br>J2 输出需等 J1 输出完（9ms） → 9–13<br>J3 输出需等 J2 输出完（13ms） → 13–17<br>⚠️ 能否让 J2&#x2F;J3 更早输出？<br>→ 不能！因为输出设备只有 1 台，且 J2 的输出必须等它自己计算完（8ms） + J1 输出完（9ms） → 实际最早 9ms 开始。</p>
<p>所以 J3 输出结束于：13 + 4 &#x3D; 17ms</p>
<p>🎯 总时间 &#x3D; 最后一个作业输出完成时间 &#x3D; 17ms<br>❌ 为什么不是 15ms（A）？<br>有人误以为：3 个作业可完全流水线：<br>输入：0–6（3×2）<br>计算：2–11（3×3，重叠）<br>输出：5–17（3×4，重叠）<br>→ 总时间 &#x3D; 6（最后输入完） + 3（最后计算） + 4（最后输出）？ &#x3D; 13？<br>错！输出不能早于对应作业计算完成时间，且设备独占。<br>最短理论下界：<br>输入总时间：3×2 &#x3D; 6ms（必须顺序）<br>计算总时间：3×3 &#x3D; 9ms（必须顺序）<br>输出总时间：3×4 &#x3D; 12ms（必须顺序）<br>→ 但可重叠，总时间 ≥ max(6, 9, 12) &#x3D; 12，但受限于阶段依赖，实际更长。<br>本题最优为 17ms。<br>✅ 答案：B. 17ms<br>🎯 考点总结：<br>资源受限下的作业调度<br>流水线思想 + 阶段依赖约束<br>关键原则：<br>同类设备只能串行使用<br>每个作业的三阶段必须顺序执行（输入→计算→输出）<br>后续阶段最早开始时间 &#x3D; max(前阶段结束时间, 设备空闲时间)<br>📌 类似题目可画甘特图辅助分析。</p>
<p>✅ 正确答案：B. 17ms</p>
<h1 id="题目-11"><a href="#题目-11" class="headerlink" title="题目"></a>题目</h1><p>内部异常（内中断）可分为故障（fault）、陷阱（trap）和终止（abort）三类。下列有关内部异常的叙述中，错误<br>的是（ ）。(2015 组成原理)<br>A.内部异常的产生与当前执行指令相关 B.内部异常的检测由CPU内部逻辑实现<br>C.内部异常的响应发生在指令执行过程中 D.内部异常处理后返回到发生异常的指令继续执行</p>
<h2 id="解析-11"><a href="#解析-11" class="headerlink" title="解析"></a>解析</h2><p>✅ 正确答案：D</p>
<p>逐项分析选项：<br>A. 内部异常的产生与当前执行指令相关<br>✅ 正确。</p>
<p>内部异常（内中断）由CPU 在执行指令过程中检测到异常条件而触发（如除零、缺页、非法操作码），是同步事件。<br>与外部中断（如键盘、时钟）的异步性形成对比。<br>B. 内部异常的检测由 CPU 内部逻辑实现<br>✅ 正确。</p>
<p>如：ALU 检测除零、MMU 检测缺页&#x2F;保护违例、译码器检测非法指令 → 均由 CPU 硬件完成。<br>C. 内部异常的响应发生在指令执行过程中<br>✅ 正确。</p>
<p>例如：<br>div 指令执行时 → 立即触发 #DE<br>访存指令执行时 MMU 查页表发现缺页 → 触发 #PF<br>→ 属于指令执行周期内的事件（即使 trap 指令 int 也是“执行该指令时”主动陷入）。<br>D. 内部异常处理后返回到发生异常的指令继续执行<br>❌ 错误（本题答案）</p>
<p>这只适用于 fault 类异常（如缺页），但：<br>Trap 类（如 int 0x80 系统调用）处理完后返回下一条指令（因为 trap 指令本身已执行完毕）；<br>Abort 类根本不返回（直接终止进程）。<br>→ 该说法以偏概全，未区分异常子类，错误。<br>📌 反例：<br>执行 int 0x80（系统调用）→ 进入 trap → 内核处理 → 返回用户态后执行 int 0x80 的下一条指令，而非重新执行 int 0x80（否则会无限循环调用）。</p>
<p>🎯 考点总结：<br>内部异常 &#x3D; 同步异常 &#x3D; 与指令流强相关<br>三类异常（fault&#x2F;trap&#x2F;abort）的核心区别在于：<br>是否可恢复<br>返回行为（重执行 &#x2F; 下一条 &#x2F; 不返回）<br>命题若用“所有内部异常都……”需警惕——trap 和 abort 不符合 D 描述<br>✅ 正确答案：D</p>
<h1 id="题目-12"><a href="#题目-12" class="headerlink" title="题目"></a>题目</h1><p>下列指令中，不能在用户态执行的是（ ）。(2014)<br>A．trap 指令 B．跳转指令 C．压栈指令 D．关中断指令</p>
<h2 id="解析-12"><a href="#解析-12" class="headerlink" title="解析"></a>解析</h2><p>答案：D．关中断指令</p>
<p>✅ 正确答案解析：<br>本题考察 CPU 特权级（Privilege Level）与指令权限，核心是区分哪些指令只能在内核态（特权态）执行。</p>
<p>现代 CPU（如 x86、ARM）通常有多个特权级（x86：Ring 0<del>3；ARM：EL0</del>EL3），操作系统运行在最高特权级（如 Ring 0 &#x2F; EL1&#x2F;EL2），用户程序运行在最低特权级（Ring 3 &#x2F; EL0）。<br>某些敏感指令若允许用户随意执行，将导致系统崩溃或安全漏洞，因此被设为特权指令（Privileged Instruction）。</p>
<p>逐项分析：<br>A. trap 指令<br>✅ 可在用户态执行</p>
<p>trap 是主动陷入内核的机制，例如：<br>x86：int 0x80、syscall<br>ARM：svc #0（Supervisor Call）<br>这些指令设计目的就是供用户程序发起系统调用，属于非特权指令（用户态可执行，执行后自动切换到内核态）。<br>✅ 合法用户态操作<br>B. 跳转指令（如 jmp, call, ret）<br>✅ 可在用户态执行</p>
<p>控制流转移是程序基本操作，用户程序大量使用。<br>CPU 会检查目标地址是否在用户空间（通过段&#x2F;页保护），但指令本身非特权。<br>C. 压栈指令（如 push, pop）<br>✅ 可在用户态执行</p>
<p>栈操作是常规计算行为（函数调用、局部变量），运行于用户栈，无需特权。<br>D. 关中断指令（如 x86 的 cli &#x2F; ARM 的 cpsid i）<br>❌ 不能在用户态执行</p>
<p>cli（Clear Interrupt Flag）禁止 CPU 响应可屏蔽中断（如键盘、网卡、时钟中断）。<br>若用户程序可随意关中断：<br>系统将无法响应时钟中断 → 调度器失效 → 其他进程永远得不到 CPU（拒绝服务）<br>无法响应设备中断 → I&#x2F;O 停滞、死机<br>因此，cli &#x2F; sti 是典型的特权指令，仅能在 Ring 0（内核态）执行。用户态执行会触发**#GP（General Protection Fault）** 异常。<br>🔍 补充：操作系统在临界区会短暂关中断（如修改调度队列），但这是内核行为；用户程序只能通过系统调用间接请求内核完成同步，不能自行关中断。</p>
<h1 id="题目-13"><a href="#题目-13" class="headerlink" title="题目"></a>题目</h1><p>下列选项中，会导致用户进程从用户态切换到内核态的操作是（ ） 。(2013)<br>I. 整数除以零 II. sin（）函数调用 III. read 系统调用<br>A. 仅 I、II B. 仅I、III C. 仅 II、III D. I、II 和 III</p>
<h2 id="解析-13"><a href="#解析-13" class="headerlink" title="解析"></a>解析</h2><p>答案：B. 仅 I、III</p>
<p>✅ 正确选项解析：<br>我们逐项分析每个操作是否会引起用户态 → 内核态的切换：</p>
<p>I. 整数除以零<br>➡️ 会触发异常（硬件中断&#x2F;陷阱）：<br>在 x86 等架构中，整数除零会引发 #DE（Divide Error）异常，这是一个同步异常（trap&#x2F;fault），由 CPU 检测到后，通过中断描述符表（IDT）跳转到内核的异常处理程序（如 do_divide_error），从而陷入内核态。<br>➤ 即使最终进程被 SIGFPE 信号终止，也先经过内核态处理。<br>✅ 会导致用户态 → 内核态切换</p>
<p>II. sin() 函数调用<br>➡️ 纯用户态库函数调用（如 glibc 的 sin()）：</p>
<p>sin() 是数学库函数（libm），其实现通常基于查表、多项式逼近等算法，不涉及系统调用或硬件异常。<br>它运行在用户空间，由 CPU 直接执行机器指令，无需陷入内核。<br>❌ 不会导致用户态 → 内核态切换<br>📌 注：除非 sin() 内部因浮点异常（如 NaN 输入触发 FE_INVALID 并启用 FE_EXCEPT）而引发信号，但标准情况下 sin() 是“安静”的纯计算函数。</p>
<p>III. read 系统调用<br>➡️ 明确的系统调用（syscall）：</p>
<p>read(fd, buf, count) 是 POSIX 标准系统调用，用户进程必须通过软中断（如 int 0x80）、syscall 指令等方式主动陷入内核，由内核的 sys_read 处理 I&#x2F;O 请求（可能涉及设备驱动、缓冲区管理等）。<br>✅ 必然导致用户态 → 核态切换</p>
<h1 id="题目-14"><a href="#题目-14" class="headerlink" title="题目"></a>题目</h1><p>计算机开机后，操作系统最终被加载到（ ） 。(2013)<br>A. BIOS B. ROM C. EPROM D. RAM</p>
<h2 id="解析-14"><a href="#解析-14" class="headerlink" title="解析"></a>解析</h2><p>答案：D. RAM</p>
<p>✅ 正确答案解析：<br>计算机启动过程简要回顾：<br>上电 → BIOS&#x2F;UEFI 固件运行<br>存储在主板上的 ROM（现代多为 Flash ROM，含 BIOS&#x2F;UEFI）中<br>执行 POST（加电自检），初始化硬件<br>BIOS&#x2F;UEFI 加载引导程序（Bootloader）<br>从硬盘&#x2F;SSD&#x2F;USB 的引导扇区（如 MBR 或 EFI 分区）读取 bootloader（如 GRUB、Windows Boot Manager）到 RAM 中并执行<br>Bootloader 加载操作系统内核<br>将 OS 内核（如 vmlinuz、ntoskrnl.exe）从磁盘读入 RAM<br>跳转到内核入口点，开始执行<br>操作系统运行<br>内核初始化，建立页表、调度器、设备驱动等<br>所有代码和数据均在 RAM 中执行（CPU 不能直接从磁盘&#x2F;ROM 执行复杂 OS）</p>
<p>A. BIOS<br>BIOS 是固件程序本身，不是存储介质；它运行后即退出，不“存放”OS<br>❌ 混淆概念<br>B. ROM<br>存放 BIOS&#x2F;UEFI，只读、容量小、速度慢，无法写入动态 OS；现代 OS 远大于 ROM 容量<br>❌<br>C. EPROM<br>一种可擦写 ROM，仍属非易失性存储器，用于固件，不用于运行 OS<br>❌<br>✅ D. RAM<br>主存（内存）</p>
<p>🎯 考点总结：<br>理解计算机启动流程（BIOS → Bootloader → OS）<br>区分存储介质角色：<br>ROM&#x2F;Flash：存放固件（BIOS&#x2F;UEFI）<br>Disk：长期存储 OS 映像<br>RAM：运行时加载 OS 并执行的唯一场所<br>📌 类比：</p>
<p>ROM 是“说明书”，硬盘是“工具箱”，<br>RAM 才是真正干活的“工作台” —— 操作系统必须摆上工作台才能开工！</p>
<h1 id="题目-15"><a href="#题目-15" class="headerlink" title="题目"></a>题目</h1><p>一个多道批处理系统中仅有P1和P2两个作业，P2比P1晚5ms到达。它们的计算和I&#x2F;O操作顺序如下：<br>P1：计算60ms，I&#x2F;O80ms，计算20ms P2：计算120ms，I&#x2F;O40ms，计算40ms<br>若不考虑调度和切换时间，则完成两个作业需要的时间最少是（ ）。(2012)<br>A.240ms B.260ms C.340ms D.360ms</p>
<h2 id="解析-15"><a href="#解析-15" class="headerlink" title="解析"></a>解析</h2><p>答案：B. 260ms</p>
<p>✅ 解题思路（文字叙述，无表格）：<br>我们有两个作业 P1 和 P2，在多道批处理系统中运行。系统具备：</p>
<p>单 CPU（计算必须串行）<br>单 I&#x2F;O 设备（I&#x2F;O 操作需互斥）<br>关键约束：</p>
<p>每个作业必须严格按“计算 → I&#x2F;O → 计算”顺序执行；<br>P2 比 P1 晚 5ms 到达；<br>不考虑调度与上下文切换开销；<br>目标是最小化总完成时间（即最后一个作业结束时刻）。<br>时间线推演（最优调度策略）：<br>0ms：P1 到达，立即开始第一段计算（60ms）→ 0~60ms：P1 计算</p>
<p>5ms：P2 到达，但 CPU 正被 P1 占用，只能等待。</p>
<p>60ms：P1 第一段计算完成，立即转入 I&#x2F;O（80ms），占用 I&#x2F;O 设备 → 60<del>140ms：P1 I&#x2F;O<br>与此同时，CPU 空闲 5ms（60</del>65）？不！应立刻调度 P2：</p>
<p>⚠️ 注意：P2 在 5ms 已到达，60ms 时 CPU 空出，P2 立即开始计算（120ms）→<br>60~180ms：P2 计算</p>
<p>此时：</p>
<p>P1 在 60<del>140ms 做 I&#x2F;O<br>P2 在 60</del>180ms 做 CPU<br>→ CPU 与 I&#x2F;O 并行，理想重叠<br>140ms：P1 的 I&#x2F;O 完成，但它需要进行第二段计算（20ms）。<br>但此时 CPU 正被 P2 占用（直到 180ms），所以 P1 进入就绪队列等待。</p>
<p>180ms：P2 计算完成，立即进入 I&#x2F;O（40ms）→ 180<del>220ms：P2 I&#x2F;O<br>同时，CPU 空出 → P1 立即开始第二段计算（20ms） → 180</del>200ms：P1 计算</p>
<p>200ms：P1 全部完成（计算结束）。</p>
<p>220ms：P2 I&#x2F;O 完成，进入最后一段计算（40ms）→ 220~260ms：P2 计算</p>
<p>260ms：P2 完成，全部作业结束。</p>
<p>验证资源冲突：<br>CPU 使用：P1(0–60) → P2(60–180) → P1(180–200) → P2(220–260)<br>注意：200–220ms CPU 空闲？看似空闲，但无法避免——因为 P2 此时仍在做 I&#x2F;O（到 220ms 才结束），且 P1 已完成。<br>若强行让 P2 先做 I&#x2F;O 再让 P1 计算？不可行——P2 必须先完成计算才能进入 I&#x2F;O（顺序约束）。<br>I&#x2F;O 使用：P1(60–140) → P2(180–220)，中间 140–180ms I&#x2F;O 空闲，但无作业需要 I&#x2F;O（P2 还在计算），合理。<br>为何不是 240ms（A）？<br>有人误以为完全重叠：<br>60（P1算）+ max(80,120)（P1 I&#x2F;O 与 P2 算）+ 20（P1算）+ max(0,40)（P2 I&#x2F;O）+ 40（P2算）？<br>但忽略了：</p>
<p>P1 第二段计算需等 P2 第一段计算结束（180ms）<br>P2 最后一段计算需等自身 I&#x2F;O 结束（220ms）<br>→ 关键路径：0 → 60 → 180 → 220 → 260<br>✅ 最终答案：B. 260ms</p>
<h1 id="题目-16"><a href="#题目-16" class="headerlink" title="题目"></a>题目</h1><p>下列选项中，不可能在用户态发生的事件是（ ） 。(2012)<br>A．系统调用 B．外部中断 C．进程切换 D．缺页</p>
<h2 id="解析-16"><a href="#解析-16" class="headerlink" title="解析"></a>解析</h2><p>答案：C．进程切换</p>
<p>✅ 解析：<br>题目问：不可能在用户态发生的事件。<br>关键是：该事件的发生时刻或执行主体是否可能处于用户态。</p>
<p>我们逐项分析：</p>
<p>A．系统调用<br>➡️ 可以在用户态“发起”。</p>
<p>用户程序在用户态执行 syscall 或 int 0x80 指令，触发系统调用；<br>虽然处理过程在内核态，但事件的起始点（即系统调用的发生）是在用户态代码中主动发起的。<br>✅ 可能在用户态发生（作为起因）<br>B．外部中断<br>➡️ 可以发生在用户态执行期间。</p>
<p>外部中断（如时钟中断、键盘输入、网卡就绪）是异步事件，可在 CPU 执行任何用户态指令时到来；<br>中断发生时，若当前正在运行用户进程，则 CPU 处于用户态，随后切换到内核态处理。<br>✅ 可能在用户态时发生（中断请求的到达时刻）<br>C．进程切换<br>➡️ 不可能在用户态发生。</p>
<p>进程切换（上下文切换）包括：<br>保存当前进程的 CPU 状态（寄存器、PC 等）<br>更新调度数据结构（如就绪队列）<br>加载新进程的上下文<br>切换页表（CR3）<br>这些操作涉及修改内核关键数据结构和特权寄存器（如 CR3），必须在内核态下执行；<br>用户态无权访问 TCB、调度队列，也不能直接修改内核栈或页表。<br>即使调度由时钟中断触发，实际的 switch_to() 代码总是在内核态执行（如 Linux 的 schedule() 函数）。<br>❌ 不可能在用户态发生 → 正确答案<br>D．缺页<br>➡️ 可以由用户态指令触发。</p>
<p>缺页异常（Page Fault）发生在用户程序执行访存指令时（如 mov (%rax), %rbx），MMU 发现页未加载；<br>此时 CPU 处于用户态，随后陷入内核处理；<br>事件的触发点在用户态。<br>✅ 可能在用户态发生<br>🎯 考点总结：<br>区分 “事件触发” vs “事件处理”：<br>系统调用、缺页、中断：触发于用户态，处理于内核态<br>进程切换：触发可能源于用户态事件（如系统调用阻塞、时钟中断），但切换动作本身只能在内核态执行<br>进程切换是内核的核心操作，涉及特权指令与敏感数据，用户态无法完成。<br>💡 类比：<br>用户可以“按电梯按钮”（触发事件），但“电梯换层”（切换）只能由电梯控制系统（内核）完成。</p>
<h1 id="题目-17"><a href="#题目-17" class="headerlink" title="题目"></a>题目</h1><p>中断处理和子程序调用都需要压栈以保护现场，中断处理一定会保存而子程序调用不需要保存其内容的是<br>（ ） 。(2012)<br>A．程序计数器 B．程序状态字寄存器 C．通用数据寄存器 D．通用地址寄存器</p>
<h2 id="解析-17"><a href="#解析-17" class="headerlink" title="解析"></a>解析</h2><p>答案：B．程序状态字寄存器</p>
<p>✅ 解析：<br>本题考察 中断处理与子程序调用在“保护现场”上的关键区别。</p>
<p>两者都会进行压栈（保存上下文），但保存的内容有差异，核心在于：</p>
<p>子程序调用 是程序主动、预期的控制转移，发生在当前特权级内（如同在用户态调用函数）；<br>中断处理 是异步、非预期的控制转移，可能跨特权级（如用户态 → 内核态），且中断发生时 CPU 状态（尤其是标志位）对后续恢复至关重要。<br>各选项分析：<br>A．程序计数器（PC &#x2F; RIP &#x2F; EIP）<br>✅ 子程序调用需保存：call 指令会自动将返回地址（下一条指令地址）压栈；<br>✅ 中断也需保存：CPU 硬件自动将断点地址压栈；<br>→ 两者都保存，不是区别点。<br>B．程序状态字寄存器（PSW，如 x86 的 RFLAGS &#x2F; EFLAGS）<br>✅ 中断处理一定会保存：<br>PSW 包含关键标志位：IF（中断允许）、TF（单步）、ZF&#x2F;SF&#x2F;CF 等；<br>中断发生时，必须保存 当时的 FLAGS，以便返回后恢复精确的执行环境；<br>x86 中，int&#x2F;异常&#x2F;中断发生时，CPU 硬件自动将 RFLAGS 压栈；<br>❌ 子程序调用通常不需要保存：<br>call&#x2F;ret 指令不保存 FLAGS；<br>普通函数调用约定（如 System V ABI）不负责保护标志寄存器——由调用者或被调用者按需用 pushf&#x2F;popf 显式保存（非常规）；<br>大多数计算类函数不会改变&#x2F;依赖 FLAGS，故默认不保存。<br>✅ 这是中断处理“一定会保存”，而子程序调用“通常不需要保存”的关键项。</p>
<p>C．通用数据寄存器（如 RAX, RBX…）<br>两者都不一定由硬件自动保存；通常由软件约定：<br>子程序调用：调用者&#x2F;被调用者按 ABI 协议决定是否保存（如 RBX, RBP 是 callee-saved）；<br>中断处理：内核中断服务程序（ISR）开头会显式保存用到的通用寄存器；<br>→ 非硬件强制差异。<br>D．通用地址寄存器（如 RSI, RDI…）<br>同上，属于通用寄存器子集，保存策略同 C，无本质区别。<br>🎯 核心考点：<br>中断是异步事件，必须完整保存整个处理器状态（含 PSW），以保证透明恢复；<br>子程序调用是同步控制流，仅需保存返回地址和按需保存部分寄存器，标志位常被忽略；<br>PSW 中的 IF（中断允许位）尤为关键：中断处理前需关中断（CLI），但返回前必须恢复原 IF 状态——这依赖于对 PSW 的保存与还原。<br>🔔 x86 实例：<br>执行 int 0x80 时，CPU 自动压栈：SS, RSP, RFLAGS, CS, RIP<br>而 call func 只压栈：RIP（返回地址）</p>
<h1 id="题目-18"><a href="#题目-18" class="headerlink" title="题目"></a>题目</h1><p>下列与中断相关的操作中，由操作系统完成的是（ ）。(2020)<br>I. 保存被中断程序的中断点 II. 提供中断服务<br>III. 初始化中断向量表 IV. 保存中断屏蔽字<br>A. I，II B. I，II，IV C. III，IV D. II，III，IV</p>
<h2 id="解析-18"><a href="#解析-18" class="headerlink" title="解析"></a>解析</h2><p>答案：D. II，III，IV</p>
<p>✅ 正确解析：<br>本题考察 中断处理过程中软硬件分工，关键是区分哪些由 硬件自动完成，哪些由 操作系统（软件）负责。</p>
<p>我们逐项分析：</p>
<p>I. 保存被中断程序的中断点<br>❌ 由硬件自动完成，不是操作系统做的。</p>
<p>“中断点”指被中断指令的下一条指令地址（返回地址）。<br>当中断&#x2F;异常发生时，CPU 硬件自动将程序计数器（PC&#x2F;EIP&#x2F;RIP）压入栈（用户栈或内核栈，取决于特权级切换）；<br>例如 x86 在中断时自动压栈：RIP, CS, RFLAGS 等。<br>→ OS 无需也不应该干预此过程。<br>II. 提供中断服务<br>✅ 由操作系统完成。</p>
<p>中断服务程序（ISR, Interrupt Service Routine）是操作系统编写并注册的内核函数，如：<br>时钟中断处理函数（更新 jiffies、调度 tick）<br>键盘中断处理（读扫描码、放入输入缓冲区）<br>网卡中断（收包、软中断触发）<br>硬件只负责跳转到 ISR 入口，具体服务逻辑完全由 OS 实现。<br>III. 初始化中断向量表<br>✅ 由操作系统完成。</p>
<p>中断向量表（Interrupt Vector Table, IVT）或中断描述符表（IDT，在保护模式下）存储各中断号对应的处理程序入口地址；<br>BIOS&#x2F;UEFI 只提供初始简单设置（如实模式 IVT），进入保护&#x2F;长模式后，OS 启动早期（如 setup_idt()）必须重新初始化 IDT，填入自己的 ISR 地址；<br>若 OS 不做此工作，中断将跳转到错误地址或默认 BIOS 处理器，无法支持现代功能。<br>IV. 保存中断屏蔽字<br>✅ 由操作系统在中断处理中完成。</p>
<p>“中断屏蔽字”指控制哪些中断被屏蔽的寄存器状态，如 x86 的 EFLAGS.IF 位，或中断控制器（如 APIC&#x2F;8259A）的屏蔽寄存器（IMR）；<br>硬件在进入中断时会自动清 IF（关中断），但：<br>OS 在调度临界区、嵌套中断管理时，需显式保存&#x2F;恢复中断屏蔽状态；<br>例如 Linux 的 local_irq_save(flags) 会保存 flags（含 IF），之后 local_irq_restore(flags) 恢复；<br>对于可屏蔽中断控制器（如 8259A），OS 也可能动态修改 IMR，并需保存上下文。<br>→ 属于操作系统为实现正确中断嵌套与同步而做的软件管理。<br>🎯 考点总结：<br>硬件负责：中断检测、特权级切换、自动保存关键寄存器（PC、PSW、栈指针等）<br>操作系统负责：<br>建立中断响应框架（初始化 IDT&#x2F;IVT）<br>编写具体中断服务逻辑<br>管理中断屏蔽与嵌套（软件层面的状态保存与恢复）<br>易错点：误以为“保存中断点”是 OS 做的——实际是 CPU 微码硬连线行为。</p>
<h1 id="题目-19"><a href="#题目-19" class="headerlink" title="题目"></a>题目</h1><p>下列关于系统调用的叙述中，正确的是（ ）。(2019)<br>I.在执行系统调用服务程序的过程中，CPU处于内核态<br>Ⅱ.操作系统通过提供系统调用避免用户程序直接访问外设<br>Ⅲ.不同的操作系统为应用程序提供了统一的系统调用接口<br>IV.系统调用是操作系统内核为应用程序提供服务的接口<br>A.仅I、IV B.仅II、III C.仅I、Ⅱ、IV D.仅I、Ⅲ、Ⅳ</p>
<h2 id="解析-19"><a href="#解析-19" class="headerlink" title="解析"></a>解析</h2><p>答案：C. 仅 I、Ⅱ、IV</p>
<p>✅ 逐项解析：<br>I. 在执行系统调用服务程序的过程中，CPU 处于内核态<br>✅ 正确。</p>
<p>系统调用通过 syscall &#x2F; int 0x80 等指令触发陷入（trap），CPU 自动切换到内核态；<br>内核的系统调用分发器（如 entry_SYSCALL_64）随后调用对应的服务例程（如 sys_read），整个过程在内核态执行；<br>返回用户态前（如 sysret）才切换回去。<br>II. 操作系统通过提供系统调用避免用户程序直接访问外设<br>✅ 正确。</p>
<p>直接访问外设（如 in&#x2F;out 指令、MMIO 地址）是特权操作，用户态执行会触发保护异常；<br>所有设备访问必须通过系统调用（如 read&#x2F;write&#x2F;ioctl）进入内核，由驱动程序代为操作；<br>这保障了安全性（防恶意程序破坏硬件）、稳定性（防冲突访问）、可移植性（抽象设备差异）。<br>III. 不同的操作系统为应用程序提供了统一的系统调用接口<br>❌ 错误。</p>
<p>系统调用接口高度依赖具体 OS 实现：<br>Linux 使用 sys_call_table，调用号如 __NR_read &#x3D; 0<br>Windows 使用 ntdll.dll → syscall → 内核 NtReadFile<br>macOS（BSD 层）系统调用号与 Linux 不同<br>即使同属 POSIX，系统调用编号、参数传递方式、内部行为也可能不同；<br>“统一接口”是库层面（如 glibc 实现 POSIX API）的努力，非系统调用本身统一。<br>→ 本项错误。<br>IV. 系统调用是操作系统内核为应用程序提供服务的接口<br>✅ 正确。</p>
<p>这是系统调用的标准定义：<br>“System calls are the fundamental interface between a process and the kernel.”<br>—— Operating System Concepts (Silberschatz)</p>
<p>应用程序通过系统调用请求内核服务：文件操作、进程控制、通信、时间等。<br>✅ 正确项：I、II、IV<br>→ 对应选项 C</p>
<p>🎯 考点总结：<br>系统调用的核心特征：内核态执行、安全隔离、内核服务入口<br>区分 系统调用（syscall） 与 API（如 POSIX）：<br>系统调用是 OS 特定的底层机制；<br>API 是标准化的编程接口，可跨平台（通过不同 syscall 实现）；<br>“统一接口”是库&#x2F;标准（如 POSIX、C 标准库）的目标，非 syscall 本身的属性。<br>✅ 正确答案：C. 仅 I、Ⅱ、IV</p>
<h1 id="题目-20"><a href="#题目-20" class="headerlink" title="题目"></a>题目</h1><p>下列关于多任务操作系统的叙述中，正确的（ ）。(2018)<br>Ⅰ.具有并发和并行的特点 Ⅱ.需要实现对共享资源的保护 Ⅲ.需要运行在多CPU的硬件平台上<br>A.仅Ⅰ B.仅Ⅱ C.仅Ⅰ、Ⅱ D.Ⅰ、Ⅱ、Ⅲ</p>
<h2 id="解析-20"><a href="#解析-20" class="headerlink" title="解析"></a>解析</h2><p>答案：C. 仅Ⅰ、Ⅱ</p>
<p>✅ 逐项解析：<br>Ⅰ. 具有并发和并行的特点<br>✅ 正确（需注意术语区分）：</p>
<p>并发（Concurrency）：指宏观上多个任务“同时推进”，微观上可能交替执行（单 CPU 通过时间片轮转实现）；<br>并行（Parallelism）：指微观上多个任务真正同时执行（需多核&#x2F;多 CPU）；<br>多任务操作系统一定支持并发；若运行在多核平台上，也能支持并行；<br>题干说“具有并发和并行的特点”，应理解为“具备支持两者的能力”，而非“必须同时发生”。现代多任务 OS（如 Linux、Windows）设计上同时支持并发与并行，故此项正确。<br>📌 注：即使在单核机器上，系统仍具备并行能力（只要换到多核平台即可发挥），这属于 OS 的设计特性。</p>
<p>Ⅱ. 需要实现对共享资源的保护<br>✅ 正确。</p>
<p>多任务环境下，多个进程&#x2F;线程可能同时访问共享资源（如内存、文件、设备、全局变量）；<br>若无保护，会导致竞态条件（Race Condition）、数据不一致、死锁等问题；<br>OS 必须提供同步机制：如互斥锁（mutex）、信号量（semaphore）、临界区等；<br>这是多任务系统正确性与稳定性的基石。<br>Ⅲ. 需要运行在多CPU的硬件平台上<br>❌ 错误。</p>
<p>多任务操作系统最早诞生于单 CPU 系统（如 UNIX V6、MS-DOS 的多任务扩展、Windows 3.x 增强模式）；<br>通过时间片轮转 + 中断 + 进程切换，单 CPU 也能实现多任务（即并发）；<br>多 CPU 是提升性能（实现并行）的可选硬件支撑，非必要前提。<br>→ 本项明显错误。<br>🎯 考点总结：<br>并发 ≠ 并行：并发是逻辑概念（任务交错推进），并行是物理概念（真正同时执行）；<br>多任务 OS 的核心在于：<br>调度（实现并发）<br>同步与保护（保障共享正确性）<br>硬件平台是实现手段，非定义约束——多任务是软件能力，可在单核上运行。</p>
<h1 id="题目-21"><a href="#题目-21" class="headerlink" title="题目"></a>题目</h1><p>处理外部中断时，应该由操作系统保存的是（ ）。 (2015)<br>A.程序计数器(PC)的内容 B.通用寄存器的内容 C.快表(TLB)中的内容 D.Cache中的内容</p>
<h2 id="解析-21"><a href="#解析-21" class="headerlink" title="解析"></a>解析</h2><p>答案：B. 通用寄存器的内容</p>
<p>✅ 解析：<br>本题考察 中断处理过程中，软硬件对“现场保存”的分工。</p>
<p>当中断发生时，硬件和操作系统协同完成上下文保存，但职责不同：</p>
<p>A. 程序计数器（PC）的内容<br>❌ 由硬件自动保存，非操作系统负责。</p>
<p>中断&#x2F;异常触发时，CPU 硬件电路会自动将当前 PC（即下一条指令地址，断点）压入栈（内核栈或当前栈）；<br>例如 x86 中，int&#x2F;中断发生时，CPU 自动压栈：RIP、CS、RFLAGS 等；<br>→ OS 无需、也不应干预此过程。<br>B. 通用寄存器的内容<br>✅ 由操作系统（软件）保存。</p>
<p>硬件不会自动保存通用寄存器（如 RAX, RBX, RCX…）；<br>中断服务程序（ISR）运行前，若需要使用这些寄存器，必须由 OS 的中断处理入口代码显式保存（如 push %rax; push %rbx; …）；<br>恢复时再弹出，以保证被中断程序的寄存器状态透明；<br>这是 OS 编写 ISR 时的标准操作（如 Linux 的 SAVE_ALL 宏保存通用寄存器）。<br>C. 快表（TLB）中的内容<br>❌ 通常不需要保存，且 OS 不负责“保存 TLB 内容”。</p>
<p>TLB 是 MMU 的高速缓存，存储虚拟页号 → 物理页帧号的映射；<br>中断本身不改变页表，TLB 内容仍然有效；<br>若中断导致进程切换（如时钟中断后调度），OS 会刷新或切换地址空间（如 mov %cr3, %rax），此时 TLB 自动失效或部分失效，但不是“保存 TLB 内容”；<br>TLB 是硬件缓存，内容不可直接读写（无指令可 dump TLB），故无法“保存”。<br>D. Cache 中的内容<br>❌ 由硬件透明管理，OS 不保存。</p>
<p>Cache（L1&#x2F;L2&#x2F;L3）是 CPU 透明缓存，内容随内存访问自动更新；<br>中断不改变内存语义，Cache 一致性由硬件协议（如 MESI）维护；<br>OS 无法也不需要保存 cache 内容。</p>
<h1 id="题目-22"><a href="#题目-22" class="headerlink" title="题目"></a>题目</h1><p>下列选项中，在用户态执行的是（ ）。 (2011)<br>A.命令解释程序 B.缺页处理程序 C.进程调度程序 D.时钟中断处理程序</p>
<h2 id="解析-22"><a href="#解析-22" class="headerlink" title="解析"></a>解析</h2><p>答案：A. 命令解释程序</p>
<p>✅ 解析：<br>题目问：哪个程序在用户态执行？<br>关键在于判断各模块的运行特权级。</p>
<p>A. 命令解释程序（Command Interpreter）<br>✅ 在用户态执行。</p>
<p>即 Shell（如 bash、zsh、cmd.exe、PowerShell）；<br>它是普通用户进程，由操作系统启动，运行在用户态；<br>功能：读取用户命令 → 解析 → 调用系统调用（如 fork + exec）启动新程序；<br>虽然它发起系统调用进入内核，但自身代码执行始终在用户态。<br>B. 缺页处理程序<br>❌ 在内核态执行。</p>
<p>缺页异常（Page Fault）触发后，CPU 陷入内核；<br>由内核的 page_fault() 处理函数（如 Linux 的 do_page_fault）响应，涉及页表修改、磁盘 I&#x2F;O 调度、内存分配等特权操作；<br>用户态无法访问页表或分配物理页。<br>C. 进程调度程序<br>❌ 在内核态执行。</p>
<p>调度器（如 Linux 的 schedule()）负责选择下一个运行进程、切换上下文、更新 TCB&#x2F;运行队列；<br>涉及修改内核关键数据结构和特权寄存器（如 CR3 切换地址空间），必须在内核态。<br>D. 时钟中断处理程序<br>❌ 在内核态执行。</p>
<p>时钟中断是硬件中断，发生时 CPU 自动切换到内核态；<br>中断服务程序（如 Linux 的 timer_interrupt）更新系统时间、触发调度 tick、处理定时器等，均为内核逻辑。<br>🎯 考点总结：<br>用户态程序：所有普通应用程序、Shell、库函数等；<br>内核态程序：中断处理、异常处理、系统调用服务例程、调度器、内存管理、设备驱动等；<br>Shell 是典型的用户态系统程序——它是用户与 OS 的桥梁，但本身不是 OS 内核的一部分。<br>📌 记忆口诀：<br>“Shell 是用户雇的秘书，内核才是公司 CEO”<br>秘书（Shell）跑腿传话（调用 syscall），但决策（调度、缺页、中断）全由 CEO（内核）在高管层（内核态）完成。</p>
<h1 id="题目-23"><a href="#题目-23" class="headerlink" title="题目"></a>题目</h1><p>响应外部中断的过程中，中断隐指令完成的操作，除保护断点外，还包括<br>______。(2012 组成原理)<br>Ⅰ．关中断 Ⅱ．保存通用寄存器的内容 Ⅲ．形成中断服务程序入口地址并送 PC<br>A．仅Ⅰ、Ⅱ B．仅Ⅰ、Ⅲ C．仅Ⅱ、Ⅲ D．Ⅰ、Ⅱ、Ⅲ</p>
<h2 id="解析-23"><a href="#解析-23" class="headerlink" title="解析"></a>解析</h2><p>答案：B．仅Ⅰ、Ⅲ</p>
<p>✅ 解析：<br>本题考察 “中断隐指令”（Interrupt Implicit Instruction） 的概念——它不是一条真实指令，而是 CPU 响应中断时硬件自动完成的一系列微操作的统称，对程序员透明。</p>
<p>这些操作由 硬件电路自动完成，发生在中断响应周期，典型的包括：</p>
<p>Ⅰ．关中断<br>✅ 是中断隐指令的操作。</p>
<p>为防止中断嵌套导致栈溢出或处理混乱，大多数体系结构在进入中断服务前硬件自动关闭可屏蔽中断（如 x86 清除 EFLAGS.IF 位）；<br>注意：非屏蔽中断（NMI）仍可响应；<br>这是硬件行为，属于中断隐指令的一部分。<br>Ⅱ．保存通用寄存器的内容<br>❌ 不是中断隐指令的操作。</p>
<p>通用寄存器（如 RAX, RBX, RCX…）的保存由中断服务程序的软件入口代码完成（如 push %rax; push %rbx; …）；<br>硬件不会自动保存通用寄存器——那样开销太大，且未必所有 ISR 都需要；<br>是否保存、保存哪些，由 OS 编程决定。<br>Ⅲ．形成中断服务程序入口地址并送 PC<br>✅ 是中断隐指令的核心操作。</p>
<p>CPU 根据中断类型号（如 IRQ0&#x3D;32），查中断向量表（IVT） 或 中断描述符表（IDT），取出对应 ISR 的入口地址；<br>将该地址装入 程序计数器（PC &#x2F; RIP），从而跳转到中断服务程序开始执行；<br>整个查表 + 跳转由硬件完成，属于中断隐指令。<br>✅ 额外补充：中断隐指令通常包括（硬件自动）：<br>保护断点：将 PC（及 CS、PSW）压栈<br>关中断（针对可屏蔽中断）<br>查中断向量表 → 获取 ISR 入口地址 → 装入 PC<br>而以下由软件（OS）完成：</p>
<p>保存通用寄存器、浮点寄存器等<br>执行具体的中断服务逻辑<br>恢复现场（弹出寄存器、开中断、iret）<br>🎯 考点总结：<br>中断隐指令 &#x3D; 硬件自动完成的操作<br>关键三步：保护断点、关中断、跳转到 ISR<br>保存通用寄存器是软件责任，非硬件隐指令</p>
<h1 id="题目-24"><a href="#题目-24" class="headerlink" title="题目"></a>题目</h1><p>下列选项中，通过系统调用完成的操作是( )。 (2021.32)<br>A．页置换 B．进程调度 C．创建新进程 D．生成随机整数</p>
<h2 id="解析-24"><a href="#解析-24" class="headerlink" title="解析"></a>解析</h2><p>答案：C．创建新进程</p>
<p>✅ 解析：<br>题目问：哪个操作是“通过系统调用完成”的？<br>即：应用程序必须通过系统调用请求内核执行该操作。</p>
<p>我们逐项分析：</p>
<p>A．页置换<br>❌ 由操作系统内核在缺页异常处理中自动完成，不需要也不允许用户程序主动发起。</p>
<p>当发生缺页时，CPU 陷入内核 → 内核的缺页处理程序决定是否需要页置换（选择牺牲页、写回磁盘、加载新页等）；<br>整个过程对用户透明，无对应系统调用；<br>用户无法也不应干预物理内存管理。<br>B．进程调度<br>❌ 由操作系统内核自主完成，非系统调用触发。</p>
<p>调度发生在：<br>时钟中断（时间片到期）<br>系统调用中进程主动阻塞（如 read 等待 I&#x2F;O）<br>进程退出、唤醒等事件<br>应用程序不能直接调用“调度”；它只能通过系统调用间接影响调度（如 sleep()、yield()），但调度决策本身是内核行为；<br>无 schedule() 系统调用。<br>C．创建新进程<br>✅ 通过系统调用完成。</p>
<p>典型系统调用：<br>UNIX&#x2F;Linux：fork(), vfork(), clone()<br>进一步配合 exec() 系列加载新程序<br>用户程序必须调用这些系统调用，才能请求内核为其创建新进程（分配 PCB、复制页表、设置上下文等）；<br>这是用户主动发起、内核执行的典型系统调用场景。<br>D．生成随机整数<br>❌ 通常在用户态完成，不一定需要系统调用。</p>
<p>普通伪随机数（如 rand()）由 glibc 等库在用户态实现，基于线性同余等算法，不涉及内核；<br>若需要真随机数（如加密用途），可读 &#x2F;dev&#x2F;random 或 &#x2F;dev&#x2F;urandom，此时通过 read() 系统调用间接获取；但：<br>read() 是通用 I&#x2F;O 系统调用，“生成随机数”本身不是系统调用；<br>题干问的是“通过系统调用完成的操作”，而“生成”动作实质在内核的 random.c 驱动中，但选项 D 描述模糊，且通常场景下不依赖 syscall；<br>相比之下，C 是明确、直接、必须通过系统调用完成的操作。<br>🎯 考点总结：<br>系统调用是 用户程序 ↔ 内核 的唯一受控接口；<br>只有需要内核特权或全局资源的操作才通过系统调用：<br>进程控制（fork, exit, wait）<br>文件 I&#x2F;O（open, read, write）<br>设备控制（ioctl）<br>通信（pipe, socket）<br>而页置换、调度等属于内核自主管理行为，对用户透明；<br>库函数（如 rand()、malloc()）≠ 系统调用。</p>
<h1 id="题目-25"><a href="#题目-25" class="headerlink" title="题目"></a>题目</h1><p>下列关于“自陷”（Trap，也称陷阱）的叙述中，错误的是（ ）。(2020 组成原理)<br>A. 自陷是通过陷阱指令预先设定的一类外部中断事件<br>B. 自陷可用于实现程序调试时的断点设置和单步跟踪<br>C. 自陷发生后CPU将转去执行操作系统内核相应程序<br>D. 自陷处理完成后返回到陷阱指令的下一条指令执行</p>
<h2 id="解析-25"><a href="#解析-25" class="headerlink" title="解析"></a>解析</h2><p>答案：A. 自陷是通过陷阱指令预先设定的一类外部中断事件</p>
<p>✅ 解析：<br>本题考查对 自陷（Trap） 的本质理解，关键在于区分：</p>
<p>Trap 是内部异常（内中断），不是外部中断；<br>它由程序主动执行特定指令（如 int 3、syscall）引发，同步、可预期；<br>与硬件异步触发的外部中断（如键盘、时钟）有根本区别。<br>逐项分析：<br>A. 自陷是通过陷阱指令预先设定的一类外部中断事件<br>❌ 错误（本题答案）</p>
<p>Trap 属于内部异常（内中断），由 CPU 在执行指令过程中检测到特定条件（如执行 int 指令）而触发；<br>外部中断来自 CPU 外部设备（如 I&#x2F;O 控制器），与当前指令流无关（异步）；<br>Trap 是同步事件，与指令强关联；外部中断是异步事件。<br>→ 将 Trap 归为“外部中断”是概念性错误。<br>B. 自陷可用于实现程序调试时的断点设置和单步跟踪<br>✅ 正确</p>
<p>断点：调试器将目标地址指令替换为 int 3（x86）触发 Trap，内核捕获后通知调试器；<br>单步跟踪：设置 EFLAGS.TF &#x3D; 1（陷阱标志），每条指令后触发单步 Trap（#DB 异常）；<br>→ Trap 是调试支持的核心机制。<br>C. 自陷发生后 CPU 将转去执行操作系统内核相应程序<br>✅ 正确</p>
<p>Trap 触发后，CPU 根据中断向量（如 int 3 → 向量 3）查 IDT，跳转到内核注册的处理程序（如 do_int3）；<br>所有 Trap 最终由内核统一接管（即使是用户态调试，也需内核转发信号）。<br>D. 自陷处理完成后返回到陷阱指令的下一条指令执行<br>✅ 正确（针对典型的 Trap 类异常）</p>
<p>Trap 的特点是：陷阱指令本身已执行完毕，返回时应继续执行下一条指令；<br>对比：Fault（如缺页）返回时重执行引发异常的指令；<br>例子：<br>int 0x80（系统调用）执行后，返回用户态执行 int 0x80 的下一条指令；<br>int 3 断点触发后，调试器恢复原指令并继续执行下一条。</p>
<h1 id="题目-26"><a href="#题目-26" class="headerlink" title="题目"></a>题目</h1><p>下列事件中，属于外部中断事件的是（）。(2020)<br>Ⅰ. 访存时缺页 Ⅱ. 定时器到时 Ⅲ. 网络数据包到达<br>A. 仅Ⅰ、Ⅱ B. 仅Ⅰ、Ⅲ C. 仅Ⅱ、Ⅲ D. Ⅰ、Ⅱ和Ⅲ</p>
<h2 id="解析-26"><a href="#解析-26" class="headerlink" title="解析"></a>解析</h2><p>答案：C. 仅Ⅱ、Ⅲ</p>
<p>✅ 解析：<br>题目要求选出 属于外部中断事件 的选项。</p>
<p>首先明确概念：<br>外部中断（External Interrupt）：<br>由 CPU 外部硬件设备 发起的异步信号，与当前执行的指令无关，通过中断控制器（如 APIC、8259A）向 CPU 发出中断请求（INTR）。<br>典型来源：时钟、键盘、鼠标、磁盘、网卡等 I&#x2F;O 设备。<br>内部异常（Internal Exception）：<br>由 CPU 执行指令过程中检测到的事件 引起，与当前指令强相关（同步），如除零、缺页、非法指令等。<br>逐项判断：<br>Ⅰ. 访存时缺页<br>❌ 不属于外部中断，而是内部异常（具体为 fault）。</p>
<p>缺页由 MMU（内存管理单元，CPU 内部组件）在执行访存指令时检测到页表项无效或未驻留而触发；<br>属于同步异常，中断向量通常为 #PF（Page Fault）；<br>→ 是内中断，非外部中断。<br>Ⅱ. 定时器到时<br>✅ 属于外部中断。</p>
<p>系统时钟定时器（如 HPET、APIC Timer）是独立硬件模块，定时产生脉冲信号，通过中断控制器向 CPU 发出中断请求（如 IRQ0 &#x2F; Local APIC LVT Timer）；<br>虽然用于系统调度等，但其触发源是外部硬件，与 CPU 当前执行的指令无关；<br>→ 是典型的可屏蔽外部中断。<br>Ⅲ. 网络数据包到达<br>✅ 属于外部中断。</p>
<p>网卡（NIC）收到数据包后，若配置为中断模式，会通过 PCIe 向中断控制器发送中断请求（如 MSI&#x2F;MSI-X）；<br>CPU 收到后暂停当前任务，转去执行网卡驱动的 ISR；<br>显然来自外部设备，是标准外部中断。<br>✅ 结论：<br>Ⅰ：❌ 内部异常<br>Ⅱ：✅ 外部中断<br>Ⅲ：✅ 外部中断<br>→ 正确选项为 C. 仅Ⅱ、Ⅲ<br>🎯 考点总结：<br>区分中断来源：<br>外部：设备（时钟、网卡、磁盘控制器 …）<br>内部：CPU 执行指令引发（缺页、除零、INT 指令 …）<br>缺页常被误认为“设备导致”，但触发机制在 CPU 内部（MMU），属异常；<br>现代系统中，为减少中断开销，网卡常使用轮询（如 NAPI），但**“数据包到达可引发中断”仍是其基本工作模式之一**，题干未限定实现方式，默认按经典中断模型理解。</p>
<h1 id="题目-27"><a href="#题目-27" class="headerlink" title="题目"></a>题目</h1><p>外部中断包括不可屏蔽中断（NMI）和可屏蔽中断。下列关于外部中断的叙述中，错误的是（ ）。(2020 组成原理)<br>A. CPU处于关中断状态时，也能响应NMI请求<br>B. 一旦可屏蔽中断请求信号有效，CPU将立即响应<br>C. 不可屏蔽中断的优先级比可屏蔽中断的优先级高<br>D. 可通过中断屏蔽字改变可屏蔽中断的处理优先级</p>
<h2 id="解析-27"><a href="#解析-27" class="headerlink" title="解析"></a>解析</h2><p>答案：B. 一旦可屏蔽中断请求信号有效，CPU将立即响应</p>
<p>✅ 解析：<br>本题考查 外部中断（特别是可屏蔽中断）的响应条件与机制。我们逐项分析：</p>
<p>A. CPU 处于关中断状态时，也能响应 NMI 请求<br>✅ 正确。</p>
<p>NMI（Non-Maskable Interrupt）是不可屏蔽中断，设计用于处理严重硬件事件（如电源故障、内存奇偶校验错）；<br>其触发不受 EFLAGS.IF 位（中断允许标志）控制，即使执行了 cli（关中断），NMI 仍可被响应；<br>这是 NMI 的核心特性。<br>B. 一旦可屏蔽中断请求信号有效，CPU 将立即响应<br>❌ 错误（本题答案）</p>
<p>可屏蔽中断（如 IRQ0~15）的响应需同时满足多个条件：<br>中断请求线有效（INTR &#x3D; 1）<br>CPU 处于开中断状态（IF &#x3D; 1）<br>当前指令执行完毕（CPU 只在指令边界响应中断）<br>无更高优先级中断&#x2F;异常正在处理<br>若 CPU 正在执行关中断代码（IF &#x3D; 0），或处于原子指令（如 lock inc）、中断服务中，即使 INTR 有效，也不会立即响应；<br>中断是异步但非即时的，需等待合适的响应点。<br>C. 不可屏蔽中断的优先级比可屏蔽中断的优先级高<br>✅ 正确。</p>
<p>硬件设计上，NMI 的优先级通常高于所有可屏蔽中断；<br>例如 x86 中，NMI 向量号为 2，高于 IRQ0（通常映射为 32+），且不受屏蔽影响；<br>这确保关键故障能被及时处理。<br>D. 可通过中断屏蔽字改变可屏蔽中断的处理优先级<br>✅ 正确。</p>
<p>中断屏蔽字（Interrupt Mask Register, IMR）是中断控制器（如 8259A、APIC）中的寄存器，用于禁止某些 IRQ 线；<br>通过编程 IMR（如 outb(0x21, mask)），可动态屏蔽低优先级中断，从而间接提升其他中断的相对优先级；<br>现代 APIC 还支持优先级寄存器（TPR），更精细地控制中断抢占。<br>🎯 考点总结：<br>中断响应 ≠ 中断请求有效：受 IF 标志、指令边界、当前状态制约；<br>“立即响应”是常见误解：CPU 必须完成当前指令（甚至微码序列）后才采样中断；<br>实时系统中，为减少延迟，会：<br>使用 NMI 处理紧急事件<br>缩短临界区（减少关中断时间）<br>采用中断嵌套与优先级管理</p>
<h1 id="题目-28"><a href="#题目-28" class="headerlink" title="题目"></a>题目</h1><p>异常事件在当前指令执行过程中进行检测，中断请求则在当前指令执行后进行检测。下列事件中。下列事<br>件中，相应处理程序执行后，必须回到当前指令重新执行的是（ ）。(2021)<br>A. 系统调用 B. 页缺失 C. DMA传送结束 D. 打印机缺纸</p>
<h2 id="解析-28"><a href="#解析-28" class="headerlink" title="解析"></a>解析</h2><p>答案：B. 页缺失</p>
<p>✅ 解析：<br>题干关键句：</p>
<p>“异常事件在当前指令执行过程中检测，中断请求在当前指令执行后检测”<br>→ 问：处理完后必须回到 当前指令 重新执行 的是哪个？</p>
<p>这指向异常中的 Fault（故障） 类事件——其特点是：引发异常的指令尚未完成，修复后需重试该指令。</p>
<p>我们逐项分析：</p>
<p>A. 系统调用<br>→ 属于 Trap（陷阱） 类异常。</p>
<p>由 syscall &#x2F; int 0x80 等指令主动触发，且该指令本身已执行完毕；<br>处理完成后，返回到该 trap 指令的下一条指令继续执行；<br>❌ 不需重执行当前指令。<br>B. 页缺失（即缺页异常，Page Fault）<br>→ 属于 Fault（故障） 类异常。</p>
<p>发生在 CPU 执行某条访存指令（如 mov (%rax), %rbx）过程中，MMU 发现页不在内存；<br>此时，该访存指令尚未完成（数据未读入）；<br>内核处理缺页：分配物理页、从磁盘加载、更新页表；<br>处理完成后，必须重新执行原访存指令，才能正确完成数据访问；<br>✅ 必须回到当前指令重新执行 —— 正确答案。<br>C. DMA 传送结束<br>→ 属于 外部中断。</p>
<p>DMA 控制器完成后向 CPU 发中断，与当前指令无关（异步）；<br>中断处理完后，返回到被中断的下一条指令继续执行；<br>❌ 不涉及重执行当前指令。<br>D. 打印机缺纸<br>→ 通常由设备通过外部中断或轮询检测发现，属于 I&#x2F;O 异常；</p>
<p>若通过中断上报（如并口中断），同 C，返回下一条指令；<br>若由系统调用（如 write）内部检测到，则 write 返回错误码（如 EIO），用户程序自行处理，不自动重试；<br>❌ 无“必须重执行当前指令”的语义。</p>
<h1 id="题目-29"><a href="#题目-29" class="headerlink" title="题目"></a>题目</h1><p>下列指令中，只能在内核态执行的是( )。(2021)<br>A、trap 指令 B、I&#x2F;O 指令 C、数据传送指令 D、设置断点指令</p>
<h2 id="解析-29"><a href="#解析-29" class="headerlink" title="解析"></a>解析</h2><p>答案：B、I&#x2F;O 指令</p>
<p>✅ 解析：<br>题目问：只能在内核态（特权态）执行的指令。<br>我们逐项分析各选项的特权级要求（以 x86 为例，其他架构原则类似）：</p>
<p>A. trap 指令<br>❌ 可在用户态执行。</p>
<p>泛指主动陷入内核的指令，如：<br>x86：int n（如 int 0x80）、syscall<br>ARM：svc #0（Supervisor Call）<br>这些指令设计目的就是供用户程序发起系统调用，属于非特权指令；<br>执行后自动切换到内核态，但发起点在用户态。<br>✅ 用户态可用。<br>B. I&#x2F;O 指令<br>✅ 只能在内核态执行。</p>
<p>典型如 x86 的 in &#x2F; out 指令（端口 I&#x2F;O），或对 MMIO 地址的直接访问（虽无专用指令，但地址访问受页保护限制）；<br>出于安全与稳定性考虑，直接硬件 I&#x2F;O 是特权操作：<br>若用户程序随意读写设备寄存器，可导致设备混乱、系统崩溃、信息泄露；<br>x86 中，执行 in&#x2F;out 时若 CPL &gt; IOPL（I&#x2F;O Privilege Level），触发 #GP（General Protection Fault）；<br>现代 OS 将 IOPL 设为 0（仅内核可 I&#x2F;O）；<br>用户程序必须通过 read&#x2F;write&#x2F;ioctl 等系统调用间接访问设备。<br>✅ 仅内核态可执行 → 正确答案。<br>C. 数据传送指令<br>❌ 可在用户态执行。</p>
<p>如 mov, push, pop, lea 等通用数据移动指令；<br>是程序基础操作，用户程序大量使用；<br>只要不访问内核地址空间（受页保护限制），完全可在用户态运行。<br>✅ 非特权指令。<br>D. 设置断点指令<br>❌ 可在用户态执行。</p>
<p>通常指 int 3（x86 断点指令），或调试器写入的软断点；<br>int 3 是一条合法的 trap 指令，用户态可执行；<br>执行后陷入内核（由调试子系统处理），但指令本身非特权；<br>硬件断点（DR0~DR7）的设置才是特权操作，但“设置断点指令”一般指 int 3。<br>✅ 用户态可用。</p>
<h1 id="题目-30"><a href="#题目-30" class="headerlink" title="题目"></a>题目</h1><p>下列关于多道程序系统的叙述中，不正确的是 ( ) (2022)<br>A.支持进程的并发执行 B.不必支持虚拟存储管理<br>C.需要实现对共享资源的管理 D.进程数越多CPU 利用率越高</p>
<h2 id="解析-30"><a href="#解析-30" class="headerlink" title="解析"></a>解析</h2><p>答案：D. 进程数越多 CPU 利用率越高</p>
<p>✅ 解析：<br>题目要求选出 不正确的叙述。我们逐项分析：</p>
<p>A. 支持进程的并发执行<br>✅ 正确。<br>多道程序系统的核心目标就是通过进程并发（宏观并行）提高资源利用率。多个进程交替或并行执行是其基本特征。</p>
<p>B. 不必支持虚拟存储管理<br>✅ 正确（即此项不是错误叙述）。</p>
<p>早期多道程序系统（如 IBM OS&#x2F;MVT）运行在无虚拟内存的硬件上，使用覆盖（Overlay） 或交换（Swapping） 技术管理内存；<br>虚拟存储（分页&#x2F;分段）是后续发展，并非多道程序的必要条件；<br>只要内存足够容纳多个作业，或配合交换区，即可实现多道程序。<br>→ 所以“不必支持”是事实陈述，正确。<br>C. 需要实现对共享资源的管理<br>✅ 正确。<br>并发进程可能竞争 CPU、内存、I&#x2F;O 设备、文件等资源，必须通过同步机制（互斥锁、信号量等）避免竞态条件，这是多道系统的基本要求。</p>
<p>D. 进程数越多 CPU 利用率越高<br>❌ 错误（本题答案）。</p>
<p>CPU 利用率并非随进程数无限增长：<br>当进程数较少时，增加进程可减少 CPU 空闲（如一个进程 I&#x2F;O 时另一个计算），提升利用率；<br>但当进程数超过系统承载能力后：<br>调度开销（上下文切换）剧增；<br>缓存&#x2F;TLB 失效率上升；<br>内存压力导致频繁缺页或交换（thrashing）；<br>实际 CPU 用于“干活”的比例反而下降；<br>存在一个最优进程数，使 CPU 利用率最高；过多会导致性能下降。<br>→ 该说法忽略了系统开销与资源瓶颈，是典型的片面认识。<br>🎯 考点总结：<br>多道程序 ≠ 无限进程；<br>性能与并发度呈倒 U 型关系：太少 → 资源闲置；太多 → 调度&#x2F;换页开销主导；<br>虚拟存储是增强手段，非多道程序的前提（历史事实：多道早于虚拟内存）。</p>
<h1 id="题目-31"><a href="#题目-31" class="headerlink" title="题目"></a>题目</h1><p>下列选项中，需要在操作系统进行初始化过程中创建的是( ) (2022)<br>A.中断向量表 B.文件系统的根目录<br>C.硬盘分区表 D.文件系统的索引节点表</p>
<h2 id="解析-31"><a href="#解析-31" class="headerlink" title="解析"></a>解析</h2><p>答案：A. 中断向量表</p>
<p>✅ 解析：<br>题目问：需要在操作系统初始化过程中创建的是哪个？<br>强调“操作系统初始化时主动创建&#x2F;设置”，而非硬件固有或用户空间后期构建的内容。</p>
<p>我们逐项分析：</p>
<p>A. 中断向量表（Interrupt Vector Table, IVT）或中断描述符表（IDT）<br>✅ 正确。</p>
<p>在实模式下，IVT 固定位于内存 0x0 处（由 BIOS 初始化），但进入保护模式&#x2F;长模式后，操作系统必须重新建立自己的中断描述符表（IDT）；<br>OS 启动早期（如 Linux 的 setup_idt()、trap_init()）会：<br>分配 IDT 内存；<br>填充各中断&#x2F;异常的处理程序入口（如 divide_error, page_fault, system_call）；<br>执行 lidt 指令加载 IDTR 寄存器；<br>这是 OS 初始化的关键步骤，否则无法响应中断和异常。<br>→ 必须由 OS 初始化时创建。<br>B. 文件系统的根目录<br>❌ 不一定由 OS 初始化时创建。</p>
<p>根目录是文件系统结构的一部分，通常在格式化磁盘时创建（如 mkfs.ext4）；<br>OS 启动时只是挂载（mount）已存在的根文件系统，不负责“创建”它；<br>即使是 initramfs 或 live 系统，根目录也是由构建工具预先生成，非 OS 运行时创建。<br>→ 属于存储介质预置内容，非 OS 初始化动作。<br>C. 硬盘分区表<br>❌ 由磁盘分区工具创建（如 fdisk, parted），非操作系统初始化过程。</p>
<p>分区表（MBR 或 GPT）位于磁盘最前端，是持久化存储结构；<br>OS 启动时读取分区表以定位分区，但不创建它；<br>若分区表损坏，OS 无法正常引导，需用外部工具修复。<br>→ 属于磁盘级元数据，非 OS 初始化职责。<br>D. 文件系统的索引节点表（inode 表）<br>❌ 在格式化文件系统时创建，非 OS 初始化时动态创建。</p>
<p>如 ext4 的 inode 表在 mkfs.ext4 时分配并初始化；<br>OS 挂载后使用它，但不负责首次创建；<br>运行时可能动态分配新 inode（当文件创建时），但“索引节点表”的总体结构是静态预分配的。<br>→ 不属于“OS 初始化过程创建”的核心数据结构。</p>
<h1 id="题目-32"><a href="#题目-32" class="headerlink" title="题目"></a>题目</h1><p>下列关于CPU 模式的叙述中，正确的是( ) (2022)<br>A. CPU 处于用户态时只能执行特权指令<br>B. CPU 处于内核态时只能执行特权指令<br>C. CPU 处于用户态时只能执行非特权指令<br>D. CPU 处于内核态时只能执行非特权指令</p>
<h2 id="解析-32"><a href="#解析-32" class="headerlink" title="解析"></a>解析</h2><p>答案：C. CPU 处于用户态时只能执行非特权指令</p>
<p>✅ 解析：<br>本题考察 CPU 特权级（运行模式）与指令权限的关系。</p>
<p>现代 CPU（如 x86、ARM）支持多特权级：</p>
<p>内核态（Kernel Mode &#x2F; Ring 0 &#x2F; EL1+）：可执行所有指令（特权 + 非特权）<br>用户态（User Mode &#x2F; Ring 3 &#x2F; EL0）：只能执行非特权指令；若尝试执行特权指令，触发保护异常（如 x86 的 #GP）<br>逐项分析：<br>A. CPU 处于用户态时只能执行特权指令<br>❌ 错误。</p>
<p>用户态禁止执行特权指令；<br>若执行 cli、in、mov cr3, %rax 等，CPU 会触发异常，终止进程。<br>B. CPU 处于内核态时只能执行特权指令<br>❌ 错误。</p>
<p>内核代码中大量使用非特权指令：<br>mov, add, call, push 等通用计算&#x2F;控制指令；<br>甚至可调用 glibc 函数（如内存操作）；<br>内核态是权限更高，不是“只能做特权事”。<br>C. CPU 处于用户态时只能执行非特权指令<br>✅ 正确。</p>
<p>这是 CPU 保护机制的核心设计：<br>非特权指令：常规运算、访存（用户空间）、控制转移等；<br>特权指令：关中断、访问控制寄存器、I&#x2F;O 指令、修改页表等；<br>用户程序被限制在“安全沙箱”内，保障系统稳定与安全。<br>D. CPU 处于内核态时只能执行非特权指令<br>❌ 错误。</p>
<p>内核必须执行特权指令才能管理工作：<br>sti&#x2F;cli 控制中断<br>mov %cr3, %rax 切换地址空间<br>wrmsr 写模型特定寄存器<br>in&#x2F;out 操作设备（虽现代驱动多用 MMIO，但仍需特权访问）<br>→ 若内核不能执行特权指令，操作系统根本无法运行</p>
<h1 id="题目-33"><a href="#题目-33" class="headerlink" title="题目"></a>题目</h1><p>执行系统调用的过程涉及下列操作，其中由操作系统完成的是( ) (2022)<br>I.保存断点和程序状态字 Ⅱ.保存通用寄存器的内容<br>Ⅲ.执行系统调用服务例程 IV.将CPU 模式改为内核态<br>A.仅I、Ⅲ B.仅Ⅱ、Ⅲ C 仅Ⅱ、IV D.仅Ⅱ、Ⅲ、IV</p>
<h2 id="解析-33"><a href="#解析-33" class="headerlink" title="解析"></a>解析</h2><p>答案：B. 仅Ⅱ、Ⅲ</p>
<p>✅ 解析：<br>本题考查 系统调用执行过程中软硬件的分工。关键在于区分哪些操作由 硬件自动完成，哪些由 操作系统（软件）完成。</p>
<p>我们逐项分析：</p>
<p>I. 保存断点和程序状态字（PSW）<br>❌ 由硬件自动完成，非操作系统。</p>
<p>执行 syscall &#x2F; int 0x80 等陷入指令时，CPU 硬件电路自动：<br>将返回地址（断点，即下一条指令地址）压栈；<br>将当前 RFLAGS（PSW）压栈；<br>切换栈指针（如从用户栈切换到内核栈）；<br>例如 x86-64 syscall 指令会自动保存 RIP → RCX，RFLAGS → R11，并加载内核 CS&#x2F;RIP；<br>→ 操作系统不参与也不控制此过程。<br>II. 保存通用寄存器的内容<br>✅ 由操作系统完成。</p>
<p>硬件不会自动保存通用寄存器（如 RAX, RBX, RCX…）；<br>为保证被中断的用户进程状态透明，内核的系统调用入口代码必须显式保存这些寄存器；<br>例如 Linux 的 entry_SYSCALL_64 中调用 SWAPGS 后，会执行 SAVE_C_REGS &#x2F; SAVE_EXTRA_REGS 宏保存寄存器；<br>→ 属于 OS 的软件现场保护。<br>III. 执行系统调用服务例程<br>✅ 由操作系统完成。</p>
<p>如 sys_read, sys_write, sys_fork 等，是 OS 内核实现的具体功能函数；<br>硬件只负责跳转到系统调用分发器（如查 sys_call_table），具体服务逻辑完全由 OS 编写。<br>IV. 将 CPU 模式改为内核态<br>❌ 由硬件自动完成。</p>
<p>syscall &#x2F; int 指令执行时，CPU 自动切换特权级（如 x86 设置 CPL&#x3D;0，ARM 切换到 EL1）；<br>这是陷入机制的固有行为，由指令微码实现，OS 无法也不需干预；<br>→ 属于硬件特权级切换。<br>🎯 考点总结：<br>硬件负责：模式切换、断点&#x2F;PSW 保存、向量查表跳转（中断隐指令范畴）；<br>操作系统负责：<br>通用寄存器等扩展现场保存；<br>参数提取、权限检查、具体服务执行；<br>恢复现场与返回；<br>易错点：误以为“切换内核态”是 OS 做的——实为指令触发的硬件行为。</p>
<h1 id="题目-34"><a href="#题目-34" class="headerlink" title="题目"></a>题目</h1><p>与宏内核操作系统相比，下列特征中微内核操作系统具有的是( ) (2023)<br>I.较好的性能Ⅱ.较高的可靠性 Ⅲ.较高的安全性 IV.较强的可扩展性<br>A.仅Ⅱ、IV B.仅I 、Ⅱ、IV C.仅I 、 Ⅲ 、IV D.仅Ⅱ、Ⅲ、IV</p>
<h2 id="解析-34"><a href="#解析-34" class="headerlink" title="解析"></a>解析</h2><p>正确选项：D. 仅Ⅱ、Ⅲ、IV<br>逐项判断：<br>I. 较好的性能<br>❌ 错误（微内核通常性能较低）</p>
<p>微内核因大量功能移到用户态，服务调用需多次进程间通信（IPC）和上下文切换；<br>例如读文件：用户程序 → IPC → 文件服务 → IPC → 设备驱动 → 硬件；<br>相比宏内核的直接系统调用，IPC 开销显著；<br>尽管现代微内核（如 L4）通过优化 IPC 大幅提升性能，但总体仍逊于高度优化的宏内核（如 Linux）；<br>→ 宏内核性能更好，I 不属于微内核优势。<br>II. 较高的可靠性<br>✅ 正确</p>
<p>微内核中，文件系统、驱动等运行在用户态；<br>若某个驱动崩溃（如显卡驱动 bug），仅该服务进程终止，内核和其他服务不受影响，系统可重启该服务；<br>宏内核中，驱动崩溃 &#x3D; 内核崩溃 &#x3D; 系统宕机（Kernel Panic &#x2F; BSOD）；<br>→ 微内核通过隔离故障域提升可靠性。<br>III. 较高的安全性<br>✅ 正确</p>
<p>用户态服务受 MMU 保护，权限最小化（Principle of Least Privilege）；<br>攻击者即使攻破一个驱动，也无法直接获得内核权限（需额外提权漏洞）；<br>宏内核中，任何模块漏洞都可能导致整个内核被接管；<br>seL4 微内核甚至通过形式化验证证明其安全属性。<br>IV. 较强的可扩展性<br>✅ 正确</p>
<p>新增功能（如新文件系统、新协议栈）只需添加用户态服务进程，无需修改&#x2F;重编译内核；<br>支持动态加载&#x2F;卸载服务；<br>宏内核扩展常需重新编译内核或加载内核模块（仍运行在内核态，风险高）；<br>→ 微内核更易定制、维护、更新。<br>✅ 结论：<br>I（性能）：❌ 微内核劣势<br>II（可靠性）：✅<br>III（安全性）：✅<br>IV（可扩展性）：✅<br>→ 正确选项：D. 仅Ⅱ、Ⅲ、IV</p>
<h1 id="题目-35"><a href="#题目-35" class="headerlink" title="题目"></a>题目</h1><p>在操作系统内核中，中断向量表适合采用的数据结构是( ) (2023)<br>A.数组 B.队列 C.单向链表 D.双向链表</p>
<h2 id="解析-35"><a href="#解析-35" class="headerlink" title="解析"></a>解析</h2><p>答案：A. 数组</p>
<p>✅ 解析：<br>中断向量表（Interrupt Vector Table, IVT）或中断描述符表（Interrupt Descriptor Table, IDT） 是操作系统用于将中断&#x2F;异常号映射到对应处理程序入口地址的关键数据结构。</p>
<p>我们分析为何 数组（Array）是最适合的数据结构：</p>
<ol>
<li>访问模式：按中断号随机、直接访问<br>中断&#x2F;异常发生时，CPU 根据中断类型号（如时钟中断 IRQ0 → 向量 32，缺页 → 向量 14）直接索引查找处理程序入口；<br>要求 O(1) 时间复杂度的随机访问；<br>→ 数组天然支持通过下标（中断号）直接寻址，完美匹配。</li>
<li>其他选项为何不合适：<br>B. 队列<br>适用于先进先出（FIFO）顺序处理（如任务调度、打印队列）；<br>中断处理不要求顺序，而是按类型号并行、独立响应；<br>无法通过中断号快速定位入口。<br>C. 单向链表 &#x2F; D. 双向链表<br>查找需遍历，时间复杂度 O(n)，无法满足中断处理低延迟、高确定性要求；<br>中断向量表大小固定（如 x86 有 256 个向量），无需动态增删；<br>链表额外指针开销无必要。</li>
<li>实际系统实现佐证：<br>x86 实模式：IVT 是位于物理地址 0x0 的 256 项数组，每项 4 字节（CS:IP）；<br>x86 保护&#x2F;长模式：IDT 是由 lidt 加载的连续内存数组，每项为门描述符（16 字节）；<br>Linux 内核中：gate_desc idt_table[256] 是静态数组；<br>ARM 异常向量表：固定偏移的跳转指令块（本质也是数组式布局）。<br>🎯 考点总结：<br>中断向量表核心需求：按中断号快速索引 → O(1) 随机访问；<br>数组是唯一满足该需求的线性结构；<br>系统设计讲究“用最简单结构满足关键性能需求”，此处数组最优。</li>
</ol>
<h1 id="题目-36"><a href="#题目-36" class="headerlink" title="题目"></a>题目</h1><p>下列操作完成时，导致 CPU 从内核态转为用户态的是( ) (2023)<br>A.阻塞过程 B.执行 CPU 调度 C.唤醒进程 D.执行系统调用</p>
<h2 id="解析-36"><a href="#解析-36" class="headerlink" title="解析"></a>解析</h2><p>最终答案（按考试惯例）：D. 执行系统调用<br>✅ 正确答案应为：系统调用返回（即系统调用完成时），但选项 D 写的是 “执行系统调用”，而非“系统调用返回”。<br>题干：“下列操作 完成时，导致 CPU 从内核态转为用户态的是”</p>
<p>我们逐项严格分析（注意“完成时”这个时间点）：</p>
<p>A. 阻塞进程<br>❌ 不会转回用户态。</p>
<p>进程在内核中执行系统调用（如 read）时发现需等待 I&#x2F;O → 主动调用 schedule() 让出 CPU；<br>当前进程进入阻塞态，CPU 切换到另一个进程（可能仍是内核态的其他进程，或用户进程）；<br>若调度到的是另一个用户进程，则 CPU 会转为用户态——但这归因于进程切换 + 新进程是用户进程，而非“阻塞操作本身导致转用户态”；<br>更关键的是：执行阻塞操作的进程自己并未回到用户态（它被挂起了）。<br>→ 不符合“操作完成时，CPU 转为用户态”（对当前上下文而言）。<br>B. 执行 CPU 调度<br>❌ 调度本身在内核态完成，不改变当前 CPU 模式。</p>
<p>schedule() 函数全程运行在内核态；<br>调度结果可能是切换到：<br>另一个内核线程（仍内核态）<br>一个用户进程（此时后续 iret&#x2F;sysret 会切回用户态）<br>但调度完成瞬间，CPU 仍在内核态；真正切换到用户态发生在上下文恢复 + 执行 iret 之后；<br>→ 调度 ≠ 模式切换。<br>C. 唤醒进程<br>❌ 唤醒操作在内核态完成，被唤醒进程只是进入就绪队列，并未立即运行，更未切换到用户态。</p>
<p>例如中断处理中唤醒等待 I&#x2F;O 的进程：调用 wake_up()，仅修改其状态为 TASK_RUNNING；<br>实际运行需等后续调度；<br>→ 唤醒完成时，CPU 仍处于中断&#x2F;系统调用上下文（内核态）。<br>D. 执行系统调用<br>❌ 执行系统调用时，CPU 从用户态 进入 内核态；</p>
<p>“执行系统调用”是一个过程，其开始时陷入内核，结束时返回用户态；<br>但题干问的是“操作完成时”，若理解为“系统调用服务例程执行完毕”，则紧接着会：<br>恢复寄存器<br>执行 sysret &#x2F; iret<br>CPU 切回用户态<br>→ 表面看，D 似乎合理。<br>⚠️ 问题在于表述歧义：</p>
<p>“执行系统调用”通常指发起并进入内核的过程（即陷入阶段），而非返回阶段；<br>严格说，“系统调用返回”才是切回用户态的时刻，但选项未写“返回”。<br>🔍 真实场景回顾（以 read 为例）：<br>text<br>1234567891011<br>→ 系统调用 返回 时，CPU 从内核态 → 用户态。</p>
<p>因此，若选项 D 是 “系统调用返回”，则正确；但题干写的是 “执行系统调用”，易被理解为“调用过程中”，属常见命题瑕疵。</p>
<p>📌 结论（结合历年真题惯例）：<br>在历年考研题中，类似题目的标准答案通常是：<br>✅ 系统调用返回 是唯一导致 CPU 从内核态回到用户态的常规路径。</p>
<p>而四个选项中，D 是唯一与“用户-内核切换”直接相关的操作，尽管表述不够精准，但命题人极可能预期选 D。</p>
<p>但严格技术意义上：</p>
<p>A、B、C 均不导致当前 CPU 切回用户态；<br>D 若理解为“系统调用整个过程（含返回）”，则其完成时确实会切回用户态。<br>✅ 最终答案（按考试惯例）：D. 执行系统调用<br>📝 注：此题存在表述瑕疵，理想选项应为“系统调用返回”或“从中断&#x2F;异常返回”。但在给定选项中，D 是唯一合理选择。</p>
<h1 id="题目-37"><a href="#题目-37" class="headerlink" title="题目"></a>题目</h1><p>下面关于中断、异常和系统调用的叙述中，错误的是( ) (2024)<br>A. 中断或异常发生时，CPU 处于内核态<br>B. 每个系统调用都有对应的内核服务例程<br>C. 中断处理程序开始执行时，CPU 处于内核态<br>D. 系统添加新类型设备时，需注册相应的中断服务例程</p>
<h2 id="解析-37"><a href="#解析-37" class="headerlink" title="解析"></a>解析</h2><p>答案：A. 中断或异常发生时，CPU 处于内核态</p>
<p>✅ 解析：<br>本题考查对中断、异常、系统调用执行时机与 CPU 模式关系的理解。关键在于区分 “发生时” 与 “处理时” 的状态。</p>
<p>A. 中断或异常发生时，CPU 处于内核态<br>❌ 错误（本题答案）</p>
<p>中断&#x2F;异常可以发生在用户态或内核态：<br>若当前正在运行用户进程，此时发生时钟中断、缺页异常、除零等，CPU 当时处于用户态；<br>随后硬件自动切换到内核态去处理；<br>“发生时”指的是事件触发的瞬间，即中断请求到达或异常指令执行的那一刻，CPU 所处的原始模式；<br>例如：用户程序执行 div 指令 → 用户态下发生除零异常 → 然后陷入内核处理；<br>→ 本项将“发生时”等同于“处理时”，混淆了时间点，是典型错误。<br>B. 每个系统调用都有对应的内核服务例程<br>✅ 正确。</p>
<p>系统调用号（如 __NR_read &#x3D; 0）对应内核中的服务函数（如 sys_read）；<br>内核通过系统调用表（sys_call_table）实现映射；<br>无对应例程的调用号会返回 -ENOSYS，但合法系统调用必有服务例程。<br>C. 中断处理程序开始执行时，CPU 处于内核态<br>✅ 正确。</p>
<p>无论是中断还是异常，CPU 在跳转到处理程序前，硬件已自动完成模式切换（如设置 CPL&#x3D;0）；<br>因此 ISR 第一行代码执行时，CPU 已在内核态。<br>D. 系统添加新类型设备时，需注册相应的中断服务例程<br>✅ 正确。</p>
<p>新设备（如新网卡）可能产生中断（如数据到达）；<br>驱动程序需通过内核 API（如 request_irq）注册其中断号与 ISR；<br>否则中断发生时无对应处理程序，可能导致系统挂起或丢失事件。</p>
<h1 id="题目-38"><a href="#题目-38" class="headerlink" title="题目"></a>题目</h1><p>系统调用的作用是（ ）。（北京交通大学2018）<br>A. 申请系统资源 B.终止系统服务 C.释放系统资源 D.请求系统服务</p>
<h2 id="解析-38"><a href="#解析-38" class="headerlink" title="解析"></a>解析</h2><p>答案：D. 请求系统服务</p>
<p>✅ 解析：<br>系统调用（System Call）是用户程序与操作系统内核交互的唯一受控接口，其根本作用是：</p>
<p>让用户程序请求内核代表它完成特权操作或访问受保护资源。</p>
<p>我们逐项分析选项：</p>
<p>A. 申请系统资源<br>⚠️ 片面。</p>
<p>申请资源（如内存 brk、文件描述符 open）确实是系统调用的功能之一；<br>但系统调用远不止“申请”，还包括：<br>释放资源（close, munmap）<br>使用资源（read, write, send）<br>控制进程（fork, exec, exit）<br>获取信息（getpid, time）<br>→ “申请”仅是子集，不全面。<br>B. 终止系统服务<br>❌ 错误。</p>
<p>用户程序无法“终止系统服务”；<br>exit 是终止自身进程，而非系统服务；<br>系统服务（如 systemd 服务）需特权命令（如 systemctl stop），底层仍通过系统调用实现，但目的不是“终止系统服务”。<br>C. 释放系统资源<br>⚠️ 片面，同 A，只是反向操作，仍不完整。</p>
<p>D. 请求系统服务<br>✅ 正确且全面。</p>
<p>“系统服务”泛指内核提供的所有功能：<br>资源管理（分配&#x2F;回收内存、CPU、I&#x2F;O）<br>进程控制<br>通信与同步<br>安全与保护<br>用户程序通过系统调用请求这些服务，内核验证后执行；<br>这是对系统调用本质的准确概括。<br>🎯 考点总结：<br>系统调用 ≠ 仅资源申请&#x2F;释放，而是全部内核功能的访问门户；</p>
<h1 id="题目-39"><a href="#题目-39" class="headerlink" title="题目"></a>题目</h1><p>操作系统中的并发性是指（ ）。（北京交通大学2018）<br>A. 若干事件在同一时刻发生 B.事件驱动 C.事件随机发生 D.若干事件在同一时间间隔内发生</p>
<h2 id="解析-39"><a href="#解析-39" class="headerlink" title="解析"></a>解析</h2><p>答案：D. 若干事件在同一时间间隔内发生</p>
<p>✅ 解析：<br>本题考查 “并发性（Concurrency）” 的准确定义，需与 “并行性（Parallelism）” 严格区分。</p>
<p>关键概念辨析：<br>✅ 并发性（Concurrency）<br>指 多个事件在同一个时间间隔内发生（宏观上“同时”进行）；<br>在单处理机系统中，通过时间片轮转、快速切换实现；<br>微观上，任一时刻只有一个进程运行，但切换速度足够快，使用户感觉多个任务“同时”推进；<br>例如：一边下载文件（I&#x2F;O 等待中），一边编辑文档（CPU 计算）——交替执行，宏观并发。<br>❌ 并行性（Parallelism）<br>指 多个事件在同一时刻（同一瞬间）真正同时发生；<br>必须依赖多处理机或多核 CPU；<br>微观上多个任务同时执行；<br>对应选项 A：“若干事件在同一时刻发生” —— 描述的是并行，不是并发。<br>其他选项：<br>B. 事件驱动<br>→ 是一种编程模型（如 GUI、网络服务器），与并发性无直接等价关系。</p>
<p>C. 事件随机发生<br>→ 错误。并发是受控调度的结果，不是随机的；中断虽异步，但并发执行是 OS 主动管理的行为。</p>
<p>📌 经典表述（汤小丹《计算机操作系统》）：</p>
<p>“并发性是指两个或多个事件在同一时间间隔内发生；并行性是指两个或多个事件在同一时刻发生。”</p>
<h1 id="题目-40"><a href="#题目-40" class="headerlink" title="题目"></a>题目</h1><p>有一台计算机，具有1MB内存，操作系统占用200KB，每个进程各占用200KB。<br>如果用户进程等待I&#x2F;O的时间为80%，若增加1MB内存，则CPU的利用率提高多少？</p>
<h2 id="解析-40"><a href="#解析-40" class="headerlink" title="解析"></a>解析</h2><p>已知条件</p>
<ul>
<li>总内存：  <ul>
<li>初始：$1,\text{MB} &#x3D; 1024,\text{KB}$  </li>
<li>增加后：$2,\text{MB} &#x3D; 2048,\text{KB}$</li>
</ul>
</li>
<li>操作系统占用：$200,\text{KB}$  </li>
<li>每个进程内存需求：$200,\text{KB}$  </li>
<li>进程 I&#x2F;O 等待比例：$p &#x3D; 80% &#x3D; 0.8$<br>→ 单个进程的 <strong>CPU 使用比例</strong> 为 $1 - p &#x3D; 0.2$</li>
</ul>
<hr>
<p>✅ 关键模型：多道程序下的 CPU 利用率</p>
<p>当系统中有 $n$ 个进程并发运行，且每个进程独立地以概率 $p$ 处于 I&#x2F;O 等待状态时：</p>
<ul>
<li>所有进程同时等待 I&#x2F;O 的概率为：$p^n$  </li>
<li>此时 CPU 空闲；其余时间至少有一个进程在使用 CPU  </li>
<li>因此，<strong>CPU 利用率为</strong>：</li>
</ul>
<p>$$<br>U(n) &#x3D; 1 - p^n<br>$$</p>
<hr>
<p>第一步：原始内存下最多可运行进程数</p>
<p>可用内存：</p>
<p>$$<br>1024,\text{KB} - 200,\text{KB} &#x3D; 824,\text{KB}<br>$$</p>
<p>每个进程需 200 KB：</p>
<p>$$<br>n_1 &#x3D; \left\lfloor \frac{824}{200} \right\rfloor &#x3D; 4<br>$$</p>
<p>（$4 \times 200 &#x3D; 800 \leq 824$，余 24 KB 不足一进程）</p>
<p>CPU 利用率：</p>
<p>$$<br>U_1 &#x3D; 1 - 0.8^4 &#x3D; 1 - 0.4096 &#x3D; 0.5904 &#x3D; 59.04%<br>$$</p>
<hr>
<p>第二步：增加 1 MB 内存后</p>
<p>总内存：$2048,\text{KB}$<br>可用内存：</p>
<p>$$<br>2048 - 200 &#x3D; 1848,\text{KB}<br>$$</p>
<p>最多进程数：</p>
<p>$$<br>n_2 &#x3D; \left\lfloor \frac{1848}{200} \right\rfloor &#x3D; 9<br>$$</p>
<p>（$9 \times 200 &#x3D; 1800 \leq 1848$）</p>
<p>CPU 利用率：</p>
<p>$$<br>U_2 &#x3D; 1 - 0.8^9<br>$$</p>
<p>计算：</p>
<p>$$<br>0.8^4 &#x3D; 0.4096,\quad 0.8^8 &#x3D; (0.4096)^2 &#x3D; 0.16777216<br>$$<br>$$<br>0.8^9 &#x3D; 0.8^8 \times 0.8 &#x3D; 0.16777216 \times 0.8 &#x3D; 0.134217728<br>$$<br>$$<br>U_2 &#x3D; 1 - 0.134217728 &#x3D; 0.865782272 \approx 86.58%<br>$$</p>
<hr>
<p>第三步：利用率提升值</p>
<p>$$<br>\Delta U &#x3D; U_2 - U_1 &#x3D; 86.58% - 59.04% &#x3D; 27.54%<br>$$</p>
<hr>
<p>✅ 最终答案：</p>
<blockquote>
<p><strong>CPU 利用率提高约 $27.5%$</strong>（即提升 <strong>27.5 个百分点</strong>）</p>
</blockquote>
<hr>
<p>📌 附注</p>
<ul>
<li>本模型假设：  <ul>
<li>进程行为独立、I&#x2F;O 比例恒定；  </li>
<li>内存是唯一限制因素；  </li>
<li>无调度开销、无换页（即所有进程常驻内存）。</li>
</ul>
</li>
<li>实际系统中，过度增加进程可能导致 thrashing 或调度开销上升，但本题按理想多道程序模型求解。</li>
</ul>
<h1 id="题目-41"><a href="#题目-41" class="headerlink" title="题目"></a>题目</h1><p>某个计算机系统有一台输入机和一台打印机，现有两道程序投入运行，且程序A先开始运行，<br>程序B后开始运行。<br>程序A的运行轨迹为：计算50ms、打印100ms、再计算50ms、打印100ms，结束。<br>程序B的运行轨迹为：计算50ms、输入80ms、再计算100ms，结束。<br>试说明：</p>
<ol>
<li>两道程序运行时，CPU是否存在空闲等待？若是，在哪段时间内等待？为什么等待？</li>
<li>程序A、B是否有等待CPU的情况？若有，指出发生等待的时刻。</li>
</ol>
<h2 id="解析-41"><a href="#解析-41" class="headerlink" title="解析"></a>解析</h2><p>我们来分析这个经典的 <strong>多道程序并发执行 + 资源竞争</strong> 问题。</p>
<p>🔧 系统资源与约束：</p>
<ul>
<li>✅ <strong>1 个 CPU</strong>：计算必须串行  </li>
<li>✅ <strong>1 台输入机</strong>：程序 B 的“输入”阶段独占  </li>
<li>✅ <strong>1 台打印机</strong>：程序 A 的“打印”阶段独占  </li>
<li>程序 A 先到，程序 B 后到（假设 B 在 A 启动后 <strong>立即到达</strong>，即 $ t &#x3D; 0^+ $，常见默认；若未说明延迟，按 <strong>B 紧随 A 启动</strong>处理）</li>
</ul>
<hr>
<p>📋 程序行为：</p>
<table>
<thead>
<tr>
<th>程序</th>
<th>阶段顺序</th>
</tr>
</thead>
<tbody><tr>
<td><strong>A</strong></td>
<td>计算 50ms → 打印 100ms → 计算 50ms → 打印 100ms （共 300ms）</td>
</tr>
<tr>
<td><strong>B</strong></td>
<td>计算 50ms → 输入 80ms → 计算 100ms （共 230ms）</td>
</tr>
</tbody></table>
<blockquote>
<p>✅ 各阶段<strong>顺序执行，不可重排</strong>；同类设备<strong>互斥使用</strong>。</p>
</blockquote>
<hr>
<p>✅ 最优调度时间线分析（争取最小总时间，避免 CPU 空闲）</p>
<p>我们按时间推进模拟最优并发执行：</p>
<hr>
<p><strong>0–50 ms</strong>  </p>
<ul>
<li>A 先到，立即开始 <strong>计算 50ms</strong>（占用 CPU）  </li>
<li>B 已到达，<strong>等待 CPU</strong></li>
</ul>
<p><strong>50–100 ms</strong>  </p>
<ul>
<li>A 计算结束，转入 <strong>打印 100ms</strong>（占用打印机）  </li>
<li><strong>CPU 空出 → B 立即开始计算 50ms</strong>（50–100 ms）</li>
</ul>
<blockquote>
<p>✔️ CPU 与打印机并行：A 打印，B 计算</p>
</blockquote>
<p><strong>100–150 ms</strong>  </p>
<ul>
<li>B 计算结束（100 ms），转入 <strong>输入 80ms</strong>（占用输入机，100–180 ms）  </li>
<li>A 打印仍在进行（50–150 ms），<strong>150 ms 打印结束</strong>  </li>
<li><strong>150 ms 时，A 需要 CPU 进行第二段计算，但 CPU 正空闲</strong> → A 立即开始 <strong>计算 50ms（150–200 ms）</strong></li>
</ul>
<blockquote>
<p>✔️ 此时：  </p>
<ul>
<li>A：计算（CPU）  </li>
<li>B：输入（输入机）<br>→ <strong>完美并行</strong></li>
</ul>
</blockquote>
<p><strong>180 ms</strong>  </p>
<ul>
<li>B 输入结束（100–180 ms）  </li>
<li>但 B 的下一段是<strong>计算 100ms</strong>，需等 CPU  </li>
<li>当前 CPU 被 A 占用（150–200 ms）</li>
</ul>
<p><strong>200 ms</strong>  </p>
<ul>
<li>A 第二段计算结束（150–200 ms）  </li>
<li>A 立即转入 <strong>第二次打印 100ms（200–300 ms）</strong>（占用打印机）  </li>
<li><strong>CPU 空出 → B 立即开始计算 100ms（200–300 ms）</strong></li>
</ul>
<blockquote>
<p>✔️ A 打印 &amp; B 计算并行</p>
</blockquote>
<p><strong>300 ms</strong>  </p>
<ul>
<li>A 打印结束，A 完成  </li>
<li>B 计算结束（200–300 ms），B 完成</li>
</ul>
<hr>
<p>最终时间线汇总：</p>
<table>
<thead>
<tr>
<th>时间段</th>
<th>CPU 活动</th>
<th>打印机</th>
<th>输入机</th>
</tr>
</thead>
<tbody><tr>
<td>0–50 ms</td>
<td>A 计算</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>50–100 ms</td>
<td><strong>B 计算</strong></td>
<td>A 打印</td>
<td>—</td>
</tr>
<tr>
<td>100–150 ms</td>
<td>—</td>
<td>A 打印</td>
<td>—</td>
</tr>
<tr>
<td><strong>⚠️ 100–150 ms：CPU 空闲 50ms</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>150–200 ms</td>
<td>A 计算</td>
<td>—</td>
<td>B 输入</td>
</tr>
<tr>
<td>200–300 ms</td>
<td>B 计算</td>
<td>A 打印</td>
<td>—</td>
</tr>
</tbody></table>
<p>Wait — 上面 <strong>100–150 ms CPU 空闲？</strong><br>但仔细看：  </p>
<ul>
<li>A 在 50–150 ms 打印（100ms）  </li>
<li>B 在 50–100 ms 计算（50ms），100 ms 就结束了  </li>
<li>B 的下一段是<strong>输入 80ms（100–180 ms）</strong>，不需 CPU<br>→ 所以 <strong>100–150 ms：A 在打印，B 在输入，CPU 无人用 → 确实空闲！</strong></li>
</ul>
<p>但能否优化？<br>→ 若让 B <strong>延迟开始计算</strong>，把计算挪到后面？<br>❌ 不行！B 必须先计算 50ms 才能输入（顺序约束），且 A 先占 CPU，B 只能 50ms 后开始计算。</p>
<p>✅ 所以 <strong>100–150 ms 的 CPU 空闲不可避免</strong>。</p>
<hr>
<p>✅ 回答问题：</p>
<ol>
<li>CPU 是否存在空闲等待？若是，在哪段时间内等待？为什么？</li>
</ol>
<p><strong>答</strong>：<br>✅ <strong>存在 CPU 空闲</strong>，发生在 <strong>100 ms 到 150 ms</strong>（共 50 ms）。<br><strong>原因</strong>：  </p>
<ul>
<li>50–100 ms：B 在使用 CPU 计算；  </li>
<li>100 ms 时，B 计算结束，转入 <strong>输入阶段（100–180 ms）</strong>，不再需要 CPU；  </li>
<li>A 此时（50–150 ms）正在使用<strong>打印机</strong>，尚未完成第一段打印，无法进入第二段计算；  </li>
<li>因此，100–150 ms 期间，<strong>A 等打印机，B 等输入设备</strong>，CPU 无进程可调度，处于空闲。</li>
</ul>
<blockquote>
<p>🔔 关键：A 和 B 同时处于 I&#x2F;O 阶段（A 打印、B 输入），无进程就绪 → CPU 空转。</p>
</blockquote>
<hr>
<ol start="2">
<li>程序 A、B 是否有等待 CPU 的情况？若有，指出发生等待的时刻。</li>
</ol>
<p><strong>答</strong>：</p>
<ul>
<li><p><strong>程序 A</strong>：<br>✅ 有等待 CPU。  </p>
<ul>
<li><strong>等待时刻：0 ms</strong><br>→ A 先启动，<strong>立即获得 CPU</strong>，<strong>无等待</strong>；  </li>
<li><strong>150 ms 时</strong>：A 打印结束，立即获得 CPU → <strong>无等待</strong>；<br>→ <strong>A 从未等待 CPU</strong>。</li>
</ul>
</li>
<li><p><strong>程序 B</strong>：<br>✅ 有等待 CPU。  </p>
<ul>
<li><strong>等待时刻：0–50 ms</strong><br>→ B 虽在 A 后立即到达，但 A 正占用 CPU，B 需等待 A 的第一段计算结束；  </li>
<li>50 ms 时获得 CPU，开始计算；  </li>
<li>后续：100 ms 输入结束 → 需计算，但 CPU 被 A 占用（150–200 ms）→<br><strong>等待时刻：180–200 ms</strong>（20 ms）  <blockquote>
<p>B 在 180 ms 输入结束，想计算，但 A 正在 150–200 ms 计算，故 B 等待 20 ms（180–200），200 ms 获得 CPU。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>✅ 所以 B 共两次等待 CPU：</p>
<ul>
<li><strong>0–50 ms</strong>（50 ms）  </li>
<li><strong>180–200 ms</strong>（20 ms）</li>
</ul>
<hr>
<p>补充：甘特图（文字版）</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">时间:  0        50       100      150      200      250      300 (ms)</span><br><span class="line">       |--------|--------|--------|--------|--------|--------|</span><br><span class="line">CPU:   A计算    B计算    [空闲]   A计算    B计算</span><br><span class="line">              (50)    (50ms)    (50ms)   (50ms)   (100ms)</span><br><span class="line"></span><br><span class="line">Printer:       A打印--------------A打印------------------------</span><br><span class="line">               (100ms)          (100ms)</span><br><span class="line"></span><br><span class="line">Input:                  B输入-------------------</span><br><span class="line">                        (80ms)</span><br></pre></td></tr></table></figure></div>

<hr>
<p>最终答案：</p>
<ol>
<li><p><strong>CPU 存在空闲等待</strong>，时间为 <strong>100 ms ~ 150 ms</strong>（50 ms），<br>原因：A 正在打印、B 正在输入，<strong>无进程处于就绪态</strong>，CPU 无任务可执行。</p>
</li>
<li><ul>
<li><strong>程序 A</strong>：<strong>无等待 CPU</strong>（始终在 I&#x2F;O 结束后立即获得 CPU）；  </li>
<li><strong>程序 B</strong>：  <ul>
<li><strong>0–50 ms</strong>：等待 A 释放 CPU；  </li>
<li><strong>180–200 ms</strong>：等待 A 完成第二段计算后释放 CPU。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux操作系统-第三章-内存</title>
    <url>/zhihaojiang.github.io/2025/12/29/20251229Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%86%85%E5%AD%98/</url>
    <content><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>某计算机采用二级页表的分页存储管理方式，按字节编址，页大小为 210 字节，页表项大<br>小为2 字节，逻辑地址结构为：页目录号 | 页号 | 页内偏移量<br>逻辑地址空间大小为 216 页，则表示整个逻辑地址空间的页目录表中包含表项的个数至少是</p>
<hr>
<p>。(2010)<br>A． 64 B． 128 C． 256 D． 512</p>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><h2 id="📊-题目条件："><a href="#📊-题目条件：" class="headerlink" title="📊 题目条件："></a>📊 题目条件：</h2><ul>
<li>采用 <strong>二级页表</strong> 管理方式  </li>
<li>按 <strong>字节编址</strong>  </li>
<li><strong>页大小 &#x3D; $2^{10}$ 字节</strong> → 即 1 KB  </li>
<li><strong>页表项大小 &#x3D; 2 字节</strong>  </li>
<li><strong>逻辑地址空间大小 &#x3D; $2^{16}$ 页</strong></li>
</ul>
<blockquote>
<p>✅ 注意：题目说“逻辑地址空间大小为 $2^{16}$ 页”，即总共有 $2^{16}$ 个页，而不是 $2^{16}$ 字节！</p>
</blockquote>
<hr>
<h2 id="🔍-目标："><a href="#🔍-目标：" class="headerlink" title="🔍 目标："></a>🔍 目标：</h2><p>求：<strong>页目录表（第一级页表）中至少包含多少个表项？</strong></p>
<hr>
<h2 id="✅-解题思路："><a href="#✅-解题思路：" class="headerlink" title="✅ 解题思路："></a>✅ 解题思路：</h2><p>在二级页表中：</p>
<ul>
<li>逻辑地址分为三部分：<strong>页目录号 | 页号 | 页内偏移量</strong>  </li>
<li>页目录表（Page Directory）的每个表项指向一个<strong>页表（Page Table）</strong>  </li>
<li>每个页表包含若干页表项，每个页表项对应一个物理页帧</li>
</ul>
<p>由于逻辑地址空间有 $2^{16}$ 个页，而每个页表能管理多少页？</p>
<p>→ 由<strong>页表大小决定</strong>。</p>
<hr>
<h3 id="步骤-1：计算一个页表能容纳多少个页表项"><a href="#步骤-1：计算一个页表能容纳多少个页表项" class="headerlink" title="步骤 1：计算一个页表能容纳多少个页表项"></a>步骤 1：计算一个页表能容纳多少个页表项</h3><ul>
<li>页大小 &#x3D; $2^{10}$ 字节  </li>
<li>页表项大小 &#x3D; 2 字节<br>→ 一个页表最多可容纳：<br>$$<br>\frac{2^{10}}{2} &#x3D; 2^9 &#x3D; 512 \text{ 个页表项}<br>$$</li>
</ul>
<p>也就是说，<strong>每个页表可以映射 512 个页</strong>。</p>
<hr>
<h3 id="步骤-2：计算需要多少个页表"><a href="#步骤-2：计算需要多少个页表" class="headerlink" title="步骤 2：计算需要多少个页表"></a>步骤 2：计算需要多少个页表</h3><p>总页数 &#x3D; $2^{16}$<br>每个页表管理 512 页 &#x3D; $2^9$ 页<br>→ 所需页表个数 &#x3D;<br>$$<br>\frac{2^{16}}{2^9} &#x3D; 2^{7} &#x3D; 128<br>$$</p>
<hr>
<h3 id="步骤-3：页目录表中表项个数-页表个数"><a href="#步骤-3：页目录表中表项个数-页表个数" class="headerlink" title="步骤 3：页目录表中表项个数 &#x3D; 页表个数"></a>步骤 3：页目录表中表项个数 &#x3D; 页表个数</h3><p>因为页目录表的每个表项指向一个页表，所以：</p>
<blockquote>
<p><strong>页目录表至少需要 128 个表项</strong></p>
</blockquote>
<hr>
<h2 id="✅-最终答案：B-128"><a href="#✅-最终答案：B-128" class="headerlink" title="✅ 最终答案：B. 128"></a>✅ 最终答案：<strong>B. 128</strong></h2><hr>
<h3 id="🎯-验证逻辑："><a href="#🎯-验证逻辑：" class="headerlink" title="🎯 验证逻辑："></a>🎯 验证逻辑：</h3><table>
<thead>
<tr>
<th>层级</th>
<th>含义</th>
<th>数量</th>
</tr>
</thead>
<tbody><tr>
<td>页目录表项数</td>
<td>指向页表的数量</td>
<td>128 &#x3D; $2^7$</td>
</tr>
<tr>
<td>每个页表项数</td>
<td>映射页的数量</td>
<td>512 &#x3D; $2^9$</td>
</tr>
<tr>
<td>总页数</td>
<td>$2^7 \times 2^9 &#x3D; 2^{16}$ ✅</td>
<td></td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>B. 128</strong></p>
<h1 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h1><p>某系统采用改进型CLOCK置换算法，页表项中字段A为访问位，M为修改位。A&#x3D;0表示页<br>最近没有被访问，A&#x3D;1表示页最近被访问过。M&#x3D;0表示页没有被修改过，M&#x3D;1表示页被修<br>改过。按(A，M)所有可能的取值，将页分为四类：(0，0)、(1，0)、(0，1)和(1，1)，则该<br>算法淘汰页的次序为</p>
<hr>
<p>。(2016)<br>A．(0，0)，(0，1)，(1，0)，(1，1)<br>B．(0，0)，(1，0)，(0，1)，(1，1)<br>C．(0，0)，(0，1)，(1，1)，(1，0)<br>D．(0，0)，(1，1)，(0，1)，(1，0)</p>
<h2 id="解析-1"><a href="#解析-1" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：A. (0, 0), (0, 1), (1, 0), (1, 1)</strong></p>
<p>本题考查 <strong>改进型 CLOCK 置换算法（Enhanced Clock Algorithm）</strong> 的淘汰次序。</p>
<hr>
<h2 id="🔍-改进型-CLOCK-算法原理："><a href="#🔍-改进型-CLOCK-算法原理：" class="headerlink" title="🔍 改进型 CLOCK 算法原理："></a>🔍 改进型 CLOCK 算法原理：</h2><p>在基本 CLOCK 算法基础上，增加对 <strong>访问位 A</strong> 和 <strong>修改位 M</strong> 的判断，将页面分为四类：</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>(A, M)</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>(0, 0)</td>
<td>最近未访问、未修改 → 最优淘汰对象</td>
</tr>
<tr>
<td>2</td>
<td>(0, 1)</td>
<td>最近未访问、但被修改过 → 需写回磁盘，代价较高</td>
</tr>
<tr>
<td>3</td>
<td>(1, 0)</td>
<td>最近被访问过、未修改 → 可能还会被访问，保留</td>
</tr>
<tr>
<td>4</td>
<td>(1, 1)</td>
<td>最近被访问过、且被修改 → 最重要，应保留</td>
</tr>
</tbody></table>
<hr>
<h2 id="📌-淘汰优先级（从高到低）："><a href="#📌-淘汰优先级（从高到低）：" class="headerlink" title="📌 淘汰优先级（从高到低）："></a>📌 淘汰优先级（从高到低）：</h2><blockquote>
<p><strong>按 (A, M) 组合的“价值”排序，越不重要越先淘汰</strong></p>
</blockquote>
<p>标准顺序是：</p>
<ol>
<li><strong>(0, 0)</strong> —— 既没访问也没修改 → 最安全，直接淘汰  </li>
<li><strong>(0, 1)</strong> —— 未访问但修改过 → 需写回，代价大，但比“被访问过的”优先淘汰  </li>
<li><strong>(1, 0)</strong> —— 被访问过但未修改 → 说明可能还会用，尽量保留  </li>
<li><strong>(1, 1)</strong> —— 被访问过且修改过 → 最重要，最后淘汰</li>
</ol>
<p>→ 所以淘汰次序为：<strong>(0,0) → (0,1) → (1,0) → (1,1)</strong></p>
<hr>
<h2 id="✅-对照选项："><a href="#✅-对照选项：" class="headerlink" title="✅ 对照选项："></a>✅ 对照选项：</h2><p>A. (0,0), (0,1), (1,0), (1,1) ✅ 正确<br>B. (0,0), (1,0), (0,1), (1,1) ❌ 错误（(1,0) 不该在 (0,1) 前）<br>C. (0,0), (0,1), (1,1), (1,0) ❌ 错误（(1,1) 不该在 (1,0) 前）<br>D. (0,0), (1,1), (0,1), (1,0) ❌ 错误（(1,1) 是最重要的）</p>
<hr>
<h3 id="🎯-考点总结："><a href="#🎯-考点总结：" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><ul>
<li>改进型 CLOCK 算法通过 (A,M) 四元组分类页面；  </li>
<li>淘汰时优先选择 <strong>A&#x3D;0</strong> 的页（未被访问），再考虑 M 值；  </li>
<li>目标：<strong>减少 I&#x2F;O 开销</strong>（避免淘汰需写回的页）和 <strong>保留活跃页</strong>。</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>A. (0, 0), (0, 1), (1, 0), (1, 1)</strong></p>
<h1 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h1><p>系统为某进程分配了4个页框，该进程已访问的页号序列为2，0，2，9，3，4，2，8，<br>2，4，8，4，5。若进程要访问的下一页的页号为7，依据LRU算法，应淘汰页的页号是</p>
<hr>
<p>。(2015)<br>A．2 B．3 C．4 D．8</p>
<h2 id="解析-2"><a href="#解析-2" class="headerlink" title="解析"></a>解析</h2><p>我们来分析这道经典的 <strong>LRU（Least Recently Used）页面置换算法</strong> 题目。</p>
<hr>
<h2 id="📊-题目条件：-1"><a href="#📊-题目条件：-1" class="headerlink" title="📊 题目条件："></a>📊 题目条件：</h2><ul>
<li>进程被分配 <strong>4 个页框</strong>（物理内存帧）  </li>
<li>已访问的页号序列：<code>2, 0, 2, 9, 3, 4, 2, 8, 2, 4, 8, 4, 5</code>  </li>
<li>下一个要访问的页是：<strong>7</strong> → 此时内存已满，需淘汰一页（LRU 策略）<br>→ 问：<strong>应淘汰哪个页？</strong></li>
</ul>
<hr>
<h2 id="✅-解题思路：-1"><a href="#✅-解题思路：-1" class="headerlink" title="✅ 解题思路："></a>✅ 解题思路：</h2><p>我们需要根据 <strong>LRU 算法</strong>，找出当前内存中<strong>最近最少使用</strong>的页。</p>
<p>LRU 的核心思想：<strong>淘汰最近最久未被访问的页</strong>。</p>
<p>我们从头开始模拟访问过程，记录每个时刻内存中的页，并标记其“最后访问时间”或“访问顺序”。</p>
<hr>
<h3 id="🧩-模拟过程（维护一个“访问历史”列表，越靠左越久未用）"><a href="#🧩-模拟过程（维护一个“访问历史”列表，越靠左越久未用）" class="headerlink" title="🧩 模拟过程（维护一个“访问历史”列表，越靠左越久未用）"></a>🧩 模拟过程（维护一个“访问历史”列表，越靠左越久未用）</h3><p>初始：内存空</p>
<hr>
<h4 id="访问-2"><a href="#访问-2" class="headerlink" title="访问 2"></a>访问 2</h4><ul>
<li>内存：[2] （未满）</li>
</ul>
<h4 id="访问-0"><a href="#访问-0" class="headerlink" title="访问 0"></a>访问 0</h4><ul>
<li>内存：[2, 0]</li>
</ul>
<h4 id="访问-2-1"><a href="#访问-2-1" class="headerlink" title="访问 2"></a>访问 2</h4><ul>
<li>命中 → 更新顺序：将 2 移到最右 → [0, 2]</li>
</ul>
<h4 id="访问-9"><a href="#访问-9" class="headerlink" title="访问 9"></a>访问 9</h4><ul>
<li>缺页 → 加入 9 → [0, 2, 9]</li>
</ul>
<h4 id="访问-3"><a href="#访问-3" class="headerlink" title="访问 3"></a>访问 3</h4><ul>
<li>缺页 → 加入 3 → [0, 2, 9, 3] ← 已满！</li>
</ul>
<h4 id="访问-4"><a href="#访问-4" class="headerlink" title="访问 4"></a>访问 4</h4><ul>
<li>缺页 → 需淘汰 LRU（最左：0）→ 淘汰 0 → 加入 4 → [2, 9, 3, 4]</li>
</ul>
<h4 id="访问-2-2"><a href="#访问-2-2" class="headerlink" title="访问 2"></a>访问 2</h4><ul>
<li>命中 → 将 2 移到最右 → [9, 3, 4, 2]</li>
</ul>
<h4 id="访问-8"><a href="#访问-8" class="headerlink" title="访问 8"></a>访问 8</h4><ul>
<li>缺页 → 淘汰 LRU（最左：9）→ 加入 8 → [3, 4, 2, 8]</li>
</ul>
<h4 id="访问-2-3"><a href="#访问-2-3" class="headerlink" title="访问 2"></a>访问 2</h4><ul>
<li>命中 → 将 2 移到最右 → [3, 4, 8, 2]</li>
</ul>
<h4 id="访问-4-1"><a href="#访问-4-1" class="headerlink" title="访问 4"></a>访问 4</h4><ul>
<li>命中 → 将 4 移到最右 → [3, 8, 2, 4]</li>
</ul>
<h4 id="访问-8-1"><a href="#访问-8-1" class="headerlink" title="访问 8"></a>访问 8</h4><ul>
<li>命中 → 将 8 移到最右 → [3, 2, 4, 8]</li>
</ul>
<h4 id="访问-4-2"><a href="#访问-4-2" class="headerlink" title="访问 4"></a>访问 4</h4><ul>
<li>命中 → 将 4 移到最右 → [3, 2, 8, 4]</li>
</ul>
<h4 id="访问-5"><a href="#访问-5" class="headerlink" title="访问 5"></a>访问 5</h4><ul>
<li>缺页 → 淘汰 LRU（最左：3）→ 加入 5 → [2, 8, 4, 5]</li>
</ul>
<hr>
<h3 id="✅-当前内存状态（在访问-5-后）："><a href="#✅-当前内存状态（在访问-5-后）：" class="headerlink" title="✅ 当前内存状态（在访问 5 后）："></a>✅ 当前内存状态（在访问 5 后）：</h3><p>内存中的页：<strong>2, 8, 4, 5</strong></p>
<p>访问顺序（从左到右：最近最少使用 → 最近使用）：</p>
<ul>
<li>最左：2（上次访问较早）  </li>
<li>然后：8  </li>
<li>然后：4  </li>
<li>最右：5（最新访问）</li>
</ul>
<blockquote>
<p>注意：虽然 2 在序列中出现多次，但最后一次访问是在访问 8 之前，之后没有再访问，所以它现在是“最近最少使用”的。</p>
</blockquote>
<hr>
<h3 id="🔍-下一步：访问-7"><a href="#🔍-下一步：访问-7" class="headerlink" title="🔍 下一步：访问 7"></a>🔍 下一步：访问 7</h3><ul>
<li>7 不在内存 → 缺页 → 需淘汰一页  </li>
<li>根据 LRU，淘汰 <strong>最左边的页</strong> → 即 <strong>2</strong></li>
</ul>
<hr>
<h2 id="✅-正确答案：A-2"><a href="#✅-正确答案：A-2" class="headerlink" title="✅ 正确答案：A. 2"></a>✅ 正确答案：<strong>A. 2</strong></h2><hr>
<h3 id="🎯-关键点总结："><a href="#🎯-关键点总结：" class="headerlink" title="🎯 关键点总结："></a>🎯 关键点总结：</h3><ul>
<li>LRU 维护的是“访问时间顺序”，不是“访问频率”；  </li>
<li>“最近最少使用” &#x3D; “在当前时刻，距离上次访问时间最长的页”；  </li>
<li>本题中，虽然 2 出现频繁，但最后一次访问是在访问 8 之前，之后没有更新，因此被淘汰。</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>A. 2</strong></p>
<h1 id="题目-3"><a href="#题目-3" class="headerlink" title="题目"></a>题目</h1><p>.在分段存储管理系统中，用共享段表描述所有被共享的段。若进程P1和P2 共享段S，下列<br>叙述中，错误的是</p>
<hr>
<p>。(2019)<br>A．在物理内存中仅保存一份段S 的内容<br>B．段S 在P1和P2中应该具有相同的段号<br>C．P1 和P2 共享段S 在共享段表中的段表项<br>D．P1和P2都不再使用段S 时才回收段S 所占的内存空间</p>
<h2 id="解析-3"><a href="#解析-3" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：B. 段 S 在 P1 和 P2 中应该具有相同的段号</strong></p>
<hr>
<h3 id="✅-解析："><a href="#✅-解析：" class="headerlink" title="✅ 解析："></a>✅ 解析：</h3><p>本题考查 <strong>分段存储系统中共享段的实现机制</strong>，与 2019 年第 7 题完全相同（重复题）。</p>
<p>我们逐项分析：</p>
<hr>
<h4 id="A-在物理内存中仅保存一份段-S-的内容"><a href="#A-在物理内存中仅保存一份段-S-的内容" class="headerlink" title="A. 在物理内存中仅保存一份段 S 的内容"></a>A. 在物理内存中仅保存一份段 S 的内容</h4><p>✅ 正确。  </p>
<ul>
<li>共享段的核心目的就是节省内存 —— 多个进程访问同一段时，<strong>物理内存只保留一份副本</strong>；  </li>
<li>通过各自的段表项指向同一个物理地址实现共享。</li>
</ul>
<hr>
<h4 id="B-段-S-在-P1-和-P2-中应该具有相同的段号"><a href="#B-段-S-在-P1-和-P2-中应该具有相同的段号" class="headerlink" title="B. 段 S 在 P1 和 P2 中应该具有相同的段号"></a>B. 段 S 在 P1 和 P2 中应该具有相同的段号</h4><p>❌ <strong>错误（本题答案）</strong>  </p>
<ul>
<li><strong>段号是进程私有的</strong>！每个进程有自己的段表，段号是该进程内部的索引；  </li>
<li>P1 可以把共享段 S 放在段号 3，P2 可以放在段号 5 —— 只要它们的段表项都指向共享段表中的同一个段描述符即可；  </li>
<li><strong>段号无需相同</strong>，只要逻辑上能映射到同一物理段就行。</li>
</ul>
<blockquote>
<p>📌 类比：两个程序都调用 <code>printf</code>，但一个程序中 <code>printf</code> 在段号 2，另一个在段号 4 —— 只要都指向同一个共享代码段，就可正常运行。</p>
</blockquote>
<hr>
<h4 id="C-P1-和-P2-共享段-S-在共享段表中的段表项"><a href="#C-P1-和-P2-共享段-S-在共享段表中的段表项" class="headerlink" title="C. P1 和 P2 共享段 S 在共享段表中的段表项"></a>C. P1 和 P2 共享段 S 在共享段表中的段表项</h4><p>✅ 正确。  </p>
<ul>
<li>系统维护一个<strong>共享段表</strong>，记录所有被共享的段；  </li>
<li>当 P1 和 P2 都共享段 S 时，它们的段表项会指向<strong>共享段表中的同一个条目</strong>（包含物理起始地址、长度、权限等）；<br>→ 实现“多对一”映射。</li>
</ul>
<hr>
<h4 id="D-P1-和-P2-都不再使用段-S-时才回收段-S-所占的内存空间"><a href="#D-P1-和-P2-都不再使用段-S-时才回收段-S-所占的内存空间" class="headerlink" title="D. P1 和 P2 都不再使用段 S 时才回收段 S 所占的内存空间"></a>D. P1 和 P2 都不再使用段 S 时才回收段 S 所占的内存空间</h4><p>✅ 正确。  </p>
<ul>
<li>这是共享资源的典型管理策略：<strong>引用计数（Reference Count）</strong>；  </li>
<li>共享段表中通常有一个“引用计数”字段，每增加一个进程共享，计数 +1；减少一个，计数 -1；  </li>
<li>计数为 0 时，才释放物理内存。</li>
</ul>
<hr>
<h3 id="🎯-考点总结：-1"><a href="#🎯-考点总结：-1" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>选项</th>
<th>是否正确</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>A</td>
<td>✅</td>
<td>共享段节省内存</td>
</tr>
<tr>
<td>B</td>
<td>❌</td>
<td>段号是进程私有，无需一致</td>
</tr>
<tr>
<td>C</td>
<td>✅</td>
<td>共享段表统一管理</td>
</tr>
<tr>
<td>D</td>
<td>✅</td>
<td>引用计数机制</td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>B. 段 S 在 P1 和 P2 中应该具有相同的段号</strong></p>
<h1 id="题目-4"><a href="#题目-4" class="headerlink" title="题目"></a>题目</h1><p>.某进程访问的页b 不在内存中，导致产生缺页异常，改缺页异常处理过程中不一定包含的操<br>作是( ) (2022)<br>A.淘汰内存中的页 B.建立页号与页框号的对应关系<br>C.将页b 从外存读入内存 D.修改页表中页b 对应的存在位</p>
<h2 id="解析-4"><a href="#解析-4" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：A. 淘汰内存中的页</strong></p>
<p>本题考查 <strong>缺页异常处理过程</strong> 中哪些操作是“不一定包含”的。</p>
<hr>
<h2 id="📌-缺页异常处理流程（标准步骤）："><a href="#📌-缺页异常处理流程（标准步骤）：" class="headerlink" title="📌 缺页异常处理流程（标准步骤）："></a>📌 缺页异常处理流程（标准步骤）：</h2><p>当进程访问的页 <code>b</code> 不在内存中时，触发缺页中断，操作系统执行以下操作：</p>
<ol>
<li><p><strong>检查是否有空闲页框</strong>  </p>
<ul>
<li>若有 → 直接分配，无需淘汰；  </li>
<li>若无 → 执行页面置换算法，<strong>淘汰一个页</strong>（如 LRU、Clock 等）；</li>
</ul>
</li>
<li><p><strong>将页 b 从外存读入内存</strong>（磁盘 I&#x2F;O）  </p>
</li>
<li><p><strong>建立页号与页框号的对应关系</strong>（更新页表）  </p>
</li>
<li><p><strong>修改页表中页 b 对应的存在位为 1</strong>  </p>
</li>
<li><p><strong>恢复进程执行</strong>（重新执行引发缺页的指令）</p>
</li>
</ol>
<hr>
<h2 id="逐项分析："><a href="#逐项分析：" class="headerlink" title="逐项分析："></a>逐项分析：</h2><h4 id="A-淘汰内存中的页"><a href="#A-淘汰内存中的页" class="headerlink" title="A. 淘汰内存中的页"></a>A. 淘汰内存中的页</h4><p>❌ <strong>不一定包含</strong> —— 只有当<strong>内存已满</strong>时才需要淘汰；  </p>
<ul>
<li>如果系统有空闲页框，直接分配即可，无需淘汰；<br>→ 是“可能”发生，非“一定”发生。</li>
</ul>
<h4 id="B-建立页号与页框号的对应关系"><a href="#B-建立页号与页框号的对应关系" class="headerlink" title="B. 建立页号与页框号的对应关系"></a>B. 建立页号与页框号的对应关系</h4><p>✅ <strong>一定包含</strong> —— 这是地址映射的核心，必须更新页表。</p>
<h4 id="C-将页-b-从外存读入内存"><a href="#C-将页-b-从外存读入内存" class="headerlink" title="C. 将页 b 从外存读入内存"></a>C. 将页 b 从外存读入内存</h4><p>✅ <strong>一定包含</strong> —— 因为页 b 不在内存，必须从磁盘加载。</p>
<h4 id="D-修改页表中页-b-对应的存在位"><a href="#D-修改页表中页-b-对应的存在位" class="headerlink" title="D. 修改页表中页 b 对应的存在位"></a>D. 修改页表中页 b 对应的存在位</h4><p>✅ <strong>一定包含</strong> —— 存在位从 0 改为 1，表示该页已在内存。</p>
<hr>
<h3 id="🎯-考点总结：-2"><a href="#🎯-考点总结：-2" class="headerlink" title="🎯 考点总结："></a>🎯 考点总结：</h3><table>
<thead>
<tr>
<th>操作</th>
<th>是否一定包含</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>A. 淘汰内存中的页</td>
<td>❌ 否</td>
<td>仅当无空闲页框时发生</td>
</tr>
<tr>
<td>B. 建立页号与页框号对应</td>
<td>✅ 是</td>
<td>必须更新页表</td>
</tr>
<tr>
<td>C. 从外存读入页 b</td>
<td>✅ 是</td>
<td>缺页的本质是页不在内存</td>
</tr>
<tr>
<td>D. 修改存在位</td>
<td>✅ 是</td>
<td>标记页已驻留</td>
</tr>
</tbody></table>
<hr>
<p>✅ 正确答案：<strong>A. 淘汰内存中的页</strong></p>
<hr>
<p>📌 记忆口诀：  </p>
<blockquote>
<p>“缺页处理四步走：<strong>读入、建表、改位、可选淘汰</strong>”<br>—— 淘汰是“可选”，其余是“必做”。</p>
</blockquote>
<hr>
<p>✅ 最终答案：<strong>A</strong></p>
<h1 id="题目-5"><a href="#题目-5" class="headerlink" title="题目"></a>题目</h1><p>下列因素,影响请求分页系统有效（平均）访存时间的是<br>I、 缺页率<br>II、 磁盘读写时间<br>III、内存访问时间<br>IV 、执行缺页处理程序的 CPU 时间<br>A、II,III B、I,IV C、I,III,IV D、I,II,III,IV</p>
<h2 id="解析-5"><a href="#解析-5" class="headerlink" title="解析"></a>解析</h2><p><strong>答案：D. I, II, III, IV</strong></p>
<p>本题考查 <strong>请求分页系统中，影响“有效（平均）访存时间”（Effective Memory Access Time, EMAT）的因素</strong>。</p>
<p>在请求分页系统中，<strong>一次内存访问可能触发缺页中断</strong>，导致：</p>
<ul>
<li>访问内存 → 若命中 → 时间 &#x3D; 内存访问时间  </li>
<li>若缺页 → 需执行缺页处理程序 → 包括：  <ul>
<li>CPU 处理缺页异常（CPU 时间）  </li>
<li>磁盘读取页面（磁盘读写时间）  </li>
<li>将页面装入内存后重新执行指令</li>
</ul>
</li>
</ul>
<p>因此，<strong>平均访存时间是命中与缺页情况的加权平均</strong>。</p>
<hr>
<h3 id="📊-有效访存时间公式："><a href="#📊-有效访存时间公式：" class="headerlink" title="📊 有效访存时间公式："></a>📊 有效访存时间公式：</h3><p>设：</p>
<ul>
<li>$ p $ &#x3D; 缺页率（Page Fault Rate）  </li>
<li>$ m $ &#x3D; 内存访问时间（Memory Access Time）  </li>
<li>$ d $ &#x3D; 缺页处理时间（包括 CPU 处理 + 磁盘 I&#x2F;O）</li>
</ul>
<p>则：</p>
<p>$$<br>\text{EMAT} &#x3D; (1 - p) \cdot m + p \cdot d<br>$$</p>
<p>而 $ d $ 本身包含：</p>
<ul>
<li>执行缺页处理程序的 CPU 时间  </li>
<li>磁盘读写时间</li>
</ul>
<p>→ 所以，<strong>所有四个因素都直接影响 EMAT</strong>。</p>
<hr>
<h3 id="逐项分析：-1"><a href="#逐项分析：-1" class="headerlink" title="逐项分析："></a>逐项分析：</h3><h4 id="I-缺页率"><a href="#I-缺页率" class="headerlink" title="I. 缺页率"></a>I. 缺页率</h4><p>✅ <strong>影响</strong> —— 是公式中的核心变量 $ p $，缺页率越高，EMAT 越长。</p>
<h4 id="II-磁盘读写时间"><a href="#II-磁盘读写时间" class="headerlink" title="II. 磁盘读写时间"></a>II. 磁盘读写时间</h4><p>✅ <strong>影响</strong> —— 是缺页处理时间 $ d $ 的主要部分，磁盘慢则 $ d $ 大，EMAT 增大。</p>
<h4 id="III-内存访问时间"><a href="#III-内存访问时间" class="headerlink" title="III. 内存访问时间"></a>III. 内存访问时间</h4><p>✅ <strong>影响</strong> —— 是命中时的时间 $ m $，即使缺页率低，若内存访问慢，EMAT 也会高。</p>
<h4 id="IV-执行缺页处理程序的-CPU-时间"><a href="#IV-执行缺页处理程序的-CPU-时间" class="headerlink" title="IV. 执行缺页处理程序的 CPU 时间"></a>IV. 执行缺页处理程序的 CPU 时间</h4><p>✅ <strong>影响</strong> —— 是缺页处理时间 $ d $ 的一部分，CPU 处理开销大，$ d $ 增大 → EMAT 增大。</p>
<hr>
<h3 id="🎯-结论："><a href="#🎯-结论：" class="headerlink" title="🎯 结论："></a>🎯 结论：</h3><p>所有四项均影响请求分页系统的有效访存时间。</p>
<hr>
<p>✅ 正确答案：<strong>D. I, II, III, IV</strong></p>
<hr>
<h3 id="💡-补充说明："><a href="#💡-补充说明：" class="headerlink" title="💡 补充说明："></a>💡 补充说明：</h3><p>这是操作系统性能评估的核心内容。实际系统中，为降低 EMAT，常采用：</p>
<ul>
<li>提高命中率（增加物理内存、优化置换算法）  </li>
<li>使用高速缓存（TLB）减少缺页次数  </li>
<li>使用 SSD 替代 HDD 降低磁盘读写时间  </li>
<li>优化缺页处理程序减少 CPU 开销</li>
</ul>
<hr>
<p>✅ 最终答案：<strong>D</strong></p>
<h1 id="题目-6"><a href="#题目-6" class="headerlink" title="题目"></a>题目</h1><p>给出某进程访问页面的序列：<br>…, 1, 3, 4, 5, 6, 0, 3, 2, 3, 2, ↑t, 0, 4, 0, 3, 2, 9, 2, 1, …<br>工作集窗口大小 &#x3D; 6<br>问：在 t 时刻 的工作集是什么？</p>
<h2 id="解析-6"><a href="#解析-6" class="headerlink" title="解析"></a>解析</h2><p>我们来分析这道关于 <strong>工作集（Working Set）</strong> 的题目。</p>
<hr>
<h3 id="📊-题目条件：-2"><a href="#📊-题目条件：-2" class="headerlink" title="📊 题目条件："></a>📊 题目条件：</h3><ul>
<li>给出某进程访问页面的序列：<br><code>…, 1, 3, 4, 5, 6, 0, 3, 2, 3, 2, ↑t, 0, 4, 0, 3, 2, 9, 2, 1, …</code>  </li>
<li>工作集窗口大小 &#x3D; 6  </li>
<li>问：在 <strong>t 时刻</strong> 的工作集是什么？</li>
</ul>
<hr>
<h3 id="✅-工作集定义："><a href="#✅-工作集定义：" class="headerlink" title="✅ 工作集定义："></a>✅ 工作集定义：</h3><blockquote>
<p><strong>工作集（Working Set）</strong> 是指：<strong>在最近 k 次内存访问中，所访问到的不同页面的集合</strong>。  </p>
<ul>
<li>k 是“窗口大小”（本题为 6）  </li>
<li>从当前时刻 t 往前数 k 个访问记录（包含 t 时刻的访问），取其中出现的所有不同页号组成集合。</li>
</ul>
</blockquote>
<blockquote>
<p>⚠️ 注意：工作集是“最近访问过的页面”，不是“当前内存中的页面”；它反映的是程序的局部性行为。</p>
</blockquote>
<hr>
<h3 id="🔍-解题步骤："><a href="#🔍-解题步骤：" class="headerlink" title="🔍 解题步骤："></a>🔍 解题步骤：</h3><h4 id="Step-1：确定-t-时刻之前的-6-个访问记录"><a href="#Step-1：确定-t-时刻之前的-6-个访问记录" class="headerlink" title="Step 1：确定 t 时刻之前的 6 个访问记录"></a>Step 1：确定 t 时刻之前的 6 个访问记录</h4><p>观察序列：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">..., 1, 3, 4, 5, 6, 0, 3, 2, 3, 2, ↑t, 0, 4, 0, 3, 2, 9, 2, 1, ...</span><br></pre></td></tr></table></figure></div>

<p>t 时刻的箭头指向的是 <strong>第 11 个访问位置（从左往右数）</strong>，即：</p>
<blockquote>
<p>访问序列（标序号）：</p>
</blockquote>
<table>
<thead>
<tr>
<th>序号</th>
<th>页面</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>6</td>
<td>0</td>
</tr>
<tr>
<td>7</td>
<td>3</td>
</tr>
<tr>
<td>8</td>
<td>2</td>
</tr>
<tr>
<td>9</td>
<td>3</td>
</tr>
<tr>
<td>10</td>
<td>2</td>
</tr>
<tr>
<td>11</td>
<td>← t</td>
</tr>
</tbody></table>
<p>→ 所以，在 t 时刻，<strong>往前数 6 个访问</strong> 是指：</p>
<p><strong>序号 6 到 11</strong>（包含 t 时刻的访问）：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">序号 6: 0</span><br><span class="line">序号 7: 3</span><br><span class="line">序号 8: 2</span><br><span class="line">序号 9: 3</span><br><span class="line">序号 10: 2</span><br><span class="line">序号 11: （t 时刻访问的页）？？</span><br></pre></td></tr></table></figure></div>

<p>但注意：<strong>t 时刻的访问尚未发生</strong> —— 箭头在“2”之后，“0”之前，说明：</p>
<blockquote>
<p><strong>t 时刻是刚刚完成第 10 次访问（页面 2）之后</strong>，即将进行第 11 次访问（页面 0）。</p>
</blockquote>
<p>所以，<strong>t 时刻的工作集应基于“最近 6 次已完成的访问”</strong>，即：</p>
<p><strong>从第 5 次到第 10 次访问</strong>（共 6 次）：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">第 5 次：6</span><br><span class="line">第 6 次：0</span><br><span class="line">第 7 次：3</span><br><span class="line">第 8 次：2</span><br><span class="line">第 9 次：3</span><br><span class="line">第 10 次：2</span><br></pre></td></tr></table></figure></div>

<p>→ 这 6 次访问的页面为：<code>6, 0, 3, 2, 3, 2</code></p>
<p>→ 去重后得到工作集：<strong>{6, 0, 3, 2}</strong></p>
<hr>
<h3 id="✅-对照选项：-1"><a href="#✅-对照选项：-1" class="headerlink" title="✅ 对照选项："></a>✅ 对照选项：</h3><p>A. {6, 0, 3, 2} ✅ 正确<br>B. {2, 3, 0, 4} ❌ 包含 4（不在最近6次中）<br>C. {0, 4, 3, 2, 9} ❌ 包含 4、9（超出范围）<br>D. {4, 5, 6, 0, 3, 2} ❌ 包含 4、5（超出范围）</p>
<hr>
<h4 id="🎯-关键点："><a href="#🎯-关键点：" class="headerlink" title="🎯 关键点："></a>🎯 关键点：</h4><ul>
<li>工作集是“最近 k 次访问中出现的页面”，不是“当前内存中的页面”；  </li>
<li>“t 时刻”通常指“刚完成某次访问后”，因此取“前 k 次访问”；  </li>
<li>本题中，t 时刻位于“2”之后、“0”之前，故取第 5~10 次访问。</li>
</ul>
<hr>
<p>✅ 正确答案：<strong>A. {6, 0, 3, 2}</strong></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>多元统计分析</title>
    <url>/zhihaojiang.github.io/2025/12/28/20260116%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B9%A0%E9%A2%98/</url>
    <content><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="数字特征"><a href="#数字特征" class="headerlink" title="数字特征"></a>数字特征</h2><p>已知x的数学期望和协方差矩阵 求y的期望和协方差矩阵</p>
<p><strong>期望</strong></p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>原理</p>

    </div>
    <div class="notel-content">
      <p>∵ y &#x3D; Ax<br>∴ E(y) &#x3D; A E(x)</p>

    </div>
  </div>

<p><strong>协方差</strong></p>

  <div class="note-large default">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <i class="notel-icon fa-solid fa-info"></i><p>原理</p>

    </div>
    <div class="notel-content">
      <p>V(y) &#x3D; A V(x)A’</p>

    </div>
  </div>


<h2 id="欧式距离和马氏距离"><a href="#欧式距离和马氏距离" class="headerlink" title="欧式距离和马氏距离"></a>欧式距离和马氏距离</h2><p><strong>欧式距离</strong></p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>对两个 $p$ 维向量 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^p$，其欧式距离为：<br>$$<br>d_E(\mathbf{x}, \mathbf{y}) &#x3D; |\mathbf{x} - \mathbf{y}|<em>2 &#x3D; \sqrt{(\mathbf{x} - \mathbf{y})^\top (\mathbf{x} - \mathbf{y})} &#x3D; \sqrt{\sum</em>{i&#x3D;1}^p (x_i - y_i)^2}<br>$$</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>几何直观：即高维空间中的“直线距离”  </li>
<li><strong>各变量平等对待</strong>：未考虑变量的量纲（单位）与相关性  </li>
<li>对<strong>尺度敏感</strong>：若某变量单位是“米”，另一是“毫米”，后者将主导距离计算</li>
</ul>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>设<br>$$<br>\mathbf{x} &#x3D; \begin{bmatrix}100\ 1\end{bmatrix},\quad<br>\mathbf{y} &#x3D; \begin{bmatrix}99\ 2\end{bmatrix}<br>\Rightarrow d_E &#x3D; \sqrt{(1)^2 + (-1)^2} &#x3D; \sqrt{2} \approx 1.41<br>$$<br>看似接近，但如果第一维是“身高（cm）”，第二维是“体重（kg）”，实际意义可能并不对等。</p>
<hr>
<p><strong>马氏距离</strong></p>
<h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><p>给定协方差矩阵 $\boldsymbol{\Sigma}$（假设正定，即 $\boldsymbol{\Sigma} &gt; 0$），点 $\mathbf{x}$ 到均值 $\boldsymbol{\mu}$ 的马氏距离为：<br>$$<br>d_M(\mathbf{x}, \boldsymbol{\mu}) &#x3D; \sqrt{(\mathbf{x} - \boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})}<br>$$</p>
<p>两点间马氏距离（以某一总体协方差为基准）：<br>$$<br>d_M(\mathbf{x}, \mathbf{y}) &#x3D; \sqrt{(\mathbf{x} - \mathbf{y})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \mathbf{y})}<br>$$</p>
<blockquote>
<p>实际中，$\boldsymbol{\Sigma}^{-1}$ 常用样本协方差矩阵 $\mathbf{S}^{-1}$ 估计。</p>
</blockquote>
<h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><ul>
<li><strong>标准化 + 去相关</strong>：相当于对数据先做<strong>白化变换（Whitening）</strong>：<br>令 $\mathbf{z} &#x3D; \boldsymbol{\Sigma}^{-1&#x2F;2}(\mathbf{x} - \boldsymbol{\mu})$，则 $\operatorname{Cov}(\mathbf{z}) &#x3D; \mathbf{I}$，此时：<br>$$<br>d_M(\mathbf{x}, \boldsymbol{\mu}) &#x3D; |\mathbf{z}|_2 &#x3D; d_E(\mathbf{z}, \mathbf{0})<br>$$</li>
<li>自动<strong>消除量纲影响</strong>，并<strong>考虑变量间相关性</strong></li>
</ul>
<h3 id="几何解释"><a href="#几何解释" class="headerlink" title="几何解释"></a>几何解释</h3><ul>
<li>等马氏距离的点集构成一个<strong>椭球面</strong>，主轴方向由 $\boldsymbol{\Sigma}$ 的特征向量决定，长短轴由特征值决定  </li>
<li>若 $\boldsymbol{\Sigma} &#x3D; \sigma^2 \mathbf{I}$，则马氏距离退化为欧式距离的缩放：<br>$$<br>d_M &#x3D; \frac{1}{\sigma} d_E<br>$$</li>
</ul>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>设二维正态总体：<br>$$<br>\boldsymbol{\mu} &#x3D; \begin{bmatrix}0\0\end{bmatrix},\quad<br>\boldsymbol{\Sigma} &#x3D; \begin{bmatrix}4 &amp; 3\3 &amp; 5\end{bmatrix}<br>\Rightarrow<br>\boldsymbol{\Sigma}^{-1} &#x3D; \frac{1}{4\cdot5 - 3^2} \begin{bmatrix}5 &amp; -3\-3 &amp; 4\end{bmatrix}<br>&#x3D; \frac{1}{11} \begin{bmatrix}5 &amp; -3\-3 &amp; 4\end{bmatrix}<br>$$</p>
<p>取 $\mathbf{x} &#x3D; \begin{bmatrix}2\1\end{bmatrix}$，则：<br>$$<br>\mathbf{x} - \boldsymbol{\mu} &#x3D; \begin{bmatrix}2\1\end{bmatrix},\quad<br>d_M^2 &#x3D; \begin{bmatrix}2 &amp; 1\end{bmatrix} \cdot \frac{1}{11} \begin{bmatrix}5 &amp; -3\-3 &amp; 4\end{bmatrix} \cdot \begin{bmatrix}2\1\end{bmatrix}<br>&#x3D; \frac{1}{11} (2,1) \begin{bmatrix}10 - 3 \ -6 + 4\end{bmatrix}<br>&#x3D; \frac{1}{11} (2,1) \begin{bmatrix}7 \ -2\end{bmatrix}<br>&#x3D; \frac{14 - 2}{11} &#x3D; \frac{12}{11}<br>$$<br>$$<br>\Rightarrow d_M &#x3D; \sqrt{12&#x2F;11} \approx 1.045<br>$$</p>
<p>若用欧式距离：$d_E &#x3D; \sqrt{4 + 1} &#x3D; \sqrt{5} \approx 2.236$，显然高估了“实际偏离程度”。</p>
<p>我们来逐步解答这个<strong>连续型随机向量的联合密度函数标准化与独立性判断</strong>问题——这是多元统计分析中<strong>概率基础与独立性检验</strong>的经典考点。</p>
<hr>
<h2 id="联合密度"><a href="#联合密度" class="headerlink" title="联合密度"></a>联合密度</h2><p>给定三元函数：<br>$$<br>f(x, y, z) &#x3D; k x y z^2, \quad \text{定义域： } 0 &lt; x &lt; 1,; 0 &lt; y &lt; 1,; 0 &lt; z &lt; 3<br>$$<br>其余区域 $f &#x3D; 0$。</p>
<p>要求：</p>
<ol>
<li>求常数 $k$，使得 $f(x,y,z)$ 为<strong>合法的联合概率密度函数（pdf）</strong>；</li>
<li>判断随机变量 $X, Y, Z$ 是否<strong>相互独立</strong>。</li>
</ol>
<hr>
<h3 id="📌-考点：联合密度的归一化条件"><a href="#📌-考点：联合密度的归一化条件" class="headerlink" title="📌 考点：联合密度的归一化条件"></a>📌 考点：联合密度的归一化条件</h3><p>对任意联合 pdf，必须满足：<br>$$<br>\iiint_{\mathbb{R}^3} f(x,y,z),dx,dy,dz &#x3D; 1<br>$$</p>
<p>由于支撑集为 $(0,1)\times(0,1)\times(0,3)$，仅在此区域积分：</p>
<p>$$<br>\int_0^3 \int_0^1 \int_0^1 k, x y z^2 ; dx, dy, dz &#x3D; 1<br>$$</p>
<p>因被积函数可分离变量，积分可拆：<br>$$<br>k \left( \int_0^1 x,dx \right) \left( \int_0^1 y,dy \right) \left( \int_0^3 z^2,dz \right) &#x3D; 1<br>$$</p>
<p>分别计算：</p>
<ul>
<li>$\int_0^1 x,dx &#x3D; \left[ \frac{x^2}{2} \right]_0^1 &#x3D; \frac{1}{2}$</li>
<li>$\int_0^1 y,dy &#x3D; \frac{1}{2}$</li>
<li>$\int_0^3 z^2,dz &#x3D; \left[ \frac{z^3}{3} \right]_0^3 &#x3D; \frac{27}{3} &#x3D; 9$</li>
</ul>
<p>代入：<br>$$<br>k \cdot \frac{1}{2} \cdot \frac{1}{2} \cdot 9 &#x3D; k \cdot \frac{9}{4} &#x3D; 1<br>\quad \Rightarrow \quad<br>k &#x3D; \frac{4}{9}<br>$$</p>
<p>✅ <strong>答案 1</strong>：<br>$$<br>\boxed{k &#x3D; \dfrac{4}{9}}<br>$$</p>
<hr>
<h3 id="📌-考点：相互独立的充要条件"><a href="#📌-考点：相互独立的充要条件" class="headerlink" title="📌 考点：相互独立的充要条件"></a>📌 考点：<strong>相互独立的充要条件</strong></h3><p>随机变量 $X, Y, Z$ 相互独立<br>$\iff$ 联合密度可分解为边缘密度的乘积：<br>$$<br>f(x,y,z) &#x3D; f_X(x), f_Y(y), f_Z(z), \quad \forall x,y,z<br>$$</p>
<p>我们采用<strong>构造边缘密度 → 验证乘积是否等于联合密度</strong>的方法。</p>
<hr>
<h3 id="①-求边缘密度"><a href="#①-求边缘密度" class="headerlink" title="① 求边缘密度"></a>① 求边缘密度</h3><h4 id="f-X-x-："><a href="#f-X-x-：" class="headerlink" title="$f_X(x)$："></a>$f_X(x)$：</h4><p>$$<br>f_X(x) &#x3D; \int_0^3 \int_0^1 f(x,y,z), dy, dz<br>&#x3D; \int_0^3 \int_0^1 \frac{4}{9} x y z^2 , dy, dz<br>$$</p>
<p>先对 $y$ 积分：<br>$$<br>\int_0^1 y,dy &#x3D; \frac{1}{2} \quad \Rightarrow\quad<br>f_X(x) &#x3D; \frac{4}{9} x \cdot \frac{1}{2} \cdot \int_0^3 z^2,dz<br>&#x3D; \frac{4}{9} x \cdot \frac{1}{2} \cdot 9 &#x3D; 2x<br>$$</p>
<p>✔️ 支撑集：$0 &lt; x &lt; 1$，故<br>$$<br>f_X(x) &#x3D; 2x,\quad 0&lt;x&lt;1<br>$$</p>
<h4 id="f-Y-y-：由对称性（-x-与-y-在-f-中地位相同）"><a href="#f-Y-y-：由对称性（-x-与-y-在-f-中地位相同）" class="headerlink" title="$f_Y(y)$：由对称性（$x$ 与 $y$ 在 $f$ 中地位相同）"></a>$f_Y(y)$：由对称性（$x$ 与 $y$ 在 $f$ 中地位相同）</h4><p>$$<br>f_Y(y) &#x3D; 2y,\quad 0&lt;y&lt;1<br>$$</p>
<h4 id="f-Z-z-："><a href="#f-Z-z-：" class="headerlink" title="$f_Z(z)$："></a>$f_Z(z)$：</h4><p>$$<br>f_Z(z) &#x3D; \int_0^1 \int_0^1 f(x,y,z), dx, dy<br>&#x3D; \frac{4}{9} z^2 \int_0^1 x,dx \int_0^1 y,dy<br>&#x3D; \frac{4}{9} z^2 \cdot \frac{1}{2} \cdot \frac{1}{2}<br>&#x3D; \frac{4}{9} z^2 \cdot \frac{1}{4} &#x3D; \frac{1}{9} z^2<br>$$</p>
<p>✔️ 支撑集：$0 &lt; z &lt; 3$，故<br>$$<br>f_Z(z) &#x3D; \frac{1}{9} z^2,\quad 0&lt;z&lt;3<br>$$</p>
<hr>
<h3 id="②-检验乘积是否等于联合密度"><a href="#②-检验乘积是否等于联合密度" class="headerlink" title="② 检验乘积是否等于联合密度"></a>② 检验乘积是否等于联合密度</h3><p>计算：<br>$$<br>f_X(x) f_Y(y) f_Z(z) &#x3D; (2x)(2y)\left(\frac{1}{9}z^2\right) &#x3D; \frac{4}{9} x y z^2<br>$$</p>
<p>而这正是：<br>$$<br>f(x,y,z) &#x3D; \frac{4}{9} x y z^2<br>$$</p>
<p>✅ 完全一致！</p>
<hr>
<h3 id="✅-答案-2："><a href="#✅-答案-2：" class="headerlink" title="✅ 答案 2："></a>✅ 答案 2：</h3><p>$$<br>\boxed{X,;Y,;Z\ \text{相互独立}}<br>$$</p>
<blockquote>
<p>💡 注意：虽然 $f(x,y,z)$ 是乘积形式 $k \cdot x \cdot y \cdot z^2$，但<strong>不能仅凭形式判断独立</strong>！<br>必须验证：各因子的支撑集是<strong>矩形区域</strong>（即各变量定义域互不依赖），且归一化后边缘积等于联合。本题满足，故独立。</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>多元统计</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析与算法设计--显式欧拉法</title>
    <url>/zhihaojiang.github.io/2026/01/17/20260117/</url>
    <content><![CDATA[<h1 id="显式欧拉法"><a href="#显式欧拉法" class="headerlink" title="显式欧拉法"></a>显式欧拉法</h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>使用<strong>显式欧拉法</strong>求解初值问题：</p>
<p>$$<br>\begin{cases}<br>y’ &#x3D; f(x, y) &#x3D; 3x + 2y, \<br>y(0) &#x3D; 1, \<br>0 \le x \le 0.3, \quad h &#x3D; 0.1<br>\end{cases}<br>$$</p>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><details>
<summary><b>点击查看答案</b></summary>

<h3 id="显式欧拉公式回顾："><a href="#显式欧拉公式回顾：" class="headerlink" title="显式欧拉公式回顾："></a>显式欧拉公式回顾：</h3><p>$$<br>y_{n+1} &#x3D; y_n + h \cdot f(x_n, y_n)<br>$$<br>其中：</p>
<ul>
<li>$ x_n &#x3D; x_0 + n h $</li>
<li>$ y_0 &#x3D; y(x_0) $ 已知</li>
</ul>
<hr>
<h3 id="给定参数："><a href="#给定参数：" class="headerlink" title="给定参数："></a>给定参数：</h3><ul>
<li>$ x_0 &#x3D; 0 $</li>
<li>$ y_0 &#x3D; 1 $</li>
<li>$ h &#x3D; 0.1 $</li>
<li>需计算到 $ x &#x3D; 0.3 $ ⇒ 共 3 步：$ n &#x3D; 0,1,2 $</li>
</ul>
<hr>
<h3 id="逐步计算："><a href="#逐步计算：" class="headerlink" title="逐步计算："></a>逐步计算：</h3><h4 id="第-0-步：-n-0"><a href="#第-0-步：-n-0" class="headerlink" title="第 0 步：$ n &#x3D; 0 $"></a>第 0 步：$ n &#x3D; 0 $</h4><ul>
<li>$ x_0 &#x3D; 0 $</li>
<li>$ y_0 &#x3D; 1 $</li>
<li>$ f(x_0, y_0) &#x3D; 3(0) + 2(1) &#x3D; 2 $</li>
<li>$ y_1 &#x3D; y_0 + h \cdot f(x_0, y_0) &#x3D; 1 + 0.1 \times 2 &#x3D; 1 + 0.2 &#x3D; \boxed{1.2} $</li>
<li>$ x_1 &#x3D; 0.1 $</li>
</ul>
<h4 id="第-1-步：-n-1"><a href="#第-1-步：-n-1" class="headerlink" title="第 1 步：$ n &#x3D; 1 $"></a>第 1 步：$ n &#x3D; 1 $</h4><ul>
<li>$ x_1 &#x3D; 0.1 $</li>
<li>$ y_1 &#x3D; 1.2 $</li>
<li>$ f(x_1, y_1) &#x3D; 3(0.1) + 2(1.2) &#x3D; 0.3 + 2.4 &#x3D; 2.7 $</li>
<li>$ y_2 &#x3D; y_1 + h \cdot f &#x3D; 1.2 + 0.1 \times 2.7 &#x3D; 1.2 + 0.27 &#x3D; \boxed{1.47} $</li>
<li>$ x_2 &#x3D; 0.2 $</li>
</ul>
<h4 id="第-2-步：-n-2"><a href="#第-2-步：-n-2" class="headerlink" title="第 2 步：$ n &#x3D; 2 $"></a>第 2 步：$ n &#x3D; 2 $</h4><ul>
<li>$ x_2 &#x3D; 0.2 $</li>
<li>$ y_2 &#x3D; 1.47 $</li>
<li>$ f(x_2, y_2) &#x3D; 3(0.2) + 2(1.47) &#x3D; 0.6 + 2.94 &#x3D; 3.54 $</li>
<li>$ y_3 &#x3D; y_2 + h \cdot f &#x3D; 1.47 + 0.1 \times 3.54 &#x3D; 1.47 + 0.354 &#x3D; \boxed{1.824} $</li>
<li>$ x_3 &#x3D; 0.3 $</li>
</ul>
<hr>
<h3 id="结果汇总表："><a href="#结果汇总表：" class="headerlink" title="结果汇总表："></a>结果汇总表：</h3><table>
<thead>
<tr>
<th>$ n $</th>
<th>$ x_n $</th>
<th>$ y_n $ (Euler)</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.0</td>
<td>1.000</td>
</tr>
<tr>
<td>1</td>
<td>0.1</td>
<td>1.200</td>
</tr>
<tr>
<td>2</td>
<td>0.2</td>
<td>1.470</td>
</tr>
<tr>
<td>3</td>
<td>0.3</td>
<td><strong>1.824</strong></td>
</tr>
</tbody></table>
<h3 id="考点总结"><a href="#考点总结" class="headerlink" title="考点总结"></a>考点总结</h3><table>
<thead>
<tr>
<th>考点</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>显式欧拉公式</strong></td>
<td>$ y_{n+1} &#x3D; y_n + h f(x_n, y_n) $，<strong>单步、显式、一阶精度</strong></td>
</tr>
<tr>
<td><strong>局部截断误差</strong></td>
<td>$ O(h^2) $，<strong>全局误差</strong> $ O(h) $</td>
</tr>
<tr>
<td><strong>稳定性</strong></td>
<td>对刚性方程不稳定；本例 $ \lambda &#x3D; 2 &gt; 0 $，虽非刚性，但误差仍累积</td>
</tr>
<tr>
<td><strong>与隐式欧拉对比</strong></td>
<td>隐式 $ y_{n+1} &#x3D; y_n + h f(x_{n+1}, y_{n+1}) $，需解方程，但更稳定</td>
</tr>
<tr>
<td><strong>改进方法</strong></td>
<td>改进欧拉（Heun）、RK2、RK4 可显著提高精度</td>
</tr>
</tbody></table>
</details>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>算法设计</tag>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析与算法设计--拉格朗日线性插值</title>
    <url>/zhihaojiang.github.io/2026/01/17/20260117%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E4%B8%8E%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1--%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC/</url>
    <content><![CDATA[<h1 id="拉格朗日线性插值"><a href="#拉格朗日线性插值" class="headerlink" title="拉格朗日线性插值"></a>拉格朗日线性插值</h1><h2 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h2><p>当只有两个数据点 $(x_0, y_0)$ 和 $(x_1, y_1)$ 时，拉格朗日插值多项式为一次多项式（直线）：<br>$$<br>P_1(x) &#x3D; y_0 \cdot \frac{x - x_1}{x_0 - x_1} + y_1 \cdot \frac{x - x_0}{x_1 - x_0}<br>$$<br>这等价于两点式直线方程。</p>
<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>已知：</p>
<ul>
<li>$x_0 &#x3D; 100,\ y_0 &#x3D; \sqrt{100} &#x3D; 10$</li>
<li>$x_1 &#x3D; 121,\ y_1 &#x3D; \sqrt{121} &#x3D; 11$</li>
<li>要求：$x &#x3D; 115$ 时的 $y \approx P_1(115)$</li>
</ul>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><details>
<summary><b>点击查看答案</b></summary>
代入公式：

<p>$$<br>P_1(115) &#x3D; 10 \cdot \frac{115 - 121}{100 - 121} + 11 \cdot \frac{115 - 100}{121 - 100}<br>$$</p>
<p>计算各部分：</p>
<ul>
<li>$115 - 121 &#x3D; -6$</li>
<li>$100 - 121 &#x3D; -21$</li>
<li>$115 - 100 &#x3D; 15$</li>
<li>$121 - 100 &#x3D; 21$</li>
</ul>
<p>所以：</p>
<p>$$<br>P_1(115) &#x3D; 10 \cdot \frac{-6}{-21} + 11 \cdot \frac{15}{21}<br>&#x3D; 10 \cdot \frac{6}{21} + 11 \cdot \frac{15}{21}<br>$$</p>
<p>化简分数：</p>
<ul>
<li>$\frac{6}{21} &#x3D; \frac{2}{7}$</li>
<li>$\frac{15}{21} &#x3D; \frac{5}{7}$</li>
</ul>
<p>因此：</p>
<p>$$<br>P_1(115) &#x3D; 10 \cdot \frac{2}{7} + 11 \cdot \frac{5}{7}<br>&#x3D; \frac{20}{7} + \frac{55}{7}<br>&#x3D; \frac{75}{7}<br>\approx 10.7142857<br>$$</p>
<h2 id="与真实值比较"><a href="#与真实值比较" class="headerlink" title="与真实值比较"></a>与真实值比较</h2><p>真实值：<br>$$<br>\sqrt{115} \approx 10.7238053<br>$$</p>
<p>插值结果：<br>$$<br>P_1(115) \approx 10.7143<br>$$</p>
<p><strong>误差</strong> ≈ $10.7238 - 10.7143 &#x3D; 0.0095$，相对误差约 <strong>0.09%</strong>，效果不错！</p>
</details>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>算法设计</tag>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析与算法设计--牛顿插值</title>
    <url>/zhihaojiang.github.io/2026/01/17/20260117%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E4%B8%8E%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1--%E7%89%9B%E9%A1%BF%E6%8F%92%E5%80%BC/</url>
    <content><![CDATA[<h1 id="牛顿插值"><a href="#牛顿插值" class="headerlink" title="牛顿插值"></a>牛顿插值</h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>已知函数 $ f(x) $ 的部分取值如下表：</p>
<table>
<thead>
<tr>
<th>$ x_i $</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>4</th>
</tr>
</thead>
<tbody><tr>
<td>$ f(x_i) $</td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>6</td>
</tr>
</tbody></table>
<ol>
<li>构造<strong>差商表</strong>（一阶、二阶、三阶差商）；  </li>
<li>写出以 $ x_0&#x3D;0 $ 为基点的<strong>三次牛顿插值多项式</strong> $ N_3(x) $；  </li>
<li>用 $ N_3(x) $ 估计 $ f(1.5) $ 的近似值；  </li>
<li>（选做&#x2F;拓展）若已知 $ f(x) &#x3D; \ln(x+1) + x^2 - x + 1 $，求插值余项 $ R_3(1.5) $ 的理论表达式与上界估计（提示：用余项公式）。</li>
</ol>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><details>
<summary><b>点击查看答案</b></summary>
###  一、构造差商表

<p>已知数据点：</p>
<table>
<thead>
<tr>
<th>$ i $</th>
<th>$ x_i $</th>
<th>$ f(x_i) $</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>6</td>
</tr>
</tbody></table>
<p>我们按定义逐阶计算差商（记 $ f[x_i, x_{i+1}, \dots, x_{i+k}] $ 为 $ k $ 阶差商）。</p>
<h3 id="0-阶差商（即函数值）："><a href="#0-阶差商（即函数值）：" class="headerlink" title="0 阶差商（即函数值）："></a>0 阶差商（即函数值）：</h3><p>$$<br>\begin{aligned}<br>f[x_0] &amp;&#x3D; f(0) &#x3D; 1 \<br>f[x_1] &amp;&#x3D; f(1) &#x3D; 3 \<br>f[x_2] &amp;&#x3D; f(2) &#x3D; 2 \<br>f[x_3] &amp;&#x3D; f(4) &#x3D; 6<br>\end{aligned}<br>$$</p>
<h3 id="一阶差商："><a href="#一阶差商：" class="headerlink" title="一阶差商："></a>一阶差商：</h3><p>$$<br>\begin{aligned}<br>f[x_0,x_1] &amp;&#x3D; \frac{f[x_1] - f[x_0]}{x_1 - x_0} &#x3D; \frac{3 - 1}{1 - 0} &#x3D; 2 \<br>f[x_1,x_2] &amp;&#x3D; \frac{2 - 3}{2 - 1} &#x3D; -1 \<br>f[x_2,x_3] &amp;&#x3D; \frac{6 - 2}{4 - 2} &#x3D; \frac{4}{2} &#x3D; 2<br>\end{aligned}<br>$$</p>
<h3 id="二阶差商："><a href="#二阶差商：" class="headerlink" title="二阶差商："></a>二阶差商：</h3><p>$$<br>\begin{aligned}<br>f[x_0,x_1,x_2] &amp;&#x3D; \frac{f[x_1,x_2] - f[x_0,x_1]}{x_2 - x_0} &#x3D; \frac{-1 - 2}{2 - 0} &#x3D; \frac{-3}{2} &#x3D; -1.5 \<br>f[x_1,x_2,x_3] &amp;&#x3D; \frac{f[x_2,x_3] - f[x_1,x_2]}{x_3 - x_1} &#x3D; \frac{2 - (-1)}{4 - 1} &#x3D; \frac{3}{3} &#x3D; 1<br>\end{aligned}<br>$$</p>
<h3 id="三阶差商："><a href="#三阶差商：" class="headerlink" title="三阶差商："></a>三阶差商：</h3><p>$$<br>f[x_0,x_1,x_2,x_3] &#x3D; \frac{f[x_1,x_2,x_3] - f[x_0,x_1,x_2]}{x_3 - x_0} &#x3D; \frac{1 - (-1.5)}{4 - 0} &#x3D; \frac{2.5}{4} &#x3D; \frac{5}{8} &#x3D; 0.625<br>$$</p>
<h3 id="差商表整理如下："><a href="#差商表整理如下：" class="headerlink" title="差商表整理如下："></a>差商表整理如下：</h3><table>
<thead>
<tr>
<th>$ i $</th>
<th>$ x_i $</th>
<th>$ f[x_i] $</th>
<th>$ f[x_i,x_{i+1}] $</th>
<th>$ f[x_i,x_{i+1},x_{i+2}] $</th>
<th>$ f[x_i,x_{i+1},x_{i+2},x_{i+3}] $</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>2</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>3</td>
<td></td>
<td><strong>−1.5</strong></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>−1</strong></td>
<td></td>
<td><strong>0.625</strong></td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>2</td>
<td></td>
<td><strong>1</strong></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>2</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>6</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<blockquote>
<p><strong>考点提醒</strong>：  </p>
<ul>
<li>差商具有<strong>对称性</strong>（与节点顺序无关），但表中通常按<strong>左对齐递推</strong>计算；  </li>
<li>若等距节点，可联系<strong>差分</strong>（forward&#x2F;backward difference），但本题节点不等距（0,1,2,4），<strong>必须用差商</strong>；  </li>
<li>差商是牛顿插值系数的核心来源。</li>
</ul>
</blockquote>
<h3 id="写出三次牛顿插值多项式-N-3-x"><a href="#写出三次牛顿插值多项式-N-3-x" class="headerlink" title="写出三次牛顿插值多项式 $ N_3(x) $"></a>写出三次牛顿插值多项式 $ N_3(x) $</h3><p>牛顿插值公式（以 $ x_0 &#x3D; 0 $ 为起点）为：</p>
<p>$$<br>\begin{aligned}<br>N_3(x) &amp;&#x3D; f[x_0] \<br>&amp;\quad + f[x_0,x_1](x - x_0) \<br>&amp;\quad + f[x_0,x_1,x_2](x - x_0)(x - x_1) \<br>&amp;\quad + f[x_0,x_1,x_2,x_3](x - x_0)(x - x_1)(x - x_2)<br>\end{aligned}<br>$$</p>
<p>代入已算得的差商值：</p>
<p>$$<br>\begin{aligned}<br>N_3(x) &amp;&#x3D; 1 \<br>&amp;\quad + 2(x - 0) \<br>&amp;\quad + (-1.5)(x - 0)(x - 1) \<br>&amp;\quad + 0.625(x - 0)(x - 1)(x - 2)<br>\end{aligned}<br>$$</p>
<p>即：</p>
<p>$$<br>\boxed{<br>N_3(x) &#x3D; 1 + 2x - \frac{3}{2}x(x-1) + \frac{5}{8}x(x-1)(x-2)<br>}<br>$$</p>
<p>（保留分数形式更精确，避免浮点误差）</p>
<blockquote>
<p> <strong>考点提醒</strong>：  </p>
<ul>
<li>牛顿插值是<strong>增量式构造</strong>，比拉格朗日插值更易增加新节点（只需加一项）；  </li>
<li>多项式<strong>无需展开</strong>即可用于计算（推荐用嵌套&#x2F;Horner 形式，见下文）；  </li>
<li>注意：插值多项式唯一，牛顿与拉格朗日形式等价，但牛顿形式<strong>计算效率更高</strong>，尤其适合变节点情形。</li>
</ul>
</blockquote>
</details>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>算法设计</tag>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析与算法设计--改进欧拉法</title>
    <url>/zhihaojiang.github.io/2026/01/17/20260117%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E4%B8%8E%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1--%E6%94%B9%E8%BF%9B%E6%AC%A7%E6%8B%89%E6%B3%95/</url>
    <content><![CDATA[<h1 id="改进欧拉法"><a href="#改进欧拉法" class="headerlink" title="改进欧拉法"></a>改进欧拉法</h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>用 <strong>改进欧拉法</strong>求解初值问题：</p>
<p>$$<br>\begin{cases}<br>y’ &#x3D; f(x, y) &#x3D; 3x + 2y \<br>y(0) &#x3D; 1 \<br>0 \le x \le 0.3,\quad h &#x3D; 0.1<br>\end{cases}<br>$$</p>
<hr>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><details>
<summary><b>点击查看答案</b></summary>

<h3 id="改进欧拉法公式"><a href="#改进欧拉法公式" class="headerlink" title="改进欧拉法公式"></a>改进欧拉法公式</h3><p>对每一步 $ n &#x3D; 0,1,2,\dots $：</p>
<ol>
<li><strong>预测（显式欧拉一步）</strong>：<br>$$<br>\tilde{y}_{n+1} &#x3D; y_n + h , f(x_n, y_n)<br>$$</li>
<li><strong>校正（梯形公式）</strong>：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, \tilde{y}_{n+1}) \right]<br>$$</li>
</ol>
<blockquote>
<p>本质：用区间端点的斜率平均值代替单点斜率，提高精度。<br>精度：<strong>二阶方法</strong>，全局误差 $ O(h^2) $，比显式欧拉更准。</p>
</blockquote>
<hr>
<h3 id="已知："><a href="#已知：" class="headerlink" title="已知："></a>已知：</h3><ul>
<li>$ x_0 &#x3D; 0 $, $ y_0 &#x3D; 1 $</li>
<li>$ h &#x3D; 0.1 $</li>
<li>$ f(x, y) &#x3D; 3x + 2y $</li>
</ul>
<p>我们计算到 $ x &#x3D; 0.3 $，共 3 步。</p>
<hr>
<h2 id="逐步计算："><a href="#逐步计算：" class="headerlink" title="逐步计算："></a>逐步计算：</h2><hr>
<h3 id="▶-第-0-步：-n-0-x-0-0-y-0-1"><a href="#▶-第-0-步：-n-0-x-0-0-y-0-1" class="headerlink" title="▶ 第 0 步：$ n &#x3D; 0 $, $ x_0 &#x3D; 0 $, $ y_0 &#x3D; 1 $"></a>▶ 第 0 步：$ n &#x3D; 0 $, $ x_0 &#x3D; 0 $, $ y_0 &#x3D; 1 $</h3><ol>
<li><p><strong>预测</strong>：<br>$$<br>\tilde{y}_1 &#x3D; y_0 + h f(x_0, y_0) &#x3D; 1 + 0.1 \cdot (3\cdot0 + 2\cdot1) &#x3D; 1 + 0.1 \cdot 2 &#x3D; 1.2<br>$$</p>
</li>
<li><p><strong>计算校正所需斜率</strong>：</p>
<ul>
<li>$ f(x_0, y_0) &#x3D; 2 $ （已算）</li>
<li>$ f(x_1, \tilde{y}_1) &#x3D; f(0.1, 1.2) &#x3D; 3(0.1) + 2(1.2) &#x3D; 0.3 + 2.4 &#x3D; 2.7 $</li>
</ul>
</li>
<li><p><strong>校正</strong>：<br>$$<br>y_1 &#x3D; y_0 + \frac{h}{2} \left[ f(x_0, y_0) + f(x_1, \tilde{y}_1) \right]<br>&#x3D; 1 + \frac{0.1}{2} (2 + 2.7) &#x3D; 1 + 0.05 \times 4.7 &#x3D; 1 + 0.235 &#x3D; \boxed{1.235}<br>$$</p>
</li>
</ol>
<p>→ $ x_1 &#x3D; 0.1 $, $ y_1 &#x3D; 1.235 $</p>
<hr>
<h3 id="▶-第-1-步：-n-1-x-1-0-1-y-1-1-235"><a href="#▶-第-1-步：-n-1-x-1-0-1-y-1-1-235" class="headerlink" title="▶ 第 1 步：$ n &#x3D; 1 $, $ x_1 &#x3D; 0.1 $, $ y_1 &#x3D; 1.235 $"></a>▶ 第 1 步：$ n &#x3D; 1 $, $ x_1 &#x3D; 0.1 $, $ y_1 &#x3D; 1.235 $</h3><ol>
<li><p><strong>预测</strong>：<br>$$<br>\tilde{y}_2 &#x3D; y_1 + h f(x_1, y_1)<br>&#x3D; 1.235 + 0.1 \cdot \big[ 3(0.1) + 2(1.235) \big]<br>&#x3D; 1.235 + 0.1 \cdot (0.3 + 2.47) &#x3D; 1.235 + 0.1 \cdot 2.77 &#x3D; 1.235 + 0.277 &#x3D; 1.512<br>$$</p>
</li>
<li><p><strong>斜率</strong>：</p>
<ul>
<li>$ f(x_1, y_1) &#x3D; 2.77 $ （已算）</li>
<li>$ f(x_2, \tilde{y}_2) &#x3D; f(0.2, 1.512) &#x3D; 3(0.2) + 2(1.512) &#x3D; 0.6 + 3.024 &#x3D; 3.624 $</li>
</ul>
</li>
<li><p><strong>校正</strong>：<br>$$<br>y_2 &#x3D; y_1 + \frac{h}{2} \big[ f(x_1, y_1) + f(x_2, \tilde{y}_2) \big]<br>&#x3D; 1.235 + 0.05 \cdot (2.77 + 3.624) &#x3D; 1.235 + 0.05 \cdot 6.394 &#x3D; 1.235 + 0.3197 &#x3D; \boxed{1.5547}<br>$$</p>
</li>
</ol>
<p>→ $ x_2 &#x3D; 0.2 $, $ y_2 &#x3D; 1.5547 $</p>
<p>（保留4位小数，后续一致）</p>
<hr>
<h3 id="▶-第-2-步：-n-2-x-2-0-2-y-2-1-5547"><a href="#▶-第-2-步：-n-2-x-2-0-2-y-2-1-5547" class="headerlink" title="▶ 第 2 步：$ n &#x3D; 2 $, $ x_2 &#x3D; 0.2 $, $ y_2 &#x3D; 1.5547 $"></a>▶ 第 2 步：$ n &#x3D; 2 $, $ x_2 &#x3D; 0.2 $, $ y_2 &#x3D; 1.5547 $</h3><ol>
<li><p><strong>预测</strong>：<br>$$<br>\tilde{y}_3 &#x3D; y_2 + h f(x_2, y_2)<br>&#x3D; 1.5547 + 0.1 \cdot \big[ 3(0.2) + 2(1.5547) \big]<br>&#x3D; 1.5547 + 0.1 \cdot (0.6 + 3.1094) &#x3D; 1.5547 + 0.1 \cdot 3.7094 &#x3D; 1.5547 + 0.37094 &#x3D; 1.92564<br>$$</p>
</li>
<li><p><strong>斜率</strong>：</p>
<ul>
<li>$ f(x_2, y_2) &#x3D; 3.7094 $</li>
<li>$ f(x_3, \tilde{y}_3) &#x3D; f(0.3, 1.92564) &#x3D; 3(0.3) + 2(1.92564) &#x3D; 0.9 + 3.85128 &#x3D; 4.75128 $</li>
</ul>
</li>
<li><p><strong>校正</strong>：<br>$$<br>y_3 &#x3D; y_2 + \frac{h}{2} \big[ f(x_2, y_2) + f(x_3, \tilde{y}_3) \big]<br>&#x3D; 1.5547 + 0.05 \cdot (3.7094 + 4.75128)<br>&#x3D; 1.5547 + 0.05 \cdot 8.46068 &#x3D; 1.5547 + 0.423034 &#x3D; \boxed{1.977734}<br>$$</p>
</li>
</ol>
<p>→ $ x_3 &#x3D; 0.3 $, $ y_3 \approx 1.9777 $</p>
<p>（四舍五入到6位：1.977734）</p>
<hr>
<h3 id="✅-改进欧拉法结果汇总："><a href="#✅-改进欧拉法结果汇总：" class="headerlink" title="✅ 改进欧拉法结果汇总："></a>✅ 改进欧拉法结果汇总：</h3><table>
<thead>
<tr>
<th>$ n $</th>
<th>$ x_n $</th>
<th>预测 $ \tilde{y}_{n+1} $</th>
<th>校正 $ y_{n+1} $</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.0</td>
<td>1.2000</td>
<td><strong>1.2350</strong></td>
</tr>
<tr>
<td>1</td>
<td>0.1</td>
<td>1.5120</td>
<td><strong>1.5547</strong></td>
</tr>
<tr>
<td>2</td>
<td>0.2</td>
<td>1.9256</td>
<td><strong>1.9777</strong></td>
</tr>
</tbody></table>
<p>最终近似解：<br>$$<br>\boxed{y(0.3) \approx 1.9777}<br>$$</p>
</details>


]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>算法设计</tag>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析与算法设计--高斯列主元消去法</title>
    <url>/zhihaojiang.github.io/2026/01/17/20260117%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E4%B8%8E%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1--%E9%AB%98%E6%96%AF%E5%88%97%E4%B8%BB%E5%85%83%E6%B6%88%E5%8E%BB%E6%B3%95/</url>
    <content><![CDATA[<h1 id="高斯列主元消去法"><a href="#高斯列主元消去法" class="headerlink" title="高斯列主元消去法"></a>高斯列主元消去法</h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>使用 <strong>高斯列主元消去法</strong>求解如下线性方程组：</p>
<p>$$<br>\begin{cases}<br>12x_1 - 3x_2 + 3x_3 &#x3D; 15 \quad \text{(1)}\<br>-18x_1 + 3x_2 - x_3 &#x3D; -15 \quad \text{(2)}\<br>x_1 + x_2 + x_3 &#x3D; 6 \quad \text{(3)}<br>\end{cases}<br>$$</p>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><details>
<summary><b>点击查看答案</b></summary>

<h3 id="写出增广矩阵"><a href="#写出增广矩阵" class="headerlink" title="写出增广矩阵"></a>写出增广矩阵</h3><p>$$<br>\left[<br>\begin{array}{ccc|c}<br>12 &amp; -3 &amp; 3 &amp; 15 \<br>-18 &amp; 3 &amp; -1 &amp; -15 \<br>1 &amp; 1 &amp; 1 &amp; 6<br>\end{array}<br>\right]<br>$$</p>
<h3 id="第1列选主元"><a href="#第1列选主元" class="headerlink" title="第1列选主元"></a>第1列选主元</h3><p>第1列元素绝对值：<br>|12| &#x3D; 12,<br>|−18| &#x3D; <strong>18</strong> ← 最大，<br>|1| &#x3D; 1  </p>
<p><strong>主元为 −18</strong>，位于第2行 → 将第1行与第2行交换：</p>
<p>$$<br>\left[<br>\begin{array}{ccc|c}<br>-18 &amp; 3 &amp; -1 &amp; -15 \quad \text{(R1)}\<br>12 &amp; -3 &amp; 3 &amp; 15 \quad \text{(R2)}\<br>1 &amp; 1 &amp; 1 &amp; 6 \quad \text{(R3)}<br>\end{array}<br>\right]<br>$$</p>
<blockquote>
<p>注：列主元只在当前列下方（含当前行）找最大，不考虑符号，取绝对值最大者。</p>
</blockquote>
<hr>
<h3 id="消去第1列下方元素"><a href="#消去第1列下方元素" class="headerlink" title="消去第1列下方元素"></a>消去第1列下方元素</h3><h4 id="计算乘子："><a href="#计算乘子：" class="headerlink" title="计算乘子："></a>计算乘子：</h4><ul>
<li>$ m_{21} &#x3D; \frac{a_{21}}{a_{11}} &#x3D; \frac{12}{-18} &#x3D; -\frac{2}{3} $</li>
<li>$ m_{31} &#x3D; \frac{1}{-18} &#x3D; -\frac{1}{18} $</li>
</ul>
<h4 id="行变换："><a href="#行变换：" class="headerlink" title="行变换："></a>行变换：</h4><ul>
<li>$ R_2 \leftarrow R_2 - m_{21} R_1 &#x3D; R_2 + \frac{2}{3} R_1 $  </li>
<li>$ R_3 \leftarrow R_3 - m_{31} R_1 &#x3D; R_3 + \frac{1}{18} R_1 $</li>
</ul>
<p>计算新 R₂：<br>$$<br>\begin{aligned}<br>R_2 &amp;: [12,\ -3,\ 3\ |\ 15] \<br>+\frac{2}{3}R_1 &amp;: +\frac{2}{3}[-18,\ 3,\ -1\ |\ -15] &#x3D; [-12,\ 2,\ -\frac{2}{3}\ |\ -10] \<br>\Rightarrow R_2’ &amp;: [0,\ -1,\ \frac{7}{3}\ |\ 5]<br>\end{aligned}<br>$$</p>
<p>计算新 R₃：<br>$$<br>\begin{aligned}<br>R_3 &amp;: [1,\ 1,\ 1\ |\ 6] \<br>+\frac{1}{18}R_1 &amp;: +\frac{1}{18}[-18,\ 3,\ -1\ |\ -15] &#x3D; [-1,\ \frac{1}{6},\ -\frac{1}{18}\ |\ -\frac{5}{6}] \<br>\Rightarrow R_3’ &amp;: [0,\ \frac{7}{6},\ \frac{17}{18}\ |\ \frac{31}{6}]<br>\end{aligned}<br>$$</p>
<p>当前矩阵为：</p>
<p>$$<br>\left[<br>\begin{array}{ccc|c}<br>-18 &amp; 3 &amp; -1 &amp; -15 \<br>0 &amp; -1 &amp; \frac{7}{3} &amp; 5 \<br>0 &amp; \frac{7}{6} &amp; \frac{17}{18} &amp; \frac{31}{6}<br>\end{array}<br>\right]<br>$$</p>
<hr>
<h3 id="第2列选主元"><a href="#第2列选主元" class="headerlink" title="第2列选主元"></a>第2列选主元</h3><p>第2列下方元素（从第2行开始）：</p>
<ul>
<li>$ |a_{22}| &#x3D; |-1| &#x3D; 1 $  </li>
<li>$ |a_{32}| &#x3D; \left|\frac{7}{6}\right| \approx 1.1667 $ ← 更大！</li>
</ul>
<p>→ 主元为 $ \frac{7}{6} $，在第3行 → <strong>交换第2行和第3行</strong></p>
<p>$$<br>\left[<br>\begin{array}{ccc|c}<br>-18 &amp; 3 &amp; -1 &amp; -15 \quad \text{(R1)}\<br>0 &amp; \frac{7}{6} &amp; \frac{17}{18} &amp; \frac{31}{6} \quad \text{(R2)}\<br>0 &amp; -1 &amp; \frac{7}{3} &amp; 5 \quad \text{(R3)}<br>\end{array}<br>\right]<br>$$</p>
<hr>
<h3 id="消去第2列下方元素"><a href="#消去第2列下方元素" class="headerlink" title="消去第2列下方元素"></a>消去第2列下方元素</h3><p>计算乘子：<br>$$<br>m_{32} &#x3D; \frac{a_{32}}{a_{22}} &#x3D; \frac{-1}{7&#x2F;6} &#x3D; -\frac{6}{7}<br>$$</p>
<p>行变换：<br>$$<br>R_3 \leftarrow R_3 - m_{32} R_2 &#x3D; R_3 + \frac{6}{7} R_2<br>$$</p>
<p>先算 $ \frac{6}{7} R_2 $:<br>$$<br>\frac{6}{7} \cdot \left[0,\ \frac{7}{6},\ \frac{17}{18},\ \frac{31}{6}\right]<br>&#x3D; \left[0,\ 1,\ \frac{6}{7} \cdot \frac{17}{18},\ \frac{6}{7} \cdot \frac{31}{6} \right]<br>&#x3D; \left[0,\ 1,\ \frac{102}{126} &#x3D; \frac{17}{21},\ \frac{31}{7} \right]<br>$$</p>
<p>加到 R₃ 上：</p>
<p>R₃ 原为：$ [0,\ -1,\ \frac{7}{3},\ 5] $</p>
<p>$$<br>\begin{aligned}<br>\text{新 } R_3 &amp;: [0,\ -1+1,\ \frac{7}{3} + \frac{17}{21},\ 5 + \frac{31}{7}] \<br>&amp;&#x3D; [0,\ 0,\ \frac{49}{21} + \frac{17}{21},\ \frac{35}{7} + \frac{31}{7}] \<br>&amp;&#x3D; [0,\ 0,\ \frac{66}{21} &#x3D; \frac{22}{7},\ \frac{66}{7}]<br>\end{aligned}<br>$$</p>
<p>得到上三角矩阵：</p>
<p>$$<br>\left[<br>\begin{array}{ccc|c}<br>-18 &amp; 3 &amp; -1 &amp; -15 \<br>0 &amp; \frac{7}{6} &amp; \frac{17}{18} &amp; \frac{31}{6} \<br>0 &amp; 0 &amp; \frac{22}{7} &amp; \frac{66}{7}<br>\end{array}<br>\right]<br>$$</p>
<h3 id="回代求解"><a href="#回代求解" class="headerlink" title="回代求解"></a>回代求解</h3><p>从最后一行开始：</p>
<h4 id="第3行："><a href="#第3行：" class="headerlink" title="第3行："></a>第3行：</h4><p>$$<br>\frac{22}{7} x_3 &#x3D; \frac{66}{7} \Rightarrow x_3 &#x3D; \frac{66&#x2F;7}{22&#x2F;7} &#x3D; \frac{66}{22} &#x3D; 3<br>$$</p>
<h4 id="第2行："><a href="#第2行：" class="headerlink" title="第2行："></a>第2行：</h4><p>$$<br>\frac{7}{6} x_2 + \frac{17}{18} x_3 &#x3D; \frac{31}{6}<br>\Rightarrow \frac{7}{6} x_2 + \frac{17}{18} \cdot 3 &#x3D; \frac{31}{6}<br>\Rightarrow \frac{7}{6} x_2 + \frac{51}{18} &#x3D; \frac{31}{6}<br>$$</p>
<p>化简：$ \frac{51}{18} &#x3D; \frac{17}{6} $，右边 $ \frac{31}{6} $</p>
<p>$$<br>\frac{7}{6} x_2 &#x3D; \frac{31}{6} - \frac{17}{6} &#x3D; \frac{14}{6} &#x3D; \frac{7}{3}<br>\Rightarrow x_2 &#x3D; \frac{7}{3} \cdot \frac{6}{7} &#x3D; 2<br>$$</p>
<h4 id="第1行："><a href="#第1行：" class="headerlink" title="第1行："></a>第1行：</h4><p>$$<br>-18 x_1 + 3 x_2 - x_3 &#x3D; -15<br>\Rightarrow -18 x_1 + 3 \cdot 2 - 3 &#x3D; -15<br>\Rightarrow -18 x_1 + 6 - 3 &#x3D; -15<br>\Rightarrow -18 x_1 + 3 &#x3D; -15<br>\Rightarrow -18 x_1 &#x3D; -18<br>\Rightarrow x_1 &#x3D; 1<br>$$</p>
<h3 id="最终解："><a href="#最终解：" class="headerlink" title="最终解："></a>最终解：</h3><p>$$<br>\boxed{<br>x_1 &#x3D; 1,\quad x_2 &#x3D; 2,\quad x_3 &#x3D; 3<br>}<br>$$</p>
<h3 id="验算（代入原方程）："><a href="#验算（代入原方程）：" class="headerlink" title="验算（代入原方程）："></a>验算（代入原方程）：</h3><ol>
<li>$ 12(1) - 3(2) + 3(3) &#x3D; 12 - 6 + 9 &#x3D; 15 $   </li>
<li>$ -18(1) + 3(2) - 1(3) &#x3D; -18 + 6 - 3 &#x3D; -15 $   </li>
<li>$ 1 + 2 + 3 &#x3D; 6 $</li>
</ol>
<hr>
<h3 id="考点总结（高斯列主元消去法）"><a href="#考点总结（高斯列主元消去法）" class="headerlink" title="考点总结（高斯列主元消去法）"></a>考点总结（高斯列主元消去法）</h3><table>
<thead>
<tr>
<th>考点</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>列主元选取</strong></td>
<td>每步在当前列（从对角元开始往下）选<strong>绝对值最大</strong>元素所在行，与当前行交换，避免小主元导致的数值不稳定</td>
</tr>
<tr>
<td><strong>乘子计算</strong></td>
<td>$ m_{ij} &#x3D; a_{ij}^{(k)} &#x2F; a_{kk}^{(k)} $，用于消元</td>
</tr>
<tr>
<td><strong>行变换</strong></td>
<td>$ R_i \leftarrow R_i - m_{ij} R_k $，仅修改下方行</td>
</tr>
<tr>
<td><strong>上三角回代</strong></td>
<td>从最后一行向上代入，注意分数运算或用小数保留精度</td>
</tr>
<tr>
<td><strong>复杂度</strong></td>
<td>$ O(n^3) $，适用于中小规模稠密系统</td>
</tr>
<tr>
<td><strong>与全主元区别</strong></td>
<td>全主元在右下子矩阵中找最大元（行列都可交换），更稳定但开销大；<strong>列主元更常用</strong></td>
</tr>
</tbody></table>
</details>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
        <tag>算法设计</tag>
        <tag>数值分析</tag>
      </tags>
  </entry>
</search>
